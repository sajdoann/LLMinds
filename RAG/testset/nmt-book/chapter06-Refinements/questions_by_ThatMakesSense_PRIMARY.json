[
    "What is checkpoint ensemble?",
    "Why does ensemble decoding work?",
    "What is checkpoint ensembling?",
    "How do you combine scores from left-to-right and right-to-left systems in reranking?",
    "Why do right-to-left systems produce different output order?",
    "What method is used to create an inventory of subword units and legitimate words?",
    "What is Byte Pair Encoding?",
    "How does the attention mechanism work in neural machine translation models for copying source words?",
    "What is the purpose of using traditional statistical machine translation word and phrase translation models to filter the target vocabulary?",
    "What is the main idea of using back translation to improve neural translation models with monolingual data?",
    "How much synthetic parallel data should be used in relation to the amount of existing true parallel data?",
    "What is the recommended method for training a combined model with a language model and a translation model?",
    "What is the concern with using a large neural language model in conjunction with a translation model?",
    "How should the weight of the translation model and the language model be balanced?",
    "What is the goal of using round-trip training in machine translation?",
    "What are the two objectives for model training in the round-trip scenario?",
    "What is the purpose of scaling updates by the language model cost LM . e. . and the forward translation cost MT . for each of the translations e. . in the n-best list?",
    "What is dual learning setup?",
    "What is the purpose of using monolingual data in machine translation?",
    "What type of neural network architecture is used in the decoder?",
    "What is the purpose of the attention mechanism in the encoder?",
    "What is the condition for the hidden state in a deep recurrent neural network?",
    "What is the alternative idea for alternating recurrent neural networks?",
    "What is the main benefit of residual connections in deep neural networks?",
    "Why is deep architecture typically exploited after a basic functioning model has been acquired?",
    "What is the purpose of using pre-computed word alignments in neural machine translation models?",
    "How can pre-computed word alignments be used in the training process of neural machine translation models?",
    "What is the advantage of using pre-computed word alignments in training neural machine translation models?",
    "What is cross entropy cost CE?",
    "Why do some input words not receive enough attention during translation?",
    "What is meant by 'over-generation' in the context of coverage?",
    "What is the common practice in traditional statistical machine translation for giving proper weight to different scoring functions?",
    "What is the challenge in neural machine translation regarding giving proper weight to different scoring functions?",
    "How are coverage tracking and training objective integrated in neural machine translation?",
    "What is the fertility component in neural machine translation models?",
    "What is the engineering approach to improving neural machine translation models?",
    "What problem does adding coverage tracking to the training objective in neural machine translation pose?",
    "What are the main differences between an engineering approach and a generic machine learning technique for improving translation systems?",
    "What are some potential adjustments needed to improve neural machine translation systems?",
    "What is the main argument in favor of deep learning for neural machine translation systems?",
    "What is the main challenge in machine translation systems when it comes to adapting to a chosen use case?",
    "What is domain adaptation, and what are its challenges?",
    "What are some methods for domain adaptation in machine translation?",
    "What is the most popular method for domain adaptation in neural machine translation?",
    "Why might it be beneficial to specialize a model to in-domain data?",
    "What are some potential issues with subsampling in-domain data from large collections?",
    "What are some potential benefits of using ensemble decoding for domain adaptation?",
    "Why might it be necessary to choose weights for each model in ensemble decoding?",
    "What is the purpose of subsampling in-domain data from large collections?",
    "Why are traditional statistical machine translation and neural translation methods different?",
    "What are some ways to use subsampled data in multiple domain settings?",
    "What is the approach for neural models when dealing with domain mismatch between training and test data?",
    "Why is it recommended to mix in-domain and out-of-domain data during adaptation?",
    "What is the main goal of using domain adaptation for neural machine translation?",
    "Why is it recommended to mix in-domain and out-of-domain data during the adaptation phase?",
    "What type of linguistic annotation would add value to neural machine translation models?",
    "What is the benefit of adding linguistic annotation to the input sentence in neural machine translation models?",
    "What is the purpose of semantic annotation in linguistic annotations?",
    "What is Morphology?",
    "How do we encode the word-level factored representation in a neural machine translation system?",
    "What is the main difference between syntax-based statistical machine translation models and traditional n-gram language models?",
    "What type of networks do the best-performing syntactic parsers use?",
    "What is the challenge in integrating syntactic parsing and machine translation into a unified framework?",
    "What are some approaches to syntactic parsing in machine translation?",
    "Can we train a neural machine translation system that accepts text in any language as input and translates it into any other language?",
    "How is the combined model trained on both data sets?",
    "Why is it advantageous to train a single neural machine translation system on multiple parallel corpora?",
    "What is the purpose of adding a tag to the input sentence during inference?",
    "What is the benefit of sharing components among language-pair-specific models?",
    "Can the same parameter values be used across different models for different language pairs?",
    "What is the goal of training a single neural machine translation model for multiple languages?",
    "Can a single canonical neural translation model learn from multiple languages simultaneously?",
    "How does a shared attention mechanism affect the performance of multi-language input and output models?"
]