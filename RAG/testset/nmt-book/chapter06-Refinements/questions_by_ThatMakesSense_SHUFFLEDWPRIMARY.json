[
    "is checkpoint What ensemble?",
    "does ensemble decoding work? Why",
    "checkpoint is ensembling? What",
    "and How reranking? systems you right-to-left from combine do left-to-right in scores",
    "output different order? produce systems do right-to-left Why",
    "an create and method subword words? inventory used is legitimate What units of to",
    "Pair What is Encoding? Byte",
    "source models in How the neural mechanism translation machine copying for work does words? attention",
    "using is translation statistical machine of translation filter target and purpose phrase the traditional word vocabulary? to the What models",
    "monolingual models with neural What is idea translation data? using to back improve translation of the main",
    "parallel used existing data? true amount data should of be How in parallel to synthetic much relation the",
    "model? with recommended a model translation the combined language a for training What model is a method and",
    "using the is model? translation a language What in large with conjunction model neural concern a with",
    "and balanced? model the model the translation should weight How language the be of",
    "machine round-trip using of What the translation? goal is in training",
    "two round-trip in are objectives What for the model training the scenario?",
    ". of . e. the purpose language in of e. MT updates What for model cost the . is list? the LM the by cost scaling translation n-best . the and each translations forward",
    "learning What setup? is dual",
    "data purpose using is translation? the of monolingual in What machine",
    "What is in used the architecture decoder? of neural type network",
    "mechanism in encoder? the the attention What the of purpose is",
    "network? is in the state a recurrent hidden What condition the neural for deep",
    "neural the idea alternative alternating networks? What is for recurrent",
    "networks? is benefit in main What deep residual neural the connections of",
    "exploited after been a is basic architecture deep has acquired? functioning Why model typically",
    "in What of machine purpose neural using is models? translation the word alignments pre-computed",
    "in How used be training word of neural machine translation can process models? pre-computed the alignments",
    "machine word training translation using the in What advantage is of pre-computed neural alignments models?",
    "What is cost entropy cross CE?",
    "some Why receive words enough during do translation? not attention input",
    "of meant coverage? the is What in context 'over-generation' by",
    "weight giving for the statistical traditional translation to What practice scoring different proper is machine in common functions?",
    "scoring regarding giving functions? proper translation challenge different neural the is to What machine in weight",
    "How neural translation? tracking in integrated are training and objective coverage machine",
    "in is neural component What translation fertility machine the models?",
    "machine approach engineering the translation What to neural improving is models?",
    "in objective neural What tracking adding to machine the does translation problem pose? training coverage",
    "improving technique the learning approach a for generic and engineering between differences translation systems? an are machine What main",
    "neural are potential machine needed improve What some adjustments to systems? translation",
    "in the neural argument of systems? What is translation learning main for deep machine favor",
    "main it challenge to case? to machine What is a systems in adapting use chosen translation when the comes",
    "domain are adaptation, and what What its challenges? is",
    "in What some adaptation translation? domain machine methods are for",
    "in most is method domain for popular neural What machine translation? adaptation the",
    "it beneficial to might model a to data? in-domain Why be specialize",
    "in-domain issues collections? with are potential subsampling What data from large some",
    "potential are using ensemble adaptation? some for of domain benefits What decoding",
    "model might ensemble weights choose necessary decoding? for to be each in Why it",
    "is subsampling of in-domain the What purpose data from collections? large",
    "methods statistical machine neural translation different? and Why are translation traditional",
    "some multiple What data settings? are use to domain in subsampled ways",
    "mismatch when between and with What neural domain training test models data? for is dealing approach the",
    "out-of-domain Why to adaptation? data mix is during recommended it in-domain and",
    "is for neural What machine main of using goal adaptation translation? the domain",
    "out-of-domain recommended it during and Why is data to the adaptation in-domain mix phase?",
    "machine of neural type annotation linguistic to translation would What models? add value",
    "adding input annotation What models? of the to translation sentence linguistic in is the machine neural benefit",
    "is purpose the linguistic annotations? in annotation semantic What of",
    "Morphology? What is",
    "factored a encode neural we word-level machine do system? translation in the How representation",
    "is main between language translation models? What and the difference syntax-based n-gram traditional machine models statistical",
    "syntactic use? What of the networks parsers best-performing do type",
    "and framework? translation machine What unified the syntactic parsing challenge is a integrating into in",
    "syntactic What translation? some to machine parsing in approaches are",
    "into other accepts language? it text neural train input any as and translates Can any language translation that in we a system machine",
    "both trained sets? data is on the combined How model",
    "to it neural machine parallel on corpora? Why multiple train system translation a single is advantageous",
    "to during the input purpose tag a What is the sentence inference? of adding",
    "benefit components of among models? What the is sharing language-pair-specific",
    "for values language used different models across the Can different same parameter be pairs?",
    "neural the training goal multiple model a What machine is single translation for languages? of",
    "from Can single learn translation model a languages multiple neural simultaneously? canonical",
    "a attention performance the affect mechanism shared of does models? and input multi-language output How"
]