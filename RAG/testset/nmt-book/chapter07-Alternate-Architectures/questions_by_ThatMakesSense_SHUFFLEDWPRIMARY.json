[
    "of input neural using the recurrent the networks What on is disadvantage side?",
    "process a the similar building bottom-up, hierarchical of What up sentence to? is representation",
    "the in the decide What decoder the is reverse has on to that process? problem",
    "word do a convolutional and right encode left context? How layers with its",
    "network What used is neural of the type in encoder?",
    "parallel decoder? in How processed of are words in convolutional version the the",
    "What is self-attention?",
    "work? self-attention How does",
    "What is the the self-attention purpose residual in of layer? connections",
    "output is of computation? What attention the added to the",
    "of to the computation? What added the attention is output",
    "deep is used speed layering and to skip up in layers technique What over the model training?",
    "proposed Who refinement wider model layer? each incorporates a of with that the context"
]