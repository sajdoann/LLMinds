[
    "What is the main idea of the text discussed in Section 6.9?",
    "What are the three approaches discussed for handling multiple language pairs?",
    "What is the purpose of sharing components in NMT models?",
    "What are the three components that can be shared among NMT models?",
    "Why is there no need to mark the output language when sharing components among NMT models?",
    "What is the purpose of training the encoder on monolingual input language data in the context of shared components?",
    "What happens when the decoder is trained in isolation with monolingual language model data?",
    "In what paper is explored how well a single canonical neural translation model is able to learn from multiple to multiple languages by simultaneously training on parallel corpora?",
    "How many words are in the title of the document?",
    "What is the main topic of this document?",
    "What are some examples given for the translation of a sentence from the Subtitles corpus?",
    "How does the performance of Neural Machine Translation systems compare to Statistical Machine Translation systems when translated out-of-domain?",
    "What is the purpose of the 'Lookaroundyou.' sentence in this document?",
    "What does the document suggest about the fluent output of Neural Machine Translation systems?",
    "What is the purpose of Figure 8.1 and Figure 8.2 in this document?",
    "What are some current challenges in Neural Machine Translation as discussed in the document?",
    "What is the key contribution of the attention model in Neural Machine Translation?",
    "How does the attention model functionally play the role of word alignment compared to statistical machine translation?",
    "What are some examples of prior work that used the alignments provided by the attention model?",
    "What is the relationship between beam size and model score in neural translation models?",
    "How does decoding work in neural translation models?",
    "What is the purpose of increasing the beam size in traditional statistical machine translation decoding?",
    "What is the effect of normalizing sentence-level model scores by output length on translation quality?",
    "What is the optimal beam size for different language pairs?",
    "What do the studies in the text compare?",
    "In what language directions were the comparisons made in the studies mentioned?",
    "What is one cause of deteriorating quality mentioned in the text?",
    "What is the concept discussed in Section 6.9 of the document?",
    "How can the idea of marking the output language with tokens such as [SPANISH] be applied more widely?",
    "What is meant by sharing components in neural machine translation models?",
    "What is the objective of training the encoder on monolingual input language data in the context of sharing components?",
    "What experiment is Johnson et al. (2016) exploring in their work?",
    "How many words are in this text?",
    "What is the name of the file being processed?",
    "What is the main topic of this document?",
    "What are some examples of sentences and their translations from different corpora using both neural and statistical machine translation systems?",
    "What is the main difference in performance between neural and statistical machine translation systems when they are used out-of-domain?",
    "Provide an example of a sentence from the Subtitles corpus translated by both the neural and statistical machine translation systems",
    "What are some current challenges in Neural Machine Translation as discussed in the document?",
    "How does the attention model in Neural Machine Translation work according to the document?",
    "What is the purpose of comparing the soft alignment matrix with word alignments obtained by fast-align in the document?",
    "What are some examples given in the document of prior work that used alignments provided by the attention model?",
    "What is the significance of Figure 8.5 in the document?",
    "What is the beam size used by UELB for Czech-English translation?",
    "What is the unnormalized BLEU score for English-Czech translation using a beam size of 37?",
    "What is the unnormalized BLEU score for English-Czech translation using a beam size of 37?",
    "What is the unnormalized BLEU score for German-English translation using a beam size of 29?",
    "What is the normalized BLEU score for Romanian-English translation when using a beam size of 26?",
    "What is the minimum beam size used in the experiments?",
    "What is the maximum beam size used in the experiments?",
    "What is the BLEU score for English-Czech translation when using a beam size of 8 and a normalized value of 22.32244?",
    "What is the maximum BLEU score achieved for any language pair in the experiments?",
    "What is the average unnormalized BLEU score for all language pairs when using a beam size of 22?",
    "What is the BLEU score for Romanian-English translation when using a beam size of 25 and a normalized value of 24?",
    "What is the relationship between beam size and model score in neural translation models?",
    "How does decoding work in neural translation models?",
    "What is the effect of increasing the beam size on translation quality?",
    "What is the problem with increasing the beam size, and how can it be alleviated?",
    "What is the purpose of normalizing sentence-level model scores by length?",
    "What are the main causes of deteriorating quality in drops with larger beams?",
    "In which linguistic categories were Bentivogli et al. (2016) studying English-German translations?",
    "What broad aspects did Toral and SÃ¡nchez-Cartagena (2017) compare for neural language directions?"
]