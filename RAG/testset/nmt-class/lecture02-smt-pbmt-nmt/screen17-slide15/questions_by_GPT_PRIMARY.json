[
    "What is the purpose of smoothing in language models, and how does backing off to shorter n-grams address the issue of zero probability for unseen sequences?",
    "How do interpolation and backoff methods differ in combining probabilities from different n-gram models, and under what circumstances might one be preferred over the other?"
]