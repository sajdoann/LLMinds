[
    "How have the development of long short-term memory (LSTM) cells and gated recurrent units (GRUs) advanced the training of deep neural networks?",
    "What role do the reset and update gates play within the architecture of a Gated Recurrent Unit (GRU)?",
    "Why does the GRU architecture use two different nonlinear functions, tanH and sigmoid, in its operations?",
    "How does the process of subword units or byte pair encoding address the challenges of processing large vocabularies in machine translation?",
    "What are the advantages of using subword units like byte pair encoding in neural machine translation systems?"
]