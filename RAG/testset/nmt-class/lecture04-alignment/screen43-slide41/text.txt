 So now what is the IBM Model 1? So the IBM Model 1 is a generative model that covers the first step of the translation, of the word-based translation. And it only relies, the IBM Model 1, only relies on this lexical translation. So formally we have a foreign sentence and we have the foreign sentence of some length and the target English sentence E of some length as well. And we also define the alignment between these source and target words using the alignment function. So if we know the alignment, we define the IBM Model 1 and this is its definition. The probability of the English aligned to the given source French is this. is the product of the lexical probabilities in the alignment. So you know which words in French and English are aligned to each other. You know in your dictionary what is the probability of that pair of words. And you only multiply these probabilities together. So that is the lexical translation. The position of the words is not considered there at all. The positions are only used within the alignment function to like see which words are at which positions. And then there is this normalization constant. If you look at it in the language in the source and target sentences. So in the foreign language, in the source language you have included the null position. That is this one more possible alignment point or target point of the alignment. So for every word and there is le target words you are deciding where you aligned it. So you have lf plus one option to choose from. normalizing this out and you see the word to which it was really aligned and that word gives you the the translation probability so this is the definition of the of the conditional probability of target sentence and alignment given the source sentence text let's