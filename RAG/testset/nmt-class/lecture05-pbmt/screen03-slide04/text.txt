 Let's go to the summary of Phrasebase MT. You have seen this slide before. It just tells us that you start with a parallel corpus, which is word-aligned. So you have correspondences between individual words. These correspondences obviously don't have to be word for word. So there are sometimes multiple words that correspond to one word in the other language. And you extract the translation dictionary, so to say. This differs from the normal translation dictionary for humans because it contains many multi word expressions and also all these words are fully inflected. So you in the dictionary you see the exact forms of words as they appear in the text. And this is the linguistic knowledge which is normally expected to be to be handled by human users of such dictionaries. But Phrasebase MT has encoded all this linguistic knowledge simply into these short phrases. and then equipped with this dataset you can translate new sentences, new input sentences. And there you choose such segmentation of input sentence into these short phrases so that the replacements are well chosen. And you put these replacements together to make the output sentence as fluent as possible. So for example the triagrams should be very likely. So this the overview is that that phrase-based MT reads the whole collection of parallel data. It extracts puzzle pieces, a huge collection of puzzle pieces. And each of these puzzle pieces corresponds to one source phrase and one target phrase. And you use these puzzle pieces to cover the source sentence. You select the subset of them and the ordering of them so that they best, so that the output sentence seems best.