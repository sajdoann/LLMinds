[
    "What is a key difference in how Sub-Bord Text Encoder (STE) and Byte-Pair Encoding (BPE) handle words with empty suffixes in the context of the provided examples?",
    "How did the handling of empty suffixes in Czech differ between SentencePiece and BPE, and what was the outcome in terms of tokenization?",
    "What are the key differences between how Subword Text Encoder (STE) and Byte-Pair Encoding (BPE) handle word tokenization, particularly in languages like Czech with complex morphology, and how does this affect the model's ability to generalize word meanings?"
]