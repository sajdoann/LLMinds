[
    "What can be done using the attention weights in a similar way to the attention in a sequence-to-sequence algorithm to understand where a network is looking?",
    "What information does the network use when producing the next layer representation of a pronoun, according to the trained weights in the head of the layer 5 encoder?",
    "What type of information can be used to identify the antecedent of a pronoun in a sentence, based on the attention weights in a neural network?"
]