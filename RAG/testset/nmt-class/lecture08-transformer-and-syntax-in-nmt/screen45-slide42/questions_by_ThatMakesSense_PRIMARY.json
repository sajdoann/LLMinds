[
    "What approach was retried with CCG tags and applied to both sequence-to-sequence models and modern transformer models?",
    "What type of tagging was used for the output sentences in the modified transformer model?",
    "What effect did the use of a secondary decoder with interleaving have on the output sentences?",
    "What was the purpose of using a single dummy tag in the modified model?",
    "Where was the paper 'Replacing Linguists with Dummies' published?"
]