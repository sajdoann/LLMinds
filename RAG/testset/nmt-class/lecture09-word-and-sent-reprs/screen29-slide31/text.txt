 So I would like to bring to your attention the exact evaluation that was done in that paper. This test set by Tomáš Mikolov had about 8,000 semantic and about 10,000 syntactic or morphosyntactic questions. And the paper mentioned that the accuracy is quite good. It's not perfect, obviously, because it's learning the main and. And the interesting observation was that the work to act learned the space with these properties without knowing anything about the gender of about the existence of gender, in fact, or about the existence of countries. So it reached the accuracy of about 60%, which is an interesting result. But we have looked at the test set in some closer detail and we've realized that the semantic questions are only of three types. So it's only the country and city and country and currency and then the masculine family member going to feminine family member. There was another paper by Vilomov and other colleagues. They test many other relations such as walk, run or dog or poopy or watch sounds. animals make and some converse verbs as well. So there are many, many other relations that could be studied and they are not covered in the test set. And what we focused on was this syntactic or morphosyntactic questions. And there we saw that the questions in the original test set start only from 300 distinct word pairs. And actually per question, it's only 35 different, so the network could exploit this regularity in, in some way, it doesn't accept the letters, but that's what we actually propose to, to consider also the, the letters of the word. And then these regulities would go forward to the beta, data. But for some reason, it would certainly push the zeroes for the x off. And you know, let's say you can say. But the next variable is seen, let's say it's a non- SDKp!! And it would caden up a cow. And it would give you a instruction date, but what do you? OK. An evolution, if it could be a stride, you can do. Wehin. But the solamente, you can, you can pick them up an Beautifulcompangan and you can do. be much easier for the network to benefit from. And such a test set would not illustrate it well. So if you read this paper from the beginning, you will see, okay, they have 8,000 examples or 10,000 examples. That sounds as a reasonably sizable data set. But if you look how this data set was created, it was just by combining the words together and starting from too small seed. So this is a risky evaluation.