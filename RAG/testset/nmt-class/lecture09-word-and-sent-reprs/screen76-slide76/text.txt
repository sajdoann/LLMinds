 So that is ways of multiple ways of evaluating the meaning or the semantics of the sentence representation. How well the sentence representation serves in these semantic processing tasks. And now how do we get these sentence representations. So I've said that we use the the attention sequence to sequence paper. But there is the problem that has doublebed. There is no sentence embedding. What you have in the sequence to sequence with annotation feature is the bidirection encoder and then the attention mechanism. And the attention mechanism and every step of the decoding process will come up with a different vector. So there is no like single vector representation of the input sentence. And you cannot just concatenate these vectors because the sentence has different like varies in length. So you could not use the centeval.