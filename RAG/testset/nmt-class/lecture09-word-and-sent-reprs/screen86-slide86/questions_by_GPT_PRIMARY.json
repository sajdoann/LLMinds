[
    "How do inner attention or compound attention mechanisms enhance the performance of translation models despite their restrictions?",
    "Why might fixing the number of attention points throughout sentence generation still be beneficial in translation models?"
]