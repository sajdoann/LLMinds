[
    "What is the default number of layers in the encoder and decoder of the transformer setup?",
    "How many layers are used when increasing the depth of the network?",
    "What is the total number of parameters for the wide network?",
    "How many GPUs are needed to train the deep network with 1.3 billion parameters?",
    "What is the maximum number of layers used in the largest setup discussed in the paper?",
    "How many heads does the largest setup use?",
    "What is the total number of parameters for the largest setup discussed in the paper?"
]