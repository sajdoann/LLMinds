 Here is some illustrations with pictures. So multi-target and multi-source are interesting for these different reasons. In multi-target focus, you would focus on efficiency. So when you are translating into many different languages at once, because this is a multinational institution and you need to cater for audience who speak very diverse set of languages, you would ideally run just one system and run it like once and it would emit in parallel on GPU all these target languages at once. So that would be beneficial and that's what we are trying. How many target languages can you put into a model so that you don't decrease the performance too much. The multi-source setup is what I already highlighted. Here is an example. I've talked about the morphological information which is available in the additional languages. Here the example is in the lexical domain. So when you are translating the German word Schloss to French, it would be easier if you already had a translation into English and this translation in English would have already disambiguated whether this is a castle or a lock. So the word Schloss is ambiguous. In French you have to make a choice. I don't It's multilingual, you have many languages, but you have only pairs. And this is a dataset which is much easier to obtain than this multiparlallel corpus.