[
    "What are the two main components of each encoder and decoder layer in the transformer setup?",
    "How many sub-layers do the encoder and decoder layers have, and what do these sub-layers consist of?",
    "Question: How is the transformer model applied in multi-language setups, and what are its key components and advantages over recurrent neural networks in this context?"
]