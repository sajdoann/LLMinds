[
    "What is the difference in the number of parameters between the default transformer setup and the deep setup?",
    "What is the number of parameters in the deep transformer network setup that uses 12 layers in the encoder, 12 in the decoder, a doubled feedforward network dimension, and doubled heads?",
    "What is the effect of increasing the depth of the transformer setup from 12 layers to 24 layers, and doubling the size of the feedforward network and the number of heads, on the number of parameters to be trained?"
]