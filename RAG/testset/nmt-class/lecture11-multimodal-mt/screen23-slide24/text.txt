 in a certain way. Here is a summary. So during this lecture I'll be going somewhat back and forth between the practical problems of the deployment and the theoretical considerations and the models under the hood. So right now I'll focus for a little while on the infrastructure. This is the architecture that we have in our project. And there is one central component which we call the mediator. And this mediator and serves as a hub for all the different workers. And these workers are the independent systems developed at the participating universities and institutes. So there are people who work on the speech recognition. There are people who work on the segmentation of the flow of words into sentences. Many of us are working on machine translation engines. There is then the final presentation. And that presentation goes to the web where it is observed or watched by walled the participants. So if we want to subtitle a session, we will start a client of this and the client will gather the sound. It will ship it to the mediator and ask for the complete processing pipeline and the mediator would connect all the different institutes together and it would ship the packets with sound data to the ASR and then with the word candidates and so on. And finally it will receive a confirmation that the whole input has been processed. And this all happens online with partial input. And these partial outputs are also propagated along the pipeline. So the web keeps constantly updating as there is the flow of new words coming in and as these words are translated. So this architecture is resilient to some types of errors, but not to all types of errors.