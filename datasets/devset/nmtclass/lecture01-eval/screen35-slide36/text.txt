Okay, so that was the ranking. Now another style of evaluation. Ideally we would want to check whether the translation is saying the same thing as the source. So how do we operationalize this? How do we ask that question? Like does this sentence say what it should say? So the way to do is to run something which can be labeled blind editing or comprehension test. In this blind editing, you first show only the output and you ask humans to correct it. So here is a sentence. Tell me what it says. Because the sentence will contain many errors. It's from MT output. So first humans somehow guess what was the meaning of the sentence. Maybe it is fluent. If it's fluent, perfect. There is no change needed. We can just ship it. It says what it says. If there is an error, we make a guess, fix the sentence. And then a second person comes