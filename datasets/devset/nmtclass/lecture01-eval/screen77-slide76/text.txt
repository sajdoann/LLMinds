me a better improvement and then also I applied a similar tokenization to the reference and my MT output and that gave me plus 10 points. So obviously this just highlights that I was very young and stupid and I didn't know that the tokenization absolutely has to match, but because I didn't know it I just learned the hard way in that experiment. So the impression was that complicated methods bring more. I trust these. But the most important message was that huge jumps of the absolute BLEU scores are due to just superficial properties, the tokenization and all that. And for this reason, it is absolutely critical that when you are comparing your system with other systems, that you get the outputs, and you look at the numbers, and you run the same processing pipeline on these outputs. You cannot copy numbers from any paper because you don't know what type of tokenization they use and all that.