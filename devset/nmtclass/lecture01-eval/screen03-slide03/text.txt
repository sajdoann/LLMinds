So now for today I'm going to talk about machine translation evaluation and for that we first need to very briefly summarize what is the task of machine translation for us and then we'll go over well maybe two high number of evaluation methods and they are grossly divided into manual evaluation methods where you need humans annotators or assessors and then the automatic evaluation where you implement algorithms and these algorithms somehow estimate the quality of the MT output. And if I have the time at the end I'll also briefly mention empirical confidence bounds on these scores and also the question whether you should evaluate some individual components in the system or whether you should evaluate the system end-to-end.