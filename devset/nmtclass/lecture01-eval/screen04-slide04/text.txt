Okay, so why is measuring of output quality in machine translation important or actually absolutely critical? Why do we put it in the very first lecture? Well, without some metric, without some form of measuring the current quality, you would not be able to track your progress. So there would be no research possible. So empirically you would not know where to go, which system is better. Here is an example from the history. Back then, in 1970s people used or relied primarily on manual judgments. So there was one particular system developed at Euratom. It was a system based system for Russian to English translation, and they gave the same outputs to two groups of people. The first groups of annotators were teachers of language, and they scored the system, and they gave it 1 out of 5 possible points, so like a D minus, that was the worst score ever. They said it's totally useless garbage, it doesn't make any sense, this Russian to English translation. And then the same outputs were scored by people in the field, nuclear physicists, and these nuclear physicists gave it an A plus for 4.5 out of 5 points for the same outputs. And the reason is that suddenly the articles, this was articles on nuclear physics were no longer in Cyrillic, so the nuclear physicists could see the keywords. Maybe the sentence structure was totally wrong, but the keywords were there. So they understood what the formulas were also there, so they could understand the formulas and suddenly the whole article made a lot of sense. For someone who doesn't read Cyrillic, this was simply a lifesaver. So with the same output you can get very different assessment depending on who are you asking. So that's the importance of choosing the right metric and then if you choose the metric that in turn influences where the research goes. So one metric that we will discuss today is called BLEU score and that scores short sequences of words like four words at once and because of the popularity of that metric there was like a positive loopback that the research focused on methods which delivered translation which as piece-wise good. So the phrase-based machine translation, which we'll discuss in the next lecture in a very brief overview and then in some more detail later, that delivers translations perfect in four-word windows, but that can easily forget the verb in the sentence. So the sentence doesn't make any meaning altogether, but piece-wise it is perfect. If another metric was chosen then maybe the focus would be on other methods and like before neural MT came we would have totally different MT systems. So the metrics drive the research. So if you choose your metric right, you arrive at the point where you are happy, where you have the system which does what you want. If you choose a wrong metric, well then you are optimizing towards some