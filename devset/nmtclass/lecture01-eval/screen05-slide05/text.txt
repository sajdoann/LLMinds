So what is our goal? We restrict the task to the following conditions. We have no writer's ambition, so we are not translatologists. We want kind of literal translation as literal as possible and we don't aim to handle any cultural differences or other things that human translators care about. That said, the methods actually do it by themselves. They are trained on data so if the data reveal these cultural differences, then suddenly the system does that as well. Yeah, you have a question? What do you mean by cultural differences? So that's, yeah, an example of these cultural differences, I remember of a story I heard somewhere. The psychologists ran a test on bilingual kids and these bilingual kids were English-Romanian. And in the test, the kids were given, like small kids, they were given a soup. It was known they didn't like. And when they were given the soup by someone who is talking in English to them, they said no thank you. And when they were given the soup in the Romanian context of their bilingual brain, they said no. So that's like a cultural difference. The way of agreeing or disagreeing varies and in the English language or I would say English culture, British culture, you are trying to be polite and that is part of the phrases that the kids learn. So that's something that we would expect for our systems to, like if they were ideal, to obey the culture rules of the setting where they are applied. And the systems are not designed with this in mind, but it comes for free if it's in the data. So that's the cultural differences. And then the expected output quality. So this is the very rough scale, the roughest possible scale, and then we'll refine that in the manual evaluation and automatic evaluation. So the output can be worth reading. If you do not know the language, the source language, the machine translation would be of some use to you. It could be worth editing. So if you are a professional translator, the output will save you a lot of typing. So that's perfect. Notice that here the goal is slightly different. That already like asks for different optimization. Either preserving the core meaning or minimizing the edits necessary to bring it to a perfect output. And then the third stage would be worth publishing so that you could immediately publish that result and have no fear that people will laugh at you. So in general we are aiming at level one or two depending on the language pair and available data. And the level two remains and it will remain risky because the systems cannot step out of the training data, they have read more text than a human can read in a lifetime. So there is a little chance that they could avoid like stupid pitfalls, but still it's uncertain because they don't understand what is the message and who is the intended audience of that message and so on. So it remains risky.