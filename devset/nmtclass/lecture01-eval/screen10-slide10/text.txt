reasonably well. So here is a result from 2018 using this style of evaluation, the direct assessment, and it was switched to source based, not reference based. So because we had the reference like sitting aside, we were able to mix it among the systems. And people, the assessors, were evaluating not only machine translation systems compared to the source, but also the human professional translation. So like standard, normally picked translation agency, and we didn't pay any extra double checks. We paid the normal price that someone from the street would order. It happened that our system, system trained by Martin Popel, was significantly better than the professional translation in this style of evaluation. So that already is suspicious. The significance is indicated by these bars. So the professionals were on par, indistinguishable, in quality from the Edinburgh machine translation system. So that is suspicious.