Okay, so the best setting that we could do in this area is mixing all together. So it's something that Martin Popel is trying and I'm not showing the results because it's not yet published anywhere, but here we are benefiting from showing more systems, so we are showing two or more systems so that people have like and idea what is the average performance there. One of these systems can be also humans. We are showing the source and we are showing the whole document. And the whole document is often too long, so what we do is we just highlight 10 sentences in a row in this document and ask people to score these 10 sentences in a row. So that way the scoring doesn't take too much time. There is the chance to see the whole document. We are getting 10 scores per one row. And we have all the benefits. And actually, we are asking three scores. We are asking adequacy, fluency for each of the sentences and an overall quality. And then maybe one more score for the whole chunk of sentences. So we are getting quite a large number of numbers. So the statistical significance can be achieved reasonably well. But it is very time-consuming. People really have to focus on that. So this is something we cannot do with the Turkers.