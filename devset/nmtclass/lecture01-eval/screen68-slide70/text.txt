detail now. So there is a lot of different automatic evaluation metrics. As I said, there were years and still running, years of competition. How do people like, which metric matches better the human assessments. So many metrics were created. The one that still remains the standard in the field is called BLEU and it is simply checking the number of n-grams that are confirmed by the reference. So here we have the source, ... we have the reference translation .... And we have four MT systems. And if the word produced by the system is not confirmed by the reference no score is given .... If the word alone is scored well then like unigram wise the system is getting a point and up to four-grams. And if a particular sequence of four words is confirmed by the reference, then the system is getting one four-gram. So the first system, which is phrase-based translation, Moses open source machine translation system, in uni-grams it produced nine good ones. So one, two, three, four, five, six, seven, eight and the full stop is the ninth out of ten, ten words in total. So it gets score of 9 out of 10 uni-grams, it gets the score of 7 out of 9 bigrams, 5 out of 8 trigrams, and 4 out of 7 four-grams. And so this is like checking whether the long sentences and short sequences are confirmed by the reference. And then to aggregate these n-gram scores, you just take the geometric mean of those, and then you apply on ... which we will discuss in a second. So there could be some weights in the geometric mean, but the weights are always said uniformly, because for some situations the longer sentences could be potentially more important than the shorter ones, but people don't care much. Yeah, so this is it. And here you see that Moses, which is phrase-based, has produced many long sequences which were in line with the reference whereas PC Translation which was the rule based system well, it said the same thing, but it used different words and it didn't get any four-gram and any trigram. It only scored a few individual words and just two bigrams. You already see the beginning of the problem the BLEU has promoted the use of phrase based systems because they got, they were getting higher BLEU scores, they were getting the four grams correct. In that year I think PC Translator was already losing but still it was not losing by that much as the BLEU score suggests.