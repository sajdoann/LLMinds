Yeah, so one very critical thing is when you're designing any automatic evaluation metric is to avoid cheating or gaming your metric. You want to make sure that there is no simple way to fool your metric into thinking that you're good. So one way in which the BLEU score could be cheated but it is not because it has a mechanism to avoid it is that you could be producing only reliable words so if you are translation into English, it's absolutely certain that there will be the definite article in the sentence. So what if we just produce the definite articles? So if we just produce the the the the as the output. So here we would be like the metric would be very stupid if it would be giving credits to all the copies of the definite article. It counts only those, only as many outputs of the word, as there appear in the reference. So if one of the references uses two definite articles, then up to two will be scored. And the same strategy, this clipped count, is used obviously also for the higher n-grams. Then another strategy in which people could, or the systems could fool the BLEU score, would be producing only the reliable words. So we know that the sentence is, like we know that the definite article is a good thing to put into an english sentence so let's just do the the the full stop. This is three out of three uni-grams confirmed. So this seems like the best possible score if the best score would not look at longer sentences. And obviously it is not a good output. So put in another way, the metrics can be either precision based or recall based. So either you are checking whether all your output is confirmed by the reference, so that's precision based, or you're checking whether you have produced all what the output expects and that's recall based. So, brevity penalty is precision based because it is checking whether all your words or your n-grams were confirmed by the reference. And it doesn't contain, or without the brevity penalty, it would not contain any recall check at all. And it would be easily fooled by making like very high precision and low recall outputs. So the brevity penalty is exactly to introduce the recall aspect. The brevity penalty simply strikes a score, reduces the score if the output is too short compared to the reference. And that's the trick. So the idea is the output must be of the expected length, and then when it's of the expected length, then the precision aspect will take care if it's reasonable or worse in that output. But if it's too short, then obviously something must have been omitted. So that's the brevity penalty. So the brevity penalty is this simple formula. If our output is longer than the reference, then okay, we don't get any penalty. If our output is shorter than the reference, then we get an exponentially growing penalty so that we are penalized for trying to game the metric. The question is what is the length of the reference if you have more references? So the BLEU score was originally designed and tested with four different references used at a time. But then what is the length? That's the question. If the number of references is lower, then the BLEU scores are less reliable. So that's the BLEU score and this is something which you really should know how it works, and you should know its problems. And we're now going to