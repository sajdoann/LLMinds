So to fix this fundamental problem we can evaluate coarser units, so not exact word forms, but lemmas or deep-lemmas. We can focus on characters instead of words, so that's chrF3 or chrF3. That's something which is equally simple to the BLEU score calculation and it should be popular because it is simpler and correlates better with humans. We can also use shorter and gapy sequences. So these other metrics are a bit more complicated and there is a number of, a large number of other metrics. And another option is that you could use better references. If you use more references alone that helps, but it is costly. If you use references which are created from the MT outputs, then you will indeed have a mismatch only when there was an error that the post editor had to fix. So if you have references that are based on the MB outputs, then they will serve better.