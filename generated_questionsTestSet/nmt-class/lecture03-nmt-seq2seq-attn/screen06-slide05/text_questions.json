{
  "all_questions": [
    {
      "question": "What is the primary building block of neural networks?",
      "context": "The basic building block of neural networks is one fully connected layer.",
      "difficulty": "easy",
      "category": "factual",
      "evaluation": {
        "answerable": false,
        "context_relevance": 0.5714285714285714,
        "diversity_score": 0.7673611111111112
      }
    },
    {
      "question": "How does the input vector get converted to an output vector in a fully connected layer?",
      "context": "These inputs are real numbers and then they are converted to some output vector again a sequence of real numbers.",
      "difficulty": "medium",
      "category": "factual",
      "evaluation": {
        "answerable": false,
        "context_relevance": 0.45454545454545453,
        "diversity_score": 0.8263888888888888
      }
    },
    {
      "question": "What role does the weight matrix play in the transformation of input vectors to output vectors?",
      "context": "This transformation is governed by a matrix the weight matrix that tells you how to combine the input how to combine the input features.",
      "difficulty": "medium",
      "category": "factual",
      "evaluation": {
        "answerable": false,
        "context_relevance": 0.3333333333333333,
        "diversity_score": 0.7553921568627451
      }
    },
    {
      "question": "What effect does the addition of the bias term have on the output vector?",
      "context": "So this vector is an intermediate state of calculation. So you first reweight the input features with the weight matrix and then you add the bias term.",
      "difficulty": "hard",
      "category": "analytical",
      "evaluation": {
        "answerable": false,
        "context_relevance": 0.3,
        "diversity_score": 0.761322463768116
      }
    },
    {
      "question": "What can be considered as the activation function in a fully connected layer, assuming there is no input?",
      "context": "So this bias term is like the basic activation if there is no input.",
      "difficulty": "medium",
      "category": "inferential",
      "evaluation": {
        "answerable": false,
        "context_relevance": 0.2857142857142857,
        "diversity_score": 0.8039529914529915
      }
    }
  ],
  "selected_questions": [
    {
      "question": "What is the primary building block of neural networks?",
      "context": "The basic building block of neural networks is one fully connected layer.",
      "difficulty": "easy",
      "category": "factual",
      "evaluation": {
        "answerable": false,
        "context_relevance": 0.5714285714285714,
        "diversity_score": 0.7673611111111112
      }
    },
    {
      "question": "How does the input vector get converted to an output vector in a fully connected layer?",
      "context": "These inputs are real numbers and then they are converted to some output vector again a sequence of real numbers.",
      "difficulty": "medium",
      "category": "factual",
      "evaluation": {
        "answerable": false,
        "context_relevance": 0.45454545454545453,
        "diversity_score": 0.8263888888888888
      }
    },
    {
      "question": "What can be considered as the activation function in a fully connected layer, assuming there is no input?",
      "context": "So this bias term is like the basic activation if there is no input.",
      "difficulty": "medium",
      "category": "inferential",
      "evaluation": {
        "answerable": false,
        "context_relevance": 0.2857142857142857,
        "diversity_score": 0.8039529914529915
      }
    }
  ]
}