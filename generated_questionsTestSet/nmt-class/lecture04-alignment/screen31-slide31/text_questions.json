{
  "all_questions": [
    {
      "question": "What is a limitation of the lexical probabilities used in IBM Model 1?",
      "context": "The lexical probabilities disregard the positions of words in sentences and they can be estimated fully automatically in the expectation maximization loop.",
      "difficulty": "easy",
      "category": "factual",
      "evaluation": {
        "answerable": true,
        "context_relevance": 0.3333333333333333,
        "diversity_score": 0.6103238866396761
      }
    },
    {
      "question": "What is the primary application of the IBM Model 1?",
      "context": "So let's now look at the details of IBM Model 1. The lexical probabilities disregard the positions of words in sentences and they can be estimated fully automatically in the expectation maximization loop.",
      "difficulty": "medium",
      "category": "factual",
      "evaluation": {
        "answerable": true,
        "context_relevance": 0.42857142857142855,
        "diversity_score": 0.5575396825396826
      }
    },
    {
      "question": "What is a problem with using the same word alignment for two copies of the same word?",
      "context": "If there are two copies of the same word then these lexical alignments are highly inadequate because they do not distinguish whether the first copy of the word corresponds to the first copy or the second copy.",
      "difficulty": "easy",
      "category": "factual",
      "evaluation": {
        "answerable": true,
        "context_relevance": 0.6363636363636364,
        "diversity_score": 0.7824404761904762
      }
    },
    {
      "question": "What is the main challenge with applying the IBM Model 1 for translation?",
      "context": "So the IBM Model 1 is good for finding a dictionary of word level translations but it is not good for translation as such because it doesn't consider the position of the words in the sentence at all.",
      "difficulty": "medium",
      "category": "factual",
      "evaluation": {
        "answerable": true,
        "context_relevance": 0.375,
        "diversity_score": 0.7041666666666666
      }
    },
    {
      "question": "What technique is described to make the expectation maximization loop tractable?",
      "context": "So I would highly recommend that you reimplement this IBM Model 1 in your favorite language and look at the outputs. So for my students this is actually homework. So I'll send you the details how to do it, what data set you should use.",
      "difficulty": "hard",
      "category": "inferential",
      "evaluation": {
        "answerable": true,
        "context_relevance": 0.125,
        "diversity_score": 0.7835081585081585
      }
    }
  ],
  "selected_questions": [
    {
      "question": "What is a problem with using the same word alignment for two copies of the same word?",
      "context": "If there are two copies of the same word then these lexical alignments are highly inadequate because they do not distinguish whether the first copy of the word corresponds to the first copy or the second copy.",
      "difficulty": "easy",
      "category": "factual",
      "evaluation": {
        "answerable": true,
        "context_relevance": 0.6363636363636364,
        "diversity_score": 0.7824404761904762
      }
    },
    {
      "question": "What is the main challenge with applying the IBM Model 1 for translation?",
      "context": "So the IBM Model 1 is good for finding a dictionary of word level translations but it is not good for translation as such because it doesn't consider the position of the words in the sentence at all.",
      "difficulty": "medium",
      "category": "factual",
      "evaluation": {
        "answerable": true,
        "context_relevance": 0.375,
        "diversity_score": 0.7041666666666666
      }
    },
    {
      "question": "What is the primary application of the IBM Model 1?",
      "context": "So let's now look at the details of IBM Model 1. The lexical probabilities disregard the positions of words in sentences and they can be estimated fully automatically in the expectation maximization loop.",
      "difficulty": "medium",
      "category": "factual",
      "evaluation": {
        "answerable": true,
        "context_relevance": 0.42857142857142855,
        "diversity_score": 0.5575396825396826
      }
    },
    {
      "question": "What technique is described to make the expectation maximization loop tractable?",
      "context": "So I would highly recommend that you reimplement this IBM Model 1 in your favorite language and look at the outputs. So for my students this is actually homework. So I'll send you the details how to do it, what data set you should use.",
      "difficulty": "hard",
      "category": "inferential",
      "evaluation": {
        "answerable": true,
        "context_relevance": 0.125,
        "diversity_score": 0.7835081585081585
      }
    }
  ]
}