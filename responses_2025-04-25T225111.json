{
    "testset/demagog-statements-public/s_id21794/text.en.txt": [
        "How many pardons did each of the following Czech presidents grant during their time in office: Václav Havel, Václav Klaus, and Miloš Zeman?",
        "Question: Did Václav Havel pardon any individuals involved in parricide or restitution fraud, and if so, who were they?",
        "What specific individuals did Václav Havel pardon, and why were these pardons controversial?"
    ],
    "testset/demagog-statements-public/s_id21452/text.en.txt": [
        "Is Miloš Zeman's statement about the abolition of tax exemptions saving 380 billion crowns accurate, considering the differing estimates from the Ministry of Finance and Alena Schillerová?",
        "What proposal did Miloš Zeman repeatedly express in his budget speeches, and what was the estimated amount he claimed would be saved by abolishing tax exemptions?",
        "What figure did Miloš Zeman mention regarding the savings from abolishing tax exemptions, and how does it compare to the estimated state budget deficit?"
    ],
    "testset/demagog-statements-public/s_id21519/text.en.txt": [
        "Under what specific conditions are pensions in the Czech Republic automatically increased due to inflation, as described in the text?",
        "What is the starting month for determining the period used to assess inflation for the automatic increase of pensions under the extraordinary valorization mechanism?",
        "What is the last month mentioned in the text for which the mechanism of extraordinary pension valorization was applied?"
    ],
    "testset/demagog-statements-public/s_id21793/text.en.txt": [
        "What specific action did Miloš Balák allow ESG to perform before the tender was announced, according to the court ruling?",
        "Did the state suffer any economic damage as a result of Miloš Balák's actions?",
        "Question: Did Miloš Balák personally enrich himself or cause economic damage to the state in the case involving the Lánská obory?"
    ],
    "testset/demagog-statements-public/s_id22921/text.en.txt": [
        "What was the percentage increase in the share of foreigners in the Czech Republic's population and their involvement in criminal activity between 2020 and the first half of 2023?",
        "Does the percentage increase in the number of foreigners in the Czech Republic correspond to a similar percentage increase in their share of criminal activity?",
        "What was the percentage increase in the foreign population and their share of criminal activity in the Czech Republic from 2020 to 2023, and how do these increases compare?"
    ],
    "testset/demagog-statements-public/s_id21477/text.en.txt": [
        "How did the salary policies implemented by the Petr Fiala government differ from the proposals made by former Finance Minister Alena Schillerová regarding state employees' salaries?",
        "What was the discrepancy between Schillerová's initial spring 2021 comments on salary adjustments for state employees and the actual government decisions made later?",
        "What did Alena Schillerová propose in the spring of 2021 regarding salary increases for state employees, and how did the Fiala government's actions in December 2021 compare to her proposal?"
    ],
    "testset/demagog-statements-public/s_id21480/text.en.txt": [
        "What does the Czech National Bank identify as the main cause of the current high inflation in the Czech Republic?",
        "Question: According to economists and the Czech National Bank, what are the two main factors contributing to the current inflation in the Czech Republic?",
        "What percentage of the current inflation in the Czech Republic is attributed to international factors according to economists and the Czech National Bank?"
    ],
    "testset/demagog-statements-public/s_id22492/text.en.txt": [
        "Question: According to the text, why is Andrej Babiš's statement considered misleading regarding the government's proposal to modify the rules for sending soldiers abroad?",
        "What specific condition does the government cite for sending soldiers abroad without parliamentary approval, and what broader purposes do the proposed amendments aim to achieve?",
        "What did Andrej Babiš fail to mention about the government's proposal when reacting to the moderator's question?"
    ],
    "testset/demagog-statements-public/s_id22954/text.en.txt": [
        "What was the maximum budget deficit allowed for next year according to the government?",
        "What was the budget deficit planned for next year in the final draft submitted by the Ministry of Finance?",
        "What was the final agreed budget deficit for next year after the government's adjustments?"
    ],
    "testset/demagog-statements-public/s_id23626/text.en.txt": [
        "What was the stance of the STAN movement regarding the agreement and the 2014 amendment to the law on politicians' salaries?",
        "What was the main purpose of the agreement reached around 2015 between the opposition and the coalition regarding politicians' salaries, and which political groups were involved?",
        "Did the STAN movement's representatives participate in the negotiations regarding the automatic mechanism for increasing politicians' salaries around 2015?"
    ],
    "testset/demagog-statements-public/s_id21804/text.en.txt": [
        "What was the initial answer given by Marian Jurečka about whether the income calculation for the contribution was based on gross or net income, and what correction did he later make?",
        "What did Minister Marian Jurečka clarify about the income limit for the one-time contribution for each child?",
        "What clarification did Marian Jurečka provide regarding the calculation of the one-time child contribution, and how did he address the initial mistake?"
    ],
    "testset/demagog-statements-public/s_id21471/text.en.txt": [
        "What did the Prime Minister communicate to the President of the European Commission, and what resolution did the Czech Parliament adopt in support of this stance?",
        "On what date was the resolution supporting the inclusion of gas and nuclear energy in the EU taxonomy adopted by the Czech Parliament?",
        "What did Prime Minister Petr Fiala send to the President of the European Commission on December 22nd, referencing the Czech Parliament's resolution on the role of nuclear and gas energy?"
    ],
    "testset/demagog-statements-public/s_id23177/text.en.txt": [
        "Who was leading the agricultural enterprise that Petr Fiala visited during the trade union strike, and what is their relationship to Marian Jurečka?",
        "Who was one of the leading representatives or management at the agricultural enterprise that Petr Fiala visited during the trade union strike?",
        "Question: Who was one of the leaders of the agricultural enterprise that Petr Fiala visited on the day of the trade union strike?"
    ],
    "testset/demagog-statements-public/s_id21244/text.en.txt": [
        "What key principle did Petr Fiala emphasize in his speech regarding the government's responsibility towards citizens who did not vote for his coalition?",
        "What did Petr Fiala state in his first post-election speech about the government's responsibility towards all citizens?",
        "Question: What did Petr Fiala emphasize in his first post-election speech regarding unity among citizens with differing political opinions?"
    ],
    "testset/demagog-statements-public/s_id22635/text.en.txt": [
        "For which age group is it stated that the pension reform will not bring fundamental changes?",
        "Which age groups are primarily affected by the proposed changes in the pension reform?",
        "What are the main goals of the pension reform, and how will it affect different age groups, particularly the younger generation and those approaching retirement?"
    ],
    "testset/demagog-statements-public/s_id22620/text.en.txt": [
        "What has the Constitutional Court done in the past when it found doubts about the legislative process, but did not change the substance of the law?",
        "What has been the Constitutional Court's typical response when it has found doubts about the legislative process in the past, and can you provide an example from the text?",
        "What has the Constitutional Court done in the past when rejecting proposals to repeal laws, and can you provide examples from its case law?"
    ],
    "testset/demagog-statements-public/s_id22878/text.en.txt": [
        "Question: According to the text, what is the primary reason cited for delays in processing housing allowance applications in 98% of cases?",
        "What are the average processing times for housing allowance applications in most regions and Prague, and what are the legal deadlines set by the Administrative Code?",
        "What does the TEXT state about the typical duration for paying housing allowances in different regions and the primary reason cited for delays in Prague?"
    ],
    "testset/demagog-statements-public/s_id21531/text.en.txt": [
        "Which three ministries are mentioned as sharing the assistance tools for entrepreneurs during the COVID-19 pandemic?",
        "Which three ministries are primarily responsible for the assistance tools for entrepreneurs during the COVID-19 pandemic?",
        "Which three ministries are involved in providing assistance tools for entrepreneurs during the pandemic, and what programs do they manage?"
    ],
    "testset/demagog-statements-public/s_id23655/text.en.txt": [
        "Question: Is Marian Jurečka's statement that the pension system situation is worse after five years supported by the CZSO demographic projections?",
        "Question: According to the CZSO projections, how does the 2023 projection compare to the 2018 projection in terms of life expectancy, the number of people of productive age, and fertility, and what implications does this have for the pension system?",
        "What are the three main demographic indicators discussed in the CZSO report, and how do they affect the Czech pension system according to the projections?"
    ],
    "testset/demagog-statements-public/s_id22632/text.en.txt": [
        "**Question:** What timeline did Marian Jurečka provide for submitting the amendment to the government, and what conditions did he mention for doing so?",
        "What steps did Marian Jurečka outline as necessary before submitting the amendment to the government, and how did he explain the timeline for these steps in his statements?",
        "On which date did Marian Jurečka deny the claim that the government would discuss the amendment to the pension valorization mechanism in the week of March 20–26, 2023, and what explanation did he provide?"
    ],
    "testset/flat-earth-book/SECTION-9/text.txt": [
        "What evidence is presented in the text to suggest that the Moon is not merely a reflector of sunlight but might have its own source of luminosity, and how does this challenge the conventional explanation of a total lunar eclipse?",
        "What evidence does the text provide that contradicts the idea that a lunar eclipse is caused by the Earth's shadow?",
        "Question: According to the text, what contradiction exists between the traditional explanation of a lunar eclipse and the observations described?"
    ],
    "testset/flat-earth-book/SECTION-12/text.txt": [
        "What is the period of revolution of Foucault's pendulum at Paris?",
        "Question: How is the angular motion of Foucault’s pendulum at a given latitude calculated, using the Earth’s angular motion and the sine of the latitude?",
        "What was the expected period of revolution for Foucault's pendulum at Paris?"
    ],
    "testset/flat-earth-book/SECTION-11/text.txt": [
        "What is the Earth's composition, and what does the text predict will happen to it due to its internal state?",
        "What will eventually happen to the Earth due to the internal fire and surrounding combustible materials, as described in the text?",
        "According to the text, at what depth below the Earth's surface is it estimated that the temperature would reach boiling point, based on the rate of temperature increase provided?"
    ],
    "testset/flat-earth-book/SECTION-13/text.txt": [
        "Question: According to the text, how does the visibility of the Ryde Pier Light serve as evidence for a flat Earth?",
        "What is the implication of lighthouses being visible beyond the distances expected if the Earth were a globe, as described in the text?",
        "What is the primary claim made in the text regarding the shape of the Earth, supported by the observations and experiments described?"
    ],
    "testset/flat-earth-book/SECTION-7/text.txt": [
        "What is the reason for the apparent rising and setting of the Sun as explained in the text?",
        "Why does the Sun appear to rise and set?",
        "According to the text, why does the Sun appear to rise in the morning and set in the evening?"
    ],
    "testset/flat-earth-book/SECTION-4/text.txt": [
        "What phenomenon did Captain Parry observe for 24 hours near the North Pole?",
        "What does the text describe about the sun's movement near the North Pole?",
        "What shape does the Sun appear to move in from northern latitudes, and where is this movement centered?"
    ],
    "testset/flat-earth-book/SECTION-6/text.txt": [
        "Question: According to the text, why do New Zealand and England experience different lengths of daylight despite being similar in latitude?",
        "What explanation is provided in the TEXT for the more sudden and abrupt twilight observed in New Zealand compared to England, and how does it relate to the Earth's shape?",
        "What reasoning is used in the text to argue against the Earth being a globe, based on the examples of England and New Zealand?"
    ],
    "testset/flat-earth-book/SECTION-8/text.txt": [
        "Question: What causes the Sun to appear larger when it is rising or setting compared to when it is on the meridian?",
        "Why does the Sun appear larger when rising or setting than when it is on the meridian?",
        "Question: Why does the sun appear larger when it is rising or setting compared to when it is on the meridian?"
    ],
    "testset/flat-earth-book/SECTION-5/text.txt": [
        "What is the highest and lowest altitude of the Sun at the time of meridian passage from June 15th to December 21st?",
        "What is the Sun's altitude at the meridian on June 15th and December 21st, and what does this indicate about the Sun's path?",
        "Question: From which date to which date does the diameter of the Sun’s path diminish, and from which date does it begin to enlarge again?"
    ],
    "testset/flat-earth-book/SECTION-3/text.txt": [
        "What method does the text describe for measuring the distance of the Sun and stars, and what is the maximum distance stated for all visible celestial objects?",
        "What is the maximum distance of the visible objects in the firmament, such as the Sun and Stars, as demonstrated in the text?",
        "What conclusion can be drawn about the distance of the Sun from Earth based on the method described in the text and the specific observations provided?"
    ],
    "testset/flat-earth-book/SECTION-10/text.txt": [
        "What does the text suggest is the main reason for the tides in the ocean?",
        "Question: According to the doctrine presented in the text, what is the primary cause of tides in the ocean?",
        "What is the primary cause of tides in the ocean according to the text?"
    ],
    "testset/flat-earth-book/SECTION-2/text.txt": [
        "What conclusion was drawn from the air-gun experiment regarding Earth's motion?",
        "What conclusion can be drawn from the experiments described in the text regarding the Earth's axial and orbital motion?",
        "What conclusion was drawn from the experiments described in the text regarding the Earth's axial and orbital motion?"
    ],
    "testset/flat-earth-book/SECTION-1/text.txt": [
        "What does the text suggest is the reason for the \"spherical excess\" observed in surveying, and how does this affect the argument for the Earth's rotundity?",
        "Question: According to the text, what discrepancy is observed between the theoretical calculation of the Earth's circumference at a certain latitude and the practical measurements reported by navigators?",
        "What did the British government require surveyors to do in terms of datum lines when laying out railways and canals, and why was this necessary?"
    ],
    "testset/nmt-book/chapter07-Alternate-Architectures/text.txt": [
        "What is the primary purpose of the self-attention mechanism in the encoder of a neural machine translation model?",
        "What is the primary advantage of using convolutional neural networks (CNNs) and self-attention mechanisms in neural machine translation compared to traditional recurrent neural networks (RNNs)?",
        "What is the main idea behind self-attention in neural machine translation models?"
    ],
    "testset/nmt-book/chapter06-Refinements/text.txt": [
        "What technique was suggested to address the challenge of mixing in-domain and out-of-domain data during the adaptation of neural machine translation models?",
        "What is the process of linguistic annotation of input sentences in neural machine translation, and how are specific linguistic features like part-of-speech tags encoded into the model?",
        "What are the two main approaches to machine translation discussed in the text, and how has recent work attempted to balance them?"
    ],
    "testset/nmt-book/chapter01-Introduction/text.txt": [
        "What happened with neural machine translation systems in the 2016 WMT shared task for machine translation?",
        "In which year did a neural machine translation system first win in most language pairs at the WMT?",
        "In which year did a neural machine translation system win in almost all language pairs at the Conference on Machine Translation?"
    ],
    "testset/nmt-book/chapter02-Neural-Networks/text.txt": [
        "What is the primary reason for introducing a validation set in the training process of neural networks?",
        "**Question:**  \nWhat is the purpose of a validation set in neural network training, and how is it used to determine when to stop training?",
        "How is the error term for hidden nodes computed during backpropagation, and what role does the chain rule play in this process?"
    ],
    "testset/nmt-book/chapter03-Computation-Graphs/text.txt": [
        "What is the purpose of the Theano function `grad` in the context of the example computation graph for the neural network?",
        "Explain how gradients are computed in the backward pass of a computation graph for training a neural network, using the example provided.",
        "What is the role of computation graphs in the training of neural networks, and how are they utilized to compute gradients for parameter updates?"
    ],
    "testset/nmt-book/chapter05-Neural-Translation-Models/text.txt": [
        "What role does the attention mechanism play in the neural machine translation model, and how is it implemented?",
        "What are the key components of the decoder in a neural machine translation model, and how does the attention mechanism contribute to the decoding process? Additionally, explain the role of beam search in improving the translation quality.",
        "What are the three main components used by the attention mechanism to generate the input context vector for the decoder?"
    ],
    "testset/nmt-book/chapter04-Neural-Language-Models/text.txt": [
        "What is the purpose of the gates in LSTM cells and how do they contribute to the model's ability to handle long-term dependencies?",
        "What is a key difference between Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks in the context of language modeling?",
        "What are the two gates in a Gated Recurrent Unit (GRU) and what is the role of each?"
    ],
    "testset/nmt-book/chapter08-Current-Challenges/text.txt": [
        "How does the out-of-domain performance of neural machine translation systems compare to statistical machine translation systems in terms of BLEU scores, as demonstrated in the experiments?",
        "How does the performance of neural machine translation compare to statistical machine translation when tested on out-of-domain data?",
        "How do the learning curves of neural and statistical machine translation systems compare when trained on different amounts of data, as shown in the experiments?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen01-slide01/text.txt": [
        "What was the main topic of the lecture?",
        "What aspects beyond traditional translation are covered in the lecture on multimodal machine translation?",
        "What is the main focus of the last lecture on statistical machine translation?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen02-slide02/text.txt": [
        "What are the two main approaches discussed in the lecture for speech translation and which recent survey is mentioned for including visual information in machine translation?",
        "What approaches to speech translation are discussed, including both traditional methods and recent end-to-end neural network approaches, and how does the text address the role of data and visual information in this context?",
        "What are the two main approaches discussed in the lecture for speech translation, and how do they differ?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen03-slide03/text.txt": [
        "What method have they been using to translate text from the source language to the target language?",
        "What have we always been doing to convert the text from the source language to the target language?",
        "What method did they use to translate the text into the target language?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen04-slide04/text.txt": [
        "What is the purpose of adding speech on the source side according to the text?",
        "What is the purpose of adding speech on the source side in this context?",
        "What technology is mentioned as being needed to convert speech into text for the machine translation system?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen05-slide05/text.txt": [
        "What is the term for converting text back into speech in translation, and how is this exemplified in the text?",
        "What system is mentioned that would allow someone to hear speech translated into their own language whispered in their ear?",
        "What system is described in the text for translating speech into another language?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen06-slide06/text.txt": [
        "What is spoken language translation and how does it differ from the cascade approach mentioned in the TEXT?",
        "What is the direct approach mentioned for translation that doesn't involve transcription?",
        "What is spoken language translation and why is it considered a direct attempt?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen07-slide07/text.txt": [
        "What is the primary focus of the author in contrasting machine translation with the combination of ASR and MT in spoken language translation?",
        "What system does the author mention for direct speech translation?",
        "What is the primary focus of the system described in the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen08-slide08/text.txt": [
        "What is the purpose of using images in translation tasks according to the text?",
        "What are the two main purposes mentioned for using images in the context described?",
        "What are the two tasks mentioned in the text that involve the use of images?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen09-slide09/text.txt": [
        "What does the text suggest about the use of visual or video guidance in translation and its future development?",
        "What is the purpose of visual guidance in translation as described in the text?",
        "What is the purpose of visual guidance in translation according to the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen10-slide11/text.txt": [
        "What type of text inputs are typically used in spoken language translation according to the text?",
        "What is the usual input for machine translation according to the lecture?",
        "What type of input is typically used in machine translation, and are unclear snippets of text ever used?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen11-slide12/text.txt": [
        "What is the main motivation for using incremental machine translation?",
        "What is the primary motivation behind incremental machine translation and how does it ensure the stability of the translation output?",
        "What is the main aim of incremental machine translation according to the lecture?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen12-slide13/text.txt": [
        "What is the advantage of using direct speech-to-speech translation over text-based translation methods?",
        "What is the main advantage of using direct speech-to-speech translation over text-based translation followed by voice synthesis?",
        "What is the main advantage of direct speech-to-speech translation according to the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen13-slide14/text.txt": [
        "What are the two main components connected together in the cascading machine for language translation?",
        "What two components are connected in the cascading machine spoken language translation system?",
        "What are the two components used in the cascading machine for language translation?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen14-slide15/text.txt": [
        "What standard measure is mentioned for evaluating the performance of speech recognition systems?",
        "What standard measure of speech recognition improved to near human levels by around 2017?",
        "What is the expected outcome for speech recognition performance since the introduction of deep neural networks and subsequent developments, and by when is this anticipated?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen15-slide16/text.txt": [
        "According to the discussion, in which areas has machine translation been shown to perform similarly to humans?",
        "In what ways has machine translation been shown to match human performance according to the discussion?",
        "What does the TEXT suggest about machine translation in comparison to humans?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen16-slide17/text.txt": [
        "What is the proposed method to achieve great speech translation?",
        "What is the proposed method for achieving great speech translation, and what are the two main components involved?",
        "What are the steps involved in translating speech according to the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen17-slide18/text.txt": [
        "What is the main challenge mentioned in the text regarding the transition from a sequence of words to correct, clear sentences in the context of machine translation?",
        "What is the main challenge mentioned in the text regarding the transition from a sequence of words to correct, clear sentences suitable for translation?",
        "What is the main challenge in producing correct and clear sentences from ASR systems and machine translation, according to the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen18-slide19/text.txt": [
        "It seems that the provided text is incomplete. Could you please provide the full text so I can generate an appropriate question for the exam?",
        "What is the task you have to perform based on the given TEXT?",
        "What is the purpose of the TEXT field in the context of segmenting the flow of words?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen19-slide20/text.txt": [
        "What is the consequence of ASR uncertainty without context in the translation process?",
        "How does the uncertainty in ASR outputs affect the accuracy of machine translation?",
        "What is the potential issue when ASR outputs ambiguous transcriptions without access to further context?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen20-slide21/text.txt": [
        "What are the two main issues at the beginning of the pipeline when deploying the system?",
        "What problem is encountered at the beginning of the pipeline when deploying the system, and why is it important to present a stable output to the user?",
        "What is one problem at the beginning of the pipeline when deploying the system, and how is it addressed to ensure a stable and correct output for the user?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen21-slide22/text.txt": [
        "What is the main challenge when integrating components into a system, as described in the context of the ELITER project?",
        "What are the main challenges in integrating the components for the ELITER project, and how are ambiguities addressed during the process?",
        "What does the text mention as a challenge when integrating the components of the system being deployed in the ELITER project?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen22-slide23/text.txt": [
        "What challenge is faced when subtitling online sessions in another language?",
        "What makes subtitling live online sessions particularly challenging?",
        "What makes subtitling online sessions in another language challenging?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen23-slide24/text.txt": [
        "What is the role of the mediator in the described architecture?",
        "What is the central component in the described architecture and what is its role?",
        "What is the role of the mediator in the described architecture?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen24-slide25/text.txt": [
        "What are the actual issues that have been encountered during the tests?",
        "What kind of issues does the speaker discuss in their tests?",
        "What does the speaker refer to as \"true issues\" that they have encountered in their tests?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen25-slide26/text.txt": [
        "What was the main issue that caused the delay during the live subtitling event, and how was it related to the system's architecture?",
        "What was the main issue faced during the live subtitling event and what caused it?",
        "What was the main issue that caused delays during the live subtitling event, and why was it hard to diagnose?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen26-slide27/text.txt": [
        "What is the primary issue that can cause poor sound quality when the first cable is not properly connected?",
        "What issue with the first cable affects sound quality according to the text?",
        "What issue arises with the sound input when the first cable is badly plugged in?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen27-slide28/text.txt": [
        "What are the two main factors causing subtitle delays in the presentation pipeline, and who is responsible for ensuring that the subtitles are presented live without significant delays?",
        "What are the two main factors affecting the presentation of subtitles, and how do they impact the user experience?",
        "What two factors contribute to subtitle delays in the presentation pipeline?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen28-slide29/text.txt": [
        "What was the result of the misconfiguration in the setup that caused the sound to be sent twice through the pipeline?",
        "What was the primary cause of the delay in the pipeline mentioned in the text?",
        "What was the cause of the pipeline delay mentioned in the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen29-slide31/text.txt": [
        "What effect did attaching the chest mic near the shoulder and speaking away from it have on the sound quality?",
        "What mistake was made regarding the placement of the chest mic, and how did it affect the sound quality?",
        "What happened to the sound when the colleague attached the chest mic incorrectly and spoke in the wrong direction?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen30-slide32/text.txt": [
        "What two types of microphones were compared, and what is the main advantage of the headset microphone mentioned?",
        "What is the clear benefit of using the headset microphone compared to the chest microphone, as mentioned in the text?",
        "What is a clear benefit of using a headset microphone compared to a chest microphone?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen31-slide33/text.txt": [
        "What is a common problem when people use handheld microphones?",
        "What could people cover the microphone with when using handheld microphones?",
        "What could people cover a handheld microphone with, according to the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen32-slide35/text.txt": [
        "What are the two ways something could be positioned incorrectly relative to the mouth or hand?",
        "What are two possible issues with how they place the item?",
        "What are the two possible issues mentioned regarding the placement of something relative to the mouth and hand?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen33-slide36/text.txt": [
        "How does the placement of microphones relative to loudspeakers affect ASR performance?",
        "What is the potential issue with ASR quality when someone stands in front of the loudspeakers, causing the microphone to receive the same sound with a delay?",
        "What might be damaging the ASR quality according to the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen34-slide37/text.txt": [
        "What must be ensured about the output of each intermediate component in the pipeline when acquiring sound?",
        "Question: Why is it important to ensure that every intermediate component in the pipeline produces output within a reasonable volume range when acquiring sound?",
        "What is the importance of ensuring that every intermediate component in the pipeline produces output in a reasonable volume range when acquiring sound?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen35-slide38/text.txt": [
        "What did the speaker discuss and test at the beginning of the lecture?",
        "What happened at the beginning of the lecture regarding the superhuman quality of speech recognition?",
        "What did the speaker discuss regarding the failure of ASR and its superhuman quality?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen36-slide39/text.txt": [
        "What are the main issues that the ASR system faced in the described realistic setup, and how did they impact its ability to understand the speaker?",
        "What were the main problems faced by the ASR system in the described realistic setup?",
        "What challenges did the ASR system face in the described realistic setup with the high school student's presentation?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen37-slide40/text.txt": [
        "What is the word error rate of the speech recognition systems being discussed, and how does it compare to human-level recognition quality, especially in the context of offline evaluation where systems may give up on challenging recordings?",
        "What happens when the sound input is too bad for the systems to recognize, and what word error rate does that result in?",
        "What is the word error rate when a system like Google is given very poor sound input, according to the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen38-slide41/text.txt": [
        "What factors contributed to the failure of online speech recognition systems in the described scenario?",
        "What is the primary reason the online speech recognition systems failed in the presented test?",
        "What factors affect the performance of speech recognition systems, as described in the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen39-slide42/text.txt": [
        "What was the non-native person discussing in terms of reality checks and superhuman abilities in the context of speech recognition and machine translation?",
        "What was the purpose of the reality check mentioned for machine translation, and how does it relate to the idea of achieving superhuman capabilities?",
        "What was the purpose of the machine translation reality check mentioned in the text, and how does it relate to the discussion about getting superhuman abilities?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen40-slide43/text.txt": [
        "What are the two examples of translation errors mentioned in the text, and what is the impact of these errors on the translation process?",
        "What is the standard ambiguity of words and how does it cause translation errors according to the text?",
        "What are the two types of errors mentioned in the text, and what are the specific examples given for each?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen41-slide44/text.txt": [
        "What main issue does the text discuss regarding the use of machine translation for spoken language, and why is this problematic?",
        "What issue does the TEXT highlight about using speech recognition and machine translation systems together, and why is context important in this scenario?",
        "What does the author emphasize is necessary for accurate machine translation of spoken language?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen42-slide46/text.txt": [
        "What is the main limitation of current end-to-end spoken language translation systems in handling segmentation and utterances?",
        "What is the main challenge in integrating speech-to-text and machine translation systems, and how does it relate to the segmentation of sentences and the capabilities of the ASR system?",
        "What is a key limitation of end-to-end spoken language translation systems when they are expected to handle segmentation of utterances themselves?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen43-slide47/text.txt": [
        "What approaches were considered for inserting punctuation into a sequence of words?",
        "What are the different approaches mentioned for inserting punctuation into a sequence of words?",
        "How does the inclusion of sound information vary across the different approaches discussed for punctuation insertion?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen44-slide48/text.txt": [
        "What is the main consequence of misplacing punctuation marks in the context of machine translation according to the text?",
        "What are the consequences of incorrectly placed punctuation marks in the text, as illustrated by the example of \"all too well\" and its impact on translation?",
        "What is one potential consequence of misplacing punctuation in the context of machine translation, as described in the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen45-slide49/text.txt": [
        "What problem does end-to-end spoken language translation aim to avoid?",
        "What improvement does the user suggest for end-to-end spoken language translation?",
        "What is the main issue that the previous system had which end-to-end spoken language translation aims to avoid?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen47-slide49/text.txt": [
        "What is the nature of the corpora used for training and testing these systems?",
        "What is the nature of the corpora used for training and testing these systems?",
        "What is the segmentation method used for the corpora on which these systems are trained and tested?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen48-slide50/text.txt": [
        "What is a main drawback of direct spoken language translation as discussed in the text?",
        "What is the main drawback of direct spoken language translation according to the text?",
        "What is the main drawback of direct spoken language translation according to the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen49-slide51/text.txt": [
        "What are the three main components used in the multitask learning approach discussed in the text?",
        "What is a limitation of the standard training approach for speech-to-text systems mentioned in the text?",
        "In the context of training a speech-to-text system, what is the primary benefit of pre-training the translation system on a larger text corpus before fine-tuning it on a smaller SLT dataset?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen50-slide52/text.txt": [
        "What type of corpus was used in Berard's 2016 study, and what was the architecture of the neural network model employed for end-to-end spoken language translation?",
        "What type of approach was used to create the synthetic corpus for Berard's 2016 study on end-to-end spoken language translation?",
        "What type of neural network architecture was used in Berard's 2016 study for end-to-end spoken language translation?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen51-slide53/text.txt": [
        "What specific components or methods did the 2018 study use in their end-to-end approach for speech processing?",
        "What key components and techniques were used in the first truly end-to-end approach in 2018 for speech-to-text and translation tasks?",
        "What components are used in the speech encoder and in what order are they applied according to the 2018 study?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen52-slide54/text.txt": [
        "How is the neural network model pre-trained according to the text?",
        "What is the initial pre-training done on each component before incorporating the source language?",
        "What are the neural network components pre-trained on in the described approach?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen53-slide55/text.txt": [
        "Which approach, the cascaded or the ensemble method, achieved a higher test score, and what were the respective scores?",
        "What is the test score of the ensemble system that combines three subsystems, and how does it compare to the cascaded approach's score?",
        "How does the cascaded approach compare to the ensemble system in terms of performance and parameter usage, based on the test scores provided?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen54-slide56/text.txt": [
        "What is the current understanding regarding the best architecture for improving systems, given the various approaches like convolution networks with LSTMs or transformers, and the ongoing debate about which method will emerge victorious?",
        "What advancements and architectural approaches have been explored in the survey by Silvachak, and what is still unclear regarding the best approach?",
        "What approaches are still being debated as the best for the system?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen55-slide57/text.txt": [
        "What are the two main modifications made by the Italian FBK team to the standard transformer architecture in their 2019 paper?",
        "What are the two main modifications made by the Italian FBK team to the standard transformer architecture in their 2019 paper, and how does their approach differ from the standard transformer in terms of positional encoding?",
        "What modifications did the Italian FBK team make to the standard transformer architecture in their 2019 paper, and how were these modifications integrated into the network?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen56-slide58/text.txt": [
        "How does the Translator-Tran system preserve speaker characteristics in speech translation?",
        "What method does the system use to preserve speaker characteristics in the speech translation process?",
        "What is the key aspect of the system described in the text that allows it to preserve speaker characteristics in speech translation?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen57-slide59/text.txt": [
        "What is the main topic of the presentation?",
        "What is the focus of the presentation as mentioned in the text?",
        "What was the focus of the presentation mentioned?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen58-slide60/text.txt": [
        "What factors make subtitle timing and presentation crucial for effective communication?",
        "Question: Why is timing a critical factor in subtitle deployment?",
        "What are the key factors that can impact the effectiveness of subtitles in a translation system based on the provided text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen59-slide61/text.txt": [
        "What is the main problem Eliter faces when trying to display subtitles in multiple languages with limited space?",
        "What challenge do they mention when producing subtitles for a multilingual audience?",
        "What is the main challenge Eliter faces when producing subtitles for a multilingual audience?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen60-slide62/text.txt": [
        "What are paragraphs used to show according to the text?",
        "How does the text suggest presenting paragraphs to allow readers to select what they read?",
        "What is the primary purpose of the paragraphs described in the TEXT?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen61-slide63/text.txt": [
        "What challenge does the subtitler face when dealing with partial segments that are translated and subsequently updated?",
        "What issue does the subtitler component address in the described system?",
        "What challenge does the subtitler face when displaying subtitles in a limited space, and how does it ensure a smooth user experience despite updates from the segmenter and machine translation systems?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen62-slide64/text.txt": [
        "**Question:**  \nWhy is the synchronization of subtitles and slides treated differently based on the audience's language understanding?",
        "What is the preference for subtitle timing among users who understand the source language versus those who do not, based on cognitive load considerations?",
        "What determines the preferred subtitle settings for users who are following slides and subtitles in a different language, according to the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen63-slide65/text.txt": [
        "What did the speaker decide to do regarding the evaluation of spoken language translation?",
        "What did the speaker decide to skip?",
        "What action did the speaker decide to take regarding spoken language translation evaluation?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen64-slide66/text.txt": [
        "What additional factors should be considered when evaluating spoken language translation beyond the quality of the translation itself?",
        "What additional aspects must be considered when comparing machine translation systems in spoken language beyond translation quality?",
        "What additional factors should be considered when evaluating spoken language translation beyond the quality of the translation itself?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen65-slide67/text.txt": [
        "What challenge does the evaluation face when systems segment the input sound differently from the golden segmentation?",
        "What challenge arises when a system's segmentation of input sound does not align with the golden segmentation, and how should this mismatch be addressed in evaluation?",
        "What issue arises during evaluation when there is a mismatch between the system's segmentation and the golden segmentation?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen66-slide69/text.txt": [
        "What is the last part of the lecture about and how is its presentation described?",
        "What is the last part of the lecture about, and how is its presentation different from the previous parts?",
        "What is the last part of the lecture focused on?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen67-slide70/text.txt": [
        "What is the Czech translation for \"a tennis player is getting ready\"?",
        "What are the Czech translations provided for the sentence \"a tennis player is getting ready\"?",
        "What is the translation of \"a tennis player is getting ready\" into Czech?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen68-slide71/text.txt": [
        "What is the reason someone might make a random guess when interpreting the sentences in the text?",
        "What is the reason that the difference between the two sentences may seem subtle to someone who does not speak Czech?",
        "Based on the text, which sentence is in the male gender and which is in the female or feminine gender?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen69-slide72/text.txt": [
        "What can you do easily if there is an image next to the sentence in the queue?",
        "What is the purpose of the image mentioned next to the sentence about the queue?",
        "What becomes easier when there is an image next to a sentence in the queue?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen70-slide73/text.txt": [
        "What example is given in the text to illustrate a challenge in translating English captions into Hindi using images from Visual Genome?",
        "What issue did the author highlight regarding the use of images in translating English captions to Hindi?",
        "What issue was encountered when translating the English captions into Hindi using the Visual Genome dataset, and how did the image contribute to this challenge?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen71-slide74/text.txt": [
        "How many ambiguous words were manually selected for the challenge test set based on the visual genome data?",
        "What problem did the researchers encounter when trying to find ambiguous words in the Visual Genome dataset for their test set?",
        "What was the main challenge faced when using machine translation to identify ambiguous words in the dataset?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen72-slide75/text.txt": [
        "How do context clues help determine the meaning of the word \"penalty\" in the examples provided?",
        "What role does the surrounding context play in determining the meaning of the word \"penalty\" based on the examples provided?",
        "How does the context of the word \"penalty\" determine its meaning in the examples provided?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen73-slide76/text.txt": [
        "What does the attention mechanism attend to as it processes the input sentence?",
        "What is the role of attention states in the described attention architecture?",
        "What does the attention mechanism focus on as the output is being produced?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen74-slide77/text.txt": [
        "What is the role of the attention mechanism in the described image captioning task?",
        "Question:  \nIn the context of the image captioning task described, how is the attention mechanism applied, and what type of neural network is used in the encoder to process the images?",
        "What are the main components used in the image captioning task described, and how do they contribute to generating the image description?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen75-slide76/text.txt": [
        "What does the text suggest about the multi-encoder setup?",
        "What is created by putting setups together?",
        "What action is taken in the multi-encoder setup?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen76-slide77/text.txt": [
        "What setup was described for using image information with an additional encoder in the text?",
        "What is the key component used to integrate image information into the decoder in the described setup?",
        "What part of the model is used to incorporate the image information in the described setup?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen77-slide78/text.txt": [
        "What did the decoder do when processing the word \"green\" in the hierarchical attention setup described in the text?",
        "What action did the decoder take when it mentioned the color green in its output?",
        "In the described hierarchical attention setup, what happened when the decoder was processing the word \"green\" in the example sentence?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen78-slide79/text.txt": [
        "What are the training objectives of the encoder and the role of the decoder in the multi-task setup described for visually supported translation?",
        "The encoder is trained with two objectives: to produce the target text and to produce the target image representation.",
        "What is the role of the encoder in the multi-task setup described in the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen79-slide80/text.txt": [
        "Which model showed sensitivity to image incongruence in the experiment?",
        "Which model in Desmond Elliott's experiment was sensitive to the accuracy of the image provided?",
        "What key difference did Desmond Elliott's experiment reveal about the performance of hierarchical attention models compared to other models when presented with non-matching images?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen80-slide81/text.txt": [
        "What is mentioned there as well?",
        "What was mentioned about the last thing?",
        "What is mentioned in the text?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen81-slide80/text.txt": [
        "What does Raglan's paper identify as the main issue?",
        "What issue does Ozan Raglan's paper address regarding the use of visual information in the dataset?",
        "According to Ozan Raglan's paper, what is the main issue identified regarding the use of visual information?"
    ],
    "testset/nmt-class/lecture11-multimodal-mt/screen82-slide81/text.txt": [
        "What did the experiment reveal about the ability of multimodal systems to infer certain attributes from images?",
        "How did the systems trained on both text and visual information differ from those trained on text-only when processing degraded text inputs in Desmond's and Elliot's experiment?",
        "What key advantage did multimodal systems demonstrate in the experiment compared to non-multimodal systems when dealing with degraded text inputs?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen01-slide01/text.txt": [
        "What is the main topic of the lecture titled \"Whether Current Machine Translation Systems Understand What They Are Translating\"?",
        "What technical aspect is the lecture discussing in the context of machine translation?",
        "What is the main focus of the lecture on machine translation discussed in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen02-slide02/text.txt": [
        "What two levels of representations are discussed in the context of systems understanding meaning?",
        "What two main topics are discussed regarding the representations and meaning in the system?",
        "What topics will be discussed in the presentation, and in what order?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen03-slide03/text.txt": [
        "What is different about the triangle used in machine translation compared to the WOKUA triangle?",
        "How does the triangle used in machine translation differ from the WOKUA triangle?",
        "How does the triangle used in machine translation differ from the WOKUA triangle?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen04-slide04/text.txt": [
        "What part of the semiotics triangle corresponds to the symbol, which is something you hear or see?",
        "What does the source, or the lower corner of the semiotics triangle, correspond to according to Richards and Ogden?",
        "What does the source or lower corner of the semiotics triangle represent?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen05-slide05/text.txt": [
        "What does the sentence \"Danny approached the chair with a yellow bag\" symbolize?",
        "What does the symbol in the text represent?",
        "What does the yellow bag symbolize in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen06-slide06/text.txt": [
        "How does the sentence \"Danny is approaching the chair with the bag\" show ambiguity, and what are the two possible situations it refers to?",
        "What is the ambiguity in the sentence, and how does it refer to two different situations involving Danny approaching the chair and the bag?",
        "What does the text say about the ambiguity of the sentence involving Danny, the bag, and the chair?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen07-slide07/text.txt": [
        "What do syntacticists know about encoding the two different meanings in the constituency trees discussed in the text?",
        "What does the text imply about syntacticists and their understanding of constituency trees?",
        "What is the difference in the placement of the \"yellow back\" in the constituency trees that encode the two different meanings?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen08-slide08/text.txt": [
        "How do the two systems differ in connecting the bag to the person or the chair?",
        "What are the two different links between the bag and the other entities in the two semantic systems described?",
        "What is the main reason for the difference between the two systems in how they represent the connection between the bag and either the person or the chair?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen09-slide09/text.txt": [
        "How do the representations in artificial neural networks differ from those in natural neural networks when processing videos, and how does this affect their ability to perceive differences?",
        "What happens to the representations or activations in artificial neural networks when they process videos of different situations, and how does this affect their ability to perceive differences compared to natural neural networks?",
        "How does processing videos of different situations affect the representations in artificial neural networks?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen10-slide10/text.txt": [
        "What strategies do human translators use when they face ambiguity or unclear terms in the original text?",
        "How do human translators handle ambiguous situations or technical terms when the context is not sufficient?",
        "What approach do human translators take when they encounter unclear terms or ambiguous situations in the source text that they cannot resolve through context alone?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen11-slide11/text.txt": [
        "In which years and language pairs did machine translation systems surpass human performance in the WMT competitions?",
        "What language pairs and years were highlighted in the text where machine translation systems surpassed professional human translation in the WMT competition?",
        "In which years and language pairs did machine translation systems achieve performance comparable to humans, as mentioned in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen12-slide12/text.txt": [
        "Which two reasons are provided in the text to suggest that machine translation systems might understand context?",
        "What proportion of the training data used by the 2018 Charles University Transformer machine translation system was parallel text?",
        "What are the two sources of data used by the machine translation system mentioned in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen13-slide13/text.txt": [
        "What is the first sentence taught to Czech students in grammar school?",
        "What is the first sentence taught in Czech grammar schools, and how does Google translate it?",
        "What is the first sentence taught to Czech students that was mentioned in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen14-slide14/text.txt": [
        "What issue arises when using Google Translate to translate questions in free word order languages, as demonstrated in the examples?",
        "How does word order in a free word order language affect what is being checked or validated in a question?",
        "What issue arises when using Google Translate for questions in a free word order language, as demonstrated in the TEXT?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen15-slide15/text.txt": [
        "What translation error is described in the text and what problem led to this error?",
        "What is the reason Bing Translator made errors in translating the provided text?",
        "What issue did Microsoft Bing Translator have with the given input, and why?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen16-slide16/text.txt": [
        "What does the user suggest about the appropriate word order in English to highlight the topic-focused articulation, similar to the Czech sentence structure?",
        "What word order does the text suggest is appropriate for a Czech sentence to highlight the topic-focused articulation?",
        "\"Is the word order 'mom grinds meat, does mom grind meat, that is perfect, and meat moms grinding' appropriate for topic-focused articulation in a Czech sentence?\""
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen17-slide17/text.txt": [
        "What did the system say when asked if mom has meat?",
        "Why was the system's output not acceptable?",
        "Why did the system ask, \"Does mom have meat?\" after reordering the words \"mele, mama, masa\"?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen18-slide19/text.txt": [
        "What is the role of a \"cut\" in a neural network as described in the text?",
        "What is the significance of a \"cut\" in a neural network, and what does it represent regarding the input?",
        "What is a \"cut\" in the context of a neural network, and why is it significant?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen19-slide20/text.txt": [
        "How does the use of three neurons in the hidden layer help in transforming the original 2D space into a new space where it becomes easier to classify points as being in the center or on the circumference?",
        "What is the purpose of transforming the original x and y coordinates into a new space (ABC) using the distances from three lines, and how does this help in separating inner points from the circumference?",
        "What is the role of the three lines in transforming the original 2D space into the new ABC space for classification?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen20-slide21/text.txt": [
        "Is the representation in the hidden space, which is trained by the network to best separate the classes, only useful for separating those classes, or can it also be used for something else?",
        "Is the representation in the hidden space only used for separating the classes, or can it also be useful for other purposes?",
        "What is the main question posed regarding the representation created by the hidden space in the context of class separation?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen21-slide22/text.txt": [
        "Based on the provided text, describe the process used to transform the input picture into its representation in the new space.",
        "What term is used to describe the new space where hand-drawn examples are represented?",
        "What does the input picture look like in the new space, based on the hand-drawing examples?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen22-slide23/text.txt": [
        "Why is the ABC representation considered good?",
        "Why is the ABC representation considered good?",
        "What is one advantage of the ABC representation mentioned in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen23-slide24/text.txt": [
        "What can happen when a network processes a very complicated input?",
        "What happens when the network processes a very complicated input?",
        "What can happen when the network processes a very complicated input?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen24-slide25/text.txt": [
        "What is the criteria for a good hidden representation according to the text?",
        "Why is a hidden representation considered good according to the text?",
        "Question: Why would we consider a hidden representation to be good?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen25-slide26/text.txt": [
        "What are the main aspects of a good representation in machine learning according to the text?",
        "What are the key aspects of a good representation as discussed in the text?",
        "What are the key aspects of having a good representation, and how can it be evaluated?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen26-slide28/text.txt": [
        "What are the two language modeling tasks used to train word embeddings?",
        "What problem do word embeddings help to circumvent or resolve, and what are the two main language modeling tasks they are trained for?",
        "What are the two main language modeling tasks used to train word embeddings?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen27-slide29/text.txt": [
        "What happens when you take the embedding of the word \"king,\" subtract the embedding of the word \"man,\" and add the embedding of the word \"woman\"?",
        "What formula was mentioned to demonstrate the relationship between the embeddings of 'king,' 'man,' and 'woman'?",
        "What is the result of the equation embedding(king) - embedding(man) + embedding(woman)?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen28-slide30/text.txt": [
        "What distinguishes the two types of questions in the test set associated with Word2Egg?",
        "What are the two main types of questions in the test set associated with Word2Vec, and what examples are provided for each type?",
        "What are the two types of questions in the test set associated with Word2Egg, and can you provide examples of each?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen29-slide31/text.txt": [
        "What was the observed accuracy of the model in the test set described in the paper?",
        "What are the key limitations of the test set used in the evaluation of the model described in the text?",
        "What was the composition of the test set used in the evaluation, and what was the observed accuracy despite the model not being explicitly taught about gender or countries?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen30-slide32/text.txt": [
        "What accuracy was achieved on the test set when using the origin V2VAC model, and how does this performance compare to expectations given the model's training?",
        "What was the accuracy of the system on the test set, and why is it considered a good accuracy despite the lower performance?",
        "What accuracy did the system achieve on the test set, and how does it compare to its evaluation performance?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen31-slide33/text.txt": [
        "How did the performance of the subgram model compare to the word2vec model on the original test set, and what was the primary reason for the difference?",
        "What was the performance comparison between the subgram model and the word2vec model on the original test set, and what was the primary reason for the difference in their performance?",
        "What was the main reason for the difference in performance between the subgram model and the word2vec model on the original test set?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen32-slide34/text.txt": [
        "What number of rules is sufficient to surpass the performance of certain systems in datasets when focusing on regular patterns and morphological behavior?",
        "According to the text, what is the main advantage of writing nine specific rules for regular patterns over using word embeddings for a morphology task?",
        "What is the main takeaway about using nine rules for regular patterns compared to deep learning systems in achieving superior performance?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen33-slide35/text.txt": [
        "What was the number of citations for the paper submitted by the user in March 2016?",
        "In which month was Tomáš Mikolov's follow-up paper submitted?",
        "How many citations did the paper submitted in March 2016 receive, and how many did the follow-up paper by Tomáš Mikolov receive?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen34-slide36/text.txt": [
        "What is the main difference in approach between the two papers mentioned that led to the FastEx paper receiving 3,000 citations?",
        "What is one main difference between the user's paper and the FastEx paper with 3,000 citations?",
        "Why did the FastEx paper receive 3,000 citations according to the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen35-slide37/text.txt": [
        "What distinction did Hill and colleagues observe regarding monolingual models and neural MT models in terms of the similarities they reflect?",
        "What are the two types of similarities discussed in the text, and how do monolingual models and neural MT models reflect each type?",
        "What are the two types of similarities observed in human annotations for word embeddings, and which type of model (monolingual or neural MT) captures each type?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen36-slide38/text.txt": [
        "What did the text mention moving on to after discussing smaller units?",
        "What is the focus of the discussion after moving on from smaller units?",
        "What are the larger units that the text refers to when moving beyond smaller units?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen37-slide39/text.txt": [
        "What is the fixed-length vector used for in the encoder-decoder architecture?",
        "What is the term used for the point in the network where the representation of the entire input sentence is stored before the decoder processes it?",
        "What is the purpose of the encoder in the encoder-decoder architecture described in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen38-slide40/text.txt": [
        "Question:  \nAccording to the text, how are the six sentences categorized in the two-dimensional plot, and what does this categorization suggest about their meanings?",
        "What aspect of the sentences is most important in determining their position in the 2D plot?",
        "How do the vector representations of the sentences in the text illustrate the relationship between sentence meaning and their position in the plot?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen39-slide41/text.txt": [
        "What advantage do attention-based systems have over models that use fixed-size vectors to represent sentence meaning?",
        "According to Raymond Moody, what problem does the text refer to when it comes to representing sentence meaning in a single fixed-size vector?",
        "What is the main problem with representing a sentence's meaning in a single fixed-size vector, and how do attention-based systems address this issue?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen40-slide42/text.txt": [
        "What does the text emphasize as the focus of the discussion?",
        "What is the purpose of discussing aspects of meaning in the text?",
        "What is the focus now and what are we aiming to determine?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen41-slide43/text.txt": [
        "How is semantic segmentation applied to pictures according to the text?",
        "How does the author explain the meaning of a sentence using the analogy of semantic segmentation in pictures, specifically referencing the example of \"people in blue coat\" referring to two little boys?",
        "What is semantic segmentation, and how does it involve labeling pixels in pictures, as described in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen42-slide44/text.txt": [
        "What is noted about the stopping of a program in the provided text?",
        "What aspect can be discussed about both computer programs and sentences, according to the text?",
        "What aspect of computer programs is noted to be undecidable in the given text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen43-slide45/text.txt": [
        "What is the structuralist approach to linguistic meaning, and how are units of representation formed across the levels of linguistic description from morphology to semantics, as described in the Textogrammatical Theory by Petrus Gall?",
        "What does the text say about the structuralist approach to linguistic meaning and its relation to the Textogramalical Theory by Petrus Gall?",
        "What is the structuralist approach to linguistic meaning, and how is it defined across different levels according to Petrus Gall's Textogramalical Theory?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen44-slide46/text.txt": [
        "What aspects are discussed in the text when comparing traditional symbolic theories to neural network-based continuous representations in capturing sentence meaning, and how does each approach handle these aspects?",
        "What aspects of sentence meaning are better captured by symbolic theories versus continuous neural representations?",
        "What aspects of sentence meaning are better captured by symbolic theories, and which aspects are better captured by continuous representations, as discussed in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen45-slide47/text.txt": [
        "What is the key aspect that allows understanding complex sentences by composing meanings from elements?",
        "Question: According to Chris Manning, what is the key aspect that understanding complex sentences crucially relies on?",
        "What is crucially needed to understand the meaning of complex sentences according to Chris Manning?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen46-slide48/text.txt": [
        "How can the operations mentioned in the paper help represent hierarchical structures in vectors?",
        "Question: Can recurrent neural networks (RNNs) learn compositional structures, and if so, how consistent is this ability?",
        "What methods are described in the paper for representing structured data using vectors of real numbers, and how do they relate to the ability of recurrent neural networks to learn compositional structures?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen47-slide49/text.txt": [
        "How should ambiguity in sentences be modeled, given that sentence embeddings are deterministic and may not adequately capture multiple meanings?",
        "What is the main issue with using deterministic encoders for creating sentence embeddings when dealing with ambiguous expressions?",
        "What does the author suggest about how ambiguity should be modeled in the context of sentence embeddings?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen48-slide50/text.txt": [
        "What problem do stateless models face due to their deterministic mapping of expressions?",
        "What is the advantage of the decoder's state representation over the encoder's statelessness in handling ambiguity and tasks like processing jokes?",
        "What is the role of Polnes in language processing tasks, and how does the decoder's state representation improve upon stateless models in addressing ambiguity?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen49-slide51/text.txt": [
        "What was the outcome of the experiment conducted by Markus Dreyer and Daniel Marku in 2012 regarding the number of possible translations of Arabic sentences into English?",
        "How many possible translations were produced for an Arabic sentence in the experiment conducted by Markus Dreyer and Daniel Marku in 2012?",
        "How many translations were produced for an Arabic sentence in the experiment conducted by Markus Dreyer and Daniel Marku in 2012?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen50-slide52/text.txt": [
        "Do paraphrased sentences with different word reorderings share similar embeddings in sentence embedding spaces?",
        "What phenomenon does the text explore regarding the impact of paraphrasing in Czech?",
        "Do the various paraphrased Czech versions of an English sentence form a tight cluster in the embedding space, or do they interfere with the embeddings of other English sentences?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen51-slide53/text.txt": [
        "What process is described for exploring the continuous space of sentences?",
        "What process is described for exploring the continuous space of sentences, involving human informants and annotators?",
        "What is the process described for exploring and organizing the continuous space of sentences based on human input?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen52-slide52/text.txt": [
        "What is the common theme among all the sentences in the TEXT?",
        "What is the common characteristic of the sentences in the TEXT?",
        "What is the relationship between the input sentence and the generated sentences in terms of meaning?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen53-slide53/text.txt": [
        "What is the process described for modifying sentences and how are the resulting sentences related to a manifold of embeddings?",
        "What is the purpose of organizing the sentences into a partial ordered set and relating it to the manifold of some embeddings?",
        "What is the process described for organizing sentences and relating them to embeddings?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen54-slide54/text.txt": [
        "Which of the following are types of sentence modifications discussed in the text?  \nA) Politeness  \nB) Tense  \nC) Belief  \nD) Willingness  \nE) All of the above",
        "What are the different types of modifications discussed in the text?",
        "What are the different types of modifications that can be applied to a sentence?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen55-slide55/text.txt": [
        "How can incomplete or vague expressions still be understandable in communication?",
        "What is the purpose of using vague expressions when someone is out of words?",
        "What is the purpose of using vague expressions like \"do the thingy there,\" and how does context help in understanding them?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen56-slide56/text.txt": [
        "What is the main concept demonstrated by the pairs of sentences in the text?",
        "What is the relationship between the pairs of sentences provided in the TEXT regarding their politeness levels?",
        "What does the text illustrate about the pairs of sentences provided?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen57-slide57/text.txt": [
        "What dimension are the annotators asked to consider when creating sentences for the study?",
        "How many different sentences did the annotators create to express the request, ranging from less polite to more polite?",
        "What does the text suggest about the sentences created by annotators in terms of politeness and rudeness, using the example of asking someone to move?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen58-slide58/text.txt": [
        "What did they ask the third set of annotators to do with all the different wordings?",
        "What is the purpose of involving a third set of annotators?",
        "What method was suggested to organize the different wordings?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen59-slide59/text.txt": [
        "Can we identify comparable relations between sentences in the poset based on their politeness levels?",
        "Can similar relations be established between sentences that are initially incomparable in a partially ordered set, potentially through indirect means such as transitivity?",
        "Can we identify comparable relationships between sentences in a partially ordered set (poset) where some sentences are incomparable in terms of politeness or rudeness, and if so, how can we detect these relations?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen60-slide60/text.txt": [
        "What is the goal of the process described in the TEXT when dealing with highly dimensional spaces?",
        "What is the purpose of unfolding the manifold in the context of the learned representation?",
        "What is the goal regarding the structure in the highly dimensional space when dealing with learned representations?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen61-slide61/text.txt": [
        "Which continuous representation was found to have a better match with the manually collected data?",
        "Is the partial ordered set structure a better continuous representation for matching manually collected data compared to other continuous representations?",
        "What is being evaluated in terms of its match with manually collected data?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen62-slide62/text.txt": [
        "What is the main topic of the provided TEXT?",
        "What methods are used to evaluate sentence representations based on the provided TEXT?",
        "What is the purpose of evaluating sentence representation?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen63-slide63/text.txt": [
        "What is SenteVal and what is it primarily used for in the context of sentence representations?",
        "What is SenteVal primarily used for?",
        "What is SenteVal and what is it primarily used for?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen64-slide64/text.txt": [
        "What was the main purpose of the 2018 experiment described in the text, and what was used to assess the relationship between semantic representations and translation quality?",
        "What was the main goal of the 2018 experiment regarding the attention model's semantic representations in the sequence-to-sequence architecture?",
        "What was the main goal of the experiment described in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen65-slide65/text.txt": [
        "What does the Senteval evaluation tool do with the neural network representations of sentences to assess their quality?",
        "What is the purpose of the Senteval evaluation when processing a movie review with a neural network?",
        "What is the purpose of using Senteval when evaluating neural network representations of movie reviews?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen66-slide66/text.txt": [
        "What is the consequence of a sentence representation that does not effectively highlight important aspects for a classification task?",
        "What would happen to the classification task if the sentence representation did not highlight the important things in the reference source?",
        "What happens to the classification task if the representation does not highlight the important things in the reference?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen67-slide67/text.txt": [
        "What are the specific classification tasks mentioned in the text?",
        "What are the specific classification tasks mentioned in the text?",
        "Question:  \nBased on the text, identify and explain the classification tasks mentioned and provide an example for each."
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen68-slide68/text.txt": [
        "What are the three possible classifications for pairs of sentence embeddings in natural language inference tasks?",
        "What was the system's incorrect classification of the pair of sentences about the couple at the restaurant and pub?",
        "What is an example of an entailment pair and a neutral pair from the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen69-slide69/text.txt": [
        "What are the two main approaches to evaluate the similarity between two sentences according to the text?",
        "How can sentence similarity be evaluated when human informants are not available to score the similarity of sentence pairs?",
        "What method is used to evaluate sentence similarity when there is no training data available?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen70-slide70/text.txt": [
        "What example is used to illustrate the paraphrase style of evaluation?",
        "What sources of data are mentioned for evaluating the paraphrase style in the TEXT?",
        "What are the many translations of the Chinese sentence considered as in the paraphrase style evaluation?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen71-slide71/text.txt": [
        "What does the Coco dataset consist of?",
        "What is the structure of the Coco dataset in terms of images and their captions?",
        "How many captions are associated with each image in the Coco dataset?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen72-slide72/text.txt": [
        "What do the clusters in the space represent, and how are they evaluated?",
        "**Question:**  \nWhat are the two main types of clusters mentioned in the text, and what do they contain?",
        "What do the clusters correspond to in the context described?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen73-slide73/text.txt": [
        "What is the desired state of clusters according to the Davis Bulldin Index?",
        "What is the purpose of the Davis Bulldin Index?",
        "What is the desired outcome for the clusters when using the Davis Bulldin Index?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen74-slide74/text.txt": [
        "What method evaluates clustering quality by checking if each element's nearest neighbor is in the same cluster?",
        "How can you assess the quality of clustering based on the nearest neighbor of each element?",
        "What does it indicate about the clustering if the nearest neighbor of each element is in the same cluster?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen75-slide75/text.txt": [
        "What method is described for evaluating a classification task?",
        "What evaluation method involves removing data points and using them as a test set after training the classifier on the remaining data?",
        "What is one way to evaluate a classification model as described in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen76-slide76/text.txt": [
        "What limitation does the attention-based sequence-to-sequence model face in terms of sentence representation, and why is concatenating vectors from different decoding steps not a viable solution?",
        "What is the main issue with using the attention-based sequence-to-sequence model for sentence representation, and why is it challenging to apply traditional methods like concatenation for evaluation?",
        "What is a key problem when using a bidirectional encoder with attention mechanism in sequence-to-sequence models for obtaining sentence representations?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen77-slide77/text.txt": [
        "What is one option for creating fixed-size representations while still preserving attachments in the model?",
        "What method can be used to create fixed-size representations without using attention to preserve the attached information in the model?",
        "What is one option mentioned for creating fixed-size representations while potentially preserving attachments in the model without using attention?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen78-slide78/text.txt": [
        "What was the early practice of NullMT concerning the use of encoding directions?",
        "What was the early practice of NullMT regarding the use of encoding directions?",
        "What was the early practice of NullMT regarding the use of encoding directions?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen79-slide79/text.txt": [
        "What technique is described for ensuring a consistent sentence representation size regardless of the sentence length?",
        "What technique is used to ensure the sentence representation is always the same size regardless of the sentence length?",
        "What is the effect of using max pooling or average pooling over all the word vectors in a sentence, and how does it ensure that the resulting sentence representation has a consistent size regardless of the sentence length?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen80-slide80/text.txt": [
        "How does the system determine the number of views it will use when applying inner attention?",
        "What is the key characteristic of the views created by multiple attention heads in the transformer architecture?",
        "What determines the number of different views of the input sentence in inner attention?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen81-slide81/text.txt": [
        "What mechanism allows the decoder to access different parts of the sentence based on the encoder's attention heads?",
        "What does the decoder do with the attention context generated by the encoder's attention heads?",
        "What is the term used to describe the decoder's ability to attend to multiple parts of the sentence using a fixed number of attentional representations?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen82-slide82/text.txt": [
        "What assumption does the transformer-style decoder make about the output sentence?",
        "What assumption does the model make about the output sentence length in terms of the number of words or heads?",
        "What assumption does the transformer-style decoder make about the output sentence in comparison to recurrent networks?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen83-slide83/text.txt": [
        "Which dataset was used for English to German translation?",
        "What differences in datasets were used for training English to Czech and English to German systems, and how did these differences impact the results?",
        "What dataset was used for training the English-to-German translation system, and how does the domain of this dataset affect the results?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen84-slide84/text.txt": [
        "Which model achieved the best performance in terms of BLEU score?",
        "Which model achieved the best performance in terms of BLEU score?",
        "Which model achieved the best performance in terms of BLEU score?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen85-slide85/text.txt": [
        "What conclusion did the researchers draw about the trustworthiness of BLEU scores for English translation evaluation?",
        "Why do they rely on BLEU scores for English translation evaluation?",
        "Why did the researchers decide to trust BLEU scores for English translation quality evaluation?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen86-slide86/text.txt": [
        "Question: Why do setups using inner attention or compound attention perform better according to the text?",
        "Question: Why are inner or compound attention mechanisms beneficial even when their attention points are fixed?",
        "Are attention mechanisms that are restricted to a fixed number of points and cannot change throughout the output sentence still useful?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen87-slide87/text.txt": [
        "Question: How does increasing the number of heads in attention affect the model's score?",
        "What effect does increasing the number of heads in the attention mechanism have on the score, according to the text?",
        "How does the number of heads in attention affect the score?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen88-slide88/text.txt": [
        "What is the focus of the semantic evaluation provided in the text?",
        "Question: Why is the semantic evaluation of the representations learned by the English to Czech machine translation system important?",
        "What is the purpose of the semantic evaluation mentioned in the text?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen89-slide89/text.txt": [
        "What methods are highlighted as excellent for sentence representation tasks, and how does the Bag of Words approach compare when evaluated on the COCO dataset using metrics like Centival average similarity and classification accuracy?",
        "Which sentence representation methods are noted for their effectiveness in classification and similarity tasks, and how do they compare based on the evaluation measures mentioned?",
        "What does the text suggest about the effectiveness of bag of words embeddings compared to neural network systems in representing sentences?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen90-slide90/text.txt": [
        "What does the text suggest about the use of attention in models regarding their performance?",
        "What does the text suggest is better for evaluation tasks?",
        "What is the reason for the harm caused by attention in performance, and what alternative approach is suggested for better results across evaluation tasks?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen91-slide91/text.txt": [
        "How does increasing the number of heads affect performance in semantic tasks compared to translation tasks?",
        "How does increasing the number of attention heads affect performance in semantics tasks compared to translation tasks?",
        "How does increasing the number of attention heads affect performance in semantics tasks compared to translation tasks?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen92-slide92/text.txt": [
        "What is the relationship between BLEU scores and semantic evaluation tasks in machine translation systems, as described in the text?",
        "What is the relationship between BLEU scores and semantic evaluation tasks as discussed in the text?",
        "What does the negative correlation between BLEU scores and semantic tasks suggest about machine translation models?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen93-slide93/text.txt": [
        "What is the impact on the correlation between BLEU scores and other metrics when the transformer model is removed from the evaluation, and why is the suggestion to re-evaluate with deeper recurrent neural networks?",
        "What happens to the correlation between BLEU and other evaluation metrics when the transformer model is removed from the English to German translation evaluation?",
        "What is the impact of removing the transformer model from the English to German evaluation, and how does the suggestion to use deeper recurrent neural networks relate to improving semantic scoring?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen94-slide94/text.txt": [
        "What does each attention head in the eight-head attention model do when the network produces an output word?",
        "What does the attention-attention model with eight heads do when generating a particular output word?",
        "What does each head in the attention-attention model with eight heads focus on when generating an output word?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen95-slide95/text.txt": [
        "What is the order of the yellow and red hats in terms of their usage in the sentences?",
        "What pattern did you observe regarding the order of the yellow and red hats when creating sentences?",
        "What was the observed order of the yellow and red hats in the sentences?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen96-slide96/text.txt": [
        "How does the model divide the sentence structure when applying inner attention during translation?",
        "How does the model divide the sentence when using its attention mechanism for translation?",
        "How is the attention distributed across the sentence in the described translation model, and how does this differ from traditional approaches?"
    ],
    "testset/nmt-class/lecture09-word-and-sent-reprs/screen97-slide97/text.txt": [
        "How does the number of transformer heads affect performance in polarity check tasks, and why does this happen?",
        "Question: \"Why does the text suggest that having more heads in the system could be detrimental to tasks like polarity check?\"",
        "What is the reason that more heads in the system lead to worse performance in polarity check tasks?"
    ],
    "testset/nmt-class/lecture04-alignment/screen01-slide01/text.txt": [
        "Which techniques were highly critical for the phrase-based approach to machine translation, as mentioned in the lecture?",
        "What is the significance of alignment techniques in statistical machine translation according to the lecture?",
        "What is the main focus of the fourth lecture on statistical machine translation?"
    ],
    "testset/nmt-class/lecture04-alignment/screen02-slide02/text.txt": [
        "What is the main focus of the talk, and what key techniques are discussed regarding the processing of data?",
        "What is the main focus of the talk and what are the main techniques discussed regarding data processing?",
        "What is the main focus of today's talk?"
    ],
    "testset/nmt-class/lecture04-alignment/screen03-slide03/text.txt": [
        "Question: Why was word alignment necessary in the previous state of the art for statistical machine translation?",
        "What is the purpose of word alignment in the context of the previous state of the art in machine translation, and how does it contribute to the extraction of translation phrases?",
        "Question: What is the purpose of word alignment in the context of phrase-based machine translation as described in the lecture?"
    ],
    "testset/nmt-class/lecture04-alignment/screen04-slide04/text.txt": [
        "What does the speaker emphasize as the starting point?",
        "What does the speaker prioritize as the foundation of their approach?",
        "What is the starting point for the data?"
    ],
    "testset/nmt-class/lecture04-alignment/screen05-slide05/text.txt": [
        "What was the outcome of the Davaho project in terms of the Czech-English corpus?",
        "What happened to the Davaho project, which aimed to translate English Wikipedia into Czech?",
        "What are the various types of texts or data sources that were used to gather data for the Czech-English translation corpus?"
    ],
    "testset/nmt-class/lecture04-alignment/screen06-slide06/text.txt": [
        "What percentage of the data did the community-supplied localization texts account for in terms of sentences and words?",
        "What percentage of the data was composed of legal texts?",
        "What percentage of the data did the community-supplied localization texts contribute in terms of sentences and tokens?"
    ],
    "testset/nmt-class/lecture04-alignment/screen07-slide07/text.txt": [
        "What percentage of the translations were precise and flawless?",
        "What percentage of the monthly corrections to the Navajo project were either precise and flawless translations or reasonably good translations?",
        "What percentage of the translated segments had a vandalism level?"
    ],
    "testset/nmt-class/lecture04-alignment/screen08-slide08/text.txt": [
        "What does the text suggest about the quality of community supply data when contributors are identifiable versus anonymous?",
        "Why does the quality of contributions improve when contributors are identifiable by their real names or nicknames?",
        "How does the quality of community supply data differ when contributors are anonymous versus when they contribute under their own names or nicknames?"
    ],
    "testset/nmt-class/lecture04-alignment/screen09-slide26/text.txt": [
        "What issue was highlighted by the author regarding the availability of data for machine translation systems, and what is the potential impact of this issue?",
        "How does the text describe the relationship between the availability of community translations and professional translations in terms of data size?",
        "What is the estimated total number of tokens that could be available for training machine translation systems if community translations of proprietary texts and other proprietary translations with unclear licenses are included?"
    ],
    "testset/nmt-class/lecture04-alignment/screen10-slide10/text.txt": [
        "What does the text say about the legal status of subtitles created by translating movie content without permission?",
        "What is the legal status of subtitles used for translation training, and how are they treated in the Czech Republic for non-commercial research purposes?",
        "What issue does the text mention regarding the copyright labeling of community-supplied data?"
    ],
    "testset/nmt-class/lecture04-alignment/screen11-slide11/text.txt": [
        "What type of sentences are primarily used in the in-domain test set?",
        "What are the two axes used to evaluate translation quality in the described evaluation framework?",
        "What are the two evaluation axes mentioned, and how are they ordered in terms of their importance?"
    ],
    "testset/nmt-class/lecture04-alignment/screen12-slide12/text.txt": [
        "What issue arises when using only correctly labeled Community Supply Translations?",
        "What issue arises when relying solely on correctly labeled Community Supply Translations, and what is the percentage of untranslated words?",
        "What issues arise when relying solely on correctly labeled Community Supply Translations?"
    ],
    "testset/nmt-class/lecture04-alignment/screen13-slide13/text.txt": [
        "What aspect of the translation quality has been significantly reduced?",
        "What are the two community contributions mentioned, and what issue was identified with the subtitles?",
        "What two community contributions are mentioned, and how have they affected translation quality?"
    ],
    "testset/nmt-class/lecture04-alignment/screen14-slide14/text.txt": [
        "How does including proprietary translations affect the translation quality compared to the vocabulary rate?",
        "What effects occur when proprietary translations, which are out of the domain, are included in the translation process?",
        "What does the TEXT suggest about the impact of including proprietary translations outside the domain on translation quality and related aspects?"
    ],
    "testset/nmt-class/lecture04-alignment/screen15-slide15/text.txt": [
        "What were the results in terms of BLOF score and autofocular rate when all datasets except the in-domain training data were used?",
        "What result was achieved when all datasets except for the in-domain training data were used?",
        "What happened when the in-domain training data was excluded from the datasets used?"
    ],
    "testset/nmt-class/lecture04-alignment/screen16-slide16/text.txt": [
        "What does the text say about the impact of training data in the same domain as the test set on translation quality?",
        "What is considered the ideal situation for improving translation quality according to the text?",
        "What is the impact on translation quality when the training data is from the same domain as the test set?"
    ],
    "testset/nmt-class/lecture04-alignment/screen17-slide17/text.txt": [
        "Does extending your collection with professional translations damage sentence quality?",
        "What happens to the sentence quality when someone extends their collection with professional translations?",
        "What is the impact of extending your collection with professional translations on sentence quality?"
    ],
    "testset/nmt-class/lecture04-alignment/screen18-slide18/text.txt": [
        "What is the potential impact of incorporating auto-domain data and community-supplied translations on translation quality?",
        "What are the effects of including auto-domain data and community-supplied translations on vocabulary and translation quality?",
        "How does including auto-domain data and community-supplied translations affect translation quality according to the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen19-slide19/text.txt": [
        "Question: Why is in-domain training data of little use for out-of-domain translation tasks?",
        "Why is in-domain training data not effective for out-of-domain translation tasks?",
        "What issue arises when using in-domain training data for out-of-domain translation tasks?"
    ],
    "testset/nmt-class/lecture04-alignment/screen20-slide20/text.txt": [
        "What is the relationship between the BLEU scores of professional translations and community translations in the context of the discussed dataset?",
        "What does the text suggest about the BLEU scores when comparing professional translations to community translations?",
        "How do the BLEU scores of community translations compare to those of professional translations in the provided plots, and what might explain this difference?"
    ],
    "testset/nmt-class/lecture04-alignment/screen21-slide21/text.txt": [
        "What advice does the text provide regarding the use of data in machine translation, and how does it relate to knowing the domain and the impact on BLEU scores and out-of-vocabulary rates?",
        "What advice is given for machine translation when the domain is unknown, and what is recommended when the domain is known?",
        "What advice is given about using data in translation models when the domain is not known?"
    ],
    "testset/nmt-class/lecture04-alignment/screen22-slide22/text.txt": [
        "What is the total amount of data in version 2.0 of Cheng, and what are the sources of this data?",
        "What is the size of the Czech-English corpus in version 2.0 of Cheng?",
        "What was the total amount of text used in Cheng 2.0, combining both genuine parallel and synthetic texts?"
    ],
    "testset/nmt-class/lecture04-alignment/screen23-slide23/text.txt": [
        "What methods are needed to create a corpus that is automatically sentence and word level aligned?",
        "What methods are needed to create a corpus that is automatically sentence and word level aligned?",
        "What methods are necessary to create a corpus that's automatically aligned at both the sentence and word levels?"
    ],
    "testset/nmt-class/lecture04-alignment/screen24-slide24/text.txt": [
        "What is the main challenge when using search engines to gather parallel texts, and what alternative resource is suggested to overcome this issue?",
        "Question: What is BitExtrEER and what is its purpose according to the text?",
        "What was the main issue encountered when using search engines to gather seed URLs for creating parallel corpora, and what alternative resource was suggested to address this problem?"
    ],
    "testset/nmt-class/lecture04-alignment/screen25-slide25/text.txt": [
        "What was the main challenge faced when using the Common Crawl dataset for extracting parallel sentences, and how was it addressed?",
        "Why was the number of extracted English-Czech sentence pairs from Common Crawl relatively small, and what approach was suggested to address this issue?",
        "Why did the Common Crawl result in a small number of extracted Czech-English sentence pairs?"
    ],
    "testset/nmt-class/lecture04-alignment/screen26-slide26/text.txt": [
        "What is the next step after finding pairs of texts, and how are sentences aligned for any pair of languages without knowing anything about them?",
        "What is the next step in aligning sentences when working with any pair of languages without prior knowledge of them?",
        "What is the next step after identifying pairs of texts when aligning sentences between two languages without prior knowledge of the languages?"
    ],
    "testset/nmt-class/lecture04-alignment/screen27-slide27/text.txt": [
        "What symbol in Hindi corresponds to the full stop in English, and how does it help in aligning sentences when translating between the two languages?",
        "The symbol in Hindi equivalent to the full stop in English is the danda.",
        "What is the danda in the Devanagari script and what is its purpose in the context of aligning English and Hindi sentences?"
    ],
    "testset/nmt-class/lecture04-alignment/screen28-slide28/text.txt": [
        "What is the critical parallel aspect observed between the sentence lengths of translated texts in the discussion?",
        "What is the critical parallel aspect observed when sentences in two languages are placed side by side without alignment, assuming they are translations of each other?",
        "What is the main observation regarding sentence length and its role in the alignment processing of translated texts?"
    ],
    "testset/nmt-class/lecture04-alignment/screen29-slide29/text.txt": [
        "What is the primary tool for sentence alignment mentioned in the text?",
        "What tool is mentioned as the standard for sentence alignment according to the TEXT?",
        "What is the standard tool for sentence alignment discussed in the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen30-slide30/text.txt": [
        "What is the main limitation of word alignment as described in the text?",
        "What is the formal restriction on word alignments, and how does this affect their structure?",
        "What is the main limitation of the word alignment algorithms discussed in the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen31-slide31/text.txt": [
        "What is a key limitation of IBM Model 1 in the context of translation?",
        "What is the main issue with IBM Model 1's lexical alignments when there are duplicate words in the text?",
        "What is a key limitation of IBM Model 1 that affects its ability to perform accurate translations?"
    ],
    "testset/nmt-class/lecture04-alignment/screen32-slide31/text.txt": [
        "Who is the creator of the slides, and how many years old are they?",
        "How old are the slides by Philip Cain?",
        "Who created the slides mentioned by Philip Cain?"
    ],
    "testset/nmt-class/lecture04-alignment/screen33-slide32/text.txt": [
        "How can probability scoring help in the process of lexical translation as described in the text?",
        "What method is suggested to improve the accuracy of lexical translation by assigning probability scores to possible translations?",
        "What do people typically do when they need to determine the most appropriate translation of a word using a dictionary?"
    ],
    "testset/nmt-class/lecture04-alignment/screen34-slide32/text.txt": [
        "What is the most common translation of the word \"house\" in the given corpus?",
        "What is the most common translation of the German word \"house\" in the described corpus?",
        "What is an alternative translation of the German word for 'house' mentioned in the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen35-slide33/text.txt": [
        "What have we defined in the context of lexical probability between English and German words?",
        "What is the probability being calculated for each possible English word given a German word?",
        "What term describes the probability of an English word given a German word in this context?"
    ],
    "testset/nmt-class/lecture04-alignment/screen36-slide34/text.txt": [
        "What is the purpose of alignment in the context of the corpus, as described in the TEXT?",
        "What does alignment refer to in the context of the corpus, and how is it demonstrated in the given example of the sentence pair?",
        "How does the text illustrate the concept of alignment using the German and English sentence example?"
    ],
    "testset/nmt-class/lecture04-alignment/screen37-slide35/text.txt": [
        "What is the purpose of an alignment function in the context of mapping between source and target words?",
        "What is alignment defined as in the text?",
        "What is the formal definition of alignment as described in the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen38-slide36/text.txt": [
        "What is the result of the mapping when position 3 is mapped?",
        "What position does each position map to in the given mapping?",
        "What is the result of mapping position 3 to position 3?"
    ],
    "testset/nmt-class/lecture04-alignment/screen39-slide37/text.txt": [
        "What does the alignment function allow when reordering words, and provide an example from the text?",
        "What does the alignment function allow us to do with words?",
        "What is the primary capability of the alignment function described in the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen40-slide38/text.txt": [
        "Why doesn't the function need to be a bijection in the context of one-to-many translations?",
        "What is the capability of the translation function regarding one-to-many translations and why is it not considered a bijection?",
        "What is one capability of the function described in the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen41-slide39/text.txt": [
        "What can be done to source language words if there is no corresponding target word in the target language?",
        "What occurs to source language words during translation when they have no corresponding target language words?",
        "What happens to source words if none of the target language words map to them?"
    ],
    "testset/nmt-class/lecture04-alignment/screen42-slide40/text.txt": [
        "What does mapping a word to a position of zero indicate in the context of handling words without a counterpart in the target language?",
        "How can a word in the source language that has no counterpart in the target language be represented?",
        "What happens when a word has no counterpart in the other language during translation according to the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen43-slide41/text.txt": [
        "What is the IBM Model 1 and how does it define the probability of a target sentence given a source sentence?",
        "What is the primary component of the IBM Model 1 and how does it function in the context of machine translation?",
        "What is the primary method used by the IBM Model 1 for translation?"
    ],
    "testset/nmt-class/lecture04-alignment/screen44-slide26/text.txt": [
        "How does IBM Model One compute the probability of a target sentence given a source sentence?",
        "What method does IBM Model One use to calculate the probability of a target sentence given a source sentence?",
        "What is the method for calculating the probability of a source sentence in IBM Model One, and how is it derived from the lexical probabilities of individual words?"
    ],
    "testset/nmt-class/lecture04-alignment/screen45-slide43/text.txt": [
        "What is the \"chicken neck problem\" mentioned in the text, and how does it relate to estimating lexical probabilities from a parallel corpus?",
        "What is the chicken and egg problem mentioned in the context of estimating lexical probabilities from a parallel corpus, and how is it described?",
        "What is the main issue discussed in the text regarding the estimation of lexical probabilities from a parallel corpus?"
    ],
    "testset/nmt-class/lecture04-alignment/screen46-slide44/text.txt": [
        "What is the general process of the EM algorithm when dealing with incomplete data?",
        "What are the two main steps of the EM algorithm, and how does it handle incomplete data?",
        "What is the primary purpose of the EM algorithm as described in the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen47-slide45/text.txt": [
        "What is the initial probability of linking \"",
        "What does the text say about the initial lexical probabilities and how they are used to link words like \"la\" and \"maison\" with their English counterparts?",
        "How are lexical probabilities initialized at the beginning in the described system?"
    ],
    "testset/nmt-class/lecture04-alignment/screen48-slide46/text.txt": [
        "What happens to the alignment link between \"the\" and \"la\" after one iteration of the model?",
        "What does the model notice about the co-occurrence of \"the\" with \"la\" and \"meson\" after one iteration?",
        "What does the model realize after one iteration about the co-occurrence of certain words?"
    ],
    "testset/nmt-class/lecture04-alignment/screen49-slide28/text.txt": [
        "What principle explains why words not covered in other sentences get aligned to each other, as mentioned in the TEXT?",
        "What principle ensures that words like \"flower\" will eventually align to \"flare\" when other alignment options are already occupied, as explained in the text?",
        "**Question:**  \nWhy does the word \"flower\" align with \"flare\" according to the pigeonhole principle?"
    ],
    "testset/nmt-class/lecture04-alignment/screen50-slide26/text.txt": [
        "What is a key advantage of the method described in the text when it converges to a global optimum?",
        "What does the convergence process reveal about the alignment of words after quickly reaching a global optimum?",
        "What does the model learn about word alignment when convergence occurs, given that it reaches a global optimum and converges quickly?"
    ],
    "testset/nmt-class/lecture04-alignment/screen51-slide26/text.txt": [
        "What method is used to calculate the conditional probability based on the observations of the corpus?",
        "How can we calculate the conditional probability of LAW given the observed occurrences of \"the\" in the corpus?",
        "What is the method described for calculating conditional probabilities in the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen52-slide26/text.txt": [
        "What are the two main steps of the Expectation Maximization algorithm in the context of IBM Model 1, and what does each step involve?",
        "What are the two main steps of the Expectation Maximization algorithm, and what do they involve?",
        "What are the two main steps of the Expectation Maximization algorithm, and what do they involve according to the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen53-slide26/text.txt": [
        "What is the main focus when discussing the formulas and how detailed can we cover them?",
        "How detailed can we cover the formulas based on the previous TEXT?",
        "What can be determined in detail using the formulas discussed?"
    ],
    "testset/nmt-class/lecture04-alignment/screen54-slide26/text.txt": [
        "What is the probability of the alignment where \"la\" is aligned to \"the\" and \"mezon\" is aligned to \"house\" in the IBM Model One?",
        "What is the probability of the alignment where \"la\" corresponds to \"the\" and \"meson\" corresponds to \"house\" given the source sentence \"la mezon\" and the target sentence \"the house,\" and what are the updated lexical probabilities for \"the\" and \"house\" after applying the IBM Model One?",
        "What is the process for determining the most probable alignment between \"la mezon\" and \"the house\" using IBM Model One, and how are the lexical probabilities updated based on this alignment?"
    ],
    "testset/nmt-class/lecture04-alignment/screen55-slide26/text.txt": [
        "What is the formula for alignment probability in IBM Model One, as described by the chain rule, where the numerator is the alignment definition and the denominator is the probability of the target sentence given the source?",
        "What is the method for computing the probability of an alignment in IBM Model One, and how does the chain rule apply to it in terms of numerator and denominator?",
        "What are the components of the formula used to compute the alignment probability in IBM Model One, and how does the chain rule apply to it?"
    ],
    "testset/nmt-class/lecture04-alignment/screen56-slide26/text.txt": [
        "What does it mean to \"sum over all possible alignments\" when calculating the probability of a target sentence given a source sentence?",
        "What does it mean to sum over all possible alignments when calculating the probability of a target sentence given a source sentence?",
        "What is the role of the alignment matrix in calculating the probability of a target sentence given a source sentence using IBM Model 1?"
    ],
    "testset/nmt-class/lecture04-alignment/screen57-slide26/text.txt": [
        "The text provided is insufficient to generate a meaningful question.",
        "What is the main topic of the provided text?",
        "What does \"this\" refer to in the given text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen58-slide26/text.txt": [
        "It seems the provided text is incomplete or unclear. Could you please provide the full content of the slide so I can generate an appropriate question?",
        "What is this slide about?",
        "What is the speaker inviting the audience to do regarding the slide?"
    ],
    "testset/nmt-class/lecture04-alignment/screen59-slide26/text.txt": [
        "The probability of the alignment is the product of the translation probabilities for each source-target word pair, assuming independence.",
        "What is the main component of the IBM model 1, and how does it rely on lexical translation probabilities and the full probability of the target given the source across all alignments?",
        "What are the two main components of the IBM Model 1 used to calculate the probability of alignment between source and target sentences?"
    ],
    "testset/nmt-class/lecture04-alignment/screen60-slide26/text.txt": [
        "What is the main issue with summing over all possible alignments, as described in the text?",
        "Why is summing over all possible alignments not ideal when placed in the denominator?",
        "Question: Why is summing over all possible alignments particularly challenging when it comes to the denominator?"
    ],
    "testset/nmt-class/lecture04-alignment/screen61-slide26/text.txt": [
        "What algebraic technique allows swapping sums and products, and how does it help in calculating the probability of the target sentence given the source?",
        "What is the method used to swap sums and products in the context of estimating the probability of a target sentence given the source?",
        "How does the trick of swapping sums and products work, and what is its purpose in calculating the probability of the target sentence given the source?"
    ],
    "testset/nmt-class/lecture04-alignment/screen62-slide26/text.txt": [
        "What is the key concept demonstrated by swapping the sum and product?",
        "Question: How does the formula allow the sum and product to be swapped?",
        "What is the trick where the sum and the product were swapped?"
    ],
    "testset/nmt-class/lecture04-alignment/screen64-slide26/text.txt": [
        "What does the text describe as the relationship between the sum of all pairs and the product of summations in the context of a full graph?",
        "What is the process of regrouping the sum of all pairs into a product of summations?",
        "What is the key insight about regrouping the sum of all pairs into a product of summations?"
    ],
    "testset/nmt-class/lecture04-alignment/screen66-slide26/text.txt": [
        "What is the role of normalization in the alignment process, and how does it contribute to the tractability of the computation?",
        "How is the alignment probability computed in IBM Model 1 given the source and target sentences, and what simplification is applied using the chain rule to make the computation tractable?",
        "How is the probability of alignment between source and target sentences computed in the IBM Model 1, considering the alignment points and the simplification involving the chain rule?"
    ],
    "testset/nmt-class/lecture04-alignment/screen67-slide26/text.txt": [
        "What are the fractional counts used for in the described method?",
        "What is the purpose of using fractional counts derived from word alignment between source and target sentences?",
        "What is the purpose of using fractional counts in the described process?"
    ],
    "testset/nmt-class/lecture04-alignment/screen68-slide26/text.txt": [
        "How is the maximum likelihood estimate for lexical probabilities calculated based on the given text?",
        "How is the maximum likelihood estimate determined when calculating lexical probabilities based on the sum of fractional counts and the fractional count associated with a target word?",
        "What is the method described in the TEXT for computing the maximum likelihood estimate?"
    ],
    "testset/nmt-class/lecture04-alignment/screen69-slide26/text.txt": [
        "QUESTION: What is the purpose of the function \"process_data\" in the provided pseudocode?",
        "What is the task that the user needs to perform based on the provided pseudocode?",
        "What is the purpose of the `findMax` function described in the pseudocode, and how does it determine the maximum value to print?"
    ],
    "testset/nmt-class/lecture04-alignment/screen71-slide26/text.txt": [
        "What key observation can be made about the alignment of the English word \"White\" with Czech words based on the given corpus?",
        "What observation from the corpus leads to a zero probability for 'White' translating to 'Cerny'?",
        "Question:  \nWhy is there a zero probability that 'White' translates to 'Cerni' in the described model?"
    ],
    "testset/nmt-class/lecture04-alignment/screen73-slide26/text.txt": [
        "What does the IBM Model 2 add to the lexical translation process?",
        "What feature does IBM Model 2 introduce that considers the position of words in a sentence during translation?",
        "What feature does the IBM Model 3 allow that the previous models do not?"
    ],
    "testset/nmt-class/lecture04-alignment/screen74-slide26/text.txt": [
        "What are the main components used by the IBM Model 4 for word alignment in translation?",
        "How does the IBM Model 4 handle word alignment in translation, and what example is provided to illustrate this process?",
        "What are the key components of the IBM Model 4 when used for translation and word alignment, as described in the text?"
    ],
    "testset/nmt-class/lecture04-alignment/screen75-slide26/text.txt": [
        "What is the second item mentioned alongside the IBM Model 4 in the text?",
        "What model is referred to in the text as \"the IBM Model 4\"?",
        "What is referred to as the IBM Model 4 and the..."
    ],
    "testset/nmt-class/lecture04-alignment/screen76-slide26/text.txt": [
        "What is the purpose of using intersection and union in aligning English to Spanish and Spanish to English, and how does it relate to extracting dictionaries or phrase translations?",
        "What are the two primary operations used to combine English-Spanish and Spanish-English alignments, and what are their respective purposes in extracting dictionaries or phrase translations?",
        "What are the two main methods for combining alignments, and what is the name of the heuristic used to enlarge the intersection without reaching the full union?"
    ],
    "testset/nmt-class/lecture04-alignment/screen77-slide26/text.txt": [
        "What is the Symmetrisation heuristics according to the given text?",
        "What criterion is used in the Symmetrisation heuristics for the Grodiag final to include points?",
        "What is the criterion for including points in the Grodiag final according to the Symmetrisation heuristics?"
    ],
    "testset/nmt-class/lecture04-alignment/screen78-slide26/text.txt": [
        "Which words posed the greatest difficulty for humans when aligning words, as observed in the text?",
        "What type of words were the most difficult for humans to align between English and Czech, and why?",
        "Which words in English and Czech were the most difficult for humans to align, and what made them challenging?"
    ],
    "testset/nmt-class/lecture04-alignment/screen79-slide26/text.txt": [
        "What conclusion can be drawn from the comparison of human alignment accuracy and machine alignment performance when the task is well-defined versus when it is not?",
        "What is the main conclusion the author draws about the relationship between task definition and improving automatic alignment algorithms?",
        "Why did the improved model not lead to better alignment results when humans were unsure about the correct alignment?"
    ],
    "testset/nmt-class/lecture04-alignment/screen80-slide26/text.txt": [
        "Identify the two primary reasons for alignment uncertainty between English and Chinese linguistic elements and explain their implications using the example of the word \"was.\"",
        "What are the two types of alignment problems mentioned in the text, and what characteristics do they have?",
        "What are the two types of alignment problems observed between English and Chinese, and why are they problematic for alignment tasks?"
    ],
    "testset/nmt-class/lecture04-alignment/screen81-slide26/text.txt": [
        "What surprised the researchers when two groups annotated the same test set independently without knowing each other's work?",
        "What happened when two independent groups annotated the same dataset using the same linguistic theory?",
        "What does the study suggest about the consistency of linguistic annotation when based on a shared theoretical framework?"
    ],
    "testset/nmt-class/lecture04-alignment/screen82-slide26/text.txt": [
        "What is the tectogrammatic layer and how are auxiliary words treated in its deep syntactic representation?",
        "What is the essential idea of the tectogrammatic layer and how are auxiliary words treated in this representation?",
        "In the tectogrammatic layer, how are auxiliary words treated?"
    ],
    "testset/nmt-class/lecture04-alignment/screen83-slide26/text.txt": [
        "What were the key observations regarding the use of \"texogrammatic nodes\" for machine translation?",
        "What was the main observation made by the colleague regarding the task?",
        "What was the main goal of the approach described in the TEXT?"
    ],
    "testset/nmt-class/lecture04-alignment/screen84-slide26/text.txt": [
        "What is the key assumption behind the LEAF approach, and how does it align with the RIS method in terms of handling auxiliaries and headwords across languages?",
        "What is the main assumption behind the LEAF approach in linking words across languages?",
        "What is the key idea behind the LEAF approach in natural language processing?"
    ],
    "testset/nmt-class/lecture04-alignment/screen85-slide26/text.txt": [
        "\" Why do people not use the technique of moving from word alignment to phrase alignment in translation?\"",
        "What statistical problem did word alignments face in phrase-based machine translation before the advent of NeuralMT?",
        "Why are word alignments considered problematic in machine translation and what technique was used to address this issue, but ultimately led to limited improvements in translation quality?"
    ],
    "testset/nmt-class/lecture04-alignment/screen86-slide26/text.txt": [
        "What does the text caution about the use of better translations and their effect on alignment?",
        "According to the text, what potential issue can arise when using a better translation of a text?",
        "What example does the text provide to illustrate how a better translation can result in alignment becoming less reachable?"
    ],
    "testset/nmt-class/lecture04-alignment/screen87-slide32/text.txt": [
        "How does the Czech sentence indicate the start date of the routes compared to the English sentence?",
        "What is the difference in the structure of time expressions between Czech and English as illustrated in the example?",
        "How does the English sentence structure differ from the Czech in expressing the start time of the routes?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen01-slide01/text.txt": [
        "What is the basic architecture discussed in the lecture on NeuralMT, what is added to it, and what more advanced model is mentioned as the next topic?",
        "What key component is added to the sequence-to-sequence architecture in this lecture?",
        "What are the main topics covered in the third lecture on statistical machine translation?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen02-slide02/text.txt": [
        "What are the basic building blocks of neural networks that will be briefly reviewed first in today's lecture?",
        "What are the key topics covered in the lecture on neural networks and language models?",
        "What is the final critical concept discussed in the presentation?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen03-slide03/text.txt": [
        "What is the basic component that we are going to build based on the provided text?",
        "What is the basic architecture that we are going to build?",
        "What architecture are they going to build?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen04-slide04/text.txt": [
        "What is discussed about the construction of neural networks in the middle of the text?",
        "How are neural networks constructed?",
        "What is the middle part of a neural network?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen05-slide03/text.txt": [
        "What does the lecture suggest about the relationship between the system's architecture and linguistics in understanding sentence meaning?",
        "How is the meaning of the sentence handled in the lecture?",
        "How does the lecture explain the relationship between the architecture, mathematics, and linguistics in handling the meaning of sentences?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen06-slide05/text.txt": [
        "What are the three main components used in the transformation of inputs in a fully connected layer as described in the text?",
        "What are the three main components involved in the transformation of inputs into outputs in a fully connected layer of a neural network, as described in the text?",
        "What is the basic building block of neural networks as described in the text?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen07-slide06/text.txt": [
        "What type of transformation does a single layer perform on the input data, and how do the weight matrix, bias vector, and non-linearity contribute to this transformation?",
        "What is the purpose of the non-linearity in the neural network layer described, and how does it affect the coordinate space?",
        "What transformation does each neural network layer perform on the coordinate system, and what roles do weight matrices and bias vectors play in this process?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen08-slide07/text.txt": [
        "What component of the network allows it to change the size of the vector in the first example?",
        "What is the role of weight matrices in changing the size of the vector in the example?",
        "What components are used to define the structure of a neural network, including the number of layers, the size of the representations, and how weight matrices change the size of the vector?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen09-slide05/text.txt": [
        "What was scaled up to three coordinates in a complex system?",
        "What is the process of scaling the inner representation from two coordinates to three coordinates using the weight matrix in a complex system?",
        "Question: How does the weight matrix affect the scaling of the inner representation's coordinates?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen10-slide07/text.txt": [
        "What is the role of backpropagation in the training of a neural network as described in the text?",
        "How does a neural network process an input vector and adjust its parameters to minimize error?",
        "What steps does a neural network take to process an input vector and produce an output vector?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen100-slide83/text.txt": [
        "Why were the results of the two systems described in the text incomparable?",
        "What were the main reasons the results of the two systems were considered incomparable?",
        "Why were the results of the two systems considered incomparable?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen101-slide84/text.txt": [
        "What does the text suggest about comparing the attention model with the encoder-decoder architecture?",
        "What does the text suggest about comparing attention models to encoder-decoder architectures?",
        "What does the text reiterate about the importance of comparing attention models and encoder-decoder architectures?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen11-slide08/text.txt": [
        "What is the network's capability in classifying points that are near the training examples, and how does this relate to its ability to interpolate and perform accurate classifications?",
        "How does the neural network with four layers manage to linearly separate the red and blue points on the x-y plane during training?",
        "What does the network demonstrate the ability to do when classifying points near the training examples?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen12-slide09/text.txt": [
        "What method do recurrent neural networks use to handle variable-length inputs, and how is the computation structured to accommodate this?",
        "What is the primary method used by recurrent neural networks to handle variable-length input sequences, and why is a fixed maximum length employed in practice?",
        "How do recurrent neural networks (RNNs) handle processing variable-length input sequences?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen13-slide10/text.txt": [
        "What is the main problem with the vanilla recurrent neural network's state transformation as described in the text?",
        "What is one major issue with the vanilla recurrent neural network's transformation as described?",
        "What is the main issue with the vanilla recurrent neural network's transformation regarding the state representations?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen14-slide11/text.txt": [
        "What is the speaker referring to in the TEXT?",
        "What is the speaker expressing in the given text?",
        "What is the distinction between a straightforward approach and a technically oriented method?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen15-slide10/text.txt": [
        "Why does the vanishing gradient problem occur in deep networks according to the text?",
        "What causes the vanishing gradient problem in deep networks during backpropagation?",
        "Why does the vanishing gradient problem occur during backpropagation in deep networks?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen18-slide07/text.txt": [
        "What is the vanishing gradient problem and why does it occur in deeper networks during backpropagation?",
        "What is a potential issue when the gradients become too small during backpropagation in a deep network?",
        "What is the vanishing gradient problem and how does it affect the training of early layers in a deep network?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen21-slide11/text.txt": [
        "**Question:** Why are two different nonlinearity functions used in GRU units?",
        "Why are two different nonlinearity functions used in Gated Recurrent Units (GRUs)?",
        "What is the purpose of the two gates (reset gate and update gate) in a Gated Recurrent Unit (GRU), and why are two different nonlinearity functions (tanh and sigmoid) used in the GRU cell?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen22-slide12/text.txt": [
        "What is the next step after processing variable input lengths in the context of the text provided?",
        "What is the next step in the process described in the text after handling variable input lengths?",
        "What is the next step in machine translation after processing variable input lengths?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen23-slide13/text.txt": [
        "What problem arises when representing sentences as vectors in English and Czech due to their large dictionary sizes?",
        "What is the main problem mentioned with using columnar vectors to represent words in sentences, especially in languages like English and Czech?",
        "What alternative method can be used to represent sentences when the initial approach of using one-hot vectors is deemed impractical due to its large size?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen24-slide14/text.txt": [
        "What method is suggested in the text to reduce the vocabulary size by combining frequent pairs of characters?",
        "What method is discussed for reducing vocabulary size in one-hot vector representations, and what is the process involved?",
        "What approach is suggested for reducing vocabulary size when dealing with large one-hot representation vectors, as discussed in the text?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen25-slide15/text.txt": [
        "What is the next step after obtaining a vector of 30,000 elements in the vector space, considering the limitations of one-hot encoding discussed previously?",
        "What is the next step after using sub-work units to create a vector with 30,000 elements?",
        "What is the next step after obtaining a vector with approximately 30,000 elements using sub-work units?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen26-slide13/text.txt": [
        "What problem does the text identify with the current word representation method regarding the measurable similarity between words?",
        "What is a key reason the system cannot effectively use 'on' as a substitute for 'kitten,' and how do dense word representations help address this issue?",
        "What limitation does the text identify with using simple binary representations for word vectors, and how does using dense representations help address this issue?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen27-slide15/text.txt": [
        "What is one thing that word embeddings cannot capture effectively according to the text?",
        "How does the training process enable embeddings to capture specific features of words, such as tense or sentiment, and what are some examples of these features?",
        "How do the embeddings of words change when the neural network is trained for different tasks?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen28-slide16/text.txt": [
        "What is the purpose of the softmax normalization in the described neural network model?",
        "Why is hierarchical softmax not commonly used anymore in training these networks?",
        "What is the process by which the neural network emits a word, as described in the text?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen29-slide17/text.txt": [
        "What is Neural Language Modeling stated to be the basis of in the text?",
        "What is Neural Language Modeling the basis of?",
        "What is introduced as the basis in the given text?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen30-slide18/text.txt": [
        "What is the direction of the word embedding mapping, and how is it applied in both the input and output of the model?",
        "What is the primary function of a Neural Machine Translation (NMT) system as described in the text?",
        "What is the role of embeddings in the described neural network model, and how are they utilized during both training and generation?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen31-slide19/text.txt": [
        "What are the two possible views of a recurrent neural network language model?",
        "What are the two views presented on the recurrent neural network language model?",
        "What are the two primary views of the recurrent neural network language model discussed in the text?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen32-slide20/text.txt": [
        "What is the main advantage of using a bidirectional recurrent neural network compared to a unidirectional one?",
        "What is the key benefit of using a bidirectional recurrent neural network?",
        "How does a bidirectional recurrent neural network process its input?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen33-slide22/text.txt": [
        "What makes bidirectional recurrent neural networks particularly effective for natural language processing tasks, as described in the text?",
        "Why are bidirectional recurrent neural networks considered very effective for most natural language processing tasks?",
        "Question: What makes bidirectional recurrent neural networks particularly effective for most natural language processing tasks according to the text?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen34-slide23/text.txt": [
        "What architecture is being discussed in the translation systems?",
        "What architecture is primarily discussed in the context of translation systems in the TEXT?",
        "What architecture is used in translation systems as discussed?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen35-slide24/text.txt": [
        "How is the conditional language model scheme applied in the TEXT?",
        "What method is used to generate exam questions based on the information provided in the TEXT?",
        "What technique is suggested to be used again in the TEXT for generating responses?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen37-slide27/text.txt": [
        "The encoder processes the input sequence of symbols into a single vector representation, which is then used to condition the decoder. The decoder starts its generation process with this vector, using it to guide the output sequence.",
        "What is the role of the encoder in the described language model?",
        "How does the encoder condition the decoder for language model generation?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen38-slide28/text.txt": [
        "What is the role of the decoder in the encoder-decoder architecture described?",
        "What is the purpose of sharing embeddings between the source and target languages in the described encoder-decoder architecture?",
        "What is the purpose of the embeddings in the encoder-decoder architecture, and why are they often shared between the source and target languages?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen39-slide30/text.txt": [
        "What is the initial state of the decoder when implementing the conditional language model?",
        "What is the process followed by the model when generating a translation or response in the target language?",
        "What is the initial state of the decoder and how does it use this state to predict the next word in the target language?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen40-slide32/text.txt": [
        "What is the speaker about to discuss?",
        "What is the topic or subject that the speaker is about to discuss?",
        "What is the speaker going to talk about next?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen41-slide31/text.txt": [
        "What is the origin of the target language tokens in the provided text?",
        "What are the input and output in the given context?",
        "What does the input consist of in the described system?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen42-slide32/text.txt": [
        "What is the initial state of the encoder before it starts processing the input sequence?",
        "What does the final state of the encoder RNN represent after processing all the words in the input sequence?",
        "How is the state of the RNN encoder updated at each time step?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen43-slide33/text.txt": [
        "What is the process followed by the decoder to produce the output word during translation?",
        "What is the role of the output projection layer in the decoder, and how does it use the state and last word to generate the output word?",
        "What is the role of the output projection layer in the decoder, and how does it contribute to the final output?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen44-slide34/text.txt": [
        "What is the primary method used to evaluate how well the output candidate matches the expected output during the training process described in the text?",
        "What is the process for evaluating whether an output candidate matches the expected target, and how are probabilities used in this process?",
        "What method is used to adjust the system when the expected word does not have the highest probability in the output distribution?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen45-slide35/text.txt": [
        "How is the output distribution defined in the context of the given translation discussion?",
        "Question: Why is the output distribution defined as a peaked distribution with a value of 1 for the word seen in the training data and 0 for all other candidate tokens, and what are the implications of this approach?",
        "How is the output distribution defined when the set of all possible translations for a given input sentence is not available?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen46-slide36/text.txt": [
        "What is the relationship between the cross-entropy loss and the distributions produced by the soft-max function and the true distribution in this context?",
        "What is the cross-entropy loss in the context of the soft-max function and the true distribution?",
        "What is the loss computed as in terms of cross-entropy between the distribution produced by the soft-max function and the true distribution, which consists of all zeros and ones?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen47-slide37/text.txt": [
        "What operation is applied to the probability of the expected word in the softmax output to compute the loss?",
        "What is the loss incurred at each position calculated as in the described method?",
        "What is the loss computed as in this method?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen48-slide38/text.txt": [
        "How are the losses computed for each word in the output during the computation of derivatives?",
        "What is the method for computing the total loss in a model where each output word contributes a loss proportional to the negative logarithm of its predicted probability?",
        "What measure is used to compute the loss at each output word during derivative computation?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen49-slide39/text.txt": [
        "What does the speaker claim is the main problem with the training criterion of neural networks for machine translation?",
        "What does the text suggest is a limitation of training neural networks using parallel corpora?",
        "What issue does the author identify with the training criterion of neural networks for machine translation?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen50-slide40/text.txt": [
        "What is the main difference in how the decoder operates during training and when it is used at runtime?",
        "What is the difference in how the decoder is used during training and runtime concerning the output words?",
        "What is the difference in how the decoder operates during training and runtime, particularly in terms of using probability distributions and selecting words?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen51-slide42/text.txt": [
        "What happens at each step during the decoding process?",
        "What does the decoder do at each step during the decoding process?",
        "What does the decoder produce at each step during decoding?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen52-slide43/text.txt": [
        "What is the process described for decoding in the text?",
        "What is the method for decoding mentioned in the TEXT?",
        "What is the method for decoding described in the text?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen53-slide45/text.txt": [
        "What does the described decoding method not require storing, making it efficient?",
        "\" Why is greedy decoding considered suitable for neural networks when decoding sequences? \"",
        "What makes greedy decoding an effective method for neural networks?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen54-slide46/text.txt": [
        "What is a key difference between beam search and greedy decoding in neural network decoding?",
        "What is a disadvantage of greedy decoding compared to beam search, and how does beam search address this issue to produce more accurate final sentences?",
        "What is an advantage of using beam search over greedy decoding when generating sentences?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen55-slide47/text.txt": [
        "What is a hypothesis according to the provided information?",
        "What is a hypothesis, according to the given text?",
        "What is described as a partially decoded sentence with some associated score?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen56-slide48/text.txt": [
        "What is a potential issue with increasing the beam size during beam search in recurrent language models, and how does it relate to their training approach?",
        "\" Why do larger beam sizes in beam search lead to worse sentence production according to the text?\"",
        "What happens when the beam size is increased during beam search with recurrent language models, and why is this the case?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen57-slide49/text.txt": [
        "What does beam search do with the score of the prefix and the probability of the next word to extend the hypothesis?",
        "What is the process used to extend the hypothesis in beam search?",
        "How does beam search extend candidate hypotheses during the search process?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen58-slide50/text.txt": [
        "\"According to the text, why are shorter hypotheses preferred?\"",
        "Question: Why are shorter hypotheses preferred according to the text?",
        "Why does the system prefer shorter hypotheses?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen59-slide51/text.txt": [
        "What do you begin with in the beam during the beam search algorithm?",
        "What is the initial state of the beam in the beam search algorithm?",
        "What does the beam search algorithm begin with?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen60-slide53/text.txt": [
        "What is done in each step of the beam search?",
        "What happens in each step of the beam search process described in the text?",
        "What is the process of extending hypotheses in each step during the beam search?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen61-slide55/text.txt": [
        "How are candidate hypotheses handled in the next step based on the information provided?",
        "What method is used to manage candidate hypotheses in the next step?",
        "What is the process called where candidate hypotheses are scored and a subset of k candidates is preserved for the next step using a phrase-based approach?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen62-slide56/text.txt": [
        "What happens to a hypothesis if it reaches an end of sentence symbol?",
        "What happens to a hypothesis when it reaches the end of sentence symbols?",
        "What action is taken when a hypothesis reaches the end of sentence symbols?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen63-slide57/text.txt": [
        "What are the stopping conditions and the selection process in the described beam search method?",
        "What are the stopping conditions and what is selected when the process ends?",
        "What are the two conditions under which the beam search process stops?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen64-slide58/text.txt": [
        "What is the process for selecting the best hypothesis in the standard phrase-based approach?",
        "What is the method used to determine the best hypothesis in the standard phrase-based approach?",
        "What is the process for selecting the best hypothesis in the standard phrase-based approach?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen65-slide59/text.txt": [
        "What change was necessary to ensure the approach worked well for longer sentences?",
        "What change was made to improve performance for longer sentences?",
        "What modification was made to the network structure to maintain performance with longer sentences?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen66-slide60/text.txt": [
        "What is the goal of attention in the network regarding the source positions at each output time step?",
        "What is the goal of attention in terms of how it treats source positions at any time step of the output?",
        "What is the primary purpose of attention in the network when processing source positions at each output time step?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen71-slide40/text.txt": [
        "What is the primary issue with using a fixed-size representation of the entire input sentence in neural networks, and what approaches were suggested to address this problem?",
        "What is the primary issue with using a fixed-size vector representation of the entire input sentence in neural networks, and what solutions were proposed to address this issue?",
        "What is the main issue discussed regarding the use of a fixed-size vector in neural network architectures for processing input sentences?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen76-slide60/text.txt": [
        "What does the decoder use to determine which source words to focus on at each time step during the attention process?",
        "What is the role of the decoder at each time step in the context of processing the target sentence using attention?",
        "What does the decoder do at each time step regarding the source sentence?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen77-slide61/text.txt": [
        "What component is responsible for writing data to the memory in Neural Turing Machines?",
        "What are the main components of the model inspired by Neural Turing machines mentioned in the TEXT?",
        "What are the key components of a Neural Turing Machine and what is their role in processing information?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen78-slide62/text.txt": [
        "What are the two main methods by which the neural Turing machine addresses its memory?",
        "What are the two primary methods by which the memory in a neural Turing machine can be addressed?",
        "How can the memory in a neural Turing machine be addressed?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen79-slide63/text.txt": [
        "What is at the heart of attention?",
        "What is the primary focus or core aspect of attention, as mentioned in the text?",
        "What is at the heart of attention regarding these new Turing machines?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen80-slide64/text.txt": [
        "What aspect works quite well, but content-based addressing is what is...",
        "What is the effectiveness of content-based addressing?",
        "What aspect is highlighted as the focus in the provided text?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen81-slide66/text.txt": [
        "What does the attention mechanism enable the decoder to do when processing the input sentence?",
        "The attention mechanism allows the decoder to dynamically focus on different parts of the input sentence during each step of the output generation by creating a weighted sum of the encoder's states. The weights are determined based on the decoder's current state and the previous output, enabling the model to adaptively attend to relevant parts of the input as it generates each word in the output sequence.",
        "What does the text suggest is the advantage of using an attention mechanism compared to traditional methods like taking the last element or max pooling of encoder states?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen82-slide67/text.txt": [
        "What is the purpose of the attention weights in the described attention mechanism?",
        "What is the purpose of the attention weights in the described attention mechanism?",
        "What is the purpose of the attention weights in the described attention mechanism, and how are they normalized to achieve this purpose?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen83-slide68/text.txt": [
        "What type of encoder is used in the attention mechanism described, and how is its output utilized in the model?",
        "What is the role of the encoder's output in the decoder during each time step?",
        "How does the decoder access the encoder's output in the described attention mechanism?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen84-slide67/text.txt": [
        "How many items are accessible at each time step?",
        "What is accessible at each time step?",
        "How many items are accessible at each time step?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen85-slide68/text.txt": [
        "What allows the network to attend to any of the words in the input at every step?",
        "What is the purpose of scaling the context vectors with a matrix?",
        "What can the network do at every step regarding the input words?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen86-slide69/text.txt": [
        "What is the role of the attention mechanism in aligning the encoder and decoder states during the decoding process?",
        "How does the attention mechanism create alignment between the encoder and decoder states during the translation process?",
        "What is the key alignment mechanism described in the text when the decoder produces each word?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen88-slide72/text.txt": [
        "What are the key differences in positions discussed in the text?",
        "What are the key differences in positions?",
        "What are the differences between the two positions?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen90-slide72/text.txt": [
        "What are the main causes of the Industrial Revolution as discussed in the text?",
        "What percentage of adults believe in the health benefits of meditation according to the study?",
        "What is the primary reason the painting is considered a significant example of 17th-century art?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen91-slide73/text.txt": [
        "What type of alignment is used in the probabilistic model described, and what is its characteristic?",
        "What is the nature of the distribution over positions and how is the alignment characterized in SMT?",
        "**Question:**  \nIs the alignment from SMT discrete or based on a distribution?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen92-slide74/text.txt": [
        "What type of sentence is described in the text?",
        "What term is used in the text to describe the statement?",
        "What does the text state about being declarative?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen93-slide76/text.txt": [
        "What must the assistant ensure when responding to a query based on the TEXT?",
        "It seems there might be a mistake. Could you please provide the actual text you'd like me to use to generate the exam question?",
        "What is the main goal of the study mentioned in the TEXT?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen95-slide76/text.txt": [
        "How does the role of the language model differ between neural machine translation and classical statistical machine translation approaches?",
        "How does the role of the language model in neural machine translation differ from its role in classical statistical machine translation?",
        "What is the main difference in the role of language models between neural machine translation and classical statistical machine translation?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen96-slide77/text.txt": [
        "Why do the attention patterns in the encoder not always align with the word alignment?",
        "Why do the attention peaks not correspond directly to word alignment in the encoder-decoder model?",
        "\"Explain why attention peaks in encoders and decoders cannot be directly interpreted as word alignment.\""
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen97-slide78/text.txt": [
        "How did Jan Juhlers enhance the attention mechanism in his neural machine translation model, and what did the model learn to do automatically?",
        "What did the neural network learn to do with attention when provided with both the original source and the pre-translated input?",
        "What did the attention mechanism learn to do when given access to both the source sentence and the pre-translation from the classical phrase-based system?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen98-slide79/text.txt": [
        "What kind of attention does the network utilize to focus on specific areas of the image for captioning?",
        "How does the attention mechanism in an attentive image captioner function when generating a caption?",
        "What does the attention mechanism in the network do when it is generating a caption for an image?"
    ],
    "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen99-slide81/text.txt": [
        "Why does the attention mechanism appear worse than the vanilla system when comparing scores from the two papers?",
        "What is the main message about the comparison of attention mechanisms and vanilla systems?",
        "What is the main message the author is conveying about comparing scores from two papers?"
    ],
    "testset/nmt-class/lecture06-morphology/screen01-slide01/text.txt": [
        "What will be the focus of the lecture on machine translation today?",
        "What specific aspect of machine translation is the focus of today's lecture?",
        "What will be the main topic discussed in today's lecture on machine translation?"
    ],
    "testset/nmt-class/lecture06-morphology/screen02-slide02/text.txt": [
        "What are the key issues caused by the rich morphology of Czech in the context of machine translation, and how are these issues addressed in phrase-based and neural machine translation systems?",
        "What are the main challenges of translating into Czech and how do phrase-based and Neural machine translation approaches address these challenges?",
        "What is the main problem caused by the rich morphology of the Czech language in machine translation, and how do phrase-based MT and Neural MT handle this issue?"
    ],
    "testset/nmt-class/lecture06-morphology/screen03-slide03/text.txt": [
        "Why does English require more reliance on word order compared to Czech?",
        "What does the text attribute the flexibility of word order in Czech to be?",
        "What is the primary difference in the morphological systems between Czech and English as described in the text?"
    ],
    "testset/nmt-class/lecture06-morphology/screen04-slide04/text.txt": [
        "What is the additional challenge in translating the word \"saw\" into Czech compared to English, and how does this relate to the overall grammatical complexity of the Czech language?",
        "What additional complexity does translating into Czech involve compared to English?",
        "What are the main challenges in translating into Czech, as described in the text?"
    ],
    "testset/nmt-class/lecture06-morphology/screen05-slide05/text.txt": [
        "Explain the two morphological phenomena discussed in the text and provide examples from the text for each.",
        "What is the difference between compounding and agglutination as discussed in the text?",
        "What is the difference between compounding and agglutination in the context of word formation, and how does this relate to the examples provided in the text?"
    ],
    "testset/nmt-class/lecture06-morphology/screen06-slide06/text.txt": [
        "Why are BLEU scores generally lower for morphologically rich languages when translating from English?",
        "What is one reason that translation systems might see an improvement in BLEU scores when they avoid making mistakes in word forms?",
        "What improvement in BLEU scores can be expected if a machine translation system produces perfect word forms in a morphologically rich language?"
    ],
    "testset/nmt-class/lecture06-morphology/screen07-slide07/text.txt": [
        "Question: How does phrase-based machine translation handle morphology?",
        "What is a key consideration in handling morphology in phrase-based machine translation, and how can it be addressed based on the information provided?",
        "How does phrase-based machine translation handle the challenges of complex morphology in languages with extensive inflection systems, such as Turkish or Finnish, and what strategies are employed to ensure accurate translation of such words without losing grammatical information?"
    ],
    "testset/nmt-class/lecture06-morphology/screen08-slide08/text.txt": [
        "What are the two major components of phrase-based systems and how does complexity increase in each?",
        "What are the two major components of phrase-based systems and what increased complexity do they face?",
        "What are the two major components of phrase-based systems?"
    ],
    "testset/nmt-class/lecture06-morphology/screen09-slide09/text.txt": [
        "What is the main issue with the initial incorrect translation attempts of \"I saw two green striped cats\" into Czech, and why does the second candidate \"dva zelené pruhovány kočky\" not fully resolve the problem?",
        "What issue arises when using a triagram language model for translating the sentence \"I saw two green striped cats\" into Czech, and why is a larger corpus necessary to resolve it?",
        "Why is the translation \"dvou zelená pruhovány kočkách\" considered incorrect, and what does this demonstrate about language models?"
    ],
    "testset/nmt-class/lecture06-morphology/screen10-slide10/text.txt": [
        "Why is the phrase \"dvě zelené pruchované kočky\" problematic in terms of its morphological agreement?",
        "What is the morphological ambiguity in the phrase \"dvě zelené pruchované kočky\" and how does it relate to the noun phrase agreement?",
        "What ambiguity is present in determining the case of the phrase \"dvě zelené pruchované kočky\" based on the morphological analysis provided?"
    ],
    "testset/nmt-class/lecture06-morphology/screen11-slide11/text.txt": [
        "What advantages does using morphological text in language models provide for machine translation systems, as discussed in the TEXT?",
        "The main advantage of using a language model based on morphological text for machine translation is that it improves grammatical coherence by considering morphological agreement and allows for more reliable probability estimation with a smaller vocabulary, enabling the use of longer engrams for better sentence coherence.",
        "What are the advantages of using morphological text in language models, and how does this method enhance grammatical coherence in sentences?"
    ],
    "testset/nmt-class/lecture06-morphology/screen12-slide12/text.txt": [
        "What is required for the translation model to correctly propose the translation of \"kneecaps\" into Czech, considering its various cases?",
        "How many cases does the Czech word \"Češky\" have, and why is a corpus of 50 million sentence pairs necessary to determine the correct translation of \"kneecaps\"?",
        "Why is a large corpus, such as 50 million sentence pairs, necessary for translating the English word \"kneecaps\" into Czech, and what specific word form must be captured?"
    ],
    "testset/nmt-class/lecture06-morphology/screen13-slide13/text.txt": [
        "What are the two components that the factored phrase-based model separates in its translation process?",
        "What is the main innovation of the factored phrase-based model and how does it improve translation?",
        "What does the factored phrase-based model separate in the translation process?"
    ],
    "testset/nmt-class/lecture06-morphology/screen14-slide14/text.txt": [
        "How does the factor phrase-based MT model ensure both vertical and horizontal coherence in the target language?",
        "What types of coherence does the generative model ensure, and how are they maintained in the described translation process?",
        "**Question:** What are the two types of coherence that the generative model ensures, and how are they achieved?"
    ],
    "testset/nmt-class/lecture06-morphology/screen15-slide15/text.txt": [
        "What is the purpose of the predefined sequence of translation and generation steps in the system described?",
        "What is the sequence of steps involved in translating the word \"kneecaps\" into another language using the described system, and how does the system utilize monolingual corpora in this process?",
        "What is the predefined sequence of processes used in the translation system to generate the final word form?"
    ],
    "testset/nmt-class/lecture06-morphology/screen16-slide16/text.txt": [
        "What additional components are considered during the scoring of a translation in the factored phrase-based empty modal model, and how do they contribute to the overall translation quality?",
        "What components are considered when scoring the final translation in the factored phrase-based empty modal model?",
        "What method is used to train the components of the factored phrase-based empty modal model, and how does the addition of more features affect this training process?"
    ],
    "testset/nmt-class/lecture06-morphology/screen17-slide17/text.txt": [
        "What is the basis for phrase extraction in phrase-based machine translation?",
        "What is the basis for extracting phrases in phrase-based machine translation?",
        "What is the primary method used in phrase-based MT extraction as described in the TEXT?"
    ],
    "testset/nmt-class/lecture06-morphology/screen18-slide18/text.txt": [
        "What translation did you learn for \"naturally John\" in the sentence pair provided?",
        "How is \"John\" translated in this context, based on the example provided?",
        "What translation did you learn for \"naturally John\"?"
    ],
    "testset/nmt-class/lecture06-morphology/screen19-slide19/text.txt": [
        "What property does the system use to recognize reorderings in sentences?",
        "What are the syntactic differences when a sentence starts with an adverb in German compared to English, based on the text?",
        "In English sentences that begin with an adverb, where is the verb located?"
    ],
    "testset/nmt-class/lecture06-morphology/screen20-slide20/text.txt": [
        "What example sentence is used to illustrate the benefit of using factored models in the text?",
        "What are the two sentence pairs in the corpus and which cases are mentioned in each?",
        "What benefit does using factored models provide as demonstrated by the two sentence pairs?"
    ],
    "testset/nmt-class/lecture06-morphology/screen21-slide21/text.txt": [
        "What happens if you break the system that extracts the phrase table to work with fully inflected word forms, as mentioned in the TEXT?",
        "What happens if you break it?",
        "How can the database of fully inflected word forms be used to translate phrases like \"starého pána\" and \"černému psobo\"?"
    ],
    "testset/nmt-class/lecture06-morphology/screen22-slide22/text.txt": [
        "Question: How should the translation process be divided into two steps based on the provided text?",
        "What is separated into two parts according to the text?",
        "What is the method suggested for processing and translating specific phrases mentioned in the text?"
    ],
    "testset/nmt-class/lecture06-morphology/screen23-slide23/text.txt": [
        "What can you translate either from the accusative or dative case into English?",
        "How do you translate a sequence of an adjective followed by a noun in either accusative or dative case in German into English?",
        "What can you translate to an adjective and noun sequence in English?"
    ],
    "testset/nmt-class/lecture06-morphology/screen24-slide24/text.txt": [
        "What specific combination of components is used to achieve increased robustness in the described method?",
        "What is the key factor that contributes to the increased robustness mentioned in the text?",
        "How does the combination of lemmas and morphological text from unseen parallel data contribute to increased robustness in the model?"
    ],
    "testset/nmt-class/lecture06-morphology/screen25-slide25/text.txt": [
        "What was the main focus of the slides presented by Philip Kahn at MT Marathon over a decade ago?",
        "What was the main focus of the slides presented by Philip Kahn at MT Marathon more than 10 years ago?",
        "What is the origin of the slides presented in the exam?"
    ],
    "testset/nmt-class/lecture06-morphology/screen26-slide26/text.txt": [
        "What is the process of translating \"Er geht Janich nach Hause\" using phrase-based machine translation?",
        "What is the first step in the translation process when using phrase-based machine translation, as described in the text?",
        "What is the first step in translating the sentence 'Er geht Janich nach Hause' using phrase-based machine translation?"
    ],
    "testset/nmt-class/lecture06-morphology/screen27-slide27/text.txt": [
        "What should you use or search for in the search when selecting the best options?",
        "What is the focus when searching for the best options?",
        "What is being searched for in the search?"
    ],
    "testset/nmt-class/lecture06-morphology/screen29-slide30/text.txt": [
        "What was the percentage reduction in symptom severity observed in the study?",
        "What does the generation of an exam question start with according to the TEXT?",
        "How does the process of generating an exam question based on the provided TEXT work?"
    ],
    "testset/nmt-class/lecture06-morphology/screen30-slide31/text.txt": [
        "What process is described in the text where words are added and hypotheses are appended?",
        "What are the two actions mentioned in the TEXT as being involved in the process of generating a hypothesis?",
        "What action is described as being performed by adding words from the source and appending them to the current hypothesis?"
    ],
    "testset/nmt-class/lecture06-morphology/screen31-slide33/text.txt": [
        "What is the main consideration in making the final choice according to the text?",
        "What are the two main factors considered when making the final choice?",
        "What is the basis for selecting the final choice according to the TEXT?"
    ],
    "testset/nmt-class/lecture06-morphology/screen32-slide34/text.txt": [
        "How is the process of creating translation options changed with factored decoding compared to the past?",
        "How is the expansion of hypotheses in factored decoding made more complex compared to a simple lookup?",
        "How does the process of factored decoding create translation options for a source word like \"house\" and what steps are involved?"
    ],
    "testset/nmt-class/lecture06-morphology/screen33-slide35/text.txt": [
        "What is the main advantage of precomputing the processing steps for translation options, and how does it affect the search process?",
        "What is the main difference in how translation options are now constructed after pre-computation?",
        "How are the translation options now constructed and what impact does this have on the search process?"
    ],
    "testset/nmt-class/lecture06-morphology/screen34-slide36/text.txt": [
        "Why is pruning necessary during the preparation of translation options, and what is a potential consequence of not doing so?",
        "What is the reason for pruning translation options during preparation and what happens if pruning limits are exceeded?",
        "What problem occurs when translation options multiply, and why is pruning important in this context?"
    ],
    "testset/nmt-class/lecture06-morphology/screen35-slide38/text.txt": [
        "What tool or method was used to impose syntactic structure in the described setup?",
        "What approach is described to address the main problem with phrase-based translation methods?",
        "What was the purpose of using a 7-gram language model on part-of-speech tags in the experiment?"
    ],
    "testset/nmt-class/lecture06-morphology/screen36-slide39/text.txt": [
        "Question: Why does the BLEU score increase when tested on English-German or German-English translations, and how does this improvement compare to human judgments?",
        "Does the method improve the BLEU score in English-German translation, and why might human judgments show a better improvement?",
        "Question: According to the text, what limitation of the BLEU score is mentioned as a reason for its small improvement despite better translation quality?"
    ],
    "testset/nmt-class/lecture06-morphology/screen37-slide40/text.txt": [
        "What is the grammatically correct combination of a determiner and a noun in terms of number?",
        "What grammatical consideration should a language model take into account when combining determiners and nouns to avoid incorrect sequences?",
        "Why should the language model avoid certain determiner-noun combinations based on their morphological features?"
    ],
    "testset/nmt-class/lecture06-morphology/screen38-slide41/text.txt": [
        "What does the text suggest as a method for translating lemmas into Česka?",
        "What approach does the text suggest for translating lemmas into Czech?",
        "What is the linguistically motivating example provided for translating lemmas into lemmas in Česka?"
    ],
    "testset/nmt-class/lecture06-morphology/screen39-slide42/text.txt": [
        "Why did the BLEU score drop by 5 points when moving from the part-of-speech model to the linguistically adequate morphological generation model?",
        "Why did the BLEU score decrease when moving to the morphological generation model?",
        "Why did the BLEU score drop by 5 points when moving from the part-of-speech model to the linguistically adequate morphological generation model, and how do independence assumptions contribute to this decline?"
    ],
    "testset/nmt-class/lecture06-morphology/screen40-slide43/text.txt": [
        "What are the two main components integrated by the alternative decoding paths solution, and how is the system trained to balance their use?",
        "What is the method used by the system to combine models for translation, and how does it use minimum error rate training to determine when to trust direct translation versus lemma-based separation?",
        "What are the two main components that the system uses to operate simultaneously in the alternative decoding paths solution?"
    ],
    "testset/nmt-class/lecture06-morphology/screen41-slide44/text.txt": [
        "What is the outcome when both paths are taken according to the TEXT?",
        "What improvement is achieved by taking both paths mentioned?",
        "What happens when both paths are taken according to the text?"
    ],
    "testset/nmt-class/lecture06-morphology/screen42-slide45/text.txt": [
        "What additional information might need to be extracted from the source side during translation, and how can it be identified using examples such as translating from English to German or Czech, Chinese to English, or pronoun translation?",
        "What additional information must be extracted from the source language when translating into German or Czech?",
        "What type of information is needed to be extracted when translating from languages where it might be missing in the source text, such as when translating from Chinese to English?"
    ],
    "testset/nmt-class/lecture06-morphology/screen43-slide46/text.txt": [
        "How is the role of a noun in an English sentence used to determine its case in Greek during translation?",
        "What are the steps one should follow when translating a noun from English to Czech, based on the information provided in the text?",
        "What is the main consideration when determining the case of a noun in the target language during translation?"
    ],
    "testset/nmt-class/lecture06-morphology/screen44-slide47/text.txt": [
        "How does the position of a word in the tree help determine its grammatical case?",
        "What allows you to determine the case of a word in a sentence based on its position in a tree?",
        "How does parsing a sentence and traversing the tree help in determining the case of words?"
    ],
    "testset/nmt-class/lecture06-morphology/screen45-slide48/text.txt": [
        "How does using linguistic information on the source side affect predictions?",
        "How does the use of explicitly available linguistic information on the source side affect the prediction process?",
        "What does the text highlight as a positive outcome of using explicitly available linguistic information in the source language for translation prediction?"
    ],
    "testset/nmt-class/lecture06-morphology/screen46-slide49/text.txt": [
        "What is the number of language models applied in the described setups, and how do they contribute to checking the coherence of the translation?",
        "What is the most advanced setup described, and how does it benefit the translation process?",
        "What are the different setups discussed for translating English to Czech, and what are the advantages of using multiple language models in these setups?"
    ],
    "testset/nmt-class/lecture06-morphology/screen47-slide50/text.txt": [
        "What trade-off is described in the text when introducing explicit morphological tags in the tagging process on the fly during translation?",
        "What is the trade-off mentioned when using morphological tags in machine translation, and how does it affect the translation process?",
        "What is the impact of ambiguous word forms on the translation process when using on-the-fly tagging?"
    ],
    "testset/nmt-class/lecture06-morphology/screen48-slide51/text.txt": [
        "**Question:**  \nWhy did the phrase-based system outperform the translate and check system in 2009, and how did the advancements in computing power and data size contribute to this outcome?",
        "Why was the translate and check setup less effective in 2009 compared to previous years?",
        "Why was the phrase-based system superior to the \"translate and check\" system in 2009?"
    ],
    "testset/nmt-class/lecture06-morphology/screen49-slide52/text.txt": [
        "What was the main issue with synchronous factored models in translation and what solution was proposed to address this issue?",
        "What is the key reason that the factored models failed in the described translation scenario?",
        "What was the main issue with synchronous factored models and how did the use of delayed factors address this problem?"
    ],
    "testset/nmt-class/lecture06-morphology/screen50-slide53/text.txt": [
        "What is the setup that the speaker used in the last years of phrase-based MT, and what factors did their language models consider?",
        "What types of language models were used in the described phrase-based MT system, and how were they trained to improve the translation accuracy?",
        "What was the setup that the author used in the last years of phrase-based MT to optimize the translation system?"
    ],
    "testset/nmt-class/lecture06-morphology/screen51-slide54/text.txt": [
        "What are the two techniques mentioned for handling sparseness while avoiding explosion?",
        "What are the two techniques introduced to handle sparseness while avoiding information explosion?",
        "What are the two techniques mentioned to handle sparseness in translation while avoiding search errors, and what is their purpose?"
    ],
    "testset/nmt-class/lecture06-morphology/screen52-slide55/text.txt": [
        "What is the purpose of the two-step translation process described in the text when translating from English into Czech?",
        "What are the two main steps in the described translation method from English to Czech?",
        "What are the two main steps in the described translation system from English to Czech?"
    ],
    "testset/nmt-class/lecture06-morphology/screen53-slide56/text.txt": [
        "What led to the improvement in BLEUCore and Semantic POS metrics when applied to a small parallel and monolingual corpus?",
        "What metrics showed improvement when applying the two-step setup on a small parallel and monolingual corpus?",
        "What improvement did the metrics BLEUCore and Semantic POS show when the two-step setup was applied compared to the vanilla setup?"
    ],
    "testset/nmt-class/lecture06-morphology/screen54-slide57/text.txt": [
        "Why does the BLEU score decrease when using a small parallel corpus and a large monolingual corpus, and what does this suggest about the evaluation method?",
        "What does the TEXT suggest about the impact of corpus size and setup on BLEU scores when considering word sensitivity?",
        "What is the reason the vanilla setup was preferred over the semantic word counting approach based on the BLEU score in the given scenario?"
    ],
    "testset/nmt-class/lecture06-morphology/screen55-slide58/text.txt": [
        "What does the speaker equate making assumptions to?",
        "What does the text suggest happens when someone makes these assumptions?",
        "What is the result of making these assumptions according to the text?"
    ],
    "testset/nmt-class/lecture06-morphology/screen56-slide59/text.txt": [
        "What conclusion was reached about the two-step setup based on the annotators' preferences?",
        "What conclusion was reached about the two-step setup after the manual evaluation?",
        "What conclusion was reached about the two-step setup after the manual evaluation?"
    ],
    "testset/nmt-class/lecture06-morphology/screen57-slide60/text.txt": [
        "What is the purpose of reverse self-training in the context of phrase-based machine translation as described in the text?",
        "What technique allows a translation model to propose the correct word forms, such as 'kočka' and 'kočku' for 'cat,' when parallel data is limited, and how does it utilize monolingual data?",
        "What method is used to address the limitation of not having all needed word forms in the translation model, and how does it help in leveraging monolingual data to propose the required forms?"
    ],
    "testset/nmt-class/lecture06-morphology/screen58-slide61/text.txt": [
        "What would happen if you translated the phrase directly based on the small parallel data available?",
        "What problem arises when translating \"kočce\" directly into English based on the provided information?",
        "What is a problem mentioned in the TEXT regarding the direct translation of \"kočce\" into English using small parallel data?"
    ],
    "testset/nmt-class/lecture06-morphology/screen59-slide63/text.txt": [
        "What is the English translation of the Czech lemma \"kočka\" in all cases?",
        "**Question:**  \nCan the reverse translation system translate the Czech lemma \"kočka\" into English?",
        "What Czech form cannot be translated by the reverse system because it cannot handle cases?"
    ],
    "testset/nmt-class/lecture06-morphology/screen60-slide64/text.txt": [
        "What sentence is mentioned as being about a cat?",
        "What sentence does the user want included in the parallel data when reading about a cat?",
        "What is \"Chetlsem okočce\" mentioned in relation to?"
    ],
    "testset/nmt-class/lecture06-morphology/screen61-slide65/text.txt": [
        "What is the benefit of learning the new form of a noun word mentioned in the text?",
        "What is the benefit of learning a new noun form related to a cat, such as \"okotse,\" and how does it extend the translation model's capabilities?",
        "What is the benefit mentioned in the TEXT that the user is getting?"
    ],
    "testset/nmt-class/lecture06-morphology/screen62-slide66/text.txt": [
        "What method is suggested for translating Czech to English, involving the use of lemmas and synthetic parallel data?",
        "What method was used in the translation step to handle Czech into English, and how does it differ for other languages like German and Turkish?",
        "What method is described for reverse translation in the text, involving alternative decoding paths and linguistic expertise for different languages?"
    ],
    "testset/nmt-class/lecture06-morphology/screen63-slide67/text.txt": [
        "Why does using a large language model help when the data is fixed and small in size?",
        "What happens to the BLEU scores when the size of monolingual data increases, and why?",
        "What happens to translation performance when monolingual data increases, according to the text?"
    ],
    "testset/nmt-class/lecture06-morphology/screen64-slide68/text.txt": [
        "What is the main benefit of including all word forms from monolingual data in your translation model when using the reverse translation trick?",
        "What is the clear benefit of using the reverse translation trick with monolingual data in a translation model?",
        "What is the clear benefit of using the reverse translation trick with monolingual data as described in the text?"
    ],
    "testset/nmt-class/lecture06-morphology/screen65-slide69/text.txt": [
        "At what point does the reverse translation trick cease to be beneficial for parallel data collection, based on the provided information?",
        "At what point does the reverse translation trick become ineffective according to the text?",
        "At what point does the reverse translation trick become ineffective according to the text?"
    ],
    "testset/nmt-class/lecture06-morphology/screen66-slide70/text.txt": [
        "How does neural machine translation address the challenges posed by languages with complex morphology compared to traditional phrase-based systems?",
        "What is the role of morphology in neural machine translation?",
        "What aspect of language is examined in the context of neural machine translation as discussed in the TEXT?"
    ],
    "testset/nmt-class/lecture06-morphology/screen67-slide71/text.txt": [
        "What limitation do neural machine translation systems face regarding word forms, and what method is used to address this issue?",
        "Why are words broken into syllables or morphemes in neural machine translation?",
        "Question: What method is used to handle the limitations of word embeddings in neural machine translation, and what are the two examples of linguistic segmentation mentioned?"
    ],
    "testset/nmt-class/lecture06-morphology/screen68-slide72/text.txt": [
        "What is the primary goal of the method described in the text for constructing a dictionary?",
        "What happens when the most frequent character pairs are replaced with a new unit in the described tokenization method?",
        "What is the purpose of the dictionary described in the text, and how is it constructed using the method of identifying frequent character pairs?"
    ],
    "testset/nmt-class/lecture06-morphology/screen69-slide73/text.txt": [
        "What character pairs are considered frequent in the vocabulary based on the provided information?",
        "How does the frequency of the word \"low\" being seen twice affect the identification of frequent character pairs in this vocabulary?",
        "How often was the character pair 'low' observed in the described vocabulary?"
    ],
    "testset/nmt-class/lecture06-morphology/screen70-slide74/text.txt": [
        "What is the most frequent character pair mentioned in the text, and what action was taken to address its frequency?",
        "What is the shape of the new unit introduced to the vocabulary because of the most frequent character pair?",
        "What action was taken regarding the most frequent character pair \"we\" in the TEXT?"
    ],
    "testset/nmt-class/lecture06-morphology/screen71-slide75/text.txt": [
        "How does replacing a pair of characters with a single new letter affect the length of words in the corpus, as illustrated in the example?",
        "What is the result of replacing the most frequent pair of characters in the word \"LOVR\" with a single new letter?",
        "What is the example word formed after replacing pairs of characters with single new letters, resulting in four characters?"
    ],
    "testset/nmt-class/lecture06-morphology/screen72-slide76/text.txt": [
        "Which pair is identified as the most frequent and used to introduce a new merge operation for text compression?",
        "Why is the merge operation introduced for treating V, E, R as a single unit?",
        "What is the reason for treating the sequence V, E, R as a single unit in the text compression setup?"
    ],
    "testset/nmt-class/lecture06-morphology/screen73-slide77/text.txt": [
        "What is the next action that will occur, according to the text?",
        "What does the speaker predict about the next merge?",
        "What does the speaker indicate will happen next?"
    ],
    "testset/nmt-class/lecture06-morphology/screen74-slide78/text.txt": [
        "What does the ST go into?",
        "What does the text say about the ST going into the single character ST?",
        "What action is performed on the original ST to result in a single character ST?"
    ],
    "testset/nmt-class/lecture06-morphology/screen75-slide79/text.txt": [
        "What determines the vocabulary size in the described byte pair encoding system?",
        "What factors determine the size of the vocabulary in byte pair encoding as described in the text?",
        "What happens to the word 'newest' when applying merge operations in byte pair encoding, and what is the resulting sequence of translation units?"
    ],
    "testset/nmt-class/lecture06-morphology/screen76-slide80/text.txt": [
        "What is the key difference between how STE and BPE handle subword tokenization, particularly in languages like Czech, and how does this affect the model's ability to generalize?",
        "What is the advantage of using subword tokenization units like the Subword Text Encoder (STE) compared to Byte Pair Encoding (BPE) in handling Czech word endings, and how does this affect the model's ability to generalize?",
        "What is the key difference in how Sentence Piece (STE) and Byte-Pair Encoding (BPE) handle Czech words with empty suffixes, and how does this affect the model's ability to generalize?"
    ],
    "testset/nmt-class/lecture06-morphology/screen77-slide81/text.txt": [
        "What modification led to the most significant improvement in BPE's performance during the German-to-Czech translation experiments?",
        "Which method performed better in the German-to-Czech translation experiments: adding an underscore to every word or adding it after every token except for the final full stop?",
        "What was the most effective technique observed in the German-to-Czech translation experiments that improved the BLEU score, involving the addition of an underscore after each word except the last one?"
    ],
    "testset/nmt-class/lecture06-morphology/screen78-slide82/text.txt": [
        "Which method was found to be more effective for word segmentation in Turkish and Finnish, and how did it compare to BPE?",
        "Which encoder performed best in the German to Czech setup according to the text?",
        "Which method was found to work best for German-Czech setups according to the text?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen01-slide02/text.txt": [
        "What is the topic of the fifth lecture?",
        "What is the main focus of this lecture?  \nA) Syntax-based machine translation  \nB) Rule-based machine translation  \nC) Phrase-based machine translation  \nD) Statistical machine translation",
        "What is the main focus of this lecture on machine translation?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen02-slide03/text.txt": [
        "What is the process of training a phrase-based machine translation system, including feature extraction, scoring, and decoding?",
        "What is the process of translating a given input sentence once the translation tables and automatically extracted dictionaries are ready?",
        "What is the method used for training the model in phrase-based MT, as described in the lecture?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen03-slide04/text.txt": [
        "How does Phrasebase MT use parallel corpora for translation, and what is the nature of the translation units it employs?",
        "What is the main mechanism used by Phrasebase MT to handle translation?",
        "How does Phrasebase MT translate new sentences using the parallel corpus?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen04-slide05/text.txt": [
        "What is the primary goal when scoring translation candidates using the log linear model?",
        "What is the primary reason for using the log linear model in this context?",
        "What is the purpose of using the log linear model in selecting the best translation candidate, and how does it differ from traditional probability calculations?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen05-slide06/text.txt": [
        "What is the role of segmentation in phrase-based machine translation (MTE) as described in the text?",
        "What is the role of segmentation in phrase-based MTE according to the text?",
        "**Question:** What is the key assumption of phrase-based MTE, and how does it handle the segmentation of the input sentence?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen06-slide07/text.txt": [
        "What are the key features used in phrase-based machine translation, and what is the purpose of each feature?",
        "\"Identify and explain the main feature functions used in phrase-based machine translation as described in the TEXT.\"",
        "What are the key features used in phrase-based Machine Translation, and how do they contribute to the translation process?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen07-slide08/text.txt": [
        "What are the main steps involved in building a phrase-based machine translation system according to the text?",
        "What are the main steps in the phrase-based machine translation pipeline?",
        "What steps are involved in the phrase-based machine translation pipeline?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen08-slide09/text.txt": [
        "What is the origin of the counts used to estimate probabilities in phrase-based machine translation as described in the text?",
        "How are the probabilities for the most important feature in phrase-based machine translation estimated, and what counts are used for normalization?",
        "What method is used to estimate the probabilities of source and target phrase co-occurrences in phrase-based machine translation, and how are these probabilities calculated?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen09-slide10/text.txt": [
        "Question: Explain the method described in the text for building a phrase-based machine translation system, including its key components and the importance of phrase consistency.",
        "What role does consistency with word alignment play in extracting phrase pairs?",
        "What role does the consistency with word alignment play in the extraction of phrase pairs, and why is it important?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen10-slide09/text.txt": [
        "How are translation probabilities calculated using the phrases mentioned?",
        "What is the basis for the translation probabilities mentioned in the text?",
        "What is the basis for calculating translation probabilities in the described method, and what are the two main approaches mentioned?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen11-slide10/text.txt": [
        "Question: How does the scoring method for multi-word phrase pairs work, considering internal dots and word alignment, and how does lexical weighting influence the translation probability based on the frequency of phrase components?",
        "How does the scoring of phrase translation work when considering multi-word expressions and lexical weighting based on the frequency of word alignments?",
        "How is the scoring of multi-word phrase translation determined according to the text?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen12-slide11/text.txt": [
        "What is the advantage of using lexically weighted phrase probabilities compared to maximum likelihood estimates, and what are the four numbers mentioned in relation to lexical weighting?",
        "What is the phrase penalty value in the Moses decoder and what is the reason it is set to that value?",
        "Why are lexically weighted phrase probabilities considered more reliable than non-weighted ones, and what do the four numbers mentioned represent in this context?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen13-slide12/text.txt": [
        "What are the two phases of translation in a phrase-based system?",
        "What are the two phases of the translation process described, and what does each phase involve?",
        "What are the two main phases of the translation process using the phrase-based system?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen14-slide13/text.txt": [
        "What does the translation system do with the input sentence \"Er get Janik na Hause\"?",
        "What is the best translation of the sentence \"Er get Janik na Hause\" according to the system described, and what process leads to this translation?",
        "What is the best translation of the sentence \"Er get Janik na Hause\" according to the phrase table described?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen15-slide14/text.txt": [
        "What is the second stage of the translation process, and what does it start with?",
        "What is the second stage of translation mentioned in the text and what does it involve?",
        "What is the second stage of translation mentioned, and what does it involve starting with?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen16-slide15/text.txt": [
        "What does the coverage vector represent when the hypothesis is empty?",
        "What does an empty hypothesis indicate about the coverage vector and the production of output words in the translation process?",
        "What does the empty hypothesis indicate about the coverage vector and the output words in the translation process?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen17-slide16/text.txt": [
        "What was the second word translated into using hypothesis expansion?",
        "What word in the input sentence is translated as 'r'?",
        "What term is used when the initial hypothesis is expanded by translating the second word in the input?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen18-slide17/text.txt": [
        "How many hypotheses were generated when the translations for the first words \"er\" and \"now\" were added?",
        "How many translation hypotheses are mentioned in the text and what do they cover?",
        "How many hypotheses are mentioned in the text, and what do they cover?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen19-slide18/text.txt": [
        "What was the main focus of the translation process when expanding the hypothesis in the text?",
        "What is the translation of \"nach Hause\"?",
        "What is the process of expanding hypotheses in the described translation method, and how are the translations of \"ja\" and \"nach Hause\" considered in forming the final hypothesis?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen20-slide19/text.txt": [
        "What does the path through the search graph back to the initial hypothesis result in?",
        "What is the final output text of the target sentence, the best scoring sentence?",
        "What does the path through the search graph ultimately produce?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen21-slide18/text.txt": [
        "What is important to realize based on the provided text?",
        "What is important to realize?",
        "What is important to realize according to the text?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen22-slide19/text.txt": [
        "What is the main issue mentioned in the text regarding the search space?",
        "Question: Why is the search space considered pretty big in this context?",
        "What contributes to the size of the search space?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen23-slide20/text.txt": [
        "What method was used to prove that machine translation is NP-hard, and which specific NP-complete problem was reduced to a machine translation task using a bigram language model?",
        "What is the implication of having a polynomial-time solution for the machine translation problem according to the text?",
        "The question asks about the method to prove the NP-hardness of machine translation, specifically how a black box machine translation system using bigrams can be utilized to reduce an NP-complete problem. The correct answer is that the reduction is from the Hamiltonian Circuit problem."
    ],
    "testset/nmt-class/lecture05-pbmt/screen24-slide21/text.txt": [
        "How is the minimum set cover problem related to machine translation, as illustrated by the example provided in the text?",
        "What NP-complete problem is discussed in the text and how is it related to machine translation, and what does this imply about the complexity of machine translation?",
        "How does the Minimum Set Cover problem relate to machine translation as illustrated in the example, and what is the implication if P ≠ NP?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen25-slide22/text.txt": [
        "What are the three methods discussed by Barry Heddo to fight complexity, as mentioned in the slides?",
        "Question: Based on the TEXT, which methods are discussed by Barry Heddo to fight complexity?  \nA. Hypothesis recombination  \nB. Stack-based pruning  \nC. Future cost estimation  \nD. All of the above",
        "What three topics are discussed in Barry Heddo's slides to address complexity?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen26-slide23/text.txt": [
        "What action does the system take when constructing new partial hypotheses to manage the search space?",
        "What does the system do when constructing new partial hypotheses to reduce the search space?",
        "What technique is described to reduce the search space in translation, where partial hypotheses covering the same input and output are combined?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen27-slide24/text.txt": [
        "Under what condition can two hypotheses be safely recombined, and what aspect of their history is irrelevant to the scoring functions when considering future expansions?",
        "Under what condition can two translation hypotheses be safely recombined when using a trigram language model?",
        "Under what condition can two translation hypotheses be safely recombined, and what aspect of these hypotheses must be identical for this to be possible?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen28-slide25/text.txt": [
        "What is the condition on the reordering model that is imposed by the language model and not restricted by the translation model?",
        "What is the condition on the reordering model, and which model does not impose any restrictions on it?",
        "What is the source of the condition on the reordering model?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen29-slide26/text.txt": [
        "What method involves dropping less likely partial hypotheses early to reduce the search space?",
        "What does the speaker suggest about early pruning in the context of managing partial hypotheses?",
        "What action is necessary to improve the search space when it is insufficient?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen30-slide25/text.txt": [
        "What method is used in phrase-based machine translation to address the issue of longer hypotheses being scored lower, and how does it organize the search process?",
        "**Question:**  \nWhy are partial hypotheses organized into stacks in stack-based beam search, and how does this organization help manage the search space more efficiently?",
        "What problem arises when using a single queue for all partial hypotheses in the beam search for machine translation, and how does stack-based beam search address this issue?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen31-slide25/text.txt": [
        "What is the state of the stacks at the end of the described process?",
        "What is the final outcome of the process described in the studio code summary?",
        "What is the first action when starting the process, and what is the state of the stacks at the end?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen32-slide25/text.txt": [
        "What type of complexity arises when using the described pruning strategies for translation options?",
        "What type of complexity is observed when considering the number of translation options in the pruning strategies mentioned?",
        "What are the different pruning strategies mentioned in the text for reducing the number of translation hypotheses?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen33-slide25/text.txt": [
        "What is the impact of limiting the expansion of the hypothesis during translation on the complexity of the translation process?",
        "What must be limited to reduce translation complexity from quadratic to linear?",
        "What is the reason for the reduction in complexity from quadratic to linear when reordering is limited in translation?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen34-slide25/text.txt": [
        "Why are future cost estimates important for ensuring fairness in hypothesis allocation when two hypotheses have the same number of source words to translate?",
        "Why does the system use a future cost estimate when comparing hypotheses, and how does this ensure fairness in the allocation process?",
        "What is the role of the heuristic mentioned in the text, and how does it ensure a fair comparison between hypotheses that translate the easy or hard parts of a sentence first?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen35-slide25/text.txt": [
        "What is the nature of the future cost estimate in the context of translation, and why is it considered optimistic?",
        "What is the approach to estimating future costs in the translation process and why is it considered optimistic?",
        "What is the reason the future cost estimate is considered optimistic in the context described?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen36-slide25/text.txt": [
        "What method is used to estimate future translation costs, and what is the purpose of the translation options table in this process?",
        "What algorithm is described for estimating the future cost of translating parts of a sentence, using a translation options table and dynamic programming?",
        "What is the purpose of the dynamic programming table in estimating the future cost of translating a sentence?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen37-slide25/text.txt": [
        "According to the text, why are common phrases like \"the first time\" cheaper to translate than unusual phrases like \"tourism initiative addresses\"?",
        "Why are function words generally cheaper to translate than content words?",
        "What does the example of the tourism initiative primarily illustrate?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen38-slide25/text.txt": [
        "Why does the text suggest that the approach of translating hard words first leads to a better overall translation score compared to translating easy words first?",
        "What is the comparison between the two translation hypotheses, and why does the hypothesis that translates the hard words first result in a better total score?",
        "Which translation hypothesis, the one that translates easy words first or the one that translates hard words first, results in a lower total cost, and why?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen39-slide25/text.txt": [
        "What are some examples of decoding algorithms mentioned in the text?",
        "What other decoding algorithms are mentioned as possibilities for future lectures, including finite state transducers?",
        "What alternative decoding algorithms or methods are mentioned in the text?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen40-slide25/text.txt": [
        "The admissible heuristic in A-Star Search never overestimates future costs, ensuring that the algorithm explores the most promising paths first. This guarantees that when the goal is reached, the path found is the one with the lowest possible cost, thus providing the best solution.",
        "What must the heuristic satisfy for the A-Star Search to guarantee finding the best solution?",
        "What kind of heuristic must be used in the A-Star Search to ensure it finds the optimal solution?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen41-slide25/text.txt": [
        "What does the speaker indicate that \"we can\" do?",
        "What is the action or possibility being introduced by the phrase \"we can\" in the text?",
        "Question: Can we make it work?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen42-slide25/text.txt": [
        "What is the difference between local and non-local feature functions in phrase-based machine translation, and can you provide an example of each using the given example sentence?",
        "Explain the difference between local and non-local feature functions in the context of phrase-based machine translation, providing an example of each.",
        "What is the distinction between local and non-local feature functions in phrase-based machine translation, and how do they differ in their application?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen43-slide25/text.txt": [
        "How do the initial weights in the model influence the exploration of the search space during the beam search process, and why is this important for finding the optimal solution?",
        "How does the weight optimization process in machine learning affect the balance between internal model scores and external evaluation scores in phrase-based translation systems?",
        "What is the purpose of weight optimization in the described machine learning approach, and how does it influence the search space and scoring?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen44-slide25/text.txt": [
        "How does adjusting the phrase penalty affect the segmentation of the input sentence in a phrase-based machine translation model?",
        "How does the phrase penalty affect the segmentation of the input sentence during translation?",
        "What is the effect of the phrase penalty on the segmentation of the input sentence and why is it important to have a held-out set that matches the test domain?"
    ],
    "testset/nmt-class/lecture05-pbmt/screen45-slide25/text.txt": [
        "Why is the Moses decoder still considered a useful tool in machine translation and other linguistic tasks despite the prevalence of neural machine translation systems?",
        "What is the primary reason phrase-based machine translation using Moses decoder is still considered useful despite the prevalence of neural machine translation?",
        "What are the current primary use cases for the Moses decoder in machine translation?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen01-slide01/text.txt": [
        "What is the focus of the second lecture on statistical machine translation and what will the upcoming lectures cover?",
        "What was the focus of the second lecture in the series on statistical machine translation?",
        "What is the main focus of the second lecture on statistical machine translation, and what was discussed in the previous lecture?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen02-slide02/text.txt": [
        "Is neural machine translation considered a part of statistical machine translation, even though there is sometimes a terminological contrast between SMT and NMT?",
        "What is the relationship between neural machine translation (NMT) and statistical machine translation (SMT) as described in the talk?",
        "What is the relationship between neural machine translation (NMT) and statistical machine translation (SMT) as discussed in the talk?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen03-slide13/text.txt": [
        "What are the two main approaches for machine translation as described in the Wokoa Triangle, and what are their respective requirements in terms of the number of systems?",
        "What was the main motivation behind using an interlingua in machine translation systems as discussed in the text?",
        "What is the main idea behind the Wokoa Triangle in the context of machine translation, and how does it compare the direct translation approach to the interlingua-based approach in terms of system requirements?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen04-slide04/text.txt": [
        "What is the key difference between example-based machine translation and statistical machine translation approaches, as described in the text?",
        "What is one key difference between example-based machine translation and statistical machine translation, as explained in the text?",
        "Question: What is the key difference between example-based and statistical machine translation approaches discussed in the text?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen05-slide05/text.txt": [
        "Question: Name two key historical figures mentioned in the text and briefly describe their contributions to machine translation.",
        "What was Frederick Jelinek's approach to machine translation and how did he integrate linguistic modeling and statistical decision theory?",
        "What is the main idea of the TEXT regarding the development of machine translation systems?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen06-slide06/text.txt": [
        "What does specifying a probabilistic model in statistical machine translation involve, and how do linguists contribute to this process?",
        "What is the fundamental aspect of statistical machine translation, and how does linguistics contribute to it?",
        "What role do linguists play in the context of statistical machine translation?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen07-slide07/text.txt": [
        "What are the two main types of data used in traditional statistical machine translation?",
        "What are the characteristics of the minimum translation units sought in traditional statistical machine translation?",
        "What is the ultimate goal of traditional statistical machine translation, and what characteristics should the translation units ideally have?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen08-slide08/text.txt": [
        "How is the probability of a target sentence given a source sentence defined in statistical machine translation?",
        "What is the critical formula that needs to be remembered and understood for defining the probability of a target sentence given the source sentence in statistical machine translation, and how is it used to find the most probable target sentence?",
        "How is the probability of a target sentence given a source sentence defined in statistical machine translation?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen09-slide09/text.txt": [
        "Why does having multiple translations for a source sentence cause a problem in the described brute force machine translation system?",
        "What is the main issue with the probability distribution in the translation memories approach described in the text?",
        "What is the technical problem when a source sentence has multiple target translations in the described machine translation system?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen10-slide10/text.txt": [
        "What are the two main problems mentioned in the text regarding the probability distribution based on sentence occurrences, and how do they affect the distribution?",
        "What is the primary issue with the probability distribution discussed in the text and how does it affect the handling of slightly changed sentences?",
        "What is the main issue with the probability distribution created by normalizing sentence occurrence counts, and what is the result of this issue?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen11-slide11/text.txt": [
        "How does Bayes' law contribute to the process of finding the most probable target sentence in the described formula?",
        "What key statistical principle allows the simplification of the conditional probability formula when searching for the highest scoring target sentence in machine translation?",
        "What is the reason for ignoring the probability of the source sentence when applying Bayes' law to find the highest scoring target sentence in the formula?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen12-slide12/text.txt": [
        "What is the main motivation for using two tables in the noisy channel approach, and how does training the language model on monolingual data help improve translation decisions?",
        "What is the main benefit of creating two tables in the noisy channel approach, and how does it improve the translation process?",
        "What is the main motivation for incorporating a language model in machine translation systems, as discussed in the text?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen13-slide13/text.txt": [
        "What are the two models used in the log-linear approach for translating an input sentence into the target language?",
        "What is the purpose of the two models (translation and language) derived from parallel and monolingual texts in the log-linear model?",
        "What are the two main components used in the log-linear model for machine translation, and what are they derived from?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen14-slide14/text.txt": [
        "How do n-gram based language models calculate the probability of a sentence?",
        "\"How is the probability of a sentence defined in an n-gram based language model?\"",
        "How do n-gram-based language models calculate the probability of a sentence?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen15-slide15/text.txt": [
        "How is the probability of a trigram calculated according to the text?",
        "How is the probability of a trigram calculated according to the given text?",
        "How is the probability of a trigram calculated according to the method described?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen16-slide14/text.txt": [
        "Where does defining the probability of a sentence as a product of trigram probabilities struggle or break?",
        "What is a main struggle when defining the probability of a sentence as a product of trigram probabilities?",
        "What is a significant issue when defining the probability of a sentence as a product of trigram probabilities?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen17-slide15/text.txt": [
        "What is the difference between interpolation and backoff in the context of n-gram language models, and how does each method affect the calculation of sentence probability?",
        "What is the main difference between interpolation and backoff in the context of handling n-gram models?",
        "What is the difference between backoff and interpolation when handling n-grams in language modeling?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen18-slide16/text.txt": [
        "What key observation led to the modification of the translation model, allowing for the squaring of the language model's probability and the swapping of conditional probability directions despite violating the base law?",
        "What modifications were empirically found to improve translation models according to the text?",
        "What were the two key observations made by the translation model regarding the language model and the base law?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen19-slide17/text.txt": [
        "What is the purpose of normalization in the LoglingerModal framework and why is it considered difficult to compute?",
        "What is the process described for normalizing the scores of sentence pairs in LoglingerModal?",
        "What is the main computational challenge mentioned in the normalization process of LoglingerModal, and how is it addressed?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen20-slide18/text.txt": [
        "Question: Why doesn't the summation of points need to be calculated when using this formula within the argmax?",
        "Why do we not need to calculate the summation of points when using the formula within the argmax function?",
        "Why doesn't the summation of points need to be calculated when using the formula within the argmax function?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen21-slide17/text.txt": [
        "What is the role of the weights in the log-linear model discussed in the text?",
        "What is the purpose of the feature function in the log-linear model described in the text, and how does it integrate the target side to estimate probabilities?",
        "What is the purpose of the weights in the log-linear model discussed in the text?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen22-slide18/text.txt": [
        "What is the reason that normalization is not required when using the Logliner model to score candidate translations?",
        "Why is normalization unnecessary in the Logliner model when searching for the highest-scoring candidate?",
        "Question: Why is normalization not required in the Logliner model when scoring candidate translations?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen23-slide19/text.txt": [
        "What is the Logdiner model a generalization of, and how does it achieve this through the use of feature functions and exponentiation of log probabilities?",
        "How does the Logdiner model generalize the noisy channel approach, and what specific components does it use to achieve this?",
        "What does the Logdiner model generalize, and how do the feature functions and equal weights contribute to this generalization in the context of the noisy channel approach?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen24-slide20/text.txt": [
        "What is the purpose of the word penalty feature in phrase-based machine translation, and how is it implemented?",
        "### QUESTION:\nExplain the role of the phrase translation probability in phrase-based machine translation.",
        "What is the purpose of the word penalty feature in phrase-based machine translation?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen25-slide21/text.txt": [
        "Is it appropriate to use a language model to propose candidate target sentences for translation, and why might this approach be considered risky?",
        "**Question:** Should language models be used to construct candidate translations, or are they more appropriately used for scoring?",
        "Question: Should language models be used for constructing candidate translations in neural machine translation systems?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen26-slide22/text.txt": [
        "What is the purpose of the tuning step in the traditional pipeline for training classical statistical machine translation systems?",
        "What are the key steps in the traditional pipeline for training classical statistical machine translation systems?",
        "What is the purpose of the 'tuning' step in the traditional machine translation pipeline?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen27-slide23/text.txt": [
        "What two sentences are included in the training corpus?",
        "What is the purpose of the example provided in the TEXT?",
        "What example sentences were used to train the machine translation system?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen28-slide24/text.txt": [
        "What animals are Psa and Kočku identified as according to the text?",
        "What method is mentioned for identifying that \"Psa\" refers to a dog and \"Kočku\" refers to a cat?",
        "How can co-occurrence statistics be used to identify the meanings of animal names, such as Psa and Kočku?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen29-slide25/text.txt": [
        "What are the translations of the words Kočku and Videl, based on the information provided?",
        "What are the translations of \"Kočku\" and \"Videl\" into the target language as given in the text?",
        "Question:  \nBased on the text, what do the words Kočku and Videl translate to?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen30-slide26/text.txt": [
        "What does \"Nemám kočku\" mean in English?",
        "What is the translation of \"Nemám kočku\" into English?",
        "What is the translation of \"Nemám kočku\"?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen31-slide27/text.txt": [
        "Does the speaker have a cat and know how to translate, according to the text?",
        "Does the speaker have a cat?",
        "Does the speaker have a cat and know how to translate?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen32-slide28/text.txt": [
        "What is the content of the given text?",
        "What is the name mentioned in the provided text?",
        "I'm sorry, but the text provided is unclear and incomplete, making it difficult to generate a meaningful question. Could you please provide more context or clarify the content?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen33-slide29/text.txt": [
        "What is the main problem highlighted with the phrase-based system in the example provided?",
        "What is the main problem highlighted by the example of the phrase-based system translating \"nemám kočku\" as \"I have a cat\"?",
        "What is the main problem highlighted by the example of the phrase-based system translating \"nemám kočku\" as \"I have a cat\"?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen34-slide31/text.txt": [
        "What are the incorrect independence assumptions made in the approach, and how did they affect the translation process?",
        "What is the main issue with the initial approach mentioned in the text?",
        "What was the main issue with the translation approach discussed in the text?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen35-slide30/text.txt": [
        "Why does the language module prefer to drop the negation in the example?",
        "What is the language module's preference regarding the length of outputs and why does it prefer to drop negations?",
        "Why does the language module prefer to drop the negation in longer outputs?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen36-slide31/text.txt": [
        "What are the two strong independence assumptions about the phrases in the language model?",
        "What are the two strong independence assumptions about the phrases in the language model?",
        "What are the two strong independence assumptions about the phrases in the language model?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen37-slide30/text.txt": [
        "What is the trade-off between using longer units and smaller units in terms of precision and recall when extracting phrases for translation, as discussed in the text?",
        "What trade-off is mentioned regarding the size of extracted units in language processing?",
        "What is the main challenge discussed in the text regarding the use of longer units in extracting phrases, and what was the outcome of the researcher's attempt to address this issue?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen38-slide31/text.txt": [
        "What is the main problem described with the base decomposition approach in the context of translation models?",
        "What is the main problem with the base law approach in statistical machine translation, and how does the decomposition into phrases contribute to incorrect translations?",
        "What is the main problem caused by the formula's decomposition, and how does disregarding the source affect the translation units?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen39-slide32/text.txt": [
        "What approach is used to redefine the probability of the target sentence given the source in the context of neural machine translation models?",
        "How has the approach to defining the probability of the target sentence given the source been redefined in the context of neural machine translation?",
        "What is the main technical approach used in neural machine translation models according to the text?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen40-slide33/text.txt": [
        "What can a neural network with one hidden layer approximate?",
        "What is the capability of a neural network with one hidden layer despite potential training challenges?",
        "What is the capability of a neural network with one hidden layer, and what challenge is associated with training it according to the text?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen41-slide34/text.txt": [
        "How does the neural network determine whether a given point is in the center or on the circumference of the circle?",
        "How do the hidden neurons in the neural network contribute to determining whether a point is in the center or on the circumference of the circle?",
        "What is the role of the hidden layer in this neural network, and how does it help classify points as either the center or the circumference of a circle?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen42-slide35/text.txt": [
        "Under what condition will the color be blue according to the equation provided?",
        "Under what condition will the color be blue according to the program?",
        "What condition must be met for the color to be blue according to the information provided?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen43-slide36/text.txt": [
        "How many weights are required to separate points in the center from those on a circular boundary, and what is their role in the computation?",
        "How many real numbers are needed to separate points in the center from those on the circular, and why is thirteen sufficient according to the text?",
        "How many weights are needed to separate points in the center from points on a circular arrangement, and what is their role?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen44-slide37/text.txt": [
        "Why is there no need for a hidden layer when using perfect coordinates or inputs such as x1 squared and x2 squared, based on the circle equation x1² + x2² − 1 ≤ 0?",
        "What is the reason for not needing any hidden layers when using perfect coordinates, such as x1 squared and x2 squared?",
        "Why is there no need for hidden layers when using perfect coordinates and inputs like x1 squared and x2 squared for a circle?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen45-slide38/text.txt": [
        "What is the consequence of directly using X and Y coordinates for separating the center from the circumference without any transformation?",
        "What is the implication of having 'unfortunate features' in terms of linear separability?",
        "What transformation do neural networks apply to the input features to enable linear separation when the original features cannot be linearly separated?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen46-slide39/text.txt": [
        "What happens when a neural network has too many parameters and not enough training data?",
        "What happens when a network is too complex and lacks sufficient training data?",
        "What happens when a neural network is too complex, resulting in too many parameters and insufficient training data?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen47-slide40/text.txt": [
        "How does the number of neurons in the first hidden layer influence the features the network can learn?",
        "How does the number of neurons in the network influence its capacity to approximate shapes such as circles?",
        "How does the number of neurons in the network contribute to its capacity to approximate complex shapes like circles?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen48-slide41/text.txt": [
        "How is a sentence represented in terms of a matrix, and what does each column of the matrix signify?",
        "What is the structure of the matrix formed when representing the sentence \"the cat is on the mat\" using the described method?",
        "How is a sentence represented as a matrix in the context described?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen49-slide42/text.txt": [
        "Why is it difficult for current machines to process the matrix quickly?",
        "What is the size of the matrix for English and Czech, and why does it pose a problem for current machines?",
        "Why is the matrix too large to be processed quickly on current machines?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen50-slide43/text.txt": [
        "What is a key limitation of the one-hot representation when it comes to capturing relationships between words?",
        "What is the primary issue with the one-hot representation of words as described in the text?",
        "What is a major limitation of one-hot representation in capturing word relationships?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen51-slide44/text.txt": [
        "What is the solution presented in the text and how does it work?",
        "What method is used to map long word vectors into shorter representations to capture semantic meanings?",
        "What are the two main methods mentioned in the text for obtaining word embeddings?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen52-slide45/text.txt": [
        "What is the suggested solution to handle the infinite set of possible words in languages with productive morphology for neural machine translation?",
        "What is the main issue with languages that have productive morphology for neural machine translation, and how is it addressed?",
        "What approach is suggested to handle long or less frequent words in neural machine translation?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen53-slide46/text.txt": [
        "What does the text mention about length?",
        "What type of length is discussed in the text?",
        "What allows for different lengths?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen54-slide45/text.txt": [
        "How does the system use context to disambiguate words during translation, as illustrated by the example of \"migranti\" being translated as \"migrants\" rather than \"grants\"?",
        "How do support units affect the ambiguity of the source according to the text?",
        "What is the main issue discussed in the text regarding the translation process?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen55-slide46/text.txt": [
        "What approach is used to handle variable length inputs in neural networks, and what problem is encountered during training due to the network becoming deeper?",
        "What is the primary problem encountered when training neural networks with variable length inputs, and how is it addressed?",
        "What is the primary challenge when training neural networks with variable-length inputs, and how is it addressed according to the text?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen56-slide47/text.txt": [
        "Who introduced the encoder-decoder architecture in neural machine translation and for what purpose?",
        "Question: Who introduced the encoder-decoder architecture in the context of phrase-based machine translation systems?",
        "What architecture did Kyun Kun Cho introduce to improve phrase scoring in machine translation?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen57-slide48/text.txt": [
        "What process did the encoder follow when handling each word in the sentence?",
        "How did the encoder process the input sentence to produce a final state representation?",
        "What method did the team use to process the input sentence in their approach?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen58-slide49/text.txt": [
        "What inputs does the decoder use to generate each word in the target sentence?",
        "What is the decoder in the context of a neural network, and what information does it use to produce the next word in a sequence?",
        "What is the role of the decoder in generating the target sentence, and how does it function using the source sentence's vector representation?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen59-slide50/text.txt": [
        "What is mentioned about the number of parameters in the network?",
        "How long does it take to train the model and how many parameters does it have?",
        "How many sentence pairs and parameters were used in the training process described?"
    ],
    "testset/nmt-class/lecture02-smt-pbmt-nmt/screen60-slide51/text.txt": [
        "What is the primary difference between classical statistical machine translation and neural machine translation as described in the text?",
        "What are the main differences between classical statistical machine translation and neural machine translation?",
        "What is the primary goal of classical statistical machine translation, and how does it differ from the goal of neural machine translation?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen01-slide01/text.txt": [
        "What was the focus of the lecture on statistical machine translation in the pre-neural era, excluding phrase-based approaches?",
        "What is the main focus of today's lecture on machine translation?",
        "What was the main focus of the lecture on statistical machine translation?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen02-slide02/text.txt": [
        "What is the tectorochromatic layer, and what is its significance in the context of machine translation?",
        "What is the origin and current status of the tectorochromatic layer in machine translation?",
        "What are the two main types of syntactic trees discussed in the lecture, and how are they used in machine translation?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen03-slide03/text.txt": [
        "What were the main limitations of phrase-based machine translation systems before neural machine translation?",
        "What was a significant challenge for phrase-based machine translation systems in handling the translation of certain grammatical constructions, such as negation in French?",
        "What were the two main limitations of phrase-based machine translation systems discussed in the text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen04-slide04/text.txt": [
        "What model was the first to attempt solving some of the issues mentioned, and how was it described?",
        "What was the hierarchical model the first to do, and how was it described?",
        "What was the hierarchical model the first to do?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen05-slide05/text.txt": [
        "What problem arises when using David Chang's 2005 translation model with sentences that lack grammatical structure?",
        "What is a limitation of David Chang's 2005 model in terms of grammatical structure validation?",
        "What is the main limitation of the translation model described by David Chang in 2005?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen06-slide06/text.txt": [
        "What is a key advantage of the hierarchical model over the phrase-based machine translation approach?",
        "How does the hierarchical model differ from the phrase-based model in terms of extracting phrases for machine translation?",
        "What is a key difference between phrase-based and hierarchical machine translation models?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen07-slide07/text.txt": [
        "What is the role of the non-terminal 'x' in the translation process described in the text?",
        "Question: Can you provide an example of a rule based on the gappy phrase rule described, demonstrating the reordering of phrases using the single non-terminal 'x' and co-indexation?",
        "What is the role of the non-terminal \"x\" in the rule described in the text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen08-slide08/text.txt": [
        "Question: Why was it more difficult to integrate the language model into the new type of search?",
        "What constraints were applied to the rules to limit the number of extracted rules?",
        "What limitations were imposed on phrase length and rule creation to manage the large number of extractable lures in the system?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen09-slide10/text.txt": [
        "What is the main difference between constituency trees and dependency trees?",
        "What is a key characteristic of constituency trees in terms of how they represent sentence structure?",
        "What do constituency trees primarily show about the structure of a sentence?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen10-slide11/text.txt": [
        "What is the most important syntactic element within a verb phrase (VP)?",
        "What is the most important syntactic element in a VP, and why is it considered the 'hat' of the sentence?",
        "What is the most important part of a VP in a sentence?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen11-slide12/text.txt": [
        "What kind of labels are present on the internal nodes in a dependency tree?",
        "Are there non-terminal labels on the head in a dependency tree?",
        "What is not present in the internal nodes of a dependency tree?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen12-slide13/text.txt": [
        "What resource does the speaker recommend for understanding the algorithm discussed in the lecture on constituency syntax in machine translation?",
        "What is recommended for complementing the lecture on constituency syntax in machine translation, and why is the speaker skipping the illustration part?",
        "What did the speaker recommend for learning about constituency syntax in machine translation?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen13-slide14/text.txt": [
        "How are probabilities assigned to productions in context-free grammars, and how is the maximum likelihood estimate used in this process?",
        "The process of assigning probabilities to productions in a context-free grammar involves using a tree bank to count the occurrences of each production, normalizing these counts by dividing by the total number of observations to obtain probabilities, and then using these probabilities to compute the likelihood of a sentence by multiplying the probabilities of the production rules used in its parse tree. This approach leverages maximum likelihood estimation to estimate the probabilities, allowing for a structured, syntactic language modeling approach. \n\nAnswer: Probabilities are assigned by counting each production's occurrences in a tree bank, normalizing by total counts, and multiplying the probabilities of the rules used in a sentence's parse tree to compute its likelihood.",
        "How are probabilities assigned to production rules in a context-free grammar according to the text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen14-slide15/text.txt": [
        "What is the name of the best-known parsing algorithm mentioned in the text, and what is its time complexity?",
        "What is the role of the table in the CKY parsing algorithm?",
        "How does the CKY algorithm parse the sentence \"She eats a fish with a fork\" into a syntactic tree?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen15-slide16/text.txt": [
        "How are the context-free grammar rules structured to enable machine translation between Chinese and English, and what role do the non-terminals play in this process?",
        "What is the purpose of coindexation of non-terminals in the right-hand side of the rule in the described translation system?",
        "What is the role of non-terminals in the example of a context-free grammar used for Chinese to English translation?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen16-slide17/text.txt": [
        "What is the reason that the constituency trees of English and Czech cannot be mapped together using a Synchronous context-free grammar in the given example?",
        "Why is it impossible to map the constituency trees of \"John fell in love with Mary\" in English and \"Jan Miluje Marii\" in Czech using a Synchronous context-free grammar?",
        "Question: Why is it challenging to map the English and Czech constituency trees using Synchronous Context-Free Grammar?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen17-slide18/text.txt": [
        "What is the method used to ensure the correspondence of the two trees in the described Synchronous Tree Substitution Grammars?",
        "What is the key difference between Synchronous Tree Substitution Grammars and other grammatical systems that produce single-level productions, as explained in the text?",
        "What is the role of the colored parts in the trees, and what does the red part specifically indicate?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen18-slide19/text.txt": [
        "What is the relationship between synchronous tree substitution grammars and synchronous context-free grammars, and how can a special non-terminal be used to achieve a one-to-one correspondence between their productions?",
        "What does the text explain about the relationship between synchronous tree substitution grammars and synchronous context-free grammars, particularly in terms of their equivalence and the method used to map structures?",
        "What is the relationship between synchronous tree substitution grammars and synchronous context-free grammars, and how does the use of a special non-terminal like VP contribute to this equivalence?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen19-slide20/text.txt": [
        "How does the device of synchronous substitution grammars function in machine translation, particularly in terms of parsing and constructing the target sentence?",
        "How does the language model interact with the parsing process in the context of this translation method, and what is the result of this interaction?",
        "How does the device of synchronous substitution grammars differ from phrase-based MT in terms of processing input and output?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen20-slide21/text.txt": [
        "What specific information must be included in the states during the parsing process to enable the language model to score the translations accurately?",
        "What is the purpose of state splitting in the parsing process as described in the text?",
        "What is an example of a partial parse state in a hierarchical model where a span is labeled 'x' covering positions 3 to 6 in a sentence?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen21-slide22/text.txt": [
        "According to the text, why does adding syntactic information complicate the creation of syntactic trees, as discussed in David Cheng's slides from 2010?",
        "What did the example on the previous slide lack that made it linguistically inadequate?",
        "What is the main reason the previous example was considered linguistically inadequate, and how do true syntactic trees with linguist-assigned labels address this issue?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen22-slide23/text.txt": [
        "What is one reason for the more constrained extraction of phrases in SYNCHRS 3 substitution grammars, and what has been observed about the performance of different models in language pairs?",
        "What are the two main reasons mentioned for the difference in performance between hierarchical, phrase-based, and syntactic models in the context of extracting phrases using sentence and word alignments along with source and target trees?",
        "What are the two main reasons for the change in the number of extracted phrases when using the new method, and which model was found to perform the best in the experiments?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen23-slide24/text.txt": [
        "What are the reasons why that is difficult?",
        "What are the reasons why that is difficult?",
        "What are the reasons why that is difficult, and why is it challenging?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen24-slide25/text.txt": [
        "What is the main issue with syntactic approaches compared to phrase-based or hierarchical approaches in language processing?",
        "What is the main issue with syntactic approaches compared to phrase-based or hierarchical approaches?",
        "What are the two main limitations of syntactic approaches compared to phrase-based or hierarchical approaches?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen25-slide26/text.txt": [
        "What is lost when using syntactic approaches in machine translation based on the example provided with \"Brucha Verde\" and \"Green Witch\"?",
        "What issue arises in a syntactic approach to machine translation when extracting translations from word alignments, as illustrated by the example of \"Brucha Verde\" being translated to \"Green Witch\"?",
        "What is the problem with syntactic approaches in MT when the translation is not a constituent?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen26-slide27/text.txt": [
        "What is the main issue in translating the phrase \"Taiwan surplus in trade between the two shores\" according to the text?",
        "Why can't the system translate the entire noun phrase \"Taiwan surplus in trade between the two shores\" as a single unit in the target language?",
        "What is the primary reason a translation system might fail to accurately translate the sentence \"Taiwan surplus in trade between the two shores\"?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen27-slide28/text.txt": [
        "What causes the loss of coverage in the syntactic-based system as explained in the text?",
        "What is the reason for the loss of coverage in a syntactic-based system due to a dangling verb phrase, and how does this phenomenon manifest differently across languages?",
        "What causes the loss of coverage in the syntactic-based system, and how does the dangling verb phrase differ in validity between the two languages?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen28-slide29/text.txt": [
        "How does binarizing productions help the syntactic system in handling incorrect inputs?",
        "Why should a hierarchical syntactic system be modified by breaking down grammatical constructions into smaller parts?",
        "Why is it important for the syntactic system to be able to handle grammatically incorrect sentences in machine translation?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen29-slide30/text.txt": [
        "What approach did Ashish Venugopal and Andras Solman propose for machine translation that constructs phrases without relying on linguistic components?",
        "What was the key idea behind the syntax-augmented machine translation approach by Ashish Venugopal and Andras Solman, and how did it differ from traditional linguistic methods?",
        "What is the difference between the two approaches mentioned for binarization in machine translation, and how do they differ in their use of linguistic components?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen30-slide31/text.txt": [
        "What is the problem that arises when trying to plug a multi-word noun phrase (NP) into a slot that expects a singular noun in plural form, given the limitations of the grammar rules in the synchronous tree substitution grammar?",
        "What issue arises when a multi-word noun phrase (like \"checkpoints\") needs to be plugged into a slot expecting a singular noun non-terminal, and how does the lack of appropriate substitution rules contribute to this problem?",
        "What problem arises when the system tries to use a multi-word noun phrase like \"checkpoints\" in a slot expecting a plural noun?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen31-slide32/text.txt": [
        "What penalty is imposed when plugging in something that the grammar does not anticipate, according to the text?",
        "What is the main idea of David Cheng's paper regarding the flexibility of models in handling substitutions, and how does it propose to manage substitutions that the grammar does not anticipate?",
        "What is the penalty associated with allowing substitutions that are not anticipated by the grammar, as discussed in the context of making the model more flexible?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen32-slide33/text.txt": [
        "What device is necessary for Czech in machine translation beyond context-free grammars, and why are context-free grammars insufficient?",
        "Why does Czech require an additional device beyond context-free grammars in machine translation?",
        "What is the parsing approach used in the translation method described, and why does Czech require an additional device?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen33-slide34/text.txt": [
        "What was recommended for an illustration and animation in the context of moving from constituency syntax to dependency syntax?",
        "What transition is discussed in the text, and what was recommended for illustration and animation?",
        "What is the main topic that the user is discussing, and what did they suggest using for illustration and animation?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen34-slide35/text.txt": [
        "What is the main difference between constituency trees and dependency trees as described in the text?",
        "What are the main differences between constituency trees and dependency trees as described in the text?",
        "What is the main difference between constituency trees and dependency trees?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen35-slide36/text.txt": [
        "The translation errors identified in the text are:\n1. Lexical Choice: The English word \"cut\" is too general, whereas languages like Czech use specific verbs for different actions (e.g., \"káčit\" for cutting grass).\n2. Grammatical Case: The incorrect use of case in the translation did not align with the sentence's voice (active/passive), affecting the grammatical structure of the translated sentence.",
        "What are the two main errors in the translation of the sentence \"The grass around your house should be cut soon\" into Czech using Google Translate, and how does the case of \"trava\" (grass) change depending on whether the sentence is active or passive in Czech?",
        "What are the two main errors discussed in the translation example, and how do they relate to the concepts of long distance dependencies and case usage in Czech?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen36-slide37/text.txt": [
        "Question: Why are dependency trees considered more effective than n-grams in capturing the necessary context for predicting lexical choices and grammatical categories in language processing?",
        "How do dependency trees differ from n-grams in capturing the relationships between words like \"grass\" and \"cut\" in terms of their adjacency and grammatical categories?",
        "Question: Can dependency trees better capture the relationships between distant words compared to n-grams, and what statistics from a Czech tree bank support this claim?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen37-slide38/text.txt": [
        "What allows the grass and cutting to be far apart in the example provided?",
        "What is the purpose of using hierarchical phrases with gaps in the example provided?",
        "What is the primary purpose of hierarchical phrases with gaps in grammar?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen38-slide39/text.txt": [
        "What do linguists introduce to handle the phenomenon of crossing brackets in sentences like \"Mary John loves\"?",
        "What advantage do dependency trees have over constituency trees when dealing with crossing brackets in sentences like \"Mary John loves\"?",
        "What is the primary advantage of using dependency trees over constituency trees when dealing with non-projective structures in languages like Czech?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen39-slide40/text.txt": [
        "Question: How does the Dutch example illustrate the concept of norm projectivity, and why are context-free grammars inadequate for handling such cases?",
        "What is the concept of non-projectivity in dependency trees, and how is it demonstrated in the Dutch example provided? Additionally, discuss the implications of non-projectivity for grammatical models.",
        "What property of dependency trees in the Dutch example makes them non-projective, and how does this relate to the use of context-sensitive grammars?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen40-slide41/text.txt": [
        "What is the reason for the importance of non-projectivity in machine translation, as demonstrated by the dependencies between \"grass\" and \"being cut\" in the Dutch sentence \"John Grass saw being cut\"?",
        "Why is non-projectivity important in machine translation, as illustrated by the Dutch example provided?",
        "Why is non-projectivity important for machine translation, as demonstrated by the Dutch example \"John Grass saw being cut\" and the dependencies between \"grass\" and \"being cut\"?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen41-slide42/text.txt": [
        "What is the main reason hierarchical models are inadequate for translating into Czech according to the text?",
        "What is a key limitation of hierarchical models when translating into Czech, according to the text?",
        "What is the main reason why hierarchical models are inadequate for translating into Czech, according to the text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen42-slide43/text.txt": [
        "What percentage of Czech sentences are well-nested and contain at most one gap?",
        "According to the text, what percentage of Czech sentences exhibit severe non-projectivity with multiple gaps?",
        "What percentage of Czech sentences are actually well-nested and contain at most one gap?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen43-slide44/text.txt": [
        "Question: Why are dependency trees considered more appropriate for Czech compared to constituency trees, according to the discussion?",
        "Why are dependency trees considered more appropriate for Czech compared to constituency trees, and what does Heidi Fox's study suggest about their cross-language consistency?",
        "What is the primary reason dependency trees are considered more appropriate for Czech compared to constituency trees, and how does Heidi Fox's study relate to this?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen44-slide45/text.txt": [
        "What characteristic do the dependency trees observed in the machine translation context lack?",
        "How do dependency trees in machine translation demonstrate grammatical relationships between words without the use of non-terminals?",
        "What characteristic do the dependency trees observed in machine translation lack according to the provided text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen46-slide47/text.txt": [
        "What method is used to cover both the source and target sentences by applying substitution grammars synchronously using the treelets?",
        "What is the process of using treelets in translation according to the text?",
        "What is the purpose of substitution grammars in the described tree decomposition method?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen47-slide52/text.txt": [
        "What was the approach designed to do?",
        "At which levels was the approach designed to be applied?",
        "At which levels was the approach designed to be applicable?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen48-slide49/text.txt": [
        "What does the text refer to as a dedicated empty talk about deep syntax?",
        "What does the text mention as being the subject of a dedicated empty talk?",
        "What does the text refer to when mentioning \"deep syntax\"?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen49-slide50/text.txt": [
        "What approaches to machine translation are discussed, and what component contributed to the success of the more successful approach?",
        "What are the two approaches discussed in the text for machine translation, and why was the second approach more successful?",
        "What was the main reason the tecto-empty machine translation system was more successful compared to the STSG approach?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen50-slide51/text.txt": [
        "When were the tools to automatically generate deep syntactic trees from input text developed?",
        "What are the origins and key developments of the textogrammatic layer, and how did efforts such as the \"three banking effort\" and the creation of automated tools contribute to its advancement?",
        "In which historical period was the textogrammatic layer theory first formally formulated?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen51-slide52/text.txt": [
        "What is the purpose of adding nodes for entities in sentences from prodrop languages, as explained in the text?",
        "What is added to the treebank when the subject is dropped in Czech?",
        "What happens to the subject of a sentence in Czech when it is dropped, according to the text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen52-slide52/text.txt": [
        "What are the two participants involved in the event described by the predicate \"toby sem mělo zněnit\" in the tectogrammatical tree?",
        "What happens when moving from the analytical to the tectogrammatical level of representation?",
        "What are the two participants in the event described in the tectogrammatical tree of the example sentence \"toby sem mělo zněnit\"?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen53-slide52/text.txt": [
        "What differences are noted in the use of auxiliaries between Czech and English sentences according to the text?",
        "What is the main syntactic difference between Czech and English sentences concerning the use of auxiliaries?",
        "How do the auxiliaries in Czech and English sentences differ at the surface syntactic level?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen54-slide52/text.txt": [
        "What term is used to describe tectogrammatical trees that are structurally identical, and how do they relate to the predicate argument structure of a sentence?",
        "What key insight does the text provide about the relationship between tectogrammatical trees and predicate argument structures?",
        "What is the structural identity of tectogrammatical trees in terms of their isomorphic nature and how does it relate to the predicate argument structure mentioned in the text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen55-slide56/text.txt": [
        "What is the tectogrammatical hope for easier transfer and how does it simplify the process of translation between English and Czech?",
        "What is the role of the tectogrammatic layer in simplifying translation?",
        "What advantage does the tectogrammatic layer offer compared to direct translation?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen56-slide57/text.txt": [
        "What was the central idea of the approach discussed in the text?",
        "What is the main process described in the text for creating the full tree using synchronous tree substitution grammars?",
        "What is the primary method described in the text for handling the input?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen57-slide58/text.txt": [
        "What does the STSG approach treat all notes as?",
        "What is the purpose of the additional attributes in the text-organic notes according to the text?",
        "What problem arises when using a tree structure for representing text-organic notes, and how does the STSG approach address this issue?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen58-slide59/text.txt": [
        "What is the main issue discussed in the text regarding the factorization and alignment of layers in the context of phrase-based machine translation?",
        "What is the main challenge discussed in the text regarding the structure and attributes of factorizations, and what approaches were considered to address it?",
        "What is the main challenge when factorizing the structure and attributes in the discussed machine translation model?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen59-slide60/text.txt": [
        "What approaches were used in the system, and what were the results of their empirical evaluation?",
        "What approach was empirically found to be the best, and how did it compare to the other approaches in terms of performance?",
        "Which tree structure approach was empirically found to be the most effective in the system described?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen60-slide61/text.txt": [
        "What are the main reasons discussed in the TEXT for the failure of the pipeline approach?",
        "What are the key issues that led to the failure of the pipeline as discussed?",
        "What are the main reasons discussed for the failure of the pipeline, and how do they contribute to the overall issue?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen61-slide62/text.txt": [
        "Which approach is described in the text as using the tectogrammatic layer and a transfer-based method for machine translation, and which layers does it follow?",
        "What is the name of the approach used in machine translation that operates through layers like morphological, analytical for shallow syntax, and tectogrammatic, as described in the TEXT?",
        "What approach, using the tectogrammatic layer, was mentioned for machine translation and what layers does it utilize?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen62-slide63/text.txt": [
        "Who were the colleagues responsible for developing the system mentioned in the text?",
        "Who developed the processing system described in the text, and what is one benefit of this approach?",
        "What is the main benefit of the approach described, and who were the key contributors to this system?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen63-slide64/text.txt": [
        "What was introduced on the last slide of the presentation?",
        "What model was highlighted in the final slide as the transfer stack in the pipeline?",
        "What model was presented on the last slide as the transfer stack?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen64-slide65/text.txt": [
        "What is the root word of the deep syntactic tree, and what is its role in the translation process described?",
        "What is the root of the morphological layer tree, and what step is instructed to be taken first regarding the deep syntactic tree?",
        "What is the root of the tree, and which layer is accessed first during translation?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen65-slide66/text.txt": [
        "What is the first step you will take according to the text?",
        "What is the first step in identifying functional words according to the text?",
        "What are all the auxiliaries identified in the text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen66-slide67/text.txt": [
        "Where will auxiliaries belong according to the TEXT?",
        "Where do the auxiliaries belong when you contract your mark edges?",
        "Where are auxiliaries supposed to be placed when contracting mark edges?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen67-slide68/text.txt": [
        "What is the purpose of contracting certain elements in the creation of the backbone of the tectogram article 3?",
        "What is built by contracting them in the context of tectogram article 3?",
        "What action was taken to the X-series in order to build the backbone of the tectogram article 3?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen68-slide69/text.txt": [
        "What is the grammatical category of the noun phrase \"this machine\" in the given text?",
        "What grammatical category is \"this machine\" in the text?",
        "What grammatical category did \"this machine\" serve in the sentence, and what were its specific roles?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen69-slide70/text.txt": [
        "What verb form should be used for the sentence \"You fill in the grammar teams\" based on the given grammar rules and morphological details?",
        "What tense was used in the verb described in the text?",
        "What grammatical structure does the verb in the sentence have, including its tense, number, and any other specified characteristics mentioned in the text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen70-slide71/text.txt": [
        "What assumption is made about the trees when moving from the source to the target side morphological tree, and what percentage of sentences go beyond this assumption?",
        "What inherent assumption is made when cloning trees between the source and target morphological structures, and what is the viability of this assumption according to the given data?",
        "What percentage of sentences are assumed to align with the isomorphic assumption when moving from the source to the target tree?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen71-slide72/text.txt": [
        "How many translation choices are available for the English word \"machine\" when translating into Czech?",
        "How can complements and attributes be translated in Czech, and what options are available for their translation?",
        "Question: What are the options available for translating complements and attributes in the context of the provided text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen72-slide73/text.txt": [
        "What method was mentioned for selecting the best combination in the last slide of the talk?",
        "Which model was used to select the best combination, and where was this discussed in the talk?",
        "What model is mentioned in the text as being used to select the best combination?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen73-slide74/text.txt": [
        "What is the initial step in producing the final surface syntactic tree?",
        "What is done next with the best combination after it has been identified?",
        "What does 'you' start by doing when producing the final surface syntactic tree?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen74-slide75/text.txt": [
        "What grammatical number was the translation provided in?",
        "What form of \"Snudny\" was used in the translation?",
        "What is the grammatical form of \"Snudny\" in terms of number and degree?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen75-slide76/text.txt": [
        "What do adjectives inherit from nouns to ensure grammatical correctness?",
        "What do adjectives inherit from nouns according to the TEXT?",
        "What does the system ensure adjectives inherit from nouns to maintain grammatical correctness?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen76-slide77/text.txt": [
        "What is the next action after writing a sentence, as per the text?",
        "What must be added to a sentence in order to complete it?",
        "What must you do next after the initial sentence?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen77-slide78/text.txt": [
        "What does reordering sentences introduce that previous approaches could not do?",
        "What can reordering sentences introduce that previous approaches could not do?",
        "What is something that previous approaches could not do?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen78-slide79/text.txt": [
        "What is the purpose of demorphology in the context of word forms?",
        "What is the final step mentioned in the text regarding word forms?",
        "What process is described in the text where word forms are generated using demorphology?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen79-slide80/text.txt": [
        "What should the translation be?",
        "Kdo prohlásil, že překlad by měl být snadný?",
        "According to the text, how difficult is the translation mentioned?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen80-slide81/text.txt": [
        "What is the goal of the Hidden Markov Model in selecting labels for target site nodes, and what examples of lexical choices are provided for 'noun' and 'machine'?",
        "How does the Hidden Markov Model select the best combination of labels for target site nodes, considering the context of surrounding nodes?",
        "What is the main goal of using the Hidden Markov Model in selecting labels for target site nodes, as described in the text?"
    ],
    "testset/nmt-class/lecture07-syntax-in-smt/screen81-slide82/text.txt": [
        "What are the two main components of the model described in the text, and what is their role in the translation process?",
        "What are the two main components of the model described in the text?",
        "In the described HMM-based translation model, what are the two key components that influence the selection of target labels for each node?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen01-slide01/text.txt": [
        "Why would multilingual machine translation be helpful?",
        "Why would multilingual machine translation be helpful?",
        "Question: Why is multilingual machine translation considered helpful despite already involving at least two languages?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen02-slide02/text.txt": [
        "What is the primary goal in a transfer learning setup compared to a truly multilingual system, as described in the text?",
        "What are the two main setups discussed in the text for using multiple languages in translation systems, and what distinguishes them?",
        "What is the main difference between the transfer learning setup and a truly multilingual setup when dealing with multiple languages in a system?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen03-slide03/text.txt": [
        "What are the two main motivations for developing multilingual machine translation systems, and how do they improve translation quality in multilingual settings?",
        "What are the primary motivations for developing multilingual machine translation systems?",
        "What are the key motivations for developing multilingual machine translation systems, as discussed in the text?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen04-slide04/text.txt": [
        "What is the primary goal of transfer learning in machine translation?",
        "What is the primary goal of transfer learning in the context of machine translation?",
        "What is the goal of transfer learning in machine translation as described in the text?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen05-slide05/text.txt": [
        "Why does the neural machine translation system not show overfitting in the described training curve?",
        "Why is there no overfitting observed in the training curve for neural machine translation systems as mentioned in the text?",
        "What explains the behavior of the training curve in neural machine translation systems, where performance on the development set grows and then stabilizes without overfitting?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen06-slide06/text.txt": [
        "What would happen if we incorporated additional data from another language into a model using transfer learning?",
        "What would help achieve a better transfer learning curve according to the TEXT?",
        "What would happen if we incorporated additional data from another task or language in a clearer way?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen07-slide07/text.txt": [
        "Question: Based on the text, identify the three places where improvements can appear in the context of the described system.",
        "According to the text, what are the three areas where improvements can appear in neural machine translation systems?",
        "Question: According to the text, in how many places can improvements appear, and what are they?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen08-slide08/text.txt": [
        "What is the next step after training the system on the parent language pair until convergence?",
        "What is the next step after training your system on the parent language pair until convergence?",
        "What is the simplest technique to achieve transfer learning as described?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen09-slide09/text.txt": [
        "How does continuing the training of the child model with the parent model's weights affect its performance compared to initializing with random weights?",
        "How does transfer learning affect the child model's overfitting and performance compared to the baseline model?",
        "How does initializing the child model with the parent model's weights affect its performance compared to training it with random weights?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen10-slide10/text.txt": [
        "What phenomenon was observed when trying to improve the learning of a neural network through a curriculum-style training approach in the described experiment?",
        "What phenomenon is described in the text, where neural networks forget previously learned information when exposed to new training data, illustrated through the machine translation system experiment?",
        "What phenomenon is described where neural networks forget previously learned information when exposed to new training data?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen11-slide11/text.txt": [
        "Why is training a neural network on a sorted corpus a bad idea, and what is the recommended approach instead?",
        "**Question:**  \nWhy is sorting the corpus a bad idea for training the system, and what alternative method is recommended?",
        "Why is sorting the corpus a bad idea for training a neural network?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen12-slide12/text.txt": [
        "How were the sentences organized during training, and what was the progression of their lengths?",
        "What was Tom Cosme's French idea about the order of the sorted batched corpus, and how did it relate to the model's training?",
        "What approach was used to organize the training data, and how did it affect the model's performance?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen13-slide13/text.txt": [
        "What phenomenon was observed when restricting the model's training to sentences of decreasing maximum lengths, leading to it producing only short sentences?",
        "What phenomenon occurred when the model was restricted from processing sentences beyond a certain length during training?",
        "What phenomenon was observed when the model was trained with decreasing sentence length buckets, and how did it affect the model's ability to produce sentences of varying lengths?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen14-slide14/text.txt": [
        "What was the setup of early experiments in transfer learning, and what approach was used after training on the parent language pair?",
        "What was the trivial transfer method in the context of early transfer learning experiments?",
        "In the described experiments, what was done when transferring learning from the parent language pair to the child language pair?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen15-slide15/text.txt": [
        "What potential issue arises when extracting a subword dictionary from both a parent corpus and a child corpus?",
        "What is a potential issue when extracting a subword dictionary from both a parent corpus and a child corpus together?",
        "What issue arises when extracting a subword dictionary from a combination of a large parent corpus and a smaller child corpus?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen16-slide16/text.txt": [
        "What method was used to balance the vocabulary in the corpora?",
        "What method did they use to balance the vocabulary in the corpora?",
        "What method did they use to balance the vocabulary in their corpora?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen17-slide17/text.txt": [
        "Why might English have been oversampled in the subword vocabulary analysis?",
        "Why was English possibly oversampled in the study, and which language was equally represented in both the parent and child?",
        "Why was English oversampled in the study, and how did the representation of Czech and Estonian compare in the languages involved?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen18-slide18/text.txt": [
        "What does the text say about the relationship between the sizes of the corpora used for English-Slovak and English-Czech translation?",
        "What is the ratio of the corpus size difference between the Czech-English translation direction and the English-Slovak translation direction?",
        "What is the factor by which the corpus size for English-Czech is larger than that for English-Slovak?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen19-slide19/text.txt": [
        "What is the difference in BLEU scores when training a model on a child language pair versus training on a parent language first, and why is there a bigger improvement when translating into English?",
        "What is the difference in translation accuracy when training the model on child language pairs only versus first training on parent languages and then continuing on child languages, and why is the improvement larger when translating into English?",
        "What is the difference in the BLEU course performance when the model is trained on the child language pair only versus being trained first on the parent and then continuing on the child, and why does translating into English yield a larger improvement compared to translating from English?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen20-slide20/text.txt": [
        "Which languages were used in the experiment as parent languages for Estonian, and how did their corpus sizes compare to Estonian?",
        "How does the size of the Estonian corpus compare to that of the Finnish corpus?",
        "What is the relationship between Finnish and Estonian, and how do their corpus sizes compare?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen21-slide21/text.txt": [
        "What language provided the biggest improvement in scores when going from English?",
        "**Question:** Based on the text, which language provided the biggest improvement in scores?",
        "Question: Which language provided the biggest improvement in scores when moving from English?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen22-slide22/text.txt": [
        "What conclusion was drawn about the importance of the relationship between the parent and child language in the experiment?",
        "What conclusion was drawn about the importance of the relationship between the parent and child language in the experiment?",
        "What does the experiment conclude about the importance of the relationship between the parent and child language?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen23-slide23/text.txt": [
        "What languages were used in the pre-training phase, and what was the target language pair during the test?",
        "Which languages were used in the pre-training and testing phases of the study?",
        "Which languages were used in the pre-training phase and as the language pair of interest in the experiment?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen24-slide24/text.txt": [
        "Based on the experiments described, what was identified as the most crucial factor affecting the translation quality of the child language pair?",
        "What was the most important aspect identified in the experiments regarding the parent language pair, and how did it affect the child's performance?",
        "What aspect was found to be the most important in the experiments regarding the translation quality?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen25-slide25/text.txt": [
        "How did the positioning of English in the parent and child models influence the translation performance?",
        "What improvement was observed when the English language was placed on the incorrect side in the parent model, and how does this compare to when it was correctly positioned?",
        "What happened when the English language was placed on the \"wrong side\" in the parent and child models during the experiments?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen26-slide26/text.txt": [
        "What improvement was observed when training a translation model on language pairs without a common language, such as Arabic-Russian or Spanish-French, for the task of translating from Estonian to English?",
        "What was the observed outcome when training the translation model on corpora with no common language between the source and target languages?",
        "What improvement was observed when training a translation model with unrelated language pairs like Arabic-Russian or Spanish-French for an Estonian-English translation task?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen27-slide27/text.txt": [
        "In the described experiments, which language pair setups showed a non-significant improvement when the source and target pairs did not share the script?",
        "Was the improvement from pre-training on a language pair with no shared script significant or not?",
        "What was the outcome of pre-training on a language pair that does not share the same script, and how did it affect other language pairs?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen28-slide28/text.txt": [
        "What is important for the child's performance in terms of the parent's training?",
        "What happens to the child model's performance if the parent's training is stopped prematurely before it reaches full convergence?",
        "What happens to the performance if the parent is trained prematurely and the child is switched to too soon?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen29-slide29/text.txt": [
        "What does the text illustrate about the effectiveness of transfer learning when the child dataset is much smaller than the parent dataset?",
        "What is the main advantage of using transfer learning from a well-trained parent model when the child model has very limited training data?",
        "What improvement in performance was observed when using the parent model with 10,000 English-Estonian sentence pairs compared to the baseline model?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen30-slide30/text.txt": [
        "What was the source of the improved vocabulary in the child's outputs?",
        "What percentage of the child's output tokens were new words not previously used by the parent, and what type of words were these?",
        "What factors contributed to the improvement in the model's performance, and what specific aspects of the output were observed as a result?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen31-slide31/text.txt": [
        "Why are there no overlapping subword units in the child model due to the difference in scripts between Russian and Estonian?",
        "Why are there no shared subword units in the child model when translating from English to Estonian, given the addition of the English-Russian parent model?",
        "Why is there no overlap in subword units between the English-Russian and English-Estonian translation in the child model?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen32-slide32/text.txt": [
        "How does the sentence length of the training data impact the BLEU score and output length of the neural machine translation system?",
        "What is the relationship between the sentence length of the training data and the performance of the neural machine translation system, as evidenced by the BLEU score and the average output length?",
        "How does training a neural machine translation system on sentences of varying lengths affect the output sentence length and BLEU score when evaluated on test data?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen33-slide33/text.txt": [
        "What is the average sentence length achieved by the child model during testing?",
        "How does the use of constrained parents affect the child model's BLEU score and average length compared to unconstrained parents?",
        "What performance metric is used to evaluate the effectiveness of the child model's transfer learning?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen34-slide34/text.txt": [
        "What is the purpose of highlighting the baseline transfer and trivial transfer in the discussion?",
        "What did the text emphasize regarding transfer?",
        "What did the text highlight regarding the baseline transfer?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen35-slide35/text.txt": [
        "What is the next area of focus after the previous discussion?",
        "What is the main topic addressed in the provided text?",
        "What is the main focus when transitioning to multilingual machine translation as mentioned in the TEXT?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen36-slide36/text.txt": [
        "What is the purpose of pivot translation in machine translation systems, and how does it work?",
        "What is the purpose of pivot translation, and how is it applied in the context of translating between two low-resource languages?",
        "What term is used to describe a system's ability to translate between language pairs it wasn't explicitly trained on, provided the individual languages were included in the training data?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen37-slide37/text.txt": [
        "What is the primary benefit of a multi-target focus in machine translation for a multinational institution?",
        "Question: Why might using an intermediate language help in translating an ambiguous word from one language to another, as illustrated in the example with the German word 'Schloss'?",
        "What are the two main motivations for using multi-target and multi-source setups in machine translation, particularly within a multinational institution?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen38-slide38/text.txt": [
        "What is the ideal setup described for the machine translation system and what does it enable?",
        "What kind of system is described for multilingual translation?",
        "What is the main feature of the ideal flexible multilingual machine translation system described in the text?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen39-slide39/text.txt": [
        "What types of systems were used in multisource translation?",
        "What systems are mentioned as being used in multisource translation?",
        "What characteristics are mentioned about multisource translation in the TEXT?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen40-slide40/text.txt": [
        "What is the underlying principle of neural machine translation, and how does it condition the model on source sentences?",
        "What is the underlying principle of neural machine translation systems as described in the text?",
        "What underlying principle makes neural machine translation systems effective in handling multiple source languages?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen41-slide41/text.txt": [
        "What is the main drawback of the setup described by Zoffa and Knight?",
        "What is the main drawback of the setup described by Zoffa and Knight?",
        "What is the main drawback of the setup described by Zoffa and Knight for their translation model?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen42-slide42/text.txt": [
        "What was the main focus of Orhan Ferrat's 2016 experiments with non-multi-parallel corpora?",
        "What was the main focus of Orhan Ferrat's 2016 experiments with bilingual corpora, particularly regarding the use of attention mechanisms when training multiple encoders and decoders across different language pairs?",
        "What was the primary focus of Orhan Ferrat's 2016 experiments with bilingual corpora in his two papers?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen43-slide43/text.txt": [
        "What does the attention move across when producing the target output, one word at a time?",
        "What does attention do as each target word is being produced?",
        "What does attention do while generating each word in the target language during translation?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen44-slide44/text.txt": [
        "Is the attention mechanism in the model trained separately for each language pair or shared across all language pairs?",
        "What role does the attention mechanism play in the model when training across different language pairs?",
        "How does the attention mechanism function in a model that shares it across multiple language pairs, and what happens when training different encoders and decoders for specific language pairs?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen45-slide45/text.txt": [
        "How did the system's performance change when tested in a simulated low-resource setting, particularly in terms of training data size and the number of languages used?",
        "What improvements were observed when the system was tested in a simulated low resource setting, particularly when the training data was small?",
        "How did the system's performance change when tested in a simulated low-resource setting, particularly in terms of comparison to the baseline and the role of the number of languages involved?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen46-slide46/text.txt": [
        "Question: What approach did rural institutions take to overcome the challenges of online learning, and what were the benefits?",
        "What did John discover in the cave that he found using the map he inherited from his late father?",
        "What does the text indicate about the identity of the helpful assistant?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen47-slide45/text.txt": [
        "What topic or area were the experiments focused on?",
        "What were the experiments generally directed into?",
        "What general area did the experiments go into?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen48-slide46/text.txt": [
        "Question: What is the observed difference in performance between the multilingual model and single paired models when translating into English versus other languages, and what is the reasoning behind this difference?",
        "What is the comparison between multilingual and single paired models in terms of translation performance when translating into or out of English?",
        "**Question:**  \nBased on the text, explain the comparative performance of multilingual and single-pair machine translation models in different translation directions, and provide reasons for the observed patterns."
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen49-slide48/text.txt": [
        "What does the user imply about the assistant's language compared to English?",
        "Is another language mentioned as being easier than English?",
        "What is mentioned as being better than English in the TEXT?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen50-slide47/text.txt": [
        "How can a model process a sentence available in multiple languages according to the text?",
        "How can the model process a sentence available in multiple languages using encoders and decoders, and what are the methods mentioned for combining their outputs?",
        "What approach was described for processing a sentence available in multiple source languages using encoders and decoders?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen51-slide49/text.txt": [
        "How does including data from other languages in the training affect translation performance when translating from Spanish into English compared to translating from English into Spanish?",
        "How does training a model with additional language pairs beyond the primary language pair affect its translation performance when translating into English versus translating out of English?",
        "How does training with multiple languages affect translation performance when translating into English versus from English into other languages?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen52-slide50/text.txt": [
        "Which method, early averaging or late averaging, is more effective in improving translation accuracy when used alone?",
        "Which approach yields the best performance when translating from Spanish and French to English: early averaging, late averaging, or a combination of both?",
        "Which method, early averaging or late averaging, is more effective for improving translation quality when using knowledge from source languages, and how does combining both methods compare?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen53-slide52/text.txt": [
        "What was the purpose of trying to improve translation into a particle language pair by including additional languages?",
        "What aspect made the approach of improving translation into a particle language pair by including additional languages different from another method?",
        "What was the idea mentioned for improving translation into a particle language pair?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen54-slide50/text.txt": [
        "Under what circumstances is transfer learning more beneficial for maintaining performance across multiple language pairs?",
        "Under what condition are multilingual systems particularly advantageous in the context of transfer learning, as described in the text?",
        "What is the impact of the target languages being shared or distinct on the performance of multilingual systems in transfer learning?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen55-slide52/text.txt": [
        "How does zero-shot translation differ from pivot translation in terms of process and efficiency?",
        "What is the difference between pivot translation and the multi-way encoder-decoder system in the context of zero-shot translation?",
        "What does the text say about the alternative to using English as a pivot language for translating between Spanish and French?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen56-slide53/text.txt": [
        "Why did the neural network perform poorly without explicit pivoting when used for tasks that were mutually independent?",
        "**Question:** Why is pivoting necessary for the model's performance, and what happens when it isn't used?",
        "Why did the network perform poorly without explicit pivoting?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen57-slide54/text.txt": [
        "Where would one obtain a small amount of parallel data between Spanish and French for fine-tuning the network?",
        "What is the main question regarding the fine-tuning of the network with parallel data between Spanish and French?",
        "Is it possible to fine-tune the neural network to add the missing links between Spanish and French by using a small amount of parallel data, and where would this data come from?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen58-slide55/text.txt": [
        "What corpora were used to train the paths in the multi-way system?",
        "What target languages can English be used for in the multi-way system after training with the Spanish-English and English-French corpora?",
        "What is the purpose of using the English portion in the multi-way, multi-source, multi-target system?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen59-slide56/text.txt": [
        "Question: Can the Spanish-English system be used to produce synthetic Spanish from a French corpus?",
        "What is the purpose of using the Spanish-English system mentioned in the text?",
        "What can the Spanish-English system be used to produce?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen60-slide57/text.txt": [
        "What is the next step in training the network?",
        "What is the purpose of fine-tuning the network with data that goes from Spanish into French?",
        "What is the purpose of fine-tuning the network with data that goes from Spanish into French?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen61-slide58/text.txt": [
        "What is the BLEU score for pivoting without fine-tuning, and how does it compare to the score achieved with the synthetic parallel corpus?",
        "How does the BLEU score compare when using pivoting versus a synthetic parallel corpus without fine-tuning?",
        "The results show that using pivoting without fine-tuning yields a score of around 20, while employing a synthetic parallel (pseudo-parallel) corpus results in a lower BLEU score of up to 17, indicating worse performance compared to pivoting."
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen62-slide59/text.txt": [
        "How does using separate encoders and decoders for new language pairs compare to employing a true parallel corpus in terms of performance, and what role does the size of the parallel corpus play in this scenario?",
        "Is a true parallel corpus necessary to achieve performance comparable to an explicit pivoting setup?",
        "What is the performance comparison between using a single pair baseline model with sampling and a true parallel corpus in terms of translation?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen63-slide60/text.txt": [
        "What is the main advantage of training a single model with a fixed number of parameters to handle multiple languages simultaneously?",
        "What modification is made to the source sentence to specify the target language in the training setup described?",
        "How does the model determine the target language during training, and what mechanism is used to specify this target language in the source sentence?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen64-slide61/text.txt": [
        "Which language's translation into English saw improvements in blind scores according to the described experiment?",
        "What was the primary benefit of the multilingual translation system developed in Google's 2016 experiment?",
        "What year was the Google experiment regarding the multilingual system for translation conducted?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen65-slide62/text.txt": [
        "What is the impact of using English-German training data on English-French translation performance, and how do corpus sizes affect this outcome?",
        "What challenges were observed when using English-German training data for English-French translation, and how did the size and distribution of the French and German corpora affect the system's performance?",
        "What issue arises when the sizes of the corpora for different languages in a multilingual translation system are not balanced?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen66-slide61/text.txt": [
        "Can a model handle multiple source languages without losing translation quality if the target language remains the same?",
        "Can multiple source languages be fed into the same model without affecting translation quality as long as the target language remains the same?",
        "Question: Can multiple source languages be fed into the same model without losing translation quality if the target language remains the same?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen67-slide62/text.txt": [
        "What role does the first token play in the input sentence when translating different languages?",
        "Is it possible to train a model to translate into multiple languages if each input sentence starts with a specific token indicating the target language?",
        "How does the model know which language to translate into when given a sentence with different language pairs?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen68-slide63/text.txt": [
        "What was the dataset used to train Jörg Tiedemann's 2018 recurrent neural network system for Bible translation?",
        "What limitation does the dataset used by Jörg Tiedemann's system have?",
        "What dataset did Jörg Tiedemann use in his 2018 system that involved translating the Bible into many languages?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen69-slide64/text.txt": [
        "Which language families form distinct clusters in the T-SNE visualization described in the text?",
        "Which language family is identified as forming a distinct cluster in the T-SNE visualization?",
        "What language family clusters were observed when analyzing language embeddings with T-SNE?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen70-slide63/text.txt": [
        "What is one capability of the method despite its translation limitations?",
        "What capability does the system have despite its translation issues?",
        "What does the text say about the system's ability to cluster languages?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen71-slide64/text.txt": [
        "In what way are economists similar to other social scientists?",
        "It seems like the text you provided is incomplete. Could you please provide the full text so I can generate an appropriate question?",
        "What method is similar to the way linguists study the evolution of language?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen72-slide65/text.txt": [
        "Question: Did Google's research find that using high-resource languages alone in a multilingual system improved performance?",
        "What languages saw improvements in Google's recent research on multilingual systems, and why did they benefit from the use of high-resource data?",
        "\"According to the text, how does the effectiveness of multilingual systems vary between high-resource and low-resource languages?\""
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen73-slide66/text.txt": [
        "What is the range of the number of sentence pairs in the parallel corpora used by Orhan Ferrat and colleagues for their 102 languages?",
        "What is the range of data sizes used in the experiment with parallel corpora for 102 languages?",
        "What is the range of data sizes used in the experiment conducted by Orhan Ferrat and colleagues, as described in the text?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen74-slide67/text.txt": [
        "What is the main reason BLEU scores are not suitable for comparing translation quality across different languages?",
        "What trend is observed in translation quality when comparing high-resource and low-resource languages?",
        "Question: According to the text, why is the translation quality better for high resource languages than for low resource languages?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen75-slide68/text.txt": [
        "What are the key components of the encoder and decoder in the transformer setup discussed?",
        "What are the two main components of each decoder layer in the transformer setup?",
        "What are the two sub-layers in each encoder layer of the transformer setup, and what is their purpose?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen76-slide69/text.txt": [
        "What are the numbers of layers in the encoder and decoder for the largest transformer setup discussed, and how many parameters does it have?",
        "What is the key difference in performance between a \"wide\" transformer network and a \"deep\" transformer network, and why does one outperform the other on low-resource languages?",
        "Compare wide and deep transformer networks, including their structure and training requirements as described in the text."
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen77-slide70/text.txt": [
        "At what point does it become more beneficial to use a multilingual model instead of pairwise models for language translation, based on the resources available for the languages?",
        "What is the effect of using a multilingual model compared to pairwise models for high-resource versus low-resource languages, as demonstrated in the study?",
        "What is the main finding regarding the comparison between multilingual and pairwise systems for machine translation performance across different languages?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen78-slide71/text.txt": [
        "Question: How does increasing the number of parameters in the model affect its performance on high-resource language pairs, as described in the experiment?",
        "What is the impact of increasing the number of parameters on the performance of a multilingual model, particularly on high-resource language pairs, as described in the text?",
        "What performance metric is mentioned for the 50 billion parameter model on high-resource language pairs?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen79-slide72/text.txt": [
        "How does the gating network influence the training process of the model described in the text?",
        "What is the primary issue when training a model with a large number of languages without increasing its capacity?",
        "What is the function of the gating network in the model described?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen80-slide73/text.txt": [
        "What method did Orhan Ferden and colleagues use to make the neural network more efficient for multilingual machine translation?",
        "Question: How did Orhan Ferden and colleagues reduce the size of the translation model while maintaining its functionality?",
        "What specific technique did Orhan Ferden and colleagues use to reduce the size of the model while still allowing it to translate between different language pairs?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen81-slide74/text.txt": [
        "What is the reason for the underperformance of the multilingual system compared to the bilingual baselines in this setup?",
        "Question: Why does the multilingual system underperform compared to bilingual baselines, and how do adapters address this issue?",
        "What issue causes the multilingual system to underperform compared to the bilingual baselines, and how do adapters help mitigate this issue when translating into English?"
    ],
    "testset/nmt-class/lecture10-multilingual-mt/screen82-slide75/text.txt": [
        "In which context is the importance of adapters more prominent when translating out of English?",
        "What is the importance of adapters in the context of translating out of English, as mentioned in the TEXT?",
        "What is the importance of adapters when translating out of English into different target languages?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen01-slide02/text.txt": [
        "What is the main topic of the lecture?",
        "What is the main focus of today's lecture on statistical machine translation?",
        "What is the primary focus of today's lecture on statistical machine translation?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen02-slide03/text.txt": [
        "What approaches are mentioned for incorporating syntactic information into neural machine translation, and what does the text suggest about the ability of transformer networks to learn without explicit syntactic information?",
        "What are the multiple ways syntactic information can be incorporated into neural machine translation, and what conclusion is drawn about the transformer network's ability to learn without explicit syntactic information?",
        "What key components are discussed in the transformer architecture as described?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen03-slide04/text.txt": [
        "**Question:**  \nWhat role does the attention mechanism play in the decoder during the translation process?",
        "What is the role of the attention mechanism in the decoder when processing a sequence-to-sequence system?",
        "What role does the attention mechanism play in the sequence-to-sequence system described in the text, and how does it assist the decoder during the translation process?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen04-slide05/text.txt": [
        "What does the decoder state gradually accumulate in the described model?",
        "What is the role of attention energies in the described model?",
        "What is the role of the decoder state in the context of the encoder state and attention energies in the described model?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen05-slide07/text.txt": [
        "What does the decoder use to decide the next word in the sequence?",
        "What does the decoder use to decide the next word in the sequence?",
        "What does the decoder consult to decide the next word in the sequence?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen06-slide07/text.txt": [
        "What is the text moving to discuss?",
        "What model are we moving to in this discussion?",
        "What model is being discussed in the following text?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen07-slide08/text.txt": [
        "What is the central component of the transformer model introduced in the 2017 paper \"Attention is All You Need\"?",
        "In which year was the transformer model introduced, and what was the key innovation behind it as described in the paper?",
        "What was the central component of the transformer model, as introduced in the 2017 paper \"Attention is all you need\"?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen08-slide09/text.txt": [
        "What two resources does the author recommend for understanding the topic, and what are their key features?",
        "The author recommends the blog post \"Transformer Illustrated\" for its clear and simple explanation and the use of good pictures.",
        "What blog post is recommended and why?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen09-slide10/text.txt": [
        "What is the role of the decoders in a transformer model, and how do they process and refine the input sequence?",
        "How many layers of encoders and decoders are used in the transformer model as described in the original paper?",
        "How many layers of encoders and decoders are used in the original transformer model, and what is the purpose of having multiple decoder layers?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen10-slide11/text.txt": [
        "What are the two sublayers in each encoder and decoder of a transformer model?",
        "What are the two sublayers in each encoder and decoder?",
        "What are the two sublayers in each encoder and decoder in the transformer architecture?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen11-slide12/text.txt": [
        "What process allows each word to consider every other word after converting them into dense vectors?",
        "What does the self-attention mechanism enable in terms of information flow within the network?",
        "What part of the transformer model allows every word to consider every other word, thereby studying mutual dependencies between words?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen12-slide13/text.txt": [
        "What happens to the tokens after each one undergoes the same transformation in the encoder layer?",
        "What transformation is applied to each token in a feedforward network, and what is the outcome after the first encoder layer?",
        "What happens to the token representations after they are processed in the first encoder layer?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen13-slide14/text.txt": [
        "What method does the transformer model use to encode the positional information of tokens in the embeddings?",
        "How is positional encoding implemented in the transformer model to capture the position of tokens?",
        "What is the purpose of positional encoding in a transformer model?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen14-slide15/text.txt": [
        "What is the core element of the transformer network as mentioned in the text?",
        "Question:  \nWhat is the core element of the transformer network?",
        "What is the core element of the transformer network discussed in the text?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen15-slide16/text.txt": [
        "What is the main advantage of using convolutional neural networks (CNNs) over recurrent neural networks (RNNs) when processing arbitrarily long sequences?",
        "What is the key advantage of self-attention over convolutional neural networks in processing arbitrarily long sequences?",
        "What is a key advantage of using a convolutional neural network (CNN) for processing arbitrarily long sequences compared to recurrent neural networks (RNNs)?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen16-slide17/text.txt": [
        "What are the computational complexities and benefits of using self-attention networks for processing long sequences?",
        "What is the trade-off between computational complexity and GPU parallel processing in self-attention networks?",
        "What is the trade-off involved in using self-attention networks for processing long sequences?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen17-slide18/text.txt": [
        "What is the purpose of self-attention in processing long inputs?",
        "How does self-attention work in neural networks to process arbitrarily long inputs into fixed-size vectors?",
        "How does self-attention help in aggregating information from arbitrarily long inputs into a fixed-size vector in a trainable manner?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen18-slide19/text.txt": [
        "How are the keys, queries, and values generated in self-attention?",
        "What does the network use to generate the keys, queries, and values in self-attention?",
        "What are the three different views of the input units in self-attention, and how are they generated from the input word embeddings?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen19-slide20/text.txt": [
        "What are queries and keys used for in the described model?",
        "What is the purpose of calculating the dot product between query and key vectors in the described mechanism, and how does this lead to comparing every position with every other position?",
        "What is the purpose of comparing every position with every other position using query and key vectors in the described mechanism?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen20-slide21/text.txt": [
        "What is the purpose of normalizing the scores in the described vector representation?",
        "What normalization steps are taken to account for the dimensionality of the vector representation before applying softmax normalization?",
        "What normalization steps are applied to the scores to account for the dimensionality of the vector representation before applying softmax?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen21-slide22/text.txt": [
        "What is the role of self-attention in aggregating information from the entire sentence at each token position?",
        "What is the main focus of the network when performing self-attention as described in the TEXT?",
        "What does the self-attention mechanism do when processing each position in the sentence, according to the text?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen22-slide23/text.txt": [
        "How does self-attention in transformers work and what allows it to be computed in constant time?",
        "What are the key steps in performing self-attention using matrices, as described?",
        "What is the main benefit of using self-attention in the context described, and how is it achieved using matrices?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen23-slide22/text.txt": [
        "What component's attention was implemented on the GPU?",
        "Where is the attention of one head computed?",
        "Which component of the attention mechanism is computed on the GPU for each head?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen24-slide23/text.txt": [
        "What term refers to the multiple views or considerations of the input sequence in the transformer model where each node can observe all other items?",
        "What is the term used for the parallel views or considerations of the input sequence in the transformer model, where each node or item observes all other items in the sequence?",
        "What is the term for the parallel views in the transformer model where each node considers the entire input sequence?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen25-slide24/text.txt": [
        "How are the matrices in each head of the standard transform model initialized, and what happens to them during training?",
        "What is the role of initializing matrices with random values in each transformer head, and how do these matrices function during training?",
        "What is the standard number of attention heads in a transformer model, and what defines each head?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen26-slide25/text.txt": [
        "How does the model manage the eight times longer output generated by the independent heads?",
        "What method is used to handle the eight times longer output than expected?",
        "What is done with the eight outputs generated by the independent transformer heads after processing in parallel?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen27-slide26/text.txt": [
        "In the self-attention mechanism, each of the eight heads generates a representation by attending to different parts of the input sequence. These representations are concatenated side by side to form a combined output, which is then projected back to the original dimension to produce the final Z representation for the next layer.",
        "How many attention heads are used in the self-attention mechanism, and what is the role of these heads in processing the input sequence?",
        "What happens in the self-attention mechanism when there are eight attention heads?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen28-slide27/text.txt": [
        "What mechanism does the decoder self-attention use to prevent looking at future words during the attention process?",
        "What is the purpose of masking in the decoder self-attention mechanism of the Transformer model?",
        "What is the purpose of masking in the decoder self-attention mechanism of a Transformer?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen29-slide28/text.txt": [
        "What did the study reveal about the attention head's ability to identify the antecedent of a pronoun in the sentence \"the animal didn't cross the street because it was too tired\"?",
        "How does the attention mechanism in the encoder layer 5 help identify the antecedent of the pronoun \"it\" in the example sentence?",
        "What did the head in layer 5 of the encoder focus on when processing the pronoun \"it\" in the given sentence?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen30-slide29/text.txt": [
        "What is the primary focus of head number two when analyzing the syntax of a clause?",
        "What does head number two focus on when analyzing a clause, and why is this focus important?",
        "What is the primary focus of head number two when processing a clause?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen31-slide30/text.txt": [
        "What is the purpose of pruning weights in a trained neural network, and how does it affect computation time?",
        "According to the text, what can be done after training a neural network to reduce computation time without affecting performance?",
        "What is the effect of pruning weights in a neural network, as mentioned in the text?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen32-slide31/text.txt": [
        "What does the text state about the reason early papers in neural machine translation have explicit information?",
        "Why was explicit information included in early papers in neural machine translation?",
        "Question: Why did early papers in neural machine translation include explicit information?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen33-slide33/text.txt": [
        "How can linguistic information be incorporated into a neural machine translation system using the methods described in the text?",
        "How can linguistic information be integrated into a neural machine translation system, and what are some of the methods discussed for achieving this?",
        "**Question:**  \nHow can linguistic information be added to a neural machine translation system, and what are the key methods discussed in the text?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen34-slide33/text.txt": [
        "What does the text mention about the approach?",
        "What approach is discussed?",
        "What is the approach mentioned for..."
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen35-slide34/text.txt": [
        "What is the key distinction between the two variants of tree LSTMs described in the text, and how do they differ in their approach to handling children and their order?",
        "How do the tree LSTMs differ in their handling of children when processing dependency trees versus constituency trees?",
        "What modification is made to the standard LSTM or GRU models to help them better capture dependencies in sentences, and how do these modifications differ when handling dependency trees versus constituency trees?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen36-slide35/text.txt": [
        "What does the additional structure allow the encoder and decoder to do, considering it mimics human-important syntactic dependencies?",
        "What does the additional structure allow the encoder and decoder to do, considering the dependencies in the sentence?",
        "What additional element does the approach incorporate to enable a second step of reconsideration and mimic syntactic structure?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen37-slide36/text.txt": [
        "What is the primary goal of the refinement described in the paper, and how does it improve the translation task?",
        "What is the purpose of allowing information to flow both bottom-up and top-down in the network structure described in the paper?",
        "What was the goal of the refinement mentioned in the paper regarding the network structure?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen38-slide37/text.txt": [
        "How does the computation structure in graph convolution networks mimic the dependency tree?",
        "What is the role of weight matrices in the computation structure of graph convolution networks when processing dependency trees, and how does the model ensure that each node accesses information from its governor and children?",
        "How does the structure of computation in graph convolutional networks (GCNs) mimic the dependency tree to process information from surrounding words and the dependency parse?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen39-slide38/text.txt": [
        "What are the two main types of approaches discussed in the text, and how do they differ in their methodological foundations?",
        "What is the main focus of the conceptually simpler approaches discussed, which primarily stick to standard sequence-to-sequence or transformer-style processing?",
        "What are the simpler approaches discussed in the text that primarily use standard sequence-to-sequence or transformer-style processing, following the discussion of methods that limit calculations based on sentence pre-processing?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen40-slide39/text.txt": [
        "What are super tags used for in the context of encoding syntactic information?",
        "What is the purpose of super tags in the context of Combinatory Category Grammar (CCG), and how do they help encode syntactic information in individual tokens?",
        "What is the purpose of using CCG tags in syntactic parsing, and how do they assist in constructing parse trees?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen41-slide39/text.txt": [
        "What must be provided to make a verb fully saturated in CCG?",
        "What is the purpose of the slashes in the CCG text?",
        "How does the CCG text specify the complements required for a verb to be fully saturated in a sentence?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen42-slide39/text.txt": [
        "What happened next in the story?",
        "What happened next?",
        "What is the speaker about to describe?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen43-slide40/text.txt": [
        "What is the purpose of adding syntactic information to each token?",
        "What is the purpose of adding syntactic information to each token?",
        "How is syntactic information added to each token?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen44-slide41/text.txt": [
        "What technique was used to improve translation in morphologically rich languages like Czech, where the decoder considers syntactic information before lexical decisions?",
        "Which method was found to be more successful in improving translation quality: interleaving sequences or using multiple decoders?",
        "What is the advantage of using interleaved sequences in the decoder for machine translation, as discussed in the text?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen45-slide42/text.txt": [
        "What approach did the author use with their students to predict target syntax using a secondary decoder in the transformer model, and how did the use of dummy tags contribute to this method?",
        "What is the title of the paper mentioned and where was it published?",
        "What was the name of the dummy tag used in the study, and what was its purpose?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen46-slide43/text.txt": [
        "What is the main reason the interleaved setup is suggested to improve network performance compared to other setups, according to the text?",
        "What is the reason that both the interleaved and multi-decoder setups perform similarly, and what role does the network's processing depth play in this outcome?",
        "What is the main reason the multi-decoder setup outperforms the interleaved setup in the experiments described?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen47-slide44/text.txt": [
        "What is the outcome when a neural network is provided with identical tags in a multitask learning setup?",
        "What happens to the network's ability to learn when it is provided with identical tags in a multitask setting?",
        "What happens to a network's ability to learn in a multitask setting if it is given an overly easy task, and how does this compare to using CCGs or random tags?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen48-slide45/text.txt": [
        "What method is suggested to encode syntactic information, and how does it work?",
        "What is the alternative approach mentioned for encoding syntactic information into word embeddings instead of using dummy tags?",
        "What alternative method is suggested for encoding syntactic information into word embeddings without using traditional linguistic tags?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen49-slide46/text.txt": [
        "What is the role of linguistic information in attention?",
        "What is the purpose of making use of linguistic information in attention?",
        "What is the purpose of making use of linguistic information in the attention mechanism?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen50-slide47/text.txt": [
        "What modification was made to attention calculation in the paper discussed, and how does it benefit English-Chinese translation?",
        "What modification was made to the attention mechanism in the paper to avoid repeating words in the output?",
        "What approach did the paper introduce to improve English-Chinese translation by altering the attention calculation in neural networks?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen51-slide48/text.txt": [
        "What are the two main components of the training objective for the transformer model described in the text, and how were they implemented?",
        "What specific constraint was imposed on one of the attention heads in the experiment to ensure it captures the syntactic structure of the source sentence?",
        "What modification was made to the training objective to ensure that one of the attention heads in the transformer encoder represents the syntactic dependency structure of the source sentence?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen52-slide49/text.txt": [
        "Where in the transformer model are the best dependency parses produced?",
        "According to the study, where do the best dependency parses produced by the transformer occur?",
        "At which layers were the best parses achieved according to the study?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen53-slide50/text.txt": [
        "What is the structure of the dependency trees in the dummy parse described in the text?",
        "What is the dependency structure of the dummy parse described in the text?",
        "What is the structure of the dummy parse in terms of dependency trees?"
    ],
    "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen54-slide51/text.txt": [
        "Question: Why does using a dummy parse result in better translation quality compared to using a true parse, and what effect does it have on the attention matrices in the transformer model?",
        "What effect did using a dummy parse have on the attention matrices, and how did this impact translation quality?",
        "What is the effect of using a dummy parse on the attention matrices and translation quality?"
    ],
    "testset/popular/video-02/text.en.txt": [
        "How does the rat park experiment by Bruce Alexander challenge the traditional understanding of addiction, and what does it imply about the factors contributing to addiction?",
        "What do the rat experiments and the Vietnam War study suggest about the role of environment in heroin addiction?",
        "What is the main argument presented in the text regarding the cause of addiction?"
    ],
    "testset/popular/video-07/text.en.txt": [
        "What is the main challenge addressed in the speech regarding the European Union's approach to divorce laws, and how does the speaker propose to address it?",
        "What approach has the European Union suggested to tackle the issue of varying divorce laws across member states, and what are the challenges faced by the Council in reaching a decision?",
        "What issue is the speaker addressing, and what are the proposed solutions based on the speaker's perspective?"
    ],
    "testset/popular/video-13/text.en.txt": [
        "What is the origin of micro-apartments according to the speaker?",
        "What is the typical size and cost of a micro-apartment?",
        "What is the origin of the concept of micro-apartments, and which European city is currently planning to build houses with micro-apartments in the city center?"
    ],
    "testset/popular/audio-10/text.en.txt": [
        "What is the main argument presented regarding the economic benefits of the eurozone membership, using Slovakia and the Czech Republic as examples?",
        "By 2015, what was the percentage decrease in the GDP per capita difference between the Czech Republic and Slovakia compared to 2009, and what does this suggest about Slovakia's economic performance after adopting the euro?",
        "What was the difference in GDP growth rates between the Czech Republic and Slovakia between 2009 and 2016, and how did the GDP per capita difference between the two countries change during this period?"
    ],
    "testset/popular/video-14/text.en.txt": [
        "How many test miles have Google's autonomous vehicles completed according to the text?",
        "What technologies are used in Google's autonomous cars to continuously scan the surroundings?",
        "How many test miles have Google's autonomous vehicles completed as of the information provided?"
    ],
    "testset/popular/audio-09/text.en.txt": [
        "What are the two main examples Kilian Kirch-Gessner uses to illustrate the benefits of EU membership for the Czech Republic, and how have these examples impacted the local economy and culture?",
        "What example did Kilian Kirch-Gessner use to illustrate the value of the Czech Republic being part of the EU?",
        "What is the primary example the speaker uses to illustrate why it is worth being part of the EU?"
    ],
    "testset/popular/video-04/text.en.txt": [
        "What are the key differences between FFP-1, FFP-2, and FFP-3 masks in terms of filtration efficiency and their intended use?",
        "What is the difference between FFP-1, FFP-2, and FFP-3 masks, and where are they primarily used?",
        "What are the three layers of a surgical mask, and what is their purpose?"
    ],
    "testset/popular/video-23/text.en.txt": [
        "What materials or objects did children use to create their own toys during a time of scarcity?",
        "How did children in post-war Berlin obtain toys, and what was the significance of receiving new toys from American schools?",
        "What were some of the games children played and what materials were used to create their toys during this time?"
    ],
    "testset/popular/video-15/text.en.txt": [
        "Why is the manuscript called the Abrogans?",
        "How many known copies of the Abrogans are there, and where are they located?",
        "What is the significance of the find in Admont in relation to the Abrogans and the German language?"
    ],
    "testset/popular/video-08/text.en.txt": [
        "What action did the EU agree to take regarding deep-sea drilling in response to the environmental risks discussed?",
        "What does the speaker suggest about the European Maritime Safety Agency (Emser) in Lisbon?",
        "What specific measure does the speaker suggest the EU should implement regarding deep-sea drilling?"
    ],
    "testset/popular/video-06/text.en.txt": [
        "Question: Why does the speaker argue that Sarajevo should be designated as the European Capital of Culture 2014?",
        "Question: What historical event and figure did the speaker reference to illustrate Sarajevo's cultural resilience and why does this support the city's application for European Capital of Culture?",
        "What is the significance of Sarajevo applying to be the European Capital of Culture in 2014, and what historical events and cultural resilience does the text highlight?"
    ],
    "testset/popular/audio-24/text.en.txt": [
        "Why did German scientific institutions begin to confront their Nazi past in the late 1990s according to Rüdiger vom Bruch?",
        "What was the purpose of the Gedenkort Charité project, and what elements does it include?",
        "What project did Charité implement to confront its Nazi past, and what are its main components?"
    ],
    "testset/popular/audio-12/text.en.txt": [
        "How does Marjina Dlabayova describe the Czech Republic's attitude towards the European Union, and what statistic does she mention regarding the country's financial contributions since 2004?",
        "What are Marjina Dlabayova's personal reflections on the European Union's impact on individuals, based on her experiences as a student and a business owner?",
        "What two main issues does Marjina Dlabayova highlight as important to avoid in the next 15 years, and why does she consider them significant?"
    ],
    "testset/popular/audio-19/text.en.txt": [
        "What reason does Harald Storz give for the increasing number of anonymous burials in Germany?",
        "How often does the Tobias Brotherhood in Göttingen organize a funeral service for the deceased without family or friends?",
        "What is the main purpose of the Tobias Brotherhood in Göttingen?"
    ],
    "testset/ukr-biology/book02/topic01-Обмін речовин та перетворення енергії в організмі людини/text.en.txt": [
        "Which vitamin is primarily involved in the regulation of calcium metabolism in the human body?",
        "Which vitamin is essential for bone development and regulates calcium metabolism?",
        "Which vitamin is essential for bone health and what condition arises from its deficiency?"
    ],
    "testset/ukr-biology/book02/topic02-Травлення/text.en.txt": [
        "What is the nature of the environment in the stomach and what substances contribute to it?",
        "What systems regulate the digestive system, and how do they function?",
        "What organ does the pancreatic duct open into?"
    ],
    "testset/ukr-biology/book02/topic03-Дихання/text.en.txt": [
        "Which functional indicator of the respiratory system is used to assess its state and is described as the sum of tidal, reserve, and supplementary volumes?  \na) Tidal volume  \nb) Residual volume  \nc) Reserve volume  \nd) Vital capacity of the lungs",
        "What is the primary function of the bronchi in the respiratory system?",
        "What is the percentage of oxygen in exhaled air according to the provided data?"
    ],
    "testset/ukr-biology/book02/topic04-Транспорт речовин/text.en.txt": [
        "Which structure is primarily responsible for the filtration process that forms primary urine, and what is the result of this process?",
        "What is the functional unit of the kidneys, and what are the main processes involved in the formation of urine?",
        "Which organ is NOT part of the excretory system?  \na) muscles b) kidneys c) skin d) lungs"
    ],
    "testset/ukr-biology/book02/topic05-Опора та рух/text.en.txt": [
        "Which muscle is ribbon-shaped according to their shape classification?  \na) Rectus abdominis  \nb) Deltoid  \nc) Biceps  \nd) Orbicularis oculi",
        "What is the primary function of adductor muscles?",
        "What type of muscle is the biceps, according to the classification based on shape?  \na) Spindle-shaped  \nb) Square  \nc) Triangular  \nd) Ribbon-shaped"
    ],
    "testset/ukr-biology/book02/topic06-Зв’язок організму людини із зовнішнім середовищем. Нервова система/text.en.txt": [
        "What part of the brain is responsible for coordinating voluntary movements and adapting motor reactions to environmental conditions?",
        "What neurotransmitters do the sympathetic and parasympathetic nervous systems use respectively?",
        "What are the main neurotransmitters used by the sympathetic and parasympathetic divisions of the autonomic nervous system, and what effects do they have on the body?"
    ],
    "testset/ukr-biology/book02/topic07-Зв’язок організму людини із зовнішнім середовищем. Сенсорні системи/text.en.txt": [
        "What are the two main structures of the inner ear and what functions do they perform?",
        "Which structure is adjacent to the eardrum from the side of the middle ear?  \na) Malleus  \nb) Incus  \nc) Stapes  \nd) Eustachian tube",
        "**Question:**  \nWhich of the following structures are adjacent to the eardrum in the middle ear?  \na) Malleus  \nb) Incus  \nc) Stapes  \nd) Eustachian tube"
    ],
    "testset/ukr-biology/book02/topic08-Вища нервова діяльність/text.en.txt": [
        "During which stage of sleep do rapid eye movements (REM) typically occur?",
        "What percentage of total sleep duration is occupied by the REM sleep stage?",
        "Which type of thinking is demonstrated by solving a construction set puzzle with cubes, and what characterizes this type?"
    ],
    "testset/ukr-biology/book02/topic09-Регуляція функцій організму/text.en.txt": [
        "What disease is caused by the human immunodeficiency virus (HIV) and how does it affect the immune system?",
        "How does stress influence the endocrine and immune systems, and what are the potential health consequences of these effects?",
        "What are the four types of immunity, and what distinguishes natural active immunity from artificial passive immunity?"
    ],
    "testset/ukr-biology/book02/topic10-Розмноження та розвиток людини/text.en.txt": [
        "Identify the postembryonic stages of human development and match them with the appropriate age ranges for boys and girls as mentioned in the text.",
        "What are the key stages of human development, and how do they differ between the embryonic and postembryonic periods? Include the timelines and significant milestones for each stage.",
        "What are the key stages of human embryonic development, and what structures are formed during each stage?"
    ],
    "testset/ukr-biology/book05/topic01-Адаптації/text.en.txt": [
        "**Question:**  \nWhat is photoperiodism, and provide examples of how it affects the behavior and physiological processes of animals and plants?",
        "What examples of ectoparasites can you provide, and what structural features do they possess that adapt them to ectoparasitism? Additionally, could you give examples of endoparasites and explain how they infect their hosts?",
        "How do biological rhythms influence the behavior of organisms, and how do parasitic interactions affect host behavior, as illustrated by examples in the text?"
    ],
    "testset/ukr-biology/book05/topic02-Біологічні основи здорового способу життя/text.en.txt": [
        "Question:  \nBased on the information provided, match each of the following symptoms to the correct condition (heart attack, stroke, or diabetes):  \n- Sudden acceleration or deceleration of the pulse  \n- Discomfort in the body (weakness, pain, or unpleasant sensations)  \n- Speech impairment  \n- Rapid vision deterioration  \n- Blurred vision  \n- Numbness of the limbs  \n- Slow healing of wounds  \n- Constant thirst  \n- Frequent urination  \n- Tremors  \n- High blood glucose levels  \n- Periodic nausea  \n- Weakness  \n- Dizziness  \n- Loss of coordination or balance  \n- Sharp headache without any cause  \n- Difficulty breathing  \n- Sudden weakness, paralysis of the muscles of the face or limbs  \n- Constant hunger  \n- Hand tremors  \n\nList the symptoms and the corresponding condition they relate to.",
        "Question:  \n\"Using specific examples, justify the need to adhere to the principles of personal hygiene for the prevention of diseases.\"",
        "Question: Explain the two types of diabetes mellitus (Type I and Type II) using the information provided in the text, including the diagram about insulin production and reception."
    ],
    "testset/ukr-biology/book05/topic03-Екологія/text.en.txt": [
        "What are the four main components of the biosphere, and how are they defined according to the text?",
        "What are the four main components of the biosphere, and what do they include? Provide examples for each.",
        "Question: Explain the structure of the biosphere and how human activities influence it, including the concept of the noosphere and the significance of biogeochemical cycles."
    ],
    "testset/ukr-biology/book05/topic04-Сталий розвиток та раціональне природокористування/text.en.txt": [
        "What is the role of ecological thinking in the implementation of the Concept of Sustainable Development, and how does it contribute to addressing environmental challenges and making informed decisions?",
        "What are the negative consequences of human influence on nature without considering ecological principles, as illustrated in the text?",
        "What are the key elements of sustainable development and ecological thinking, and how do they influence decision-making and problem-solving in environmental contexts, using examples from the text?"
    ],
    "testset/ukr-biology/book05/topic05-Застосування результатів біологічних досліджень у медицині, селекції та біотехнології/text.en.txt": [
        "Question: What are the different categories of sources of biological hazards, and can you provide examples for each category as described in the text?",
        "What are the main tasks of animal breeding mentioned in the text?",
        "How can biological research contribute to solving global environmental issues?"
    ],
    "testset/ukr-biology/book03/topic01-Хімічний склад клітинита біологічні молекули/text.en.txt": [
        "What is ATP primarily used for in cells?",
        "**Question:**  \nWhat is the role of ATP in cellular processes, and how much energy is released when it breaks down?",
        "What are the biological roles of lipids, and provide examples of how they function in living organisms?"
    ],
    "testset/ukr-biology/book03/topic02-Структура клітини/text.en.txt": [
        "Which type of organelle is known to have three or four membranes in some cases, unlike the typical double-membrane structure?",
        "Which organelle is responsible for breaking down cellular structures and contains a variety of enzymes?",
        "Which group of cells, prokaryotic or eukaryotic, contains cilia and flagella as non-membrane organelles?"
    ],
    "testset/ukr-biology/book03/topic03-Принципи функціонування клітини/text.en.txt": [
        "What substances are exchanged between plants and animals as a result of photosynthesis and cellular respiration?",
        "In which organelle does the Calvin cycle occur?",
        "Where does the Calvin cycle, a part of the dark phase of photosynthesis, occur in the chloroplast?  \na) Thylakoid  \nb) Stroma  \nc) Cytosol  \nd) Nucleus"
    ],
    "testset/ukr-biology/book03/topic04-Збереження та реалізаціяспадкової інформації/text.en.txt": [
        "What is the correct order of the phases of mitosis?",
        "What is the penultimate phase of mitosis?",
        "During which phase of meiosis does crossing over occur, and what is its significance in genetic variation?"
    ],
    "testset/ukr-biology/book03/topic05-Закономірності успадкування ознак/text.en.txt": [
        "Which of the following hereditary diseases is caused by an extra chromosome 21, resulting in trisomy 21?  \na) Cystic Fibrosis  \nb) Hemophilia  \nc) Down Syndrome  \nd) Phenylketonuria",
        "What are the three main types of mutations based on the level of organization of the hereditary material, and how are they defined according to the text?",
        "What is the difference between somatic and germline mutations in terms of inheritance?"
    ],
    "testset/ukr-biology/book03/topic06-Еволюція органічного світу/text.en.txt": [
        "When did Sahelanthropus live?",
        "Which hominid lived in Europe approximately 100,000 years ago?",
        "What are the closest relatives of humans, and when did their last common ancestor, Nakalipithecus, live?"
    ],
    "testset/ukr-biology/book03/topic07-Біорізноманіття/text.en.txt": [
        "What is the highest taxonomic category for plants and for animals?",
        "**Question:**  \nHow does modern biological systematics classify organisms into hierarchical groups, and who were the key scientists responsible for the foundational system and the later three-domain classification?",
        "Why are viruses classified in a separate group (Vira) rather than being included in the domains of Bacteria or Archaebacteria?"
    ],
    "testset/ukr-biology/book03/topic08-Надорганізмові біологічні системи/text.en.txt": [
        "Identify an example of mutualism from the text.",
        "The correct answer to question 12 is:\n\n**b) two mice of the same species**\n\nThis is an example of intraspecific competition, where individuals of the same species compete for resources.",
        "Identify the type of interaction (mutualism, parasitism, commensalism) for the following examples: ants and aphids; caterpillars and horseflies; city swallows and humans."
    ],
    "testset/ukr-biology/book03/topic09-Біологія як основа біотехнологіїта медицини/text.en.txt": [
        "In which year was the first successful gene therapy performed on humans?",
        "What year marks the first successful gene therapy in humans and the beginning of the \"Human Gene Therapy\" journal?",
        "What is the main purpose of genetic engineering in medicine?"
    ],
    "testset/ukr-biology/book04/topic01-Біорізноманіття/text.en.txt": [
        "What are the key differences between true fungi (e.g., ascomycetes) and false fungi (e.g., oomycetes) in terms of their mycelium structure, cell wall composition, and habitat preferences?",
        "What are the characteristics and representatives of the group Myxomycetes?",
        "What is the composition of the cell wall in fungi and how does it differ among various types of fungi?"
    ],
    "testset/ukr-biology/book04/topic02-Обмін речовин і перетворення енергії/text.en.txt": [
        "What are the primary systems of the human body that eliminate toxic substances, and how do they function in the detoxification process?",
        "Which systems of the human body are involved in the elimination of toxic substances, and how do they contribute to detoxification?",
        "What are the main systems of the human body that participate in the elimination of toxic substances, and what role does each system play in this process?"
    ],
    "testset/ukr-biology/book04/topic03-Спадковість і мінливість/text.en.txt": [
        "What is the main conclusion from studying hereditary human diseases, and what system was established to prevent them?",
        "What are the three groups into which human diseases can be classified based on hereditary and environmental factors, as described in the text?",
        "**Question:**  \nDefine the first group of diseases in the classification provided and give examples of such diseases."
    ],
    "testset/ukr-biology/book04/topic04-Репродукція та розвиток організмів/text.en.txt": [
        "Question: Explain the biosocial factors influencing human reproduction and provide examples of how these factors impact societal structures.",
        "What are the key stages and processes involved in human embryogenesis, including the formation of the zygote, implantation, and the development of germ layers?",
        "What are the three subperiods of the embryonic period, and what key events occur during each?"
    ],
    "testset/world-history/chapter05-Asia-in-Ancient-Times/text.txt": [
        "What was the structure of the caste system in ancient India, and how was it justified through Vedic principles and karma?",
        "Question: Discuss the development of religious and social systems in ancient India, including the role of the caste system, the emergence of Buddhism as a challenge to Brahmanism, and the influence of the Mauryan and Gupta Empires on Indian culture and society.",
        "Question: How did the teachings of Buddhism, particularly its rejection of the caste system, challenge the established Vedic religious order in ancient India, and what role did empires like the Mauryan and Gupta play in the spread and adaptation of these ideas?"
    ],
    "testset/world-history/chapter04-The-Near-East/text.txt": [
        "What role did the Babylonian Exile play in the development of the Hebrew Bible, and how did the editing of earlier Hebrew writings during this period contribute to its formation?",
        "Question: How did the religious practices of the Hebrews evolve over time, and what role did the Babylonian exile play in shaping their religious identity?",
        "What role did King Manasseh play in relation to the religious reforms initiated by his father, King Hezekiah, and how did this reflect the ongoing tensions within Hebrew religious practices during that period?"
    ],
    "testset/world-history/chapter15-States-and-Societies-in-Sub-Saharan-Africa/text.txt": [
        "What were the key factors that led to the rise of the Songhai Empire, and how did its interactions with neighboring regions contribute to its status as one of the greatest empires of medieval Africa?",
        "Compare and contrast the Fatimid and Almohad reformist movements in North Africa, focusing on their origins, religious ideologies, and approaches to governance.",
        "What role did Gao play in the transition of power from the Mali Empire to the Songhai Empire, and how did this shift impact its status as a trade hub?"
    ],
    "testset/world-history/chapter07-Experiencing-the-Roman-Empire/text.txt": [
        "What were some of the strategies employed by the Roman Empire to manage diverse religious groups within its borders?",
        "How did the Roman Empire's approach to Christianity evolve over time, and what factors contributed to this change?",
        "How did the Roman Empire manage its diverse population, and what strategies did it employ to integrate different groups within its territories?"
    ],
    "testset/world-history/chapter14-Pax-Mongolica-The-Steppe-Empire-of-the-Mongols/text.txt": [
        "What policies did the Delhi Sultanate implement to prevent internal rebellions and control its subjects?",
        "What was the significance of the Battle of Ain Jalut in 1260, and how did it impact the Mamluk and Mongol Empires?",
        "What were the key events and figures involved in the transition of power in Egypt from the Ayyubid dynasty to the Mamluk dynasty?"
    ],
    "testset/world-history/chapter06-Mediterranean-Peoples/text.txt": [
        "How did Augustus consolidate and maintain his power after becoming emperor of Rome, and what were the key aspects of his rule?",
        "Question: What key events and figures led to the fall of the Roman Republic and the rise of the Roman Empire under Augustus?",
        "What key events and figures contributed to the fall of the Roman Republic and the rise of the Roman Empire, and how did Augustus establish the Principate?"
    ],
    "testset/world-history/chapter09-Africa-in-Ancient-Times/text.txt": [
        "What role did trans-Saharan trade play in the political and economic history of North Africa during the periods covered in the text?",
        "How did the Ptolemies establish their legitimacy as rulers of Egypt following Alexander the Great's conquest?",
        "When did camels first appear in North Africa, and how did their use contribute to Roman administration?"
    ],
    "testset/world-history/chapter03-Early-Civilizations-and-Urban-Societies/text.txt": [
        "What are the possible reasons for the decline of the Indus Valley Civilization according to the text?",
        "What unique tool did the Indus Valley Civilization use for measuring goods in trade and assessing taxes?",
        "What were the key features of the urban planning in the Indus Valley Civilization cities?"
    ],
    "testset/world-history/chapter08-The-Americas-in-Ancient-Times/text.txt": [
        "Question: How did the Inca Empire and the Mississippian tradition compare in terms of their organizational structures, use of agriculture, and ceremonial practices?",
        "What was the approximate number of miles of roads in the Inca Empire, and what was the estimated population of Cahokia at its peak?",
        "What was the administrative structure of the Inca Empire after its conquests?"
    ],
    "testset/world-history/chapter12-India,-the-Indian-Ocean-Basin,-and-East-Asia/text.txt": [
        "What were the key events that led to the decline of the Silla kingdom and its eventual replacement by the Goryeo dynasty in Korea?",
        "What were the key characteristics of the Kamakura period in Japan, and how did the rise of the samurai class and the establishment of the shogunate impact the political and social structure of the country during this time?",
        "What role did the Mongol invasions play in the development of the concept of divine winds, or kamikaze, in Japanese culture?"
    ],
    "testset/world-history/chapter10-Empires-of-Faith/text.txt": [
        "How did the Kushan Empire facilitate the spread of Buddhism to China, and what role did figures like the monk Lokaksema play in this transmission?",
        "What methods did the Kushan Empire employ to promote Buddhism, and how did this contribute to its spread in Asia?",
        "Identify and explain the key factors that contributed to the spread of Buddhism in Late Antiquity, using evidence from the text."
    ],
    "testset/world-history/chapter02-Early-Humans/text.txt": [
        "Question: How did the rise of agriculture during the Neolithic Revolution transform human societies, and what were some of the key developments and consequences of this shift?",
        "Name three regions where agriculture was independently developed and provide one crop from each region that was domesticated there.",
        "What were some of the social changes brought about by the rise of agriculture?"
    ],
    "testset/world-history/chapter01-Understanding-the-Past/text.txt": [
        "What sources did historians in the 1960s use to study the lives of the poor and illiterate, and how did this approach revolutionize the field of history?",
        "What factors have contributed to the limitations in historical records for regions like Africa and Latin America, and how do historians interpret these records using different lenses?",
        "What are the key factors that shape historical causation and interpretation, and how do they influence our understanding of the past?"
    ],
    "testset/world-history/chapter17-The-Ottomans,-the-Mamluks,-and-the-Ming/text.txt": [
        "Question: Why were the Janissaries considered more reliable than the Turkish nobles in the Ottoman Empire?",
        "What were the primary reasons for the instability in the Mamluk Sultanate, and how did this affect their rule?",
        "What was the devshirme system, and how did it influence the Ottoman military structure?"
    ],
    "testset/world-history/chapter11-The-Rise-of-Islam-and-the-Caliphates/text.txt": [
        "How did the Abbasid Translation Movement contribute to the preservation and expansion of knowledge, and what role did Chinese papermaking play in this process?",
        "Question: What were the key achievements of the Abbasid Translation Movement, and how did it influence Islamic learning and education during the early Abbasid period?",
        "How did the Abbasid Caliphate influence the religious and cultural landscape of the Islamic world during their rule?"
    ],
    "testset/world-history/chapter16-Climate-Change-and-Plague-in-the-Fourteenth-Century/text.txt": [
        "Discuss the long-term effects of the Black Death on medieval European society, including changes in economic structures, social hierarchies, religious movements, and political developments.",
        "How did the Black Death influence the social and economic structures of medieval Europe, including changes in feudalism, the rise of the merchant class, and shifts in traditional hierarchies?",
        "What were the key social and economic transformations in medieval Europe as a result of the Black Death and the Hundred Years' War, and how did these events contribute to the decline of feudalism and the rise of new power structures?"
    ],
    "testset/world-history/chapter13-The-Post-Roman-West-and-the-Crusading-Movement/text.txt": [
        "What was the immediate consequence of the fall of Jerusalem in 1187, and how did the Christian response unfold?",
        "What were the key factors leading to the decline of the Crusades in the later Middle Ages?",
        "Which Crusade was the only one to achieve its objective, and what was that objective?"
    ]
}