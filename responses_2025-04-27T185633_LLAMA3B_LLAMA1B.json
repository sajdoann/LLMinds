{
    "meta-llama/Llama-3.2-3B-Instruct": {
        "testset/demagog-statements-public/s_id21794/text.en.txt": [
            "How many people did Václav Havel pardon between 1993 and 2002?",
            "What was the total number of pardons granted by Václav Havel during his time as federal president?",
            "How many pardons did Miloš Zeman grant during his time in office, according to the information provided?"
        ],
        "testset/demagog-statements-public/s_id21452/text.en.txt": [
            "What is the estimated total value of tax reliefs in the Czech Republic for 2018, according to the Ministry of Finance's document?",
            "What was the estimated amount of tax reliefs in the Czech Republic in 2018, according to the Ministry of Finance?",
            "What amount, according to Miloš Zeman, would be saved if all tax exemptions were abolished, and how does this amount compare to the estimated state budget deficit for the year?"
        ],
        "testset/demagog-statements-public/s_id21519/text.en.txt": [
            "When will pensions be automatically valorized and increased according to the level of inflation in the last month in which the cumulative increase of over 5% occurred?",
            "What is the period used to determine price increases for further increases in pensions, and when does it begin?",
            "What is the condition for extraordinary pension valorization according to the Pension Insurance Act, specifically described in §67?"
        ],
        "testset/demagog-statements-public/s_id21793/text.en.txt": [
            "What was the value of the contract that Miloš Balák and Libor Tkadlec were accused of manipulating in the case that led to Miloš Balák's three-year prison sentence?",
            "What was the supposed profit from the unauthorized acquisition of the contract by the ESB company, according to the court?",
            "What was the supposed profit from the unauthorized acquisition of the contract by the ESB company, according to the police wiretaps?"
        ],
        "testset/demagog-statements-public/s_id22921/text.en.txt": [
            "According to the data from the Czech Police, what percentage of solved crimes were committed by foreigners in the first half of 2023?",
            "According to the data from the Czech Police, what percentage of solved crimes in the first half of 2023 were committed by foreigners?",
            "What percentage of solved crimes in the Czech Republic were committed by foreigners in the first half of 2023, according to the latest police statistics overview?"
        ],
        "testset/demagog-statements-public/s_id21477/text.en.txt": [
            "In the spring of last year, former Finance Minister Alena Schillerová stated that the path to budget consolidation lies in not valorizing the salaries of employees in the state sector, but what groups of employees were allowed to increase their salaries, according to her proposal?",
            "What was Alena Schillerová's initial stance on increasing salaries for state employees in the spring of 2021?",
            "In the spring of 2021, what was Alena Schillerová's position regarding the salaries of civil servants, according to her statements?"
        ],
        "testset/demagog-statements-public/s_id21480/text.en.txt": [
            "What is the main cause of the current inflation, according to economists and the Czech National Bank, as stated in Petr Fiala's statement?",
            "What do economists and the Czech National Bank agree on regarding the causes of the current high inflation in the Czech Republic?",
            "What is the main cause of inflation according to the Czech National Bank (CNB), according to Petr Fiala's statement?"
        ],
        "testset/demagog-statements-public/s_id22492/text.en.txt": [
            "What is the main difference between the current and proposed amendments to the Constitution regarding the government's powers when sending soldiers abroad?",
            "What is the proposed amendment to the Constitution that would allow the government to send Czech soldiers abroad for a maximum of 60 days without the prior consent of Parliament?",
            "What is the proposed amendment to the Constitution that would allow the government to send Czech soldiers abroad without the prior consent of Parliament, and for how long would this authority be limited?"
        ],
        "testset/demagog-statements-public/s_id22954/text.en.txt": [
            "What was the final draft budget for 2024 submitted to the government by the Ministry of Finance?",
            "What was the final draft budget for 2024 submitted by the Ministry of Finance to the government, according to the information provided?",
            "What was the final budget deficit planned for next year according to the Ministry of Finance's final draft budget?"
        ],
        "testset/demagog-statements-public/s_id23626/text.en.txt": [
            "What was the agreement between the opposition and the coalition regarding the growth of politicians' salaries, according to Vít Rakušan, that was concluded around 2015?",
            "What was the agreement between the opposition and the coalition regarding the salaries of politicians in 2015, according to Vít Rakušan, a representative of the STAN movement?",
            "When was the agreement between the opposition and the coalition concluded, according to Vít Rakušan?"
        ],
        "testset/demagog-statements-public/s_id21804/text.en.txt": [
            "What was the amount of the one-time contribution to be paid by the government to families with children, as announced at the press conference on April 27, 2022?",
            "What was the specific assistance announced by the government to help families with children cope with high inflation and rising energy prices?",
            "When did the government announce its measures to help families with children cope with high inflation and rising energy prices?"
        ],
        "testset/demagog-statements-public/s_id21471/text.en.txt": [
            "What was the position of the Czech Republic regarding the inclusion of gas and nuclear energy in the EU taxonomy, as stated in the letter sent by the Czech Prime Minister to the President of the European Commission?",
            "What resolution did the Czech Parliament adopt on December 14, 2021, regarding the role of nuclear energy in the decarbonization of the economy?",
            "What is the resolution adopted by both chambers of the Czech Parliament on 15.12.2021, according to which chamber, and what is the main point of this resolution?"
        ],
        "testset/demagog-statements-public/s_id23177/text.en.txt": [
            "What was the main aim of the trade union strike that took place on November 27, 2023?",
            "Did Prime Minister Petr Fiala visit the regions in a similar way to Minister of the Interior Vít Rakušan during the trade union strike in Prague?",
            "When did the trade union strike take place in Prague?"
        ],
        "testset/demagog-statements-public/s_id21244/text.en.txt": [
            "What percentage of the votes did the SPOLU coalition, formed by ODS, TOP 09 and KDU-ČSL, win in the elections to the Chamber of Deputies of the Parliament of the Czech Republic?",
            "What was the main message that Petr Fiala conveyed in his first post-election speech?",
            "What statement did Petr Fiala make in his first post-election speech about the unity of citizens in the Czech Republic?"
        ],
        "testset/demagog-statements-public/s_id22635/text.en.txt": [
            "What statement did the Minister of Labor and Social Affairs Marian Jurečka mention in February regarding the planned pension reform?",
            "What is the expected impact of the pension reform on the generation of people in their 50s and younger?",
            "What is the target age group that the pension reform aims to primarily affect, according to Finance Minister Zbyněk Stanjura?"
        ],
        "testset/demagog-statements-public/s_id22620/text.en.txt": [
            "When was the proposed proposal to submit to the Constitutional Court expected to be submitted in early May?",
            "What is the reason cited by the opposition movement ANO for submitting a proposal to the Constitutional Court to challenge the amendment to the Act on Lower Pension Valorization?",
            "What is the main reason cited by the opposition movement ANO for submitting a proposal to the Constitutional Court to repeal the amendment to the act on pension valorization?"
        ],
        "testset/demagog-statements-public/s_id22878/text.en.txt": [
            "What is the deadline for processing an application for housing allowance according to the Administrative Code?",
            "What is the deadline for processing an application for housing allowance according to the Administrative Code?",
            "What is the deadline for processing an application for housing allowance, according to the Administrative Code?"
        ],
        "testset/demagog-statements-public/s_id21531/text.en.txt": [
            "What is the name of the program under the Ministry of Industry and Trade that provides guarantees for loans to entrepreneurs?",
            "What is the name of the program under the Ministry of Industry and Trade that provides guarantees for loans to entrepreneurs?",
            "What is the primary purpose of the Antivirus A and Antivirus B programs introduced by the Ministry of Labor and Social Affairs during the COVID-19 pandemic?"
        ],
        "testset/demagog-statements-public/s_id23655/text.en.txt": [
            "What is the expected total fertility rate according to the Czech Statistical Office's 2023 demographic projection?",
            "What is the total fertility rate according to the CZSO projection from November 2023, and how does it compare to the previous projection from 2018?",
            "What is the total fertility rate assumed by the Czech Statistical Office's 2023 projection, and how does it compare to the 2018 projection?"
        ],
        "testset/demagog-statements-public/s_id22632/text.en.txt": [
            "When will the government discuss the proposal to change the rules for pension valorization according to Minister of Labor and Social Affairs Marian Jurečka?",
            "When will the government discuss the proposal to change the rules for pension valorization according to the statement by Eva Davidová, the spokesperson of the Ministry of Labour and Social Affairs?",
            "When did Minister Jurečka announce he would discuss the proposal to change the rules for pension valorization with representatives of the opposition, trade unions and employers?"
        ],
        "testset/flat-earth-book/SECTION-9/text.txt": [
            "What is the primary conclusion drawn by the author regarding the cause of a lunar eclipse, based on their observations and analysis of the Moon's appearance during the eclipse?",
            "What is the main conclusion drawn by the author regarding the cause of a Lunar Eclipse, based on their observations and analysis of the Moon's behavior during an eclipse?",
            "What is the explanation given for the Moon's self-luminosity, as observed during a lunar eclipse, according to the author of the text?"
        ],
        "testset/flat-earth-book/SECTION-12/text.txt": [
            "What is the main criticism of the Newtonian astronomers' use of the variable plane of oscillation of a pendulum to prove the Earth's motion?",
            "What is the main criticism of the Newtonian astronomers' use of the variable plane of oscillation of the pendulum to prove the Earth's diurnal motion?",
            "What is the general fact about the plane of oscillation of a pendulum that is used by the Newtonian astronomers to support their theory of the Earth's motion, but is later shown to be flawed?"
        ],
        "testset/flat-earth-book/SECTION-11/text.txt": [
            "What is the estimated rate of temperature increase with depth in the Earth, according to the observations made by M. Arago and others?",
            "What is the estimated rate of increase in temperature as one descends into the interior of the Earth, according to the experiments made at the Observatory of Paris?",
            "What is the estimated depth at which the temperature of the Earth increases by one degree Fahrenheit, according to the experiments made at the Observatory of Paris?"
        ],
        "testset/flat-earth-book/SECTION-13/text.txt": [
            "What is the estimated distance below the horizon that the Ryde Pier Light, located on the Isle of Wight, ought to be if the Earth were a globe?",
            "What is the minimum distance from an observer's position at which the top of the vane of the Eddystone Light would be visible, according to the Admiralty directions, and yet was not visible on a particular occasion?",
            "What is the altitude at which the line of sight to the Eddystone Light would fall if the Earth were a globe, according to the calculations provided in the text?"
        ],
        "testset/flat-earth-book/SECTION-7/text.txt": [
            "What is the explanation for the apparent descent of the Sun at sunset based on the perspective of the observer and the path of the Sun?",
            "What is the explanation for the apparent descent of the Sun at sunset, according to the principles of perspective and the geometry of the Earth's surface?",
            "What is the explanation for the apparent descent of the Sun after it leaves the meridian or noon-day position, according to the given phenomena of sunrise and sunset?"
        ],
        "testset/flat-earth-book/SECTION-4/text.txt": [
            "What is observed about the path of the Sun when it moves from a northern latitude before or after passing the meridian?",
            "What is the observation made by Captain Parry and his officers regarding the Sun's motion?",
            "What is the shape of the path the Sun appears to make on the horizon when viewed from any northern latitude?"
        ],
        "testset/flat-earth-book/SECTION-6/text.txt": [
            "What is the explanation given for the difference in the duration of day and night between New Zealand and England, according to the text?",
            "What is the main difference in the duration of day and night between England and New Zealand during the same season, according to the information provided in the text?",
            "What is the difference in the length of the day between New Zealand and England, specifically the difference between the longest and shortest days in each location?"
        ],
        "testset/flat-earth-book/SECTION-8/text.txt": [
            "What is the reason for the Sun appearing larger when rising and setting than when on the meridian?",
            "What is the explanation for the Sun appearing larger when rising and setting than when it is on the meridian?",
            "What is the actual reason for the Sun appearing larger when rising and setting than when on the meridian?"
        ],
        "testset/flat-earth-book/SECTION-5/text.txt": [
            "What is the Sun's altitude at noon on December 21st in London?",
            "What is the Sun's altitude at the time of Southing (being on the meridian) on December 21st?",
            "What is the difference in altitude of the Sun's path as observed at various periods of the year, according to the table provided in \"The Illustrated London Almanack\" for 1848?"
        ],
        "testset/flat-earth-book/SECTION-3/text.txt": [
            "What is the distance calculated to be less than in the calculation using the elements of observations from the Southern and Northern stations?",
            "What is the approximate distance of the Sun from the Earth, as calculated using the method described in the text?",
            "What is the estimated distance of the Sun from the Earth, based on observations made at different locations?"
        ],
        "testset/flat-earth-book/SECTION-10/text.txt": [
            "What is the general cause of tides according to the author of the text, and how does it relate to the action of the atmosphere on the Earth and the reaction of the oceanic medium?",
            "What is the general cause of tides, according to the theory presented in the text?",
            "What is the general cause of tides in the ocean, according to the text?"
        ],
        "testset/flat-earth-book/SECTION-2/text.txt": [
            "What would be the expected result if the Earth had a motion upon axes and a ball, shot upwards into the air, began to descend?",
            "What would be the result if the Earth had a motion upon axes, as evidenced by the experiment of throwing a ball upwards from the mast-head of a moving vessel?",
            "What is the expected outcome if the Earth had moved a single yard in an orbit through space, according to the experiment described in the text?"
        ],
        "testset/flat-earth-book/SECTION-1/text.txt": [
            "What is the difference in distance calculated by the theory of the Earth's rotundity versus the actual distance measured by navigators in the southern region?",
            "What is the discrepancy between the calculated circumference of the Earth according to the theory of rotundity and the actual distances measured by navigators in the southern region?",
            "What is the primary argument against the Earth's rotundity based on practical navigation and measurement of a degree of longitude?"
        ],
        "testset/nmt-book/chapter07-Alternate-Architectures/text.txt": [
            "What is the main difference between the convolutional neural networks used in the encoder and the decoder of the convolutional neural machine translation model proposed by Gehring et al. (2017)?",
            "What is the main advantage of using convolutional neural networks over recurrent neural networks in neural machine translation models, according to the text?",
            "What is the primary disadvantage of using recurrent neural networks in neural machine translation models, according to the text?"
        ],
        "testset/nmt-book/chapter06-Refinements/text.txt": [
            "What is the primary benefit of adding linguistic annotation to the input of a neural machine translation model, according to the provided text?",
            "What is the main benefit of using linguistic annotation in neural machine translation models, according to the text?",
            "What is the main benefit of adding linguistic annotation to the input sentence in neural machine translation models, and how can it be accommodated in the architecture of the model?"
        ],
        "testset/nmt-book/chapter01-Introduction/text.txt": [
            "What was the year in which almost all submissions at the shared task for machine translation organized by the Conference on Machine Translation (WMT) were neural machine translation systems?",
            "What was the year when almost all submissions at the shared task for machine translation organized by the Conference on Machine Translation (WMT) were neural machine translation systems?",
            "What was the primary factor that hindered the adoption of neural network methods in machine translation research in the early 2000s?"
        ],
        "testset/nmt-book/chapter02-Neural-Networks/text.txt": [
            "What is the purpose of the \"momentum term\" in weight update per Adam, and how does it differ from other adaptation schemes such as Adagrad and Adadelta?",
            "What is the primary goal of training neural networks, and how is it achieved through weight updates computed based on error terms associated with each non-input node in the network?",
            "What is the purpose of using a momentum term in the Adam optimization algorithm for training neural networks?"
        ],
        "testset/nmt-book/chapter03-Computation-Graphs/text.txt": [
            "What is the primary benefit of using a computation graph in neural network training, as opposed to manually computing derivatives for each node in the graph?",
            "What is the primary benefit of using a computation graph to model neural networks, as opposed to manually computing gradients for gradient descent training?",
            "What is the primary benefit of representing neural networks as computation graphs, as opposed to traditional mathematical equations or graphs?"
        ],
        "testset/nmt-book/chapter05-Neural-Translation-Models/text.txt": [
            "What is the primary difference between the attention mechanism proposed by Bahdanau et al. (2015) and the global attention model proposed by Luong et al. (2015b)?",
            "What is the primary difference between the search strategy used in traditional statistical machine translation models and that used in neural translation models?",
            "What is the primary function of the attention mechanism in a neural machine translation model?"
        ],
        "testset/nmt-book/chapter04-Neural-Language-Models/text.txt": [
            "What is the primary difference between the gated recurrent units (GRU) and the long short-term memory (LSTM) neural network architectures, in terms of the number of gates and the way they regulate the flow of information within the cell?",
            "What is the primary difference between Long Short-Term Memory (LSTM) cells and Gated Recurrent Units (GRU) cells in terms of their architecture?",
            "What is the main difference between the basic building block of LSTM networks (the cell) and traditional recurrent neural networks, in terms of how they handle memory and updating of the memory state?"
        ],
        "testset/nmt-book/chapter08-Current-Challenges/text.txt": [
            "How do the performance of neural machine translation and statistical machine translation systems compare when translating out-of-domain data versus in-domain data?",
            "How do the data needs of statistical machine translation and neural machine translation compare, particularly in terms of the role of training data and alignment mechanisms?",
            "What is the main difference in how statistical machine translation and neural machine translation systems handle out-of-domain training data, according to the study presented in the text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen01-slide01/text.txt": [
            "What aspects of machine translation will be included in the final lecture of the semester?",
            "What aspects of translation will be included in the lecture on multimodal machine translation?",
            "What aspects of translation will be included in the lecture on multimodal machine translation?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen02-slide02/text.txt": [
            "What is the focus of the second part of the lecture?",
            "What type of approaches to machine translation does the speaker contrast with the end-to-end approaches in the lecture?",
            "What type of approaches to machine translation will be discussed in the second part of the lecture?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen03-slide03/text.txt": [
            "What approach have you been using to get the text in the target language so far?",
            "What approach have we been using to translate text from the source language to the target language so far?",
            "What approach have we been using to get the text in the target language so far?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen04-slide04/text.txt": [
            "What technology is needed to convert speech into text for the machine translation system?",
            "What technology is required to convert speech into text for the machine translation system?",
            "What technology is needed to convert speech into text for a machine translation system?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen05-slide05/text.txt": [
            "What is the next step after converting text back into speech?",
            "What is the third step in a cascade of three that people may want to do after converting text back into speech?",
            "What would be the next step after converting text back into speech?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen06-slide06/text.txt": [
            "What are some issues that arise due to the use of cascades in independent components?",
            "What is an example of a direct attempt at machine translation that does not use explicit transcription?",
            "What is one of the methods people have been working on to address the issues of information loss in cascades, and how does it differ from using explicit transcription?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen07-slide07/text.txt": [
            "What type of system is described as going directly to the speech in the target language?",
            "What type of system is being contrasted with the combination of ASR and MT in the given text?",
            "What type of system is being discussed in the text that combines machine translation with ASR, as opposed to a speech-to-speech system?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen08-slide08/text.txt": [
            "Can the image used in image captioning be used in image-guided translation?",
            "What type of task can an image be used for in addition to image captioning, which involves automatically describing the image with text in the source language?",
            "What type of task can an image be used for in the context of image captioning?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen09-slide09/text.txt": [
            "What is the current status of the development of visual guided translation technology?",
            "What is the primary goal of incorporating visual guidance or video guidance into the translation process?",
            "What is the current status of visual guided translation technology?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen10-slide11/text.txt": [
            "What is the typical form of text that machine translation is usually applied to?",
            "What is the typical form of text that machine translation is usually applied to?",
            "What is typically the source of the input for machine translation?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen11-slide12/text.txt": [
            "What are some strategies used by interpreters in incremental machine translation to handle new information that may come in during the process?",
            "What are the main motivations for using incremental machine translation?",
            "What is the primary motivation for research into incremental machine translation?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen12-slide13/text.txt": [
            "What are the benefits of direct speech-to-speech translation compared to speech-to-text translation?",
            "What are the benefits of direct speech-to-speech translation compared to text-based translation?",
            "What type of model is proposed for direct speech-to-speech translation, according to the authors of the text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen13-slide14/text.txt": [
            "What are the two components that need to be connected together to create a cascading machine spoken language translation system?",
            "What are the two components that need to be connected together in the cascading machine spoken language translation?",
            "What are the two components that need to be connected together in a cascading machine spoken language translation?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen14-slide15/text.txt": [
            "What is the standard measure used to evaluate the accuracy of speech recognition systems, according to the text?",
            "When can we expect speech recognition systems to perform better than humans?",
            "What is the standard measure used to evaluate the performance of speech recognition systems?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen15-slide16/text.txt": [
            "What evaluation methods have machine translation achieved parity with humans in, according to the text?",
            "What is the context of the discussion about machine translation and its comparison to human capabilities?",
            "What has machine translation been getting on par with humans in some settings and evaluation ways, according to the past discussion?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen16-slide17/text.txt": [
            "What would be the purpose of running machine translation after ASR in a speech translation system?",
            "What type of system would be created by running ASR on the sound that you want to translate and then running machine translation?",
            "What is the proposed workflow for speech translation using ASR and machine translation?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen17-slide18/text.txt": [
            "What are some challenges associated with developing ASR systems that can produce clear and correct sentences?",
            "What are the main challenges in developing ASR systems and machine translation that need to be addressed?",
            "What is the primary challenge in developing ASR systems and machine translation that can produce clear sentences?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen18-slide19/text.txt": [
            "What do you have to segment the flow of words into?",
            "What do you have to segment the flow of words into?",
            "What do you have to segment the flow of words into?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen19-slide20/text.txt": [
            "What would happen if the ASR system had access to a list of candidate outputs, such as an NBEST list, in addition to the uncertain output it initially generated?",
            "What would happen to the machine translation if the ASR system had access to a NBEST list between the ASR and the machine translation?",
            "What happens to the machine translation if the ASR emits an ambiguous output, and how does it affect the translation process?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen20-slide21/text.txt": [
            "What is one problem at the beginning of the pipeline that needs to be addressed when deploying the system?",
            "What is one problem at the beginning of the pipeline that affects the system's performance?",
            "What is a potential problem at the beginning of the pipeline when deploying the system?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen21-slide22/text.txt": [
            "What are the potential errors that can be introduced when integrating components into a working system for speech-to-text and translation in a European project like ELITER?",
            "What is the purpose of sending NBEST lists in the transcription and translation pipeline?",
            "What are the potential errors that can be introduced when integrating independent systems into a working system in the context of speech-to-text and translation?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen22-slide23/text.txt": [
            "What challenges does the online aspect of subtitle online sessions present?",
            "What challenges does the online aspect of subtitle creation present?",
            "What challenges does the online aspect of subtitle creation pose?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen23-slide24/text.txt": [
            "What types of errors is the proposed architecture resilient to, but not to?",
            "What types of errors is the proposed architecture resilient to, but not to?",
            "What types of errors is the proposed architecture resilient to, but not to?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen24-slide25/text.txt": [
            "What issues have actually been encountered in tests, according to the speaker?",
            "What are some of the issues that the authors of the text have encountered in their tests?",
            "What are some of the issues that you have encountered in your tests, according to the text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen25-slide26/text.txt": [
            "What was the unexpected delay that occurred during the live subtitling session?",
            "What type of system is complex and non-deterministic, making it hard to diagnose and debug?",
            "What was one of the main issues encountered during the live subtitling session?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen26-slide27/text.txt": [
            "What happens to the sound quality if the first cable is badly plugged in?",
            "What happens to the sound quality if the first cable is badly plugged in?",
            "What happens to the sound quality if the first cable is badly plugged in?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen27-slide28/text.txt": [
            "What are some potential issues that can cause unacceptable delays in the presentation of subtitles to end users?",
            "What are some potential issues that can cause delays in the presentation of subtitles to end users, according to the text?",
            "What are some potential issues that can cause delays or poor performance in the presentation of subtitles to end users?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen28-slide29/text.txt": [
            "What was the cause of the delay in the pipeline due to the misconfiguration issue?",
            "What type of sound acquisition method was used in the pipeline setup?",
            "What was the intended purpose of starting the ASR system locally in the pipeline setup?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen29-slide31/text.txt": [
            "What effect did placing the chest mic on one side of the presenter's body have on the sound volume and clarity during the test session?",
            "What effect did the colleague's positioning of the chest mic have on the sound volume and clarity during the presentation?",
            "What was the result of attaching the chest mic to one side of the presenter's body?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen30-slide32/text.txt": [
            "What type of microphone showed a clear benefit in the experiment?",
            "What type of microphone showed a clear benefit in the experiment?",
            "What type of microphone provided a clear benefit in the experiment?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen31-slide33/text.txt": [
            "What are some common problems people encounter when using handheld microphones?",
            "What common problems can occur if people use handheld microphones?",
            "What common problems can occur when using handheld microphones?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen32-slide35/text.txt": [
            "What are three possible locations that could result in the object not being held properly?",
            "What are three possible locations for placing something in relation to a person's mouth and hand?",
            "What are three possible locations where they could put the object in relation to their mouth or hand?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen33-slide36/text.txt": [
            "What effect could the double sound wave from standing in front of loudspeakers have on the ASR quality?",
            "What would happen to the ASR quality if the microphone received the same sound as the loudspeakers with a little delay?",
            "What would happen to the ASR quality if the microphone receives the same sound as the loudspeakers with a little delay?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen34-slide37/text.txt": [
            "What happens if the output of a component in the pipeline is too loud?",
            "What happens if the output of an intermediate component in a pipeline is too loud?",
            "What happens if the output of an intermediate component is too loud in the pipeline?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen35-slide38/text.txt": [
            "What was the topic of the lecturer's discussion at the beginning of the lecture?",
            "What was the topic of the speaker's lecture at the beginning?",
            "What was the topic of the lecturer's discussion at the beginning of their lecture?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen36-slide39/text.txt": [
            "What would be the ideal output of the ASR system in this scenario?",
            "What would be the ideal output of an ASR system in the given example?",
            "What would happen to the ASR system's ability to recognize words if the noise in the recording were to be cancelled or reduced?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen37-slide40/text.txt": [
            "What is the word error rate of the system in comparison to human recognition quality?",
            "What is the comparison between the word error rate of the system and that of humans?",
            "What is the word error rate of the systems compared to the human level of recognition quality?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen38-slide41/text.txt": [
            "What is the speaker's occupation, as revealed in the conversation with the person who wears high heels?",
            "What were the challenges faced by the speech recognition system in the experiment with the high school students' prepared sessions?",
            "What are the limitations of speech recognition systems, as demonstrated by the experiment described in the text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen39-slide42/text.txt": [
            "What was the purpose of the non-native person's interaction with speech recognition and machine translation systems?",
            "What was the outcome of the non-native person's interaction with speech recognition and machine translation?",
            "What was the outcome of the speech recognition and machine translation after the non-native person's input?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen40-slide43/text.txt": [
            "What is the standard translation error that occurs when using a machine translation system, such as the one described in the text?",
            "What is the standard translation error that occurs when translating the word \"if\" from English to German?",
            "What is the primary issue with translating the German word \"if\" into English, and how does this affect the overall meaning of the text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen41-slide44/text.txt": [
            "What is the main difference between errors in machine translation alone and errors in the combination of speech recognition and machine translation systems?",
            "What is the primary reason why the end user should rely on a larger context when using speech recognition and machine translation systems?",
            "What are the main differences between errors in speech recognition systems and machine translation systems, according to the text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen42-slide46/text.txt": [
            "What is the primary challenge in integrating sequence of words without punctuation and lowercase with individual correct sentences in machine translation output?",
            "What are the benefits of changing the ASR to predict correct punctuation directly in the integration process of sequence of words and individual correct sentences?",
            "What is the main challenge in developing an end-to-end spoken language translation system?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen43-slide47/text.txt": [
            "What approaches can be used to insert punctuations into a sequence of words in a natural language processing model?",
            "What approach is used to insert punctuation symbols in a sequence of words, and how does it differ from using sequence labeling algorithms?",
            "How do sequence labeling algorithms handle the inclusion of sound information in the task of inserting punctuation into a sequence of words?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen44-slide48/text.txt": [
            "What is the potential impact of a misplaced punctuation mark on the output of a machine translation system?",
            "What is the effect of misplacing a punctuation mark in a machine translation system?",
            "What are the consequences of a random shift in punctuation marks in machine translation systems?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen45-slide49/text.txt": [
            "What type of translation is being discussed at the end of the text?",
            "What is the problem that end-to-end spoken language translation is supposed to avoid?",
            "What type of translation is mentioned as not having the same problems as the previous one?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen47-slide49/text.txt": [
            "How are the corpora used to train and test these systems segmented?",
            "How are the systems trained and tested?",
            "What is the basis for training and testing these systems?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen48-slide50/text.txt": [
            "What is the main drawback of using direct spoken language translation due to insufficient training data?",
            "What is the main drawback of using direct spoken language translation due to insufficient training data?",
            "What is a major drawback of using speech in the source language and text in the target language for training spoken language translation models?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen49-slide51/text.txt": [
            "What are the two main approaches to addressing the insufficient training data issue in speech-to-text systems, as described in the provided text?",
            "What is the main issue with the standard training approach for speech-to-text systems, according to the text?",
            "What is the main issue with the standard training approach for speech-to-text systems that utilizes the speech-to-text speech corpus or SLT corpus?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen50-slide52/text.txt": [
            "What type of neural network architecture was used by Berard and colleagues in their 2016 proof of concept for end-to-end spoken language translation?",
            "What type of neural network was trained on the synthetic corpus in Berard's 2016 proof of concept for end-to-end spoken language translation?",
            "What type of neural network was used in the end-to-end spoken language translation model trained on the synthetic corpus by Berard and colleagues?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen51-slide53/text.txt": [
            "What type of recurrent neural networks were used in the 2018 experiments that utilized a speech encoder and character-level decoding?",
            "What type of recurrent neural network is used in the 2018 experiment, which is a variation of the standard deep recurrent network?",
            "What type of recurrent neural network is used in the 2018 experiments, which is a variation of a standard deep recurrent network?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen52-slide54/text.txt": [
            "What is the purpose of pre-training a neural network component before adding the source language in machine translation?",
            "What is the process of pre-training for speech recognition and machine translation according to the given approach?",
            "What is the purpose of pre-training a neural network component before adding a new language to a machine translation task?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen53-slide55/text.txt": [
            "What is the number of parameters used in the ensembling system compared to the ASR only system?",
            "What is the number of parameters used in the ensembling system compared to the ASR only system?",
            "What is the parameter count of the proposed ensembling system compared to the ASR-only system?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen54-slide56/text.txt": [
            "What architecture is still not clear as the best approach in the cascaded system?",
            "What architecture is currently the most popular choice among researchers in the field, according to the survey by Silvachak?",
            "What architecture is still unclear as the best approach for the cascaded system?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen55-slide57/text.txt": [
            "What modifications did the Italian FBK team make to the standard transformer architecture in their 2019 paper?",
            "What modifications were made to the standard transformer architecture in the S-transformer approach?",
            "What two ways have the Italian FBK team modified the standard transformer architecture in their approach?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen56-slide58/text.txt": [
            "What is the name of the system developed by Google that directly translates speech-to-speech and preserves speaker characteristics?",
            "What is the name of the system developed by Google for speech-to-speech translation that preserves speaker characteristics?",
            "What is the name of the system developed by Google that uses a vocoder to synthesize the waveform in the target language?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen57-slide59/text.txt": [
            "What is the main purpose of glossing over the presentation in the speech to text translation?",
            "What is the author's intention in glossing over the presentation in the speech to text translation?",
            "What is the main topic of discussion in the given text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen58-slide60/text.txt": [
            "What are some usability issues that need to be considered when deploying a system with subtitles?",
            "What are some usability issues that need to be considered when deploying a system with subtitles?",
            "What type of settings are necessary for a system that displays subtitles to ensure users can read them effectively?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen59-slide61/text.txt": [
            "What is the main issue with producing subtitles in many languages at once?",
            "What is the challenge that the creators of the Eliter project are facing when producing subtitles in many languages at once?",
            "What is the challenge the authors of the Eliter project are facing when producing subtitles in many languages at once?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen60-slide62/text.txt": [
            "What type of output does the system provide to the user?",
            "What is the purpose of displaying paragraphs in a text format?",
            "What is the purpose of using paragraphs in a text to indicate the status of sentences?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen61-slide63/text.txt": [
            "What would happen to the subtitles if the segmenter decided to put the punctuation at a different place after some more words arrived?",
            "What is the main problem faced by the system when dealing with ASR output, segmenter output, and machine translation output in terms of subtitle display?",
            "What is the problem with the current system for handling subtitles in a video, according to the subtitler component?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen62-slide64/text.txt": [
            "What are the two different views that can be better for different settings when it comes to handling cognitive load considerations in a presentation?",
            "What type of output will users who don't speak the source language prefer, and what are they willing to wait for?",
            "What type of output would users who do not speak the source language prefer, and why?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen63-slide65/text.txt": [
            "Will the evaluation of spoken language translation be included in the exam?",
            "Will the evaluation of spoken language translation take place?",
            "Will the evaluation of spoken language translation be included in the exam?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen64-slide66/text.txt": [
            "What are some additional aspects to consider when comparing the outputs of a machine translation system in spoken language translation?",
            "What are some additional aspects to consider when comparing the outputs of a machine translation system in spoken language translation?",
            "What additional aspects should be considered when comparing the outputs of a machine translation system in spoken language translation?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen65-slide67/text.txt": [
            "What is the potential issue with the evaluation of speech recognition systems that deals with segmentation of input sound?",
            "What is the potential issue with evaluating speech recognition systems that may segment input sounds differently than the systems themselves?",
            "What is the potential issue with the evaluation process when there is a mismatch between the segmented input sound and the actual segmentation used in the system?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen66-slide69/text.txt": [
            "What is the expected duration of the presentation on visual information?",
            "What is the nature of the presentation that will be given on visual information?",
            "What will be the focus of the remaining part of the lecture?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen67-slide70/text.txt": [
            "What would be the output for the English sentence \"the chef is cooking\"?",
            "What would be the output of the given English sentence \"a tennis player is getting ready\"?",
            "What is the expected output of the given English sentence \"a tennis player is getting ready\"?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen68-slide71/text.txt": [
            "What is the grammatical gender of the first sentence in the given text?",
            "What type of sentence is the second sentence in the provided text?",
            "What is the grammatical gender of the second sentence in the given text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen69-slide72/text.txt": [
            "If there is an image next to a sentence about a queue, what can you easily do with it?",
            "If you have the queue, what else can you easily do?",
            "What can you easily do if you have the queue and there is an image next to that sentence?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen70-slide73/text.txt": [
            "What was the outcome of translating the English captions from the Visual Genome database into Hindi in the example provided?",
            "What is the purpose of translating English captions from Visual Genome into Hindi using the rectangular information from images?",
            "What is the purpose of translating English captions from Visual Genome into Hindi?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen71-slide74/text.txt": [
            "How many words were identified as ambiguous in the visual genome corpus after manual selection?",
            "What was the outcome of translating sentences with the 19 ambiguous words found in the visual genome challenge test set?",
            "How many words were found to be ambiguous in the test set, and what was the process used to subselect these words?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen72-slide75/text.txt": [
            "What would be the purpose of the surrounding words in an image of a street sign advising of \"penalty\"?",
            "What type of context can the words \"round\" in the input sensor be used to inform about?",
            "What is the primary issue with relying solely on the word \"penalty\" as an input sensor?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen73-slide76/text.txt": [
            "What is the role of the attention mechanism in the output production process according to the described architecture?",
            "What is the purpose of the attention mechanism in the context of processing input sentences?",
            "What is the role of the attention mechanism in the proposed system, and how does it focus on different parts of the input sentence?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen74-slide77/text.txt": [
            "What is the primary difference in how the attention mechanism is applied in image captioning compared to traditional language models?",
            "What is the primary function of the attention mechanism in the image captioning task described in the text?",
            "What is the role of the attention mechanism in the image captioning task described in the text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen75-slide76/text.txt": [
            "What do you attend to in the multi-encoder setup after setting up setups together?",
            "What will you attend to in a multi-encoder setup?",
            "What do you attend to in the multi-encoder setup?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen76-slide77/text.txt": [
            "What type of combination is described in the text as using an image encoder with a decoder that produces output words, similar to a combination used with multiple text inputs?",
            "What type of combination is described in this setup, involving an additional encoder of the image and multiple text inputs?",
            "What type of combination is described in the text, comparing the use of an image encoder to the combination of multiple text inputs?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen77-slide78/text.txt": [
            "What is the particular setup that was working best for Inrich Ljubovitsky and Helsel in combining attention over the source text and attention over the image?",
            "What is the name of the particular setup used by Inrich Ljubovitsky and Helsel that combined attention over the source text and attention over the image in multiple ways?",
            "What was the particular setup that was working best for the colleagues Inrich Ljubovitsky and Helsel in combining attention over the source text and attention over the image?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen78-slide79/text.txt": [
            "What type of attention is considered one of the best approaches used in visually supported translation runs, according to the survey by Sulubacak?",
            "What is a successful strategy used in the decoder for visually supported translation runs, according to the provided text?",
            "What are some of the approaches people use in a visually supported translation run, according to the survey by Sulubacak?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen79-slide80/text.txt": [
            "What type of model was sensitive to the image information in Desmond Elliott's experiment?",
            "What type of system performed better in Desmond Elliott's experiment, despite not considering images?",
            "What was the outcome for the hierarchical attention approach when the non-matching image was used in Desmond Elliott's experiment?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen80-slide81/text.txt": [
            "What is the last item mentioned in the TEXT?",
            "What is the context of \"this last\" mentioned in the TEXT?",
            "What is mentioned in the text as well as the last part of the text?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen81-slide80/text.txt": [
            "What is the main claim made by the paper from Ozan Raglan regarding the methods used?",
            "What is the main issue being addressed by the paper from Ozan Raglan?",
            "What is the main argument presented in the paper from Ozan Raglan regarding the use of visual information?"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen82-slide81/text.txt": [
            "What type of information did the multimodal system pick up from the image in the Desmond's Elliot experiment?",
            "What was the outcome for the systems trained on text only information in Desmond's Elliot experiment?",
            "What type of difference did the systems trained on text only information exhibit in the Desmond's Elliot experiment compared to the systems trained on text and visual information?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen01-slide01/text.txt": [
            "What is the title of the lecture, as described by the speaker?",
            "What is the topic of the lecture being discussed, according to the title?",
            "What is the main topic of discussion in today's lecture on machine translation?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen02-slide02/text.txt": [
            "What does it mean to mean something?",
            "What do we expect from sentence meaning?",
            "What does it mean to mean something?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen03-slide03/text.txt": [
            "What is the difference between the triangle mentioned in machine translation and the triangle seen early in the series of lectures?",
            "What is the difference between the triangle in machine translation mentioned in the text and the WOKUA triangle seen earlier in the series of lectures?",
            "What is the difference between the triangle mentioned in machine translation and the triangle seen early in the series of lectures?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen04-slide04/text.txt": [
            "What corresponds to the lower corner of the semiotics triangle according to Richards and Ogden?",
            "What is represented by the lower corner of the semiotics triangle?",
            "What corresponds to the lower corner of the semiotics triangle?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen05-slide05/text.txt": [
            "What does the symbol in the sentence \"Danny approached the chair with a yellow bag\" stand for?",
            "What does the yellow bag symbolize in the context of the sentence?",
            "What does the yellow bag symbolize in the given situation?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen06-slide06/text.txt": [
            "What is the meaning representation of the particle symbol in the context of the sentence?",
            "What is the possible ambiguity in a sentence involving the symbol \"bag\" and the action of approaching a chair?",
            "What is the meaning representation of a particle symbol, as described in the given text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen07-slide07/text.txt": [
            "How will the position of the \"yellow back\" change in the constituency tree for someone who is a syntacticist compared to someone who is not?",
            "What is the difference between the two positions of the \"yellow back\" in the constituency tree?",
            "What is the implication of knowing constituency trees on encoding different meanings in a tree?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen08-slide08/text.txt": [
            "What is the difference between the two representations when describing the same situation, according to the formal semantics described in the text?",
            "What type of link will be described between the bag and the chair in the formal semantics of the sentence?",
            "What is the difference between the two systems or representations in the given formal semantics scenario?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen09-slide09/text.txt": [
            "What will the representations, or activations, in a neural network be when processing videos of different situations?",
            "How will artificial neural networks perceive differences between various situations when processing video representations?",
            "What will be the representations of the neural networks when processing the videos of the given situations?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen10-slide10/text.txt": [
            "What happens to a machine translation system or a human translator when the original text contains ambiguous information that cannot be disambiguated from the context?",
            "What happens to a machine translation system or human translators when they are unsure of the exact meaning of a term in the original text?",
            "What is the approach that translators may take when they are unsure about the meaning of an ambiguous term in the original text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen11-slide11/text.txt": [
            "What systems significantly surpassed professional translation in the WMT competition in 2018 and 2019?",
            "What were the results of machine translation systems in the WMT competition in 2018 and 2019?",
            "What evaluation procedures were used in the WMT competition for news translation in 2018 and 2019?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen12-slide12/text.txt": [
            "How does the 2018 machine translation system for English to Czech, the Charles University Transformer setup, utilize data from the two target languages in its training process?",
            "Can machine translation systems, such as the 2018 Charles University Transformer setup, truly understand the meaning of sentences, or are they simply creating representations of words?",
            "What amount of text would be needed to read the 2018 English to Czech machine translation system's training data if one were reading eight hours a day?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen13-slide13/text.txt": [
            "How would Google translate the sentence \"ma, ma, mele, maso\" from Czech?",
            "What is the Czech translation of the sentence \"ma, ma, mele, maso\"?",
            "What happens when you feed a sentence like \"ma, ma, mele, maso\" into an online public service like Google?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen14-slide14/text.txt": [
            "What is a characteristic of a free word order language like the one mentioned in the text?",
            "Does Google Translate's neural machine translation perform well when it is trained on a language that has free word order, but is then used to translate sentences that deviate from that word order?",
            "What is the main issue with Google Translate's performance when it is asked to translate phrases outside of its training data?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen15-slide15/text.txt": [
            "What language is the translator Bing trained on?",
            "What type of text was Microsoft Bing translator likely trained on?",
            "What is the primary reason why the Microsoft Bing translator produced incorrect sentences when translating the phrase \"Mama mele maso, maso mele mama, maso mama mele\"?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen16-slide16/text.txt": [
            "What is the topic of the Czech sentence highlighted by the word order?",
            "What is the word order in the Czech sentence that highlights the topic focused articulation?",
            "What is the topic focused articulation in the Czech sentence?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen17-slide17/text.txt": [
            "What word reorderings are possible for the sentence \"does mom have meat?\"?",
            "What is the system's output when it is asked about a mother having meat?",
            "What is the system output that is not acceptable?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen18-slide19/text.txt": [
            "What is the role of a cut in the neural network in terms of observing the network's representation of the input?",
            "What is the definition of a 'cut' in the context of a neural network as described in the text?",
            "What is a cut in the context of the neural network described in the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen19-slide20/text.txt": [
            "What was the original task in one of the early lectures involving a point in a 2D space?",
            "What is the effect of adding a new dimension to the space of x and y-coordinates in a 2D space, where each new dimension represents the distance from one of three lines?",
            "What type of separation boundary can each of the three neurons in the hidden layer specify?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen20-slide21/text.txt": [
            "Is the representation learned by the network useful for something other than separating the classes it was originally trained on?",
            "Is the representation learned by the network useful for separating classes other than the ones it was originally trained for?",
            "Is the representation learned by the network good for something else than the classes it was trained to separate?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen21-slide22/text.txt": [
            "What type of task is being referred to as the \"main task\" in the given text?",
            "What is the context of the hand-drawn examples provided in the text?",
            "What is the purpose of the hand-drawn examples provided in the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen22-slide23/text.txt": [
            "What is the benefit of using the ABC representation in the given context?",
            "What is the benefit of using the ABC representation in the context of a picture?",
            "What is the benefit of using the ABC representation in the context of a picture?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen23-slide24/text.txt": [
            "What happens to your input if the network learns to process a very complicated thing into something else?",
            "What happens if your input is something very complicated and the network learns to process this complicated thing into something else?",
            "What else can happen if your input is something very complicated?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen24-slide25/text.txt": [
            "What makes a hidden representation good?",
            "What makes a hidden representation good?",
            "What does it mean for a hidden representation to \"resemble something that we are happy to see there\"?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen25-slide26/text.txt": [
            "What are some examples of secondary tasks that can be used to evaluate the learned representations in a network?",
            "What are some secondary tasks that can be used to evaluate the learned representations of a neural network?",
            "What is the main difference in the types of data needed to train speech recognition and translation tasks?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen26-slide28/text.txt": [
            "What is the main purpose of training word embeddings?",
            "What are the two primary language modeling tasks that lead to different specifications of word embeddings?",
            "What are the best known word embeddings mentioned in the text, and what are their characteristics that help in translating sentences?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen27-slide29/text.txt": [
            "What type of relation was observed between country names and capital names in the highly dimensional space of embeddings?",
            "What type of relation was observed between country names and capital names in the highly dimensional space of word embeddings?",
            "What type of relation was observed between country names and capital names in the highly dimensional space?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen28-slide30/text.txt": [
            "What type of questions did the test set associated with Word2Egg typically consist of?",
            "What were the two types of questions associated with the test set for Word2Egg?",
            "What were the two types of questions in the test set associated with Word2Egg?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen29-slide31/text.txt": [
            "What percentage of accuracy did the test set by Tomáš Mikolov reach in learning the space of semantic and syntactic relations?",
            "What percentage of accuracy did the test set by Tomáš Mikolov reach in learning the space of semantic and syntactic relations?",
            "What percentage of accuracy did the network reach on the test set of semantic questions, according to the paper by Tomáš Mikolov?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen30-slide32/text.txt": [
            "What was the accuracy of the system on the test set when using the origin V2VAC model?",
            "What was the accuracy of the system when tested on its own test set?",
            "What was the accuracy of the system on the test set when using the origin V2VAC model?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen31-slide33/text.txt": [
            "What was the performance of the model that included subgram units on the original test set?",
            "What was the performance of the subgram model compared to the word2vec model on the original test set?",
            "What was the performance of the subgram model on the original test set compared to the word2vec model?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen32-slide34/text.txt": [
            "What is the primary goal for writing nine rules to analyze regular patterns, according to the text?",
            "What is the primary goal of writing nine rules for regular patterns in order to achieve good results?",
            "What is the main difference between writing rules for regular patterns and using word embeddings for analyzing morphology?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen33-slide35/text.txt": [
            "When was the paper submitted to the conference 'text, speech and dialogue'?",
            "What conference did the authors submit their paper to in March 2016?",
            "When was the follow-up paper submitted to the archive, according to the information provided?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen34-slide36/text.txt": [
            "What is the main reason why an idea needs to be complemented with a fast and good code to spread?",
            "What is the main difference between the two papers mentioned in the text?",
            "What is the main reason for a paper to complement its idea with fast and good code to make it spread?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen35-slide37/text.txt": [
            "What are the two types of similarities that humans may evaluate when assessing the relatedness of words?",
            "What are the two types of similarities that can be observed in human annotations of words, as mentioned in the evaluation of word representations?",
            "What are the two types of similarities that can be observed in human annotations, as mentioned in the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen36-slide38/text.txt": [
            "What units are being referred to in the text that the author wants to move on to?",
            "What are the larger units being referred to in the context of the provided text?",
            "What units are being referred to in the text that the narrator wants to move on to?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen37-slide39/text.txt": [
            "What is the role of the fixed length vector in the encoder-decoder architecture?",
            "What is the purpose of the cut through the network that contains the whole representation of the sentence?",
            "What is the purpose of the cut through the network in the encoder-decoder architecture?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen38-slide40/text.txt": [
            "What is the key factor that distinguishes the sentences in the upper and lower parts of the screen?",
            "What is the primary factor that distinguishes the sentences in the upper and lower parts of the screen?",
            "What is the primary factor that determines the similarity of the sentences in the 8,000-dimensional space?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen39-slide41/text.txt": [
            "Can a fixed-size vector truly capture the meaning of a whole sentence?",
            "Can a single fixed-size vector accurately capture the meaning of a whole sentence?",
            "Can a single fixed-size vector truly capture the meaning of a whole sentence?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen40-slide42/text.txt": [
            "What do we expect regarding the aspects of meaning?",
            "What do we expect in terms of meaning?",
            "What do we expect to know about meaning based on the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen41-slide43/text.txt": [
            "What is the semantic representation of pictures according to the speaker?",
            "What is the purpose of labeling each pixel in a picture with a class label?",
            "What is the process of labeling each pixel in a picture with some class label called?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen42-slide44/text.txt": [
            "Is it possible to determine whether a computer program will stop running?",
            "Can the meaning of sentences be discussed in the same way as the expected output of computer programs?",
            "Is it possible to determine whether a computer program will stop running or not?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen43-slide45/text.txt": [
            "What is the main idea behind the Textogramalical Theory by Petrus Gall according to the structuralist approach to the meaning of the sentence?",
            "What is the main difference between the structuralist approach to the meaning of a sentence and the linguistic meaning?",
            "What is the main difference between the linguistic meaning and the structuralist approach to the meaning of a sentence, according to the provided text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen44-slide46/text.txt": [
            "What is the benefit of continuous representations that symbolic theories do not have?",
            "What is the primary benefit of continuous representations in capturing the meaning of sentences, according to the author?",
            "What is the benefit of continuous representations that symbolic theories do not possess?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen45-slide47/text.txt": [
            "What is the key concept in understanding complex sentences according to Chris Manning?",
            "What is the central idea behind the compositionality of meaning according to Chris Manning?",
            "What is the compositionality of meaning according to Chris Manning?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen46-slide48/text.txt": [
            "What is the approach used by Carverne and Canavra to represent hierarchical structure in vectors of real numbers?",
            "What is an example of a compositional structure that can be represented using the method illustrated by Carverne and Canavra, as described in the paper?",
            "What type of operations and reversibility are required to represent hierarchical structure using vectors of real numbers?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen47-slide49/text.txt": [
            "How can sentence-level embeddings created by deterministic encoders effectively encode ambiguity, considering that a single vector can only represent one possible meaning?",
            "How can sentence-level embeddings be designed to encode the ambiguity of a sentence, given that they are created by deterministic encoders?",
            "How can sentence level embeddings be used to encode ambiguity, given that they are created by deterministic encoders?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen48-slide50/text.txt": [
            "What type of model does the statefulness of the decoder correspond to in the context of human language processing?",
            "What type of model is affected by the problems associated with the statelessness of the decoder?",
            "What is the primary problem associated with stateless models, according to the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen49-slide51/text.txt": [
            "Is the space of linguistic meanings continuous?",
            "Is the linguistic space of meanings continuous?",
            "Is the linguistic space of meanings continuous?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen50-slide52/text.txt": [
            "Will the Czech paraphrases of different English sentences live in the same area in the sentence embedding space, or will they have too much conflict or interference with each other's embeddings?",
            "Will the Czech paraphrases of different English sentences live in the same area in the sentence embedding space?",
            "Will the Czech counterparts of different English sentences live in the same area in the sentence embedding space?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen51-slide53/text.txt": [
            "What type of validation is proposed for the relation between the sentences provided by human annotators?",
            "What type of directions of exploration are being proposed in this study?",
            "What is the process of validating the relation between two sentences in the proposed partial ordered set of sentences?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen52-slide52/text.txt": [
            "What is the common characteristic of the sentences in the given text?",
            "What is the purpose of the sentences having similar meanings in the given text?",
            "What is the purpose of the sentences in the given text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen53-slide53/text.txt": [
            "What is the purpose of organizing the sentences into a partial ordered set?",
            "What type of mathematical structure is being referred to as a \"manifold of some embeddings\" based on the given partial ordered set?",
            "What is the purpose of organizing the sentences into a partial ordered set?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen54-slide54/text.txt": [
            "What are some types of modification that can be made to a sentence?",
            "What are some types of modification that can be applied to sentences, according to the text?",
            "What are some examples of modification in sentences that can be used to make them more or less in the future or past?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen55-slide55/text.txt": [
            "What is the primary issue with using the expression \"so hammer the hook into the wall or put the hook on the wall or do the thingy there\" in a sentence?",
            "What is the primary concern when the expression \"so hammer the hook into the wall or put the hook on the wall or do the thingy there\" becomes too vague?",
            "What is the purpose of using the phrase \"so\" in a sentence when all other options are equally understandable?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen56-slide56/text.txt": [
            "What is the difference between polite and impolite pairs of sentences in the given examples?",
            "What is the difference between polite and impolite pairs of sentences in the given examples?",
            "What is the difference between polite and impolite pairs of sentences in the given examples?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen57-slide57/text.txt": [
            "What is the purpose of having annotators create sentences in between two extremes in the politeness and rudeness dimension?",
            "What is the purpose of asking annotators to create sentences that are in between two extremes in the politeness and rudeness dimension?",
            "What type of sentences are the annotators asked to create in the politeness and rudeness dimension exercise?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen58-slide58/text.txt": [
            "What is the purpose of asking a third set of annotators to put different wordings on a scale?",
            "What is the purpose of asking a third set of annotators to put different wordings on a scale?",
            "What is the purpose of asking a third set of annotators to put different wordings on a scale?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen59-slide59/text.txt": [
            "Will we be able to find similar relations in cases where some sentences are totally incomparable?",
            "Can we find similar relations in a partially ordered set that contains some sentences which are totally incomparable?",
            "Will we be able to find similar relations in a partially ordered set where some sentences are totally incomparable?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen60-slide60/text.txt": [
            "What happens to the structure between sentences in the learned representation when the manifold is unfolded or unrolled?",
            "What happens to the structure of the learned representation when the manifold is unfolded or unrolled?",
            "What happens to the structure of the learned representation when the manifold is unfolded?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen61-slide61/text.txt": [
            "What type of representation will have a better match with the manually collected data?",
            "What type of representation would be considered a very semantic representation of the partial ordered set of sentences in the given space?",
            "What type of representation is being referred to as having a better match with the manually collected data?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen62-slide62/text.txt": [
            "What is the topic of the text provided?",
            "What is the topic of the text?",
            "What is the topic of the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen63-slide63/text.txt": [
            "What are some examples of well-known sentence representations that were compared using the SenteVal toolkit?",
            "What is SenteVal used for in the context of sentence representations?",
            "What is SenteVal used for in the context of sentence representations?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen64-slide64/text.txt": [
            "What was the main objective of the experiment from 2018 that the author is referring to?",
            "What measures of semantics did the authors relate to the equality of translation in their 2018 experiment?",
            "What was the focus of the experiment conducted in 2018 regarding the attention model and sequence-to-sequence architecture?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen65-slide65/text.txt": [
            "What type of neural network representations would be used to convert an input sentence to a hidden representation for processing with the Senteval tool?",
            "What type of neural network representations would be used to process the input sentence for the Senteval evaluation task?",
            "What type of neural network representations would be used to convert the input sentence to a hidden representation for the Senteval evaluation task?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen66-slide66/text.txt": [
            "What would be the consequence of having a representation that fails to highlight the important things in the reference for a particle task?",
            "What would be the consequence of a poor representation in a classification task?",
            "What type of task would suffer if your representation fails to highlight the important things in the reference source?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen67-slide67/text.txt": [
            "What type of classification tasks do the individual sentence representations serve in the task of movie sentiment analysis?",
            "What are the specific classification tasks that the individual sentence representations (SOLOTARs) are used for?",
            "What is the primary purpose of the individual sentence representations described in the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen68-slide68/text.txt": [
            "What are the three classes in the natural language inference task, and how are they evaluated?",
            "What are the three possible outcomes in the natural language inference task, and how are they evaluated?",
            "What are the three classes of evaluation for the natural language inference task, and how are they assessed based on the pairs of sentence embeddings?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen69-slide69/text.txt": [
            "What method can be used to evaluate sentence embeddings if there is no training data available?",
            "What is the alternative method for evaluating sentence embeddings when there is no training data available?",
            "What is the alternative approach to evaluating sentence embeddings when there is no regression training data available?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen70-slide70/text.txt": [
            "What are the two sources of data mentioned in the text?",
            "What are the two sources of data mentioned in the text?",
            "What are the two sources of data mentioned in the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen71-slide71/text.txt": [
            "What type of data does the Coco dataset consist of?",
            "What is the nature of the relationship between a single image and the five captions in the Coco data set?",
            "What type of data does the Coco dataset contain?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen72-slide72/text.txt": [
            "What measures are used to evaluate the quality of the clusters?",
            "What measures are available to evaluate how good the clusters are?",
            "What measures are available to evaluate the quality of the clusters?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen73-slide73/text.txt": [
            "What does the Davis Bulldin Index measure?",
            "What is the purpose of the Davis Bulldin Index in the context of clustering?",
            "What is the purpose of the Davis Bulldin Index in the context of cluster separation?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen74-slide74/text.txt": [
            "What is another way of measuring the goodness of a clustering?",
            "What is another way to measure the goodness of a clustering?",
            "What is another way to measure the goodness of a clustering?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen75-slide75/text.txt": [
            "What is the purpose of using the removed points as a test set in a classification task?",
            "What is the purpose of removing points to train a classifier in a classification task?",
            "What is the purpose of using the removed points as a test set in a classification task?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen76-slide76/text.txt": [
            "What is the problem with using a sequence-to-sequence model with annotation features, bidirectional encoder, and attention mechanism to obtain a single vector representation of an input sentence?",
            "What is the main issue with using a sequence-to-sequence model with attention mechanism to generate a single vector representation of the input sentence?",
            "What is the problem with using the attention sequence to sequence paper for sentence representation in semantic processing tasks?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen77-slide77/text.txt": [
            "How do we create fixed-size representations while preserving the information attached in the model?",
            "How do we create fixed-size representations while preserving the information attached in the model?",
            "How can we create fixed-size representations in a model while still preserving the information attached to it?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen78-slide78/text.txt": [
            "What was the early practice of NullMT in encoding?",
            "What was the early practice of NullMT according to the given text?",
            "What was the early practice of NullMT in encoding?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen79-slide79/text.txt": [
            "What type of pooling (max or average) is used to ensure the resulting vector for the sentence representation is always of the same size regardless of the sentence length?",
            "What type of pooling (max or average) is used to ensure that the resulting vector for the sentence representation is always of the same size regardless of the sentence length?",
            "What type of pooling operation can be applied to sentence representations to ensure the resulting vector is always of the same size regardless of the sentence length?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen80-slide80/text.txt": [
            "What is the purpose of using multiple heads in the inner attention mechanism in a static way before the decoder starts?",
            "What is the purpose of using multiple heads in the inner attention mechanism in a transformer architecture?",
            "What is the purpose of using multiple heads in the inner attention mechanism in a transformer architecture?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen81-slide81/text.txt": [
            "What is the name given to this type of attention mechanism in the sequence-to-sequence model described in the text?",
            "What is the term used to describe the process of the decoder operating on the entire embedding of the sentence or attending to a summary of attention in the attention-attention or compound attention mechanism?",
            "What is the purpose of the \"heads\" in the attention mechanism described in the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen82-slide82/text.txt": [
            "What type of encoder and decoder are mentioned as alternatives for the recurrent network in the given text?",
            "What type of encoder and decoder is mentioned as an alternative to the recurrent network for generating output sentences?",
            "What type of encoder and decoder can be used to create a recurrent network for generating output sentences with a fixed number of words?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen83-slide83/text.txt": [
            "What effect did the size of the training data and the domain variables have on the results of the English sentence embeddings translation systems?",
            "What effect did the size of the training data and domain variables have on the results of the English-to-German sentence embeddings?",
            "What effect did the use of different datasets and the size of the training data have on the results of the English-to-German sentence embeddings?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen84-slide84/text.txt": [
            "What is the best performance in terms of BLEU score according to the results of the probes?",
            "What is the best-performing model in terms of BLEU score according to the results of the probes?",
            "What is the best-performing model according to the BLEU score results of the probes?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen85-slide85/text.txt": [
            "What is the basis for the authors' trust in using BLEU scores as a measure of translation quality?",
            "What measure of translation quality were the authors relying on, and why?",
            "What can be trusted as a measure of translation quality based on the information provided in the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen86-slide86/text.txt": [
            "What type of attention (inner or compound) is necessary for setups to perform better?",
            "What type of attention performs better in setups according to the observations made?",
            "What type of attention does the setups that perform better use?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen87-slide87/text.txt": [
            "What is the relationship between the number of heads in the attention and the score?",
            "What is the relationship between the number of heads in attention and the score?",
            "What effect does the number of heads in attention have on the score?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen88-slide88/text.txt": [
            "What is the significance of the semantic evaluation of the representations learned by the English to Czech machine translation system?",
            "What is the purpose of the semantic evaluation of the representations learned by the English to Czech machine translation system?",
            "What is the significance of the semantic evaluation of the English to Czech machine translation system mentioned in the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen89-slide89/text.txt": [
            "What type of representations emerge automatically when training neural network systems for the given tasks?",
            "What are the measures used for evaluating the performance of the neural network systems in the COCO dataset, according to the provided text?",
            "What type of representations emerge automatically when these neural network systems are trained?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen90-slide90/text.txt": [
            "What happens to the performance when using attention in a model, according to the given text?",
            "Does using the final state of the encoder and decoder improve performance across multiple evaluation tasks?",
            "What is the effect of using attention in machine learning models when evaluated across multiple tasks?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen91-slide91/text.txt": [
            "What happens to the performance in semantics tasks when there are more heads in the same setup?",
            "What is the relationship between the number of heads in a setup and performance in semantics tasks?",
            "How does the number of heads in a setup affect performance in semantics tasks?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen92-slide92/text.txt": [
            "What type of representation do sequence-to-sequence models use to store the meaning of a sentence, as illustrated by the track task in the text?",
            "What type of representation does a sequence-to-sequence model typically store, according to the text?",
            "What type of representation do sequence-to-sequence models store, according to the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen93-slide93/text.txt": [
            "Would the depth of the network lead to representations that perform better in the semantic scoring?",
            "Does the removal of the transformer model from the setup lead to a more positive correlation between the other metrics in the evaluation?",
            "Does the removal of the transformer model in the setup lead to a more positively correlated relationship between the other metrics in the English to German evaluation?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen94-slide94/text.txt": [
            "What type of attention is being referred to in the attention-attention model described in the text?",
            "What type of attention does the network learn in the attention-attention model described in the text?",
            "What is the compound attention mechanism used in the attention-attention model described in the text?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen95-slide95/text.txt": [
            "What was the observation made when the experiment was repeated for multiple sentences?",
            "What pattern did the authors observe in the use of hats at the beginning of sentences?",
            "What was the pattern observed in the use of yellow and red hats in the sentences?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen96-slide96/text.txt": [
            "Where on average across all the sentences do the heads look?",
            "What is the average position of the heads in a sentence when translating, across all sentences?",
            "What is the role of the recurrent neural model in dividing the sentence into different sections?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen97-slide97/text.txt": [
            "What happens to the performance of the system in polarity check tasks when the number of heads increases?",
            "What is the effect of having more heads in the system on its performance in polarity check tasks?",
            "What is the effect on a model's performance when the number of heads in a system increases, particularly in tasks that require searching for specific information across the entire sentence?"
        ],
        "testset/nmt-class/lecture04-alignment/screen01-slide01/text.txt": [
            "What is the primary focus of the fourth lecture on statistical machine translation?",
            "What is the primary focus of the fourth lecture on statistical machine translation?",
            "What is the relevance of the alignment part of techniques in neural machine translation?"
        ],
        "testset/nmt-class/lecture04-alignment/screen02-slide02/text.txt": [
            "What techniques will be used for word level alignment in the corpus of Cenk?",
            "What techniques will be briefly described after discussing the effect of data on translation quality?",
            "What techniques will be described after discussing the effect of data on translation quality?"
        ],
        "testset/nmt-class/lecture04-alignment/screen03-slide03/text.txt": [
            "What is the purpose of word alignment in phrase-based machine translation?",
            "What motivated the development of word alignment in phrase-based machine translation?",
            "What motivated the development of word alignment in the previous state of the art in machine translation?"
        ],
        "testset/nmt-class/lecture04-alignment/screen04-slide04/text.txt": [
            "What is the first thing the author will do with the data?",
            "What is the main point the speaker will start with when discussing the data?",
            "What will the speaker start with?"
        ],
        "testset/nmt-class/lecture04-alignment/screen05-slide05/text.txt": [
            "What type of texts were included in the CENG 0.7 corpus, and how did they contribute to the data gathering process for the Czech-English language pair?",
            "What was the outcome of the Davaho project, which aimed to translate the English Wikipedia into Czech with user corrections?",
            "What language pair did the authors have a significant amount of history of data gathering for, and what were some of the sources of texts they were able to include in their corpus?"
        ],
        "testset/nmt-class/lecture04-alignment/screen06-slide06/text.txt": [
            "What percentage of the data consisted of community-supplied localization texts?",
            "What percentage of the data consisted of community-supplied localization texts in terms of sentences?",
            "What percentage of the total data consisted of community-supplied localization texts?"
        ],
        "testset/nmt-class/lecture04-alignment/screen07-slide07/text.txt": [
            "What percentage of the 2000 segments corrected every month were deemed to be reasonably good translations?",
            "What percentage of the Navajo project's corrections were deemed \"reasonably good translations\"?",
            "What percentage of the Navajo project's translations were deemed \"precise and flawless\" by manual evaluation?"
        ],
        "testset/nmt-class/lecture04-alignment/screen08-slide08/text.txt": [
            "What is the general quality of the community-supplied data mentioned in the text?",
            "What is the quality of the community supply data if the contributors sign in under their own names?",
            "What is a notable characteristic of the community supply data that contributes to its quality?"
        ],
        "testset/nmt-class/lecture04-alignment/screen09-slide26/text.txt": [
            "What is the main issue with the licensing conditions of texts available for reuse in machine translation systems?",
            "What percentage of the available data is labelled for reuse and explicitly marked that it can be used for training of machine translation systems?",
            "What is the main concern regarding the licensing conditions of the available texts for reuse and training of machine translation systems?"
        ],
        "testset/nmt-class/lecture04-alignment/screen10-slide10/text.txt": [
            "What is the status of the community-supplied data that is not labeled with copyright text?",
            "What is the status of the community-supplied data mentioned in the text, and why is it considered unclear?",
            "What is the status of the large data source used for training, and how does it affect the translation quality?"
        ],
        "testset/nmt-class/lecture04-alignment/screen11-slide11/text.txt": [
            "What type of test sets are mentioned in the text, and what do they represent in the context of evaluating translation quality?",
            "What type of test sets are being used to evaluate the translation quality of the system?",
            "What type of test sets are being used to evaluate the translation quality of the system?"
        ],
        "testset/nmt-class/lecture04-alignment/screen12-slide12/text.txt": [
            "What will be the BLEU score if the translation is based only on the correctly labeled Community Supply Translations?",
            "What would be the expected BLEU score and out of vocabulary rate if the translators relied only on the correctly labeled Community Supply Translations?",
            "If we rely only on the correctly labeled Community Supply Translations, what can be expected about the BLEU score and out of vocabulary rate?"
        ],
        "testset/nmt-class/lecture04-alignment/screen13-slide13/text.txt": [
            "What is the result of the community contribution of subtitles in the translation quality?",
            "What improvement has been made in the out-of-vocabulary rate in the subtitles?",
            "What has been significantly reduced in the translation process?"
        ],
        "testset/nmt-class/lecture04-alignment/screen14-slide14/text.txt": [
            "Does including proprietary translations improve translation quality?",
            "Does including proprietary translations improve the translation quality?",
            "What effect does including proprietary translations out of the domain have on the translation quality?"
        ],
        "testset/nmt-class/lecture04-alignment/screen15-slide15/text.txt": [
            "What is the Blof level when using all datasets except in-domain training data?",
            "What is the BLOF rating when using all datasets except in-domain training data?",
            "What BLOF level would be achieved if all datasets except in-domain training data are used?"
        ],
        "testset/nmt-class/lecture04-alignment/screen16-slide16/text.txt": [
            "What is the ideal situation for translation quality?",
            "What is the ideal situation for achieving good translation quality?",
            "What is the ideal situation for achieving good translation quality?"
        ],
        "testset/nmt-class/lecture04-alignment/screen17-slide17/text.txt": [
            "Can extending a collection with professional translations affect the quality of a sentence?",
            "Can you still improve the quality of a sentence by adding professional translations to it?",
            "Can extending a collection with professional translations affect the quality of a sentence?"
        ],
        "testset/nmt-class/lecture04-alignment/screen18-slide18/text.txt": [
            "What happens to the translation quality when you include auto-domain data and community-supplied translations in your vocabulary?",
            "What effect does including auto-domain data and imperfect translations have on the translation quality?",
            "What is the potential trade-off between reducing the vocabulary problem and translation quality when including auto-domain data and imperfect translations?"
        ],
        "testset/nmt-class/lecture04-alignment/screen19-slide19/text.txt": [
            "What happens to the translation quality when using in-domain training data for out-of-domain translation?",
            "What is the effect of using in-domain training data for out-of-domain translation tasks?",
            "What is the effect of using in-domain training data on translation quality when the target domain is out of domain?"
        ],
        "testset/nmt-class/lecture04-alignment/screen20-slide20/text.txt": [
            "What is the comparison between the BLEU scores of professional translations and community translations in the given dataset?",
            "What is the BLEU score comparison between professional translations and community translations in the given dataset?",
            "What is the general trend in BLEU scores between professional translations and community translations in the given dataset?"
        ],
        "testset/nmt-class/lecture04-alignment/screen21-slide21/text.txt": [
            "What is the main advantage of using all available data when translating, according to the final plot in the text?",
            "What is the primary advantage of using in-domain data over using all available data?",
            "What is the primary recommendation for BLEU score, translation quality, and out-of-vocabulary rate when you know your domain?"
        ],
        "testset/nmt-class/lecture04-alignment/screen22-slide22/text.txt": [
            "What was the main reason for the filtering of the corpus in the previous release of Cheng?",
            "What is the total number of words in the Cheng 2.0 corpus combined with Czech and English?",
            "What is the approximate total number of words in Cheng and English combined in version 2.0 of the Cheng language model?"
        ],
        "testset/nmt-class/lecture04-alignment/screen23-slide23/text.txt": [
            "What methods are needed to align a corpus at both the sentence and word level?",
            "What methods are needed to align a corpus at both sentence and word levels?",
            "What methods are needed to align a corpus at both sentence and word levels?"
        ],
        "testset/nmt-class/lecture04-alignment/screen24-slide24/text.txt": [
            "What is the main challenge in obtaining seed URLs for parallel texts, and how have researchers addressed this issue?",
            "What is the main challenge in obtaining seed URLs for parallel texts, according to the text?",
            "What are the challenges in obtaining seed URLs for parallel texts, and how have researchers addressed this issue?"
        ],
        "testset/nmt-class/lecture04-alignment/screen25-slide25/text.txt": [
            "What was the outcome of the testing of the proposed method on the ShuffleChang corpus, specifically in terms of precision and recall?",
            "What was the outcome of using the Common Crawl data for extracting English-Czech parallel sentences, in terms of the number of extracted sentence pairs?",
            "What was the outcome of the attempt to extract 150 terabytes of text from Common Crawl data to create English-Czech parallel sentences?"
        ],
        "testset/nmt-class/lecture04-alignment/screen26-slide26/text.txt": [
            "What is the next step after aligning pairs of texts if we do not know anything about the languages involved?",
            "What is the next step after aligning pairs of texts when aligning sentences for any pair of languages without prior knowledge of the languages?",
            "What is the next step after aligning pairs of texts for any pair of languages if nothing is known about the languages?"
        ],
        "testset/nmt-class/lecture04-alignment/screen27-slide27/text.txt": [
            "What is the counterpart of the full stop in the Devanagari script?",
            "What is the counterpart of the full stop in the Devanagari script?",
            "What is the counterpart of the full stop in the Devanagari script?"
        ],
        "testset/nmt-class/lecture04-alignment/screen28-slide28/text.txt": [
            "What is the key factor in sentence alignment processing that allows for accurate comparisons between sentences of different lengths?",
            "What is the critical parallel part that is used in sentence alignment processing, according to the provided observation?",
            "What is the key factor that allows for parallel alignment of sentence lengths between two languages during sentence alignment processing?"
        ],
        "testset/nmt-class/lecture04-alignment/screen29-slide29/text.txt": [
            "What is the standard tool for sentence alignment, according to the information provided?",
            "What is the standard tool for sentence alignment, according to the text?",
            "What is the standard tool for sentence alignment according to the text?"
        ],
        "testset/nmt-class/lecture04-alignment/screen30-slide30/text.txt": [
            "What are the main limitations of the word alignment approach, specifically in terms of the type of alignment it can achieve?",
            "What is the main limitation of the word alignment model implemented by the Giza++ tool?",
            "What is the primary limitation of the word alignment algorithms, in terms of the type of alignment they can perform?"
        ],
        "testset/nmt-class/lecture04-alignment/screen31-slide31/text.txt": [
            "What are the limitations of the IBM Model 1 in terms of translation?",
            "What is the primary limitation of the IBM Model 1 in terms of its ability to perform translation?",
            "What is the primary limitation of the IBM Model 1 in terms of translation?"
        ],
        "testset/nmt-class/lecture04-alignment/screen32-slide31/text.txt": [
            "What year is the slide \"Let's move to the slides\" by Philip Cain?",
            "Who is the author of the text \"Let's move to the slides\"?",
            "What is the age of the slides mentioned in the text?"
        ],
        "testset/nmt-class/lecture04-alignment/screen33-slide32/text.txt": [
            "What is the purpose of obtaining lexical translation probabilities in the context of dictionary usage?",
            "What is the main limitation of traditional dictionaries in providing lexical translation probabilities?",
            "What is the purpose of obtaining lexical translation probabilities in the context of machine translation?"
        ],
        "testset/nmt-class/lecture04-alignment/screen34-slide32/text.txt": [
            "What is the most common translation of the German word \"house\" in the given corpus?",
            "What is the most common translation of the German word \"house\" in the context of a large corpus?",
            "What is the most common translation of the German word 'Haus' in the English language?"
        ],
        "testset/nmt-class/lecture04-alignment/screen35-slide33/text.txt": [
            "What do we want to collect for all the possible...?",
            "What is the focus of the task described in the given text?",
            "What do we want to collect for all the possible English words given a German word?"
        ],
        "testset/nmt-class/lecture04-alignment/screen36-slide34/text.txt": [
            "What is the alignment of words in the corpus?",
            "What is the alignment of words in a corpus?",
            "What is the purpose of indicating word alignment in a corpus?"
        ],
        "testset/nmt-class/lecture04-alignment/screen37-slide35/text.txt": [
            "What is the primary function of the alignment in the context provided?",
            "What is the primary function of the alignment described in the text?",
            "What is the function that captures the alignment between the English target word and the source word?"
        ],
        "testset/nmt-class/lecture04-alignment/screen38-slide36/text.txt": [
            "What is the mapping relationship between position 1 and position 2?",
            "What happens to the mapping of position 1 to position 2 in the given instructions?",
            "What mapping pattern is described in the given instructions?"
        ],
        "testset/nmt-class/lecture04-alignment/screen39-slide37/text.txt": [
            "What is the result of applying the alignment function to the sentences \"Klein is the house\", \"the house is small\", and \"the house can be easily captured\"?",
            "What is the result of applying the alignment function to the sentences \"Klein is the house\", \"the house is small\", and \"the house can be easily captured\"?",
            "What can the alignment function do to the words in a sentence?"
        ],
        "testset/nmt-class/lecture04-alignment/screen40-slide38/text.txt": [
            "Does the function need to be a bijection in order to capture one-to-many translations?",
            "Can a function that produces one-to-many translations still be a bijection?",
            "Can a function that produces one-to-many translations still be a bijection?"
        ],
        "testset/nmt-class/lecture04-alignment/screen41-slide39/text.txt": [
            "What will happen to the source words that do not map to any target language words?",
            "What will happen to a source word that has no corresponding mapping in the target language?",
            "What will happen to source words that do not have any alignment link in the target language?"
        ],
        "testset/nmt-class/lecture04-alignment/screen42-slide40/text.txt": [
            "Can an auxiliary symbol be used to indicate that a word has no counterpart in the other language?",
            "Can an auxiliary symbol be added to the source sentence, and if so, can it also be used to drop words in the target language?",
            "Can an auxiliary symbol be added to a source sentence to indicate a word that has no counterpart in the other language?"
        ],
        "testset/nmt-class/lecture04-alignment/screen43-slide41/text.txt": [
            "What is the role of the alignment function in the definition of the IBM Model 1?",
            "What is the definition of the normalization constant used in the IBM Model 1?",
            "What is the position of the words considered in the IBM Model 1 translation process?"
        ],
        "testset/nmt-class/lecture04-alignment/screen44-slide26/text.txt": [
            "What is the formula used by IBM Model One to calculate the probability of the whole sentence given the alignments and the lexical probabilities for each word?",
            "What is the formula used by IBM model one to calculate the probability of the whole sentence given the alignments and given the words and given the source sentence?",
            "What is the formula used by IBM model one to calculate the probability of the whole sentence given the alignments and the words in the lexical translation table?"
        ],
        "testset/nmt-class/lecture04-alignment/screen45-slide43/text.txt": [
            "How do we obtain lexical probabilities from a parallel corpus?",
            "How do we obtain lexical probabilities from a parallel corpus?",
            "How can we estimate lexical probabilities from a parallel corpus without the alignments?"
        ],
        "testset/nmt-class/lecture04-alignment/screen46-slide44/text.txt": [
            "What is the purpose of the EM algorithm in the context of estimating a model when there are missing data points?",
            "What is the purpose of the EM algorithm in relation to having complete data and the model?",
            "What is the purpose of the EM algorithm in the context of handling incomplete data?"
        ],
        "testset/nmt-class/lecture04-alignment/screen47-slide45/text.txt": [
            "What happens to the lexical probabilities at the beginning of the process described in the text?",
            "What is the initial state of the lexical probabilities for the words \"la\", \"maison\", \"house\", and \"fleur\"?",
            "What can be linked with \"la\" equally likely as with \"maison\" at the beginning?"
        ],
        "testset/nmt-class/lecture04-alignment/screen48-slide46/text.txt": [
            "What happens to the alignment link between \"the\" and \"la\" after multiple iterations of the model?",
            "What will happen to the alignment link between \"the\" and \"la\" after multiple iterations of the model?",
            "What happens to the alignment link between \"the\" and \"la\" after multiple iterations of the model?"
        ],
        "testset/nmt-class/lecture04-alignment/screen49-slide28/text.txt": [
            "What is the outcome for words that are not covered in other sentences when the probability mass is distributed according to the given principle?",
            "What is the guaranteed outcome for the word \"flower\" based on the full coverage of the words in the alignment?",
            "What is the guaranteed outcome for the word \"flower\" according to the described alignment process?"
        ],
        "testset/nmt-class/lecture04-alignment/screen50-slide26/text.txt": [
            "What can be determined about the alignment of words at the end of the process when it converges and reaches a global optimum?",
            "What is the outcome when a method converges to a global optimum and does so quickly?",
            "What will we know at the end when the process converges and has a global optimum?"
        ],
        "testset/nmt-class/lecture04-alignment/screen51-slide26/text.txt": [
            "What method is used to estimate the conditional probability of the end of the alignment given the presence of the word \"LAW\"?",
            "What method will be used to estimate the conditional probability of the word \"LAW\" at the end of an alignment?",
            "What is the method used to calculate the conditional probability based on the observations of the word \"LAW\" at the other end of the alignment?"
        ],
        "testset/nmt-class/lecture04-alignment/screen52-slide26/text.txt": [
            "What are the two main steps in the expectation maximization algorithm?",
            "What is the purpose of the modal in the expectation step of the expectation maximization algorithm?",
            "What are the two steps in the expectation maximization algorithm?"
        ],
        "testset/nmt-class/lecture04-alignment/screen53-slide26/text.txt": [
            "What is the subject of the text mentioned in the phrase \"So now the formulas\"?",
            "What does the TEXT say about covering formulas?",
            "What is the topic of the discussion in the provided TEXT?"
        ],
        "testset/nmt-class/lecture04-alignment/screen54-slide26/text.txt": [
            "What is the purpose of the normalization constant in the IBM model one, and is it ignored in the given calculation?",
            "What is the probability of the alignment given the source and target sentences after normalization, according to the IBM model one?",
            "What is the probability of the alignment given the source and target sentences after normalizing the probabilities calculated by the IBM model one?"
        ],
        "testset/nmt-class/lecture04-alignment/screen55-slide26/text.txt": [
            "What is the numerator in the probability fraction used to estimate the fractional counts in the IBM model one alignment?",
            "What is the numerator of the probability fraction in the IBM model one alignment calculation?",
            "What is the numerator of the probability fraction in the IBM model one alignment calculation?"
        ],
        "testset/nmt-class/lecture04-alignment/screen56-slide26/text.txt": [
            "What does the formula for the probability of the target sentence given the source, considering all possible alignments, rely on for each possible alignment?",
            "What does the IBM Model 1 definition say about normalizing lexical probabilities?",
            "What does the IBM Model 1 definition say about normalizing lexical probabilities?"
        ],
        "testset/nmt-class/lecture04-alignment/screen57-slide26/text.txt": [
            "What does the text \"Yeah, so this on\" convey?",
            "What is the content of the text \"Yeah, so this on\"?",
            "What is the content of the text \"Yeah, so this on\"?"
        ],
        "testset/nmt-class/lecture04-alignment/screen58-slide26/text.txt": [
            "What does the speaker say about the slide?",
            "What does the phrase \"so what\" imply about the slide?",
            "What does the phrase \"This slide, so what...\" imply?"
        ],
        "testset/nmt-class/lecture04-alignment/screen59-slide26/text.txt": [
            "What is the name of the statistical model used to find the probability of alignment given the source and target sentences?",
            "What is the name of the IBM model that relies on lexical translation probabilities and the full probability of the target given the source across all alignments?",
            "What is the name of the probability model used to find the definition of the IBM model 1, which relies on lexical translation probabilities and the full probability of the target given the source across all alignments?"
        ],
        "testset/nmt-class/lecture04-alignment/screen60-slide26/text.txt": [
            "What is a problem with having a sum in the denominator of a mathematical expression?",
            "What is a problem with having a sum in the denominator of a mathematical expression?",
            "What is a problem with having a sum in the denominator of a mathematical expression?"
        ],
        "testset/nmt-class/lecture04-alignment/screen61-slide26/text.txt": [
            "What is the purpose of factoring out elements that appear in multiple times in the calculation?",
            "What is the formula mentioned in the text as a way to estimate the probability of a target sentence given a source?",
            "What is the formula used to estimate the probability of the target sentence given the source, according to the provided text?"
        ],
        "testset/nmt-class/lecture04-alignment/screen62-slide26/text.txt": [
            "What is the trick being referred to in the formula?",
            "What is the trick mentioned in the text?",
            "What is the trick mentioned in the text?"
        ],
        "testset/nmt-class/lecture04-alignment/screen64-slide26/text.txt": [
            "What type of graph is being referred to in the context of calculating the sum of all pairs?",
            "What type of calculation are you considering when considering the sum of all pairs in the full graph?",
            "What is the nature of the \"product of summations\" mentioned in the context of the full graph?"
        ],
        "testset/nmt-class/lecture04-alignment/screen66-slide26/text.txt": [
            "What is the outcome of the product and sum operations in the IBM model 1 alignment, and how does it contribute to making the computation tractable?",
            "What is the key factor that makes the computation of the IBM model 1 alignment tractable?",
            "What is the outcome of the normalization in the IBM model 1 alignment calculation that makes the computation tractable?"
        ],
        "testset/nmt-class/lecture04-alignment/screen67-slide26/text.txt": [
            "What is the purpose of using the estimated alignment between words in the source and target sentences?",
            "What is the purpose of using the alignment between words in the source and target sentences to create the fractional counts?",
            "What is the purpose of using the estimated alignment between words in the source and target sentences?"
        ],
        "testset/nmt-class/lecture04-alignment/screen68-slide26/text.txt": [
            "What is the method used to estimate the likelihood of a word based on its observed co-occurrences with other words?",
            "What is the method used to calculate the maximum likelihood estimate of a word's probability based on its observed co-occurrences with other words?",
            "What is the process for calculating the maximum likelihood estimate of the word's probability based on observed co-occurrences with other words?"
        ],
        "testset/nmt-class/lecture04-alignment/screen69-slide26/text.txt": [
            "What programming language should be used to implement the pseudocode provided as homework?",
            "What programming language is recommended for implementing the pseudocode provided as homework?",
            "What programming language is recommended for implementing the pseudocode provided as homework?"
        ],
        "testset/nmt-class/lecture04-alignment/screen71-slide26/text.txt": [
            "What is the significance of the observation that White was never linked to Cerni in the given corpus?",
            "What is the initial state of the model and data when the Expectation-Maximization (EM) algorithm is applied to the given corpus?",
            "What is the outcome of the first iteration of the EM algorithm in the given corpus?"
        ],
        "testset/nmt-class/lecture04-alignment/screen73-slide26/text.txt": [
            "What is the primary function added by the IBM Model 2 compared to the IBM Model 1?",
            "What is the main difference between the IBM Model 2 and the IBM Model 3 in terms of lexical translation?",
            "What is the primary function added by the IBM Model 3 compared to the IBM Model 2?"
        ],
        "testset/nmt-class/lecture04-alignment/screen74-slide26/text.txt": [
            "What is the purpose of the distortion model in the IBM Model 4 word alignment system?",
            "What is the purpose of the Fertility Model in the IBM Model 4 system for word alignment?",
            "What is the purpose of the Fertility Model in the IBM Model 4, and how does it influence the translation process in word alignment?"
        ],
        "testset/nmt-class/lecture04-alignment/screen75-slide26/text.txt": [
            "What is the IBM Model 4 followed by?",
            "What is the name of the second computer model mentioned in the text?",
            "What is the name of the second computer model mentioned in the text?"
        ],
        "testset/nmt-class/lecture04-alignment/screen76-slide26/text.txt": [
            "What is the difference between using intersection and union when extracting parallel dictionaries?",
            "What is the name of the heuristic used to enlarge the intersection but not get the fully union?",
            "What is the purpose of relying on the intersection in extracting parallel dictionaries or phrase translations?"
        ],
        "testset/nmt-class/lecture04-alignment/screen77-slide26/text.txt": [
            "What is the Symmetrisation heuristic, according to the provided text?",
            "What is the Symmetrisation heuristic described in the provided text as including only points that are already in close vicinity from the intersection ones?",
            "What is the Symmetrisation heuristic that includes only points already in close vicinity from the intersection ones?"
        ],
        "testset/nmt-class/lecture04-alignment/screen78-slide26/text.txt": [
            "Do humans find it difficult to align auxiliary words in word alignment tasks, and if so, what are some common examples of such words?",
            "What do humans find most challenging when aligning words in word alignment tasks?",
            "What challenges did humans face when manually aligning words in word alignment tasks, according to the observations made?"
        ],
        "testset/nmt-class/lecture04-alignment/screen79-slide26/text.txt": [
            "What is the main message of the observation made when comparing the performance of automatic alignment with human alignment in the context of token simplification and data processing?",
            "What is the main message of the observation regarding the performance of automatic alignment as run by Giza?",
            "What is the main message about improving automatic algorithms when working on tasks that are ill-defined?"
        ],
        "testset/nmt-class/lecture04-alignment/screen80-slide26/text.txt": [
            "What are the two main types of alignments between English and Chinese that can appear to align well, but may not be meaningful in the context of translation?",
            "What are the two types of alignments between English and Chinese that may seem similar but have different underlying meanings?",
            "What are the two types of alignments between English and Chinese that may seem to align well, but actually have different implications?"
        ],
        "testset/nmt-class/lecture04-alignment/screen81-slide26/text.txt": [
            "What happened when two groups of annotators independently worked on the same test set without knowing each other?",
            "What was the result of two independent groups of annotators working on the same test set without knowing each other?",
            "What was the outcome for the two groups of annotators who independently annotated the same test set for Czech?"
        ],
        "testset/nmt-class/lecture04-alignment/screen82-slide26/text.txt": [
            "What is the purpose of marking auxiliary words in the tectogrammatic representation of sentences?",
            "What is the representation of auxiliary words in the tectogrammatic layer of Prague's Combination Linguistics Studies?",
            "What is the essential idea behind the tectogrammatic layer representation in Prague's Combination Linguistics Studies?"
        ],
        "testset/nmt-class/lecture04-alignment/screen83-slide26/text.txt": [
            "What were the main observations when applying the technique of aligning texogrammonical nodes to a phrase-based machine translation system?",
            "What were the main benefits and drawbacks of redefining the task of aligning texogrammonical nodes in a machine translation system?",
            "What was the main observation regarding the task of extracting a dictionary for a deep syntactic machine translation system?"
        ],
        "testset/nmt-class/lecture04-alignment/screen84-slide26/text.txt": [
            "What is the main difference between the approach described in the text and the RIS approach, according to the text?",
            "What is the main difference between the LEAF approach and the RIS approach in terms of linking words across languages?",
            "What is the main difference between the LEAF approach and the RIS approach in terms of how they link words across languages?"
        ],
        "testset/nmt-class/lecture04-alignment/screen85-slide26/text.txt": [
            "What was the primary reason why word alignments were problematic from a statistical point of view?",
            "What was the primary reason phrase-based machine translation using word alignments didn't bring enough improvement in translation quality?",
            "What was the outcome of trying to move from word alignment to true phrase alignment based on the phrase-based model?"
        ],
        "testset/nmt-class/lecture04-alignment/screen86-slide26/text.txt": [
            "What is the main concern mentioned in the given text regarding translations?",
            "What is the main concern about translating a text into a new language, according to the given text?",
            "What is the main point of the warning provided in the text about translations and alignment?"
        ],
        "testset/nmt-class/lecture04-alignment/screen87-slide32/text.txt": [
            "What is the difference in the way the English and Czech languages express the start date of a project or service?",
            "What is the difference in the way English and Czech express the start of a service or activity?",
            "What is the difference in the way English and Czech express the expected start date of a service or activity?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen01-slide01/text.txt": [
            "What is the main topic that the lecturer will cover in today's lecture on statistical machine translation?",
            "What is the current state of the art of NeuralMT, according to the lecturer?",
            "What is the main topic of the third lecture on statistical machine translation?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen02-slide02/text.txt": [
            "What is the topic that the speaker will be covering in the first part of the presentation?",
            "What is the primary topic of discussion in today's lecture according to the provided text?",
            "What type of slides are many of the slides based on?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen03-slide03/text.txt": [
            "What is the basic encoder decoder architecture that is going to be built?",
            "What is the basic encoder decoder architecture that is going to be built?",
            "What is the basic encoder decoder architecture that will be built?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen04-slide04/text.txt": [
            "How are neural networks constructed?",
            "How are neural networks constructed?",
            "How are neural networks constructed?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen05-slide03/text.txt": [
            "How does the model handle the meaning of the sentence without a direct link to the architecture, math, or linguistics?",
            "How does the system handle the meaning of the sentence automatically?",
            "How is the meaning of a sentence related to the architecture, the maths underneath, and linguistics in the context described?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen06-slide05/text.txt": [
            "What is the role of the bias term in the computation of the output vector H?",
            "What is the role of the bias term in the computation of the output vector H?",
            "What is the role of the bias term in a fully connected layer of a neural network?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen07-slide06/text.txt": [
            "What type of transformation occurs at one layer of a neural network, according to the given explanation?",
            "What is the effect of the activation function '10h' on the squashing of the infinite coordinate space into a finite space?",
            "What type of transformation occurs at one layer in a neural network, and how is it controlled by the values in the weight matrix and the bias vector?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen08-slide07/text.txt": [
            "How many layers are there in a network, according to the given explanation?",
            "How many layers are in a network, according to the given text?",
            "How many layers can a network have, according to the text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen09-slide05/text.txt": [
            "How did the weight matrix affect the number of coordinates in the inner representation?",
            "How was the inner representation size affected in a complex system after being scaled up to three coordinates from two coordinates?",
            "What is the result of scaling the inner representation from two coordinates by the weight matrix in a complex system?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen10-slide07/text.txt": [
            "What is the primary purpose of the backpropagation algorithm in the training process of a deep neural network?",
            "What is the basis of neural network computation according to the text?",
            "What is the purpose of the backpropagation algorithm in the training process of a feedforward neural network?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen100-slide83/text.txt": [
            "What were the main reasons why the results of the two systems were deemed incomparable?",
            "What were the main differences between the settings of the two systems studied in the papers?",
            "What can be concluded about the results of the two papers based on the differences in their settings?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen101-slide84/text.txt": [
            "What is the main message of the text about the comparison between the attention model and the encoder-decoder architecture?",
            "What is the main message being reiterated in the text?",
            "What is the main message being reiterated in the passage?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen11-slide08/text.txt": [
            "What is the primary function of the neural network in the described example, and how does it achieve this function?",
            "What is the role of the training examples in the process of a neural network learning to separate points in the x and y plane?",
            "What is the purpose of the neural network's training process in the context of separating points on the x and y plane?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen12-slide09/text.txt": [
            "What is the primary approach used to handle variable size inputs in neural networks?",
            "What is the primary way to handle variable length inputs in neural networks, according to the text?",
            "What is the purpose of unrolling the computation in the recurrent neural network to process variable length inputs?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen13-slide10/text.txt": [
            "What is the main problem with the simple definition of the transformation in a vanilla recurrent neural network?",
            "What is the problem with the simple definition of the transformation A in a vanilla recurrent neural network?",
            "What is the main problem with the simple definition of a transformation in a vanilla recurrent neural network?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen14-slide11/text.txt": [
            "What does the speaker consider \"technically\" in the given statement?",
            "What does the speaker mean by \"technically\"?",
            "What does the text describe as \"technically\"?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen15-slide10/text.txt": [
            "What happens to the values of the parameters in a deep network when they have to propagate backwards through the network to update the weights?",
            "What happens to the values of the parameters in a deep network when the changes of the parameters have to propagate backwards through the network, passing through non-linearity at every step?",
            "What happens to the values of the parameters in a deep network if they go through a non-linearity at every step during the backpropagation process?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen18-slide07/text.txt": [
            "What is the term for the problem where early parameters in a deep network do not change due to small updates during backpropagation?",
            "What is the term used to describe the problem where early parameters in a network do not change due to small update values?",
            "What is the name of the problem that occurs when the updates from backpropagation become too small, causing early layers to not change significantly during training?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen21-slide11/text.txt": [
            "What is the primary purpose of the reset gate in a Gated Recurrent Unit (GRU) network?",
            "What is the purpose of the reset gate in a GRU unit?",
            "What is the primary purpose of the reset gate in a Gated Recurrent Unit (GRU)?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen22-slide12/text.txt": [
            "What is the next step after processing variable input lengths in machine translation?",
            "What type of input lengths are being processed in machine translation?",
            "What is the next step in the machine translation process after processing variable input lengths?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen23-slide13/text.txt": [
            "What is the technical problem in processing a vector of English words of length 1 million when compared to a vector of Czech words of length 2 million or more?",
            "What is the technical problem with representing English words as columnar vectors in a dictionary?",
            "What is the technical problem with representing a vector of English words in a vector of length 1 million compared to a vector of Czech words?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen24-slide14/text.txt": [
            "What approach involves combining the most frequent pairs of characters to produce large units, which is then repeated to fully occupy the vocabulary size?",
            "What is the general idea behind the approach of combining the most frequent pairs of characters to produce large units, and then combining those units again to produce even larger units, until the vocabulary size is fully occupied?",
            "What approach involves combining the most frequent pairs of characters to produce large units, and then combining those units to produce even larger units until the vocabulary size is fully occupied?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen25-slide15/text.txt": [
            "What is the main trouble associated with using one-hot encoding in the context of embedding vectors into a continuous space?",
            "What is the main trouble associated with using one-hot encoding for embedding vectors into a continuous space?",
            "What is the main trouble associated with one-hot encoding, as previously discussed?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen26-slide13/text.txt": [
            "What is a problem with using dense representations of words in a system that relies on measurable similarity between words?",
            "What is the main problem with the computation in word representation systems due to the lack of measurable similarity between words?",
            "What is the main issue with using dense representations of words in a system that relies on similarity between words?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen27-slide15/text.txt": [
            "What are some of the dimensions or combinations of dimensions that can be used to indicate features such as politeness, past tense, or color in word embeddings?",
            "What is the primary purpose of the embeddings in a neural network, and how do they get trained for different tasks?",
            "What are the two different styles of embeddings that Word2Vec can produce?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen28-slide16/text.txt": [
            "What is the purpose of normalizing the non-scaled vector of the output vocabulary size to produce a probability distribution in the context of a recurrent neural network?",
            "What is the purpose of normalizing the scaled-up hidden state to make it a probability distribution in the output process?",
            "What is the purpose of using softmax normalization in the context of a recurrent neural network for generating output words?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen29-slide17/text.txt": [
            "What is the basis of Neural Language Modeling mentioned in the provided text?",
            "What is the basis of Neural Language Modeling according to the provided text?",
            "What is the basis of Neural Language Modeling, according to the provided text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen30-slide18/text.txt": [
            "What is the main difference between a Neural Network Translation System and an Ngram language model?",
            "What is the main difference between an Ngram language model and a recurrent neural network used in Neural Network Translation Systems?",
            "What is the primary goal of training a recurrent neural network to classify the next word in a sentence?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen31-slide19/text.txt": [
            "What are the two possible views on a recurrent neural network language model mentioned in the text?",
            "What are the two possible views of a recurrent neural network language model presented in the text?",
            "What are the two possible views on the recurrent neural network language model presented in the text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen32-slide20/text.txt": [
            "What is the benefit of using a bidirectional recurrent neural network in practice?",
            "What is the benefit of using a bidirectional recurrent neural network in practice?",
            "What is the benefit of using a bidirectional recurrent neural network in practice, as described in the text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen33-slide22/text.txt": [
            "What type of representation is beneficial for bidirectional recollect neural networks in natural language processing tasks?",
            "What is the primary advantage of using bidirectional recurrent neural networks in natural language processing tasks?",
            "What are the advantages of using bidirectional recurrent neural networks in natural language processing tasks?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen34-slide23/text.txt": [
            "What type of architecture is being referred to in the text as the final topic of discussion?",
            "What type of architecture is mentioned in the text as being related to translation systems?",
            "What type of architecture is being discussed in the text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen35-slide24/text.txt": [
            "What is the idea being referred to in the context of the conditional language model scheme?",
            "What is the idea being referred to in the conditional language model scheme?",
            "What is the idea being referred to in the conditional language model scheme?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen37-slide27/text.txt": [
            "What is the purpose of the decoder in the described language model architecture?",
            "What is the role of the encoder in the proposed network architecture?",
            "What type of network is used to process the input sequence of symbols into a single vector representation?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen38-slide28/text.txt": [
            "What is the purpose of the two embeddings in the encoder-decoder architecture?",
            "What is the primary function of the second recurrent neural network in the encoder-decoder architecture described in the text?",
            "What is the purpose of the two embeddings in the encoder-decoder architecture?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen39-slide30/text.txt": [
            "What is the purpose of ignoring the outputs of the RNN in the implementation of the source language model?",
            "What is the purpose of ignoring the outputs of the RNN in the source language model?",
            "What happens to the decoder's output after it predicts the next symbol in the target language?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen40-slide32/text.txt": [
            "What is the subject of the sentence \"So, uh, with...\".",
            "What does the speaker intend to discuss or talk about in the phrase \"So, uh, with...\".",
            "What is the subject of the sentence \"So, uh, with...\"?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen41-slide31/text.txt": [
            "What are the two main entities referred to as \"sub-work units\" in the given text?",
            "What is the nature of the input and target language sequences in a given sequence-to-sequence task?",
            "What are the two main components of the input for a translation task, as described in the text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen42-slide32/text.txt": [
            "What is the purpose of applying a non-linearity after adding the bias in the encoder's processing of an input word?",
            "What is the purpose of the non-linearity in the encoder's state calculation?",
            "What is the process of how the encoder digests the state and the current word in an RNN?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen43-slide33/text.txt": [
            "What is the purpose of the output projection layer in the decoder of a recurrent neural network, and how does it contribute to the overall decoding process?",
            "What is the purpose of the bias in the decoder's output projection layer?",
            "What is the purpose of the output projection layer in the decoder of the recurrent neural network?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen44-slide34/text.txt": [
            "What is the initial step in the training process of the system described in the text?",
            "What is the goal of scoring the output candidate in the training process of the system described in the text?",
            "What is the primary goal of scoring the output candidate in the system training process?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen45-slide35/text.txt": [
            "What is the distribution of all possible output words at a given time step in the training data, according to the described method?",
            "What is the nature of the output distribution defined in the text for a given time step in the training data?",
            "What is the nature of the output distribution defined in the training data?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen46-slide36/text.txt": [
            "What is the term used to describe the loss in the computation after cancellation of parts using zeros from a mathematical point of view?",
            "What is the loss calculated in the computation after the cancellation of parts using zeros?",
            "What is the loss calculated in the computation after cancellation of all the parts, according to the mathematical point of view?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen47-slide37/text.txt": [
            "What is the calculation for the loss incurred at a given position in the softmax output?",
            "What is the calculation used to determine the loss incurred at a particular position in the softmax output?",
            "What is calculated as the loss incurred at a particular position in the sequence during the training process?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen48-slide38/text.txt": [
            "What is the basis for calculating losses at each position in the output words?",
            "What is the basis for the computation of the derivatives in the given context?",
            "What is the basis for calculating the loss at each position in the output word?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen49-slide39/text.txt": [
            "What is the main consequence of training a neural network model for machine translation tasks?",
            "What is the consequence of training a neural network model to produce the exact word at the exact position in a machine translation task?",
            "What is the primary consequence of training a neural network model for machine translation tasks?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen50-slide40/text.txt": [
            "What is the role of the Softmax function in the training process of a neural network?",
            "What is the role of the Softmax function in the training process of the decoder in a neural network?",
            "What is the primary function of the decoder in the context of training and runtime operations?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen51-slide42/text.txt": [
            "What is the outcome at each step of the decoding process?",
            "What is the process that the decoder produces at each step in the decoding process?",
            "What happens at each step of the decoding process?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen52-slide43/text.txt": [
            "What is the method used for decoding in the given text?",
            "What is the process for decoding at each time step according to the given instructions?",
            "What is the method used to determine the next word in the decoding process?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen53-slide45/text.txt": [
            "What type of decoding method is described in the text as being memory efficient and able to produce reasonable results for neural networks?",
            "What type of decoding method is described in the text as being memory efficient and producing reasonable results for neural networks?",
            "What is the main advantage of using greedy decoding in neural networks?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen54-slide46/text.txt": [
            "What is the main difference between beam search and greedy decoding in the context of a neural network's decoding process?",
            "What is the main difference between beam search and greedy decoding in a neural network's decoding process?",
            "What is the main difference between beam search and greedy decoding in the context of neural network decoding?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen55-slide47/text.txt": [
            "What is a hypothesis in the context of the given text?",
            "What is a hypothesis in the context described?",
            "What is a hypothesis in the context of the given text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen56-slide48/text.txt": [
            "What is a potential drawback of using beam search with neural networks for language generation?",
            "What is the primary limitation of using recurrent language models with neural networks in terms of producing accurate sentences?",
            "What is a consequence of using a beam search with a large beam size in neural networks for language translation?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen57-slide49/text.txt": [
            "What happens to the score of the prefix when you compute the score of the extended hypothesis in beam search?",
            "What is the result of multiplying the score of the prefix with the probability of the next word in the beam search algorithm?",
            "What happens to the score of the prefix when a new word is added to the hypothesis in beam search?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen58-slide50/text.txt": [
            "What is the relationship between the number of words in a hypothesis and its overall score?",
            "What is the relationship between the length of a hypothesis and the overall score in the context described?",
            "What is the relationship between the length of a hypothesis and the overall score in this multiplication?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen59-slide51/text.txt": [
            "What is the starting point for the beam search algorithm?",
            "What is the starting point for the beam search algorithm?",
            "What is the initial state of the beam search algorithm?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen60-slide53/text.txt": [
            "What are the candidate hypotheses generated in each step of the beam search process?",
            "What happens to the hypotheses in the beam at each step?",
            "What are the candidate hypotheses generated in each step of the beam?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen61-slide55/text.txt": [
            "What is the purpose of preserving only k candidates in a set of candidates in the next step of a candidate hypothesis evaluation process?",
            "What is the purpose of preserving only k candidates in a candidate hypothesis by their score?",
            "What is the purpose of preserving only k candidates in the next step of a candidate hypothesis by their score?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen62-slide56/text.txt": [
            "What happens to a hypothesis when it reaches the end of a sentence?",
            "What happens to a hypothesis if it reaches the end of a sentence symbol?",
            "What happens to a hypothesis that reaches the end of a sentence symbol?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen63-slide57/text.txt": [
            "What are the two conditions that you stop searching for hypotheses in a beam?",
            "What is the condition for stopping the process in the given text?",
            "What is the condition for stopping the process of generating hypotheses?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen64-slide58/text.txt": [
            "What is the method used to select the best hypothesis in a phrase-based approach?",
            "What approach is being referred to when the hypothesis is sorted by score?",
            "What approach involves sorting the hypothesis by the score and emitting the best one?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen65-slide59/text.txt": [
            "What changes need to be made to the network structure to maintain its performance with longer sentences?",
            "What approach did the authors find worked well for short sentences but showed a significant decline in quality for longer sentences?",
            "What changes are needed to the network structure to maintain its performance for longer sentences?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen66-slide60/text.txt": [
            "What is the primary goal of the attention mechanism in a neural network?",
            "What is the primary goal of the attention mechanism in a neural network?",
            "What is the primary goal of the attention mechanism in a neural network?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen71-slide40/text.txt": [
            "What approach was used in early implementations to improve the decoder's performance by making the input sentence more salient in the sentence representation?",
            "What approach was used in early implementations to help the decoder produce a more accurate representation of the input sentence, but ultimately still resulted in issues with fabulation?",
            "What approach was used in early implementations to help the decoder produce a better representation of the input sentence?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen76-slide60/text.txt": [
            "What is the purpose of using the decoder to represent target sentence dependencies in the attention mechanism?",
            "What is the purpose of the decoder in the attention mechanism described in the text?",
            "What is the primary purpose of the attention mechanism in the given text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen77-slide61/text.txt": [
            "What is the role of the read heads in the system being described?",
            "What type of machines are Neural Turing machines vaguely inspired by?",
            "What is the role of read heads in the memory of a Neural Turing machine?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen78-slide62/text.txt": [
            "How can the memory of a neural Turing machine be addressed or used to be addressed?",
            "How can the memory of the neural Turing machine be addressed or used to be addressed?",
            "How can the memory of a neural Turing machine be addressed or used to be addressed?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen79-slide63/text.txt": [
            "What is at the heart of attention according to the new Turing machines?",
            "What is at the heart of attention according to the new Turing machines?",
            "What is at the heart of attention according to the new Turing machines?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen80-slide64/text.txt": [
            "What is the basis of the addressing method described in the text?",
            "What type of addressing is described in the text as \"work quite well\"?",
            "What is the content-based addressing method being discussed?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen81-slide66/text.txt": [
            "What is the primary function of the attention mechanism in the decoder of a bidirectional recurrent neural network?",
            "What is the primary purpose of the attention mechanism in a bidirectional recurrent neural network, and how does it differ from other methods for condensing variable-length input sequences?",
            "What is the primary function of the attention mechanism in the decoder of a bidirectional recurrent neural network?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen82-slide67/text.txt": [
            "What is the purpose of normalizing the attention energies so that they sum to one?",
            "What is the purpose of normalizing the attention energies in the attention mechanism?",
            "What is the purpose of normalizing the attention energies so that they sum to one?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen83-slide68/text.txt": [
            "How is the output of the encoder used differently in the encoder-decoder approach with an attention mechanism?",
            "What is the main difference between the decoder in the encoder-decoder approach with attention mechanism and the standard decoder?",
            "How is the output of the encoder used differently in the encoder-decoder approach with the attention mechanism?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen84-slide67/text.txt": [
            "How many items are accessible at each time step?",
            "How many items are accessible at each time step?",
            "How many elements are accessible at each time step?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen85-slide68/text.txt": [
            "What is the purpose of scaling the context vectors with a matrix in the given network architecture?",
            "What is the purpose of scaling context vectors with a matrix in the given network architecture?",
            "What is the purpose of scaling the context vectors with a matrix in the given network architecture?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen86-slide69/text.txt": [
            "What type of alignment is the attention mechanism producing between the source and target languages according to the explanation provided?",
            "What is the primary influence on the decoder during the decoding process in the given model?",
            "What is the primary purpose of the attention mechanism in the given decoding process?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen88-slide72/text.txt": [
            "What are the differences mentioned in the text?",
            "What are the differences being referred to in the given TEXT?",
            "What are the differences mentioned in the text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen90-slide72/text.txt": [
            "What can be determined about the information provided based on the previous TEXT?",
            "What is the purpose of the provided TEXT?",
            "What is the purpose of the TEXT provided?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen91-slide73/text.txt": [
            "Is the alignment from SMT considered to be discrete?",
            "What type of distribution is being referred to in the context of positions?",
            "What type of distribution is described in the given text?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen92-slide74/text.txt": [
            "Is the statement described as declarative?",
            "What type of sentence is \"Here we can say that this is declarative, well, I don't know, whatever.\"?",
            "Is the text describing something as declarative?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen93-slide76/text.txt": [
            "What is the purpose of the provided TEXT in relation to the exam question?",
            "What is the purpose of the TEXT provided?",
            "What is the purpose of the provided TEXT?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen95-slide76/text.txt": [
            "How is the alignment in neural machine translation different from classical statistical machine translation?",
            "How does the language model differ from its role in classical pre-neural approaches to machine translation?",
            "How does the alignment in neural machine translation differ from the alignment in classical statistical machine translation?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen96-slide77/text.txt": [
            "What is the main difference between attentions in the encoder and decoder in the context of word alignment?",
            "What is the main difference between attentions and word alignments according to the provided explanation?",
            "What is the main difference between attentions in word alignment and attentions between the state of the encoder and the state of the decoder?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen97-slide78/text.txt": [
            "What type of attention mechanism did the neural network learn to use in the Juhl-MT system when it was pre-trained with a classical phrase-based system?",
            "What was the outcome of the neural network's training when it was given a double input consisting of the original source sentence and the pre-translation?",
            "What is the outcome when a neural network trained with a pre-translation from a classical phrase-based MT system is allowed to attend to both the source sentence and the pre-translation simultaneously?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen98-slide79/text.txt": [
            "What type of attention does the network learn to focus on when generating image captions?",
            "What type of attention does the network learn to attend to in image captioning?",
            "What is the effect of using a 2D attention mechanism in image captioning compared to a 1D attention mechanism?"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen99-slide81/text.txt": [
            "What is the main reason given for the seemingly poor performance of the attention mechanism when compared to a vanilla system?",
            "What is the main reason for the apparent poor performance of the attention mechanism when compared to a vanilla system?",
            "What is the main reason for the seemingly negative comparison of attention mechanisms to vanilla systems when comparing scores from two papers?"
        ],
        "testset/nmt-class/lecture06-morphology/screen01-slide01/text.txt": [
            "What is the topic of the next lecture in machine translation?",
            "What is the topic of the next lecture?",
            "What topic will be discussed in today's lecture on machine translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen02-slide02/text.txt": [
            "What type of machine translation will be discussed for solving the problems caused by rich morphology in Czech?",
            "What is the main reason why the speaker is focused on morphology, according to the text?",
            "What are the main problems caused by rich morphology in Czech language that need to be addressed in machine translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen03-slide03/text.txt": [
            "How does the syntax of a sentence in Czech differ from that in English, according to the information provided in the text?",
            "How does the syntax of a sentence in Czech differ from that in English, according to the information provided in the text?",
            "How does the syntax of a sentence in Czech differ from that of English, according to the information provided?"
        ],
        "testset/nmt-class/lecture06-morphology/screen04-slide04/text.txt": [
            "What is the term used to describe the rapid increase in the number of possible combinations when translating a sentence into Czech due to the complexities of the language's grammar and word forms?",
            "What is the main challenge when translating into Czech, according to the text?",
            "What is the term used to describe the rapid increase in the number of possible combinations when translating a sentence in Czech, taking into account word forms, meanings, and endings?"
        ],
        "testset/nmt-class/lecture06-morphology/screen05-slide05/text.txt": [
            "What is the difference between compounding and agglutination in word formation?",
            "What is the main difference between compounding and agglutination in word formation?",
            "What is the difference between agglutination and compounding in word formation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen06-slide06/text.txt": [
            "What is a limitation of using the BLEU score for evaluating machine translation in morphologically rich languages?",
            "What is the main issue with using the BLEU score for machine translation evaluation in morphologically rich languages?",
            "What is the main issue with using the BLEU score for machine translation in morphologically rich languages?"
        ],
        "testset/nmt-class/lecture06-morphology/screen07-slide07/text.txt": [
            "How do we handle morphology in phrase-based machine translation?",
            "How do we handle morphology in phrase-based machine translation?",
            "How do we handle morphology in phrase-based machine translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen08-slide08/text.txt": [
            "What are the two major components of phrase-based systems, according to the text?",
            "What are the two major components of phrase-based systems, according to the text?",
            "What are the two major components of phrase-based systems?"
        ],
        "testset/nmt-class/lecture06-morphology/screen09-slide09/text.txt": [
            "What type of data is needed for the language model to be able to choose between two correct but different word forms in a sentence?",
            "What type of word forms should be used to translate the sentence \"I saw two green striped cats\" into Czech?",
            "What type of word forms would be used to translate the phrase \"I saw two green striped cats\" into Czech?"
        ],
        "testset/nmt-class/lecture06-morphology/screen10-slide10/text.txt": [
            "What is the morphological ambiguity in the phrase \"dve zelené pruchované kočky\"?",
            "What are the two possible translations of the phrase \"dva zelené pruhovány kočky\" according to the morphological text?",
            "What is the case of the word \"kočká\" in the morphological text \"dva zelená pruhovány kočká\"?"
        ],
        "testset/nmt-class/lecture06-morphology/screen11-slide11/text.txt": [
            "What is the advantage of using morphological text in language models, specifically in terms of vocabulary size and the ability to use longer engrams?",
            "What is the advantage of using a language model based on morphological text in a machine translation system, according to the provided text?",
            "What is the advantage of using a morphological language model based on morphological text compared to a language model based on word forms?"
        ],
        "testset/nmt-class/lecture06-morphology/screen12-slide12/text.txt": [
            "What is the minimum amount of data required to propose the translation \"Češkami\" in the Czech language?",
            "What is the main problem with using rich morphology in language models for translation tasks?",
            "What is the primary issue with using rich morphology in a translation model, and how does it relate to the amount of data required for accurate translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen13-slide13/text.txt": [
            "What is the benefit of using a generation step in the factored phrase-based model that can be trained independently of parallel data?",
            "What is the benefit of using a generation step in the factored phrase-based model that cannot be extracted from parallel data?",
            "What is the benefit of using a morphological module or generation step in the factored phrase-based model?"
        ],
        "testset/nmt-class/lecture06-morphology/screen14-slide14/text.txt": [
            "What is the role of the target side language model in the proposed factor phrase-based machine translation approach?",
            "What is the role of the target side language model in ensuring the coherence in the sequence of words in the proposed factor phrase based machine translation system?",
            "What type of language model is applied to the morphological tags in the factor phrase-based MT system?"
        ],
        "testset/nmt-class/lecture06-morphology/screen15-slide15/text.txt": [
            "What is the purpose of the generation step in the process of translating words from the source language to the target language?",
            "What is the purpose of the generation step in the proposed system for translating words from one language to another?",
            "What is the primary goal of the sequence of translation and generation steps in the system described in the text?"
        ],
        "testset/nmt-class/lecture06-morphology/screen16-slide16/text.txt": [
            "What type of features will be considered in the scoring of the final translation, and how will they be weighted?",
            "What is the primary procedure used for the mapping steps in factored phrase-based empty modal?",
            "What is the primary structure that factored phrase-based empty modal extends from?"
        ],
        "testset/nmt-class/lecture06-morphology/screen17-slide17/text.txt": [
            "What is phrase-based MT based on, according to the given text?",
            "What is the basis of phrase-based machine translation according to the text?",
            "What is the basis for phrase-based machine translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen18-slide18/text.txt": [
            "What can be inferred about the translation of \"naturally John\" using morphological or part of speech text?",
            "What is the difference in meaning between \"naturally John\" and \"naturally John has\" according to the provided text?",
            "What is the meaning of \"naturally John\" based on the provided text?"
        ],
        "testset/nmt-class/lecture06-morphology/screen19-slide19/text.txt": [
            "What are the two main differences in the order of a sentence between German and English?",
            "What is the general approach of the system in analyzing sentence structure based on part of speech?",
            "What is the typical order of a sentence in German when it starts with an adverb?"
        ],
        "testset/nmt-class/lecture06-morphology/screen20-slide20/text.txt": [
            "What is the grammatical case used to refer to a 'black dog' in the given sentence?",
            "What is the grammatical case of the noun'mu' in the sentence 'Černé mu psovi'?",
            "What is the grammatical case used for the noun \"mu\" in the sentence \"Černé mu psovi\"?"
        ],
        "testset/nmt-class/lecture06-morphology/screen21-slide21/text.txt": [
            "What would happen if you break the database that contains the fully inflected word forms?",
            "What happens if you break the inflected word forms in the database?",
            "What would you do if you broke the database that contains the fully inflected word forms?"
        ],
        "testset/nmt-class/lecture06-morphology/screen22-slide22/text.txt": [
            "What steps were suggested in the previous text for extracting separate phrases and tables?",
            "What steps were suggested in the previous text for extracting separate phrases and tables?",
            "What type of steps are suggested for extracting separate phrases and tables in the given text?"
        ],
        "testset/nmt-class/lecture06-morphology/screen23-slide23/text.txt": [
            "What are the two forms that can be translated to the sequence of an adjective and noun in English, according to the provided text?",
            "What is the benefit of translating accusative or dative to the sequence of an adjective and noun in English?",
            "What is the benefit of translating accusative or dative to the sequence of an adjective and noun in English?"
        ],
        "testset/nmt-class/lecture06-morphology/screen24-slide24/text.txt": [
            "What type of increased robustness can be gained by using a combination of lemmas and morphological text together in the model?",
            "What type of increased robustness have you gained by using a combination of lemmas and morphological text in your model?",
            "What is the benefit gained by combining lemmas and morphological text from parallel data?"
        ],
        "testset/nmt-class/lecture06-morphology/screen25-slide25/text.txt": [
            "What is the source of the slides being discussed in the text?",
            "What is the source of the slides being presented?",
            "What is the source of the slides being discussed?"
        ],
        "testset/nmt-class/lecture06-morphology/screen26-slide26/text.txt": [
            "What is the process of translating phrase-based machine translation with the given input sequence of words?",
            "What is the process of translating phrase-based machine translation when given an input sequence of words?",
            "What is the process of phrase translation considered in phrase-based machine translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen27-slide27/text.txt": [
            "What do you use when searching for something according to the given text?",
            "What do you use that you search for in the search?",
            "What is the basis for selecting the best option?"
        ],
        "testset/nmt-class/lecture06-morphology/screen29-slide30/text.txt": [
            "What is the starting point for further development in the given context?",
            "What is the starting point for a hypothesis?",
            "What is the starting point for the process being described?"
        ],
        "testset/nmt-class/lecture06-morphology/screen30-slide31/text.txt": [
            "What is the process described in the given text?",
            "What process involves covering words from the source and appending the current hypothesis with the words in the target?",
            "What is the process described in the given text for adding new words to the current hypothesis?"
        ],
        "testset/nmt-class/lecture06-morphology/screen31-slide33/text.txt": [
            "What will be the final choice based on the information given?",
            "What will be the final choice based on the given criteria?",
            "What will be the final choice based on the path that covers everything?"
        ],
        "testset/nmt-class/lecture06-morphology/screen32-slide34/text.txt": [
            "What is the process of generating the surface form of the target site in factored decoding?",
            "What is the process for generating the surface form of the target site in factored decoding, according to the given explanation?",
            "What is the process of creating the translation options in factored decoding, according to the given explanation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen33-slide35/text.txt": [
            "What is different in the construction of translation options in the new system compared to the old one?",
            "What is the main difference between the way translation options are constructed before and after the pre-computation of processing steps?",
            "What is the main difference in how translation options are constructed in the new system compared to the previous system?"
        ],
        "testset/nmt-class/lecture06-morphology/screen34-slide36/text.txt": [
            "What are the potential consequences if the pruning limits are exceeded in the process of generating translation options?",
            "What are the potential consequences if the memory complexity of the system grows too far beyond the pruning limits?",
            "What is the result of not pruning the translation options in the system?"
        ],
        "testset/nmt-class/lecture06-morphology/screen35-slide38/text.txt": [
            "What is the main problem of phrase-based empty models that this setup aims to address?",
            "What is the main problem that phrase-based empty models face when it comes to understanding sentences?",
            "What is the main problem of phrase-based empty taggers that the proposed approach attempts to address?"
        ],
        "testset/nmt-class/lecture06-morphology/screen36-slide39/text.txt": [
            "What is the primary reason why a machine translation model may not show a significant increase in BLEU score when tested on English-German or German-English pairs?",
            "Does the BLEU score increase significantly when a system is tested on English-German or German-English translations?",
            "Does the BLEU score increase significantly when a machine translation is tested on English-German or German-English?"
        ],
        "testset/nmt-class/lecture06-morphology/screen37-slide40/text.txt": [
            "What type of sequence should a language model over the morphological analyzer avoid, according to the given information?",
            "What is the grammatically correct sequence of a determiner and a noun according to the language model?",
            "What should a language model over the morphologicalales remove from a sequence of a determiner in singular followed by a noun in plural?"
        ],
        "testset/nmt-class/lecture06-morphology/screen38-slide41/text.txt": [
            "What type of translation process is being suggested as \"linguistically motivating\" according to the text?",
            "What is the proposed approach for translating lemmas to lemmas, based on the example of translating \"kneecap\" into Czech?",
            "Is the proposed approach of translating lemmas to lemmas, followed by part of speech tech, and then morphology, linguistically motivating?"
        ],
        "testset/nmt-class/lecture06-morphology/screen39-slide42/text.txt": [
            "How can the introduction of additional independence assumptions in morphological generation models lead to a decrease in translation quality?",
            "What is the likely reason for the drop in BLEU score after introducing additional independence assumptions in the morphological generation model?",
            "What is the main reason for the decrease in translation quality when introducing additional independence assumptions in morphological generation models?"
        ],
        "testset/nmt-class/lecture06-morphology/screen40-slide43/text.txt": [
            "What is the purpose of the'minimum error rate training' in the alternative decoding paths solution?",
            "What is the main goal of combining two models to operate at once in the alternative decoding paths solution?",
            "What is the name of the solution described in the text, which combines two models to operate at once?"
        ],
        "testset/nmt-class/lecture06-morphology/screen41-slide44/text.txt": [
            "What improvement can be expected if both paths are taken?",
            "What improvement is being referred to in the text that is greater than the baseline?",
            "What improvement can be achieved by following both paths?"
        ],
        "testset/nmt-class/lecture06-morphology/screen42-slide45/text.txt": [
            "What type of information may need to be extracted from the source side when translating from Chinese to English?",
            "What are some examples of situations where additional information needs to be extracted monolingually from the source side during translation?",
            "What are some examples of language pairs for which additional information may need to be extracted from the source side alone during translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen43-slide46/text.txt": [
            "What type of case in Greek should a particle noun serve as if it serves as the subject or object in a sentence?",
            "What type of information is used to determine whether a particle noun should be translated as nominative or accusative in the target language?",
            "What type of case in Greek is typically assigned to an object in a sentence, according to the provided translation table?"
        ],
        "testset/nmt-class/lecture06-morphology/screen44-slide47/text.txt": [
            "What is the purpose of traversing the tree in parsing a source sentence?",
            "How does knowing a word's position in the tree help determine its case?",
            "What information can be inferred about the case of a word based on its position in the tree?"
        ],
        "testset/nmt-class/lecture06-morphology/screen45-slide48/text.txt": [
            "What is the main benefit of using explicitly available linguistic information on the source side in the prediction process?",
            "What is the outcome of using explicitly available linguistic information on the source side in the context described?",
            "What is the outcome of using explicitly available linguistic information on the source side for prediction?"
        ],
        "testset/nmt-class/lecture06-morphology/screen46-slide49/text.txt": [
            "What is the primary benefit of applying a second language model in the \"translate and Czech\" setup compared to the vanilla setup?",
            "What is the benefit of applying a second language model in the \"translate and Czech\" setup compared to the vanilla setup?",
            "What are the three language models used in the Czech translation setup to check the coherence of the translated text?"
        ],
        "testset/nmt-class/lecture06-morphology/screen47-slide50/text.txt": [
            "What is the effect on the number of translation options when morphological tags are introduced into the tagging process on the fly?",
            "What is the trade-off involved in adding morphological tags to the tagging process, and how does it affect the language model's ability to select the correct translation option?",
            "What is the potential consequence if the trade-off between adding morphological tags to the tagging process and the resulting increase in search complexity is not well balanced?"
        ],
        "testset/nmt-class/lecture06-morphology/screen48-slide51/text.txt": [
            "What was the best result achieved in terms of translation quality in 2009?",
            "What was the best setup for translation in 2009, according to the results?",
            "What was the best translation setup in 2009, according to the results?"
        ],
        "testset/nmt-class/lecture06-morphology/screen49-slide52/text.txt": [
            "What happens when pruning limits are too strict in the factorized models, according to the explanation provided?",
            "What is the main reason why the factored models failed in the translation process?",
            "What happens to some of the translation options if the pruning limits are too strict in the synchronous factored models?"
        ],
        "testset/nmt-class/lecture06-morphology/screen50-slide53/text.txt": [
            "What was the name of the language model that was based on four grams and was trained on a large amount of data, including almost four gigabytes of Czech texts?",
            "What was the best setup used in the speaker's system in the last years of phrase-based MT, according to the BLEU score results?",
            "What is the optimal setup for phrase-based machine translation, according to the author's experience with the author's best system in the last years of phrase-based MT?"
        ],
        "testset/nmt-class/lecture06-morphology/screen51-slide54/text.txt": [
            "What are the two techniques mentioned for handling sparseness in search results without causing an explosion?",
            "What are the two techniques mentioned in the text that aim to handle sparseness in search while avoiding the explosion?",
            "What are the two techniques that try to handle the sparseness in the pruning process without leading to an explosion?"
        ],
        "testset/nmt-class/lecture06-morphology/screen52-slide55/text.txt": [
            "What is the main goal of the proposed two-step system for translating English into lemmatized Czech, and what is the limitation of the second step in this system?",
            "What is the main goal of the proposed two-step system for translating English into Czech?",
            "What is the main goal of the two-step system described in the text for translating from English into lemmatized Czech?"
        ],
        "testset/nmt-class/lecture06-morphology/screen53-slide56/text.txt": [
            "What are the two metrics that showed improvement from the vanilla setup to the two-step setup in the experiment?",
            "What two metrics did the authors find improved from a vanilla setup to a two-step setup in their experiment?",
            "What two metrics, BLEUCore and Semantic POS, improved when applying the two-step setup to a small parallel and small monolingual corpus?"
        ],
        "testset/nmt-class/lecture06-morphology/screen54-slide57/text.txt": [
            "What is the BLEU score's sensitivity to the number of words dropped in the Czech translation?",
            "What is the BLEU score's sensitivity towards dropped words in the Czech four-gram setup?",
            "What is the BLEU score's sensitivity to dropped words in the context of machine translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen55-slide58/text.txt": [
            "What does the phrase \"shooting yourself in the foot\" mean in the given context?",
            "What is the consequence of making certain assumptions?",
            "What is being assumed in the situation described in the text?"
        ],
        "testset/nmt-class/lecture06-morphology/screen56-slide59/text.txt": [
            "Was the two-step setup preferred by both annotators in the manual evaluation?",
            "Was the two-step setup preferred by the annotators, and if so, did they agree on its benefits?",
            "Was the two-step setup found to be worthwhile based on the manual evaluation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen57-slide60/text.txt": [
            "What is the purpose of using a small parallel corpus in the reverse self-training process for phrase-based machine translation?",
            "What is the purpose of the reverse self-training technique in the context of phrase-based machine translation?",
            "What are the clever techniques used to train a language model in order to select the good combination of word forms?"
        ],
        "testset/nmt-class/lecture06-morphology/screen58-slide61/text.txt": [
            "How would translating the phrase directly into English help in creating a useful source English for the phrase \"kočce\"?",
            "What would happen if the translator directly translated the phrase \"I read about kočce\" without any prior knowledge of its meaning?",
            "What would happen if you translated the given phrase directly without considering the context of the small parallel data available?"
        ],
        "testset/nmt-class/lecture06-morphology/screen59-slide63/text.txt": [
            "Will a reverse translation system trained on Czech be able to translate the form \"kočce\" to English?",
            "What is the purpose of a reverse translation system in Czech?",
            "What type of system will be trained to back off and rely on lemmas in English translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen60-slide64/text.txt": [
            "What is the text about?",
            "What is the text that the speaker is including in their parallel data?",
            "What does the phrase \"Chetlsem okočce\" mean in the given context?"
        ],
        "testset/nmt-class/lecture06-morphology/screen61-slide65/text.txt": [
            "What is the benefit of extending a language model to learn new forms of noun words?",
            "What type of benefit do you get when your language model is able to learn and appreciate new forms of noun words?",
            "What is the purpose of extending the translation model to learn new forms of a noun word like \"okotse\"?"
        ],
        "testset/nmt-class/lecture06-morphology/screen62-slide66/text.txt": [
            "What approach should be used for reverse translation steps in language models that involve morphologically poorer languages, such as English?",
            "What type of linguistic expertise would be required for translating Czech into another language such as Turkish compared to English?",
            "What type of linguistic expertise is required for translation into languages with richer morphology compared to English?"
        ],
        "testset/nmt-class/lecture06-morphology/screen63-slide67/text.txt": [
            "What is the effect of growing monolingual data on the BLEU scores of a translation model?",
            "What is the effect on BLEU scores when monolingual data grows, according to the given information?",
            "What is the effect on BLEU scores when monolingual data grows?"
        ],
        "testset/nmt-class/lecture06-morphology/screen64-slide68/text.txt": [
            "What is the benefit of including all the word forms from monolingual data in a translation model using the reverse translation trick?",
            "What is the benefit of including all word forms from monolingual data in a translation model using reverse translation trick?",
            "What is the benefit of including all word forms from monolingual data in a translation model using the reverse translation trick?"
        ],
        "testset/nmt-class/lecture06-morphology/screen65-slide69/text.txt": [
            "At what point does the approach of using reverse translation tricks become less beneficial?",
            "At what point does the approach of using reverse translation become less beneficial?",
            "At what point does the reverse translation trick lose its benefit in terms of collecting parallel data?"
        ],
        "testset/nmt-class/lecture06-morphology/screen66-slide70/text.txt": [
            "What is the topic of the discussion in the provided text?",
            "What is the topic of the discussion in the given text?",
            "What is the topic of the passage that is being discussed in the context of neural machine translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen67-slide71/text.txt": [
            "What is the main limitation of neural machine translation in terms of the number of word forms it can handle?",
            "What is the main limitation of the word forms that can be stored in neural machine translation embedding tables?",
            "What limitations do neural machine translation systems face when dealing with words that have a large number of morphological variations, such as compound words?"
        ],
        "testset/nmt-class/lecture06-morphology/screen68-slide72/text.txt": [
            "What is the primary goal of constructing a dictionary of frequent words or character pairs in the context of tokenization?",
            "What is the primary method used to construct a fixed-size dictionary of frequent words and character pairs?",
            "What is the primary method used to construct the dictionary in the given text?"
        ],
        "testset/nmt-class/lecture06-morphology/screen69-slide73/text.txt": [
            "What happens when each word in the vocabulary is seen exactly once in the corpus?",
            "What type of data is the vocabulary described as, given that it includes frequencies of words?",
            "What happens to character pairs that are not seen in the corpus during the merge operation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen70-slide74/text.txt": [
            "What is the new unit introduced to the vocabulary in the example?",
            "What is the new unit introduced to the vocabulary in the given example?",
            "What is the new unit introduced to the vocabulary in the example?"
        ],
        "testset/nmt-class/lecture06-morphology/screen71-slide75/text.txt": [
            "What is the process of scanning for the most frequent pair of characters in a corpus after replacing a pair of characters with a single new letter?",
            "What is the result of replacing a pair of characters in a corpus with a single new letter?",
            "What is the new letter used to replace a pair of characters in the corpus?"
        ],
        "testset/nmt-class/lecture06-morphology/screen72-slide76/text.txt": [
            "What type of operation is introduced in the setup to treat V, E, R as a single unit for text compression?",
            "What is the most frequent pair of letters in the text that is being merged into a single unit?",
            "What is the new merge operation that is introduced to help with the compression of the text being trained on?"
        ],
        "testset/nmt-class/lecture06-morphology/screen73-slide77/text.txt": [
            "What is the next merge likely to be?",
            "What is the speaker's attitude towards the next merge?",
            "What is the expected outcome of the next merge?"
        ],
        "testset/nmt-class/lecture06-morphology/screen74-slide78/text.txt": [
            "What is the relationship between the words \"This\" and \"ST\" in the given text?",
            "What type of character does the single character ST refer to?",
            "What is the relationship between the words \"this\" in the given sentences?"
        ],
        "testset/nmt-class/lecture06-morphology/screen75-slide79/text.txt": [
            "What is the main advantage of using neural subword units in machine translation systems compared to phrase-based models?",
            "What is the primary difference between phrase-based encoding and neural encoding in the context of machine translation?",
            "What is the main advantage of neural empty over phrase-based empty in the context of machine translation?"
        ],
        "testset/nmt-class/lecture06-morphology/screen76-slide80/text.txt": [
            "What is the effect of adding underscores before processing a corpus with Byte Pair Encoding (BPE)?",
            "What is the main difference in how the sub-bord text encoder (STE) and Byte Pair Encoding (BPE) handle empty suffixes in words?",
            "What is the difference in how the sub-bord text encoder (STE) and Byte Pair Encoding (BPE) handle empty suffixes in words?"
        ],
        "testset/nmt-class/lecture06-morphology/screen77-slide81/text.txt": [
            "What effect did adding an underscore at the end of every word have on the BLEU score in the German-to-Czech experiments?",
            "What technique was found to be the best for improving BLEU score in German-to-Czech language pair experiments?",
            "What was the best technique found for improving the BLEU score in the German-to-Czech language pair experiments?"
        ],
        "testset/nmt-class/lecture06-morphology/screen78-slide82/text.txt": [
            "What was found to work best in the German to Czech setups for linguistic segmentation of words?",
            "What was found to be the most effective method for word segmentation in the German to Czech setups?",
            "What was found to work best in the German to Czech setups in terms of text segmentation?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen01-slide02/text.txt": [
            "What type of machine translation is the focus of this lecture?",
            "What is the topic of this lecture?",
            "What is the topic of the fifth lecture on machine translation?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen02-slide03/text.txt": [
            "What is the main topic of the talk that will be covered in the lecture on phrase-based machine translation?",
            "What is the main focus of the lecture on phrase-based machine translation, according to the speaker?",
            "What is the main focus of the decoding part of the lecture, according to the speaker?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen03-slide04/text.txt": [
            "What is the primary function of Phrasebase MT in translating new input sentences?",
            "What is the primary difference between the translation dictionary used by Phrasebase MT and a normal translation dictionary for humans?",
            "What is the main difference between the translation dictionary used in Phrasebase MT and a normal translation dictionary for humans?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen04-slide05/text.txt": [
            "What is the purpose of running the probability estimate within the argmax in the log linear model?",
            "What is the purpose of the weighted sum in the log linear model when generating the output option?",
            "What is the purpose of running the probability estimate within the argmax in the log linear model?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen05-slide06/text.txt": [
            "What is the role of the segmentation in the phrase-based model of Machine Translation Evaluation (MTE)?",
            "What is the role of the segmentation in the phrase-based machine translation (MTE) model?",
            "What is the significance of the segmentation in the phrase-based machine translation model?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen06-slide07/text.txt": [
            "What is the primary function of the phrase translation probability feature in phrase-based MT systems?",
            "What is the primary function of the phrase translation probability feature in phrase-based MT systems?",
            "What is the purpose of the phrase translation probability feature in phrase-based MT, and how does it relate to the segmentation of the input sentence?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen07-slide08/text.txt": [
            "What are the steps involved in finding parallel texts in the phrase-based machine translation system?",
            "What are the steps involved in training a phrase-based machine translation system, according to the given text?",
            "What are the steps involved in the training of a phrase-based machine translation system, according to the described pipeline approach?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen08-slide09/text.txt": [
            "What is the purpose of dividing the count of co-occurrences by the count of the source phrase alone in phrase-based machine translation?",
            "What is the purpose of dividing the count of co-occurrences by the count of the source phrase alone in phrase-based machine translation?",
            "What is the method used to estimate the probabilities of the most important feature in phrase-based machine translation, according to the text?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen09-slide10/text.txt": [
            "What is the purpose of the consistency with word alignment in the phrase table extraction process?",
            "What is the significance of the consistency with word alignment in the phrase table extraction process?",
            "What is the role of word alignment in the extraction of consistent phrases in the phrase table?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen10-slide09/text.txt": [
            "What are the two types of scores mentioned in the phrase translation probabilities?",
            "What are the two types of scores mentioned in the phrase translation probabilities?",
            "What is the purpose of dividing co-occurrence counts by either the count of the source phrase or the count of the target phrase in phrase translation probabilities?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen11-slide10/text.txt": [
            "What is the effect of lexical weighting on phrase translation when a phrase consists of multiple word units?",
            "What is the purpose of using lexical weighting in phrase translation when dealing with multi-word expressions?",
            "What is the effect of lexical weighting on phrase translation when dealing with multi-word expressions like \"faster and full stop\"?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen12-slide11/text.txt": [
            "What is the purpose of dividing phrase counts by 2 when performing the maximum likelihood estimate?",
            "What is the purpose of dividing the phrase counts by two in the maximum likelihood estimate?",
            "What is the significance of the phrase penalty in the standard decoder, specifically in the Moses decoder?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen13-slide12/text.txt": [
            "What is the process of selecting puzzle pieces to cover the input sentence in the phrase-based translation system?",
            "How does the phrase-based system select the applicable phrases for a given sentence in the first phase of translation?",
            "How does the phrase-based system determine the applicable phrases for a given sentence in the first phase of translation?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen14-slide13/text.txt": [
            "What are some possible translations for the phrase \"Er get\" from the given sentence?",
            "What is the process the system uses to select the best translation for the input sentence \"Er get Janik na Hause\"?",
            "What is the best choice for translating the sentence \"Er get Janik na Hause\" according to the phrase table?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen15-slide14/text.txt": [
            "What is the second stage of the translation process described in the text?",
            "What is the name of the second stage of the translation process mentioned in the given text?",
            "What is the second stage of the translation process according to the text?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen16-slide15/text.txt": [
            "What is the coverage vector in this context?",
            "What is the coverage vector in this scenario?",
            "What is the coverage vector in the empty hypothesis state?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen17-slide16/text.txt": [
            "What is hypothesis expansion in the context of word translation?",
            "What is the term for expanding an initial hypothesis by translating the second word in the input?",
            "What is the term for expanding the initial hypothesis with the word that translates the second word in the input?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen18-slide17/text.txt": [
            "How many hypotheses cover different source words and produce different translations according to the initial hypothesis?",
            "How many hypotheses cover different source words and produce different translations?",
            "How many hypotheses cover different source words and produce different translations?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen19-slide18/text.txt": [
            "What is the outcome of the hypothesis after considering all possible orderings of phrases?",
            "What is the outcome of the process of expanding the hypothesis with the translation of the third word \"ja\"?",
            "What is the main goal of the expansion of hypothesis in the given context?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen20-slide19/text.txt": [
            "What is the final full output text of the target sentence, also known as the best scoring sentence?",
            "What is the purpose of the path through the search graph in the given context?",
            "What is the final full output text of the target sentence, according to the given explanation?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen21-slide18/text.txt": [
            "What does the speaker think is important to realize now?",
            "What does the speaker consider to be the current importance?",
            "What is the main point of the given text?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen22-slide19/text.txt": [
            "What is the number of hypotheses that the search space should consider?",
            "What is the scope of possible hypotheses when considering multiple translation options for each particle span, but also multiple spans?",
            "What is the main concern with the search space for possible hypotheses in this context?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen23-slide20/text.txt": [
            "What is the key assumption made in the proof of NP-hardness of machine translation?",
            "What is the main task that needs to be solved in order to prove the NP-hardness of machine translation?",
            "What is the general assumption made in the proof of NP-hardness of machine translation, and how is it used to prove the NP-hardness of machine translation?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen24-slide21/text.txt": [
            "What is the minimum set cover task related to, according to the given explanation?",
            "What is the relationship between the minimum set cover problem and the back optimization problem, as mentioned in the provided text?",
            "What is the minimum set cover problem, and how is it related to machine translation?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen25-slide22/text.txt": [
            "What topics will be discussed according to the slides by Barry Heddo?",
            "What are the three topics that Barry Heddo's slides will cover regarding complexity?",
            "What are the three topics to be discussed according to the slides by Barry Heddo?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen26-slide23/text.txt": [
            "What is the purpose of recombining partial hypotheses that cover the same set of input words and produce the same output in the search space reduction process?",
            "What is the purpose of the \"safe modification of the search space\" described in the text?",
            "What is the purpose of recombining two hypotheses that cover the same set of input words and produce the same output in the process of expanding the search space?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen27-slide24/text.txt": [
            "What is the effect on the scores of two hypotheses that have the same last two words when using a trigram language model?",
            "What type of language model is assumed to be used when combining two hypotheses with the same last two words?",
            "What type of language model is assumed to be used when combining hypotheses that have the same last two words?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen28-slide25/text.txt": [
            "What restrictions does the translation model impose on the reordering model?",
            "What are the conditions imposed by the language model on the reordering model?",
            "What are the conditions that impose restrictions on the reordering model?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen29-slide26/text.txt": [
            "What needs to be done before the search space is sufficient?",
            "What is the purpose of \"early pruning\" in the search space?",
            "What do we need to do to address the insufficient search space in the given context?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen30-slide25/text.txt": [
            "What is the purpose of the stack limit in the stack-based beam search algorithm for phrase-based machine translation?",
            "What is the main difference between a breadth-first search and the stack-based beam search used in phrase-based MT?",
            "What is the purpose of organizing partial hypotheses in a sequence of stacks in phrase-based machine translation?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen31-slide25/text.txt": [
            "What happens to the final stack at the end of the process?",
            "What happens to the final stack at the end of the process?",
            "What happens to the stack if it grows too big?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen32-slide25/text.txt": [
            "What are some common pruning strategies used in hypothesis stacking?",
            "What are the two different strategies for pruning hypotheses mentioned in the text?",
            "What are the two pruning strategies mentioned in the text for hypothesis selection?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen33-slide25/text.txt": [
            "What happens to the search complexity if the reordering is limited to expanding hypothesis only close to the currently translated one?",
            "If we limit the reordering, what is the expected complexity of the search?",
            "What is the complexity of the search algorithm if the reordering is limited and the translation options are expanded only close to the currently translated one?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen34-slide25/text.txt": [
            "What is the purpose of the additional score component considered in the hypothesis allocation process to address the unfairness in the initial scoring?",
            "What is the purpose of the additional score component considered in the partial hypothesis allocation process?",
            "What is the purpose of the additional score component considered in the hypothesis allocation process?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen35-slide25/text.txt": [
            "What type of model is considered in the text when estimating the future cost of translation?",
            "What is the nature of the future cost estimate in the context of the A star search?",
            "What is the basis of the future cost estimate for the translation process?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen36-slide25/text.txt": [
            "What is the nature of the algorithm used to estimate the future cost of translation, according to the text?",
            "What type of algorithm is used to estimate the future cost of translation, according to the given text?",
            "What type of algorithm is used to estimate the future cost in sentence translation?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen37-slide25/text.txt": [
            "What is the general rule about the cost of translating function words versus content words?",
            "What is the general cost of translating function words compared to content words?",
            "What is the general rule about the cost of translating function words compared to content words?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen38-slide25/text.txt": [
            "What is the effect of translating the hard words first, according to the future cost estimate?",
            "What is the purpose of the \"future cost estimate\" in the comparison between the two hypotheses?",
            "What is the purpose of the \"future cost estimate\" in the system's translation process?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen39-slide25/text.txt": [
            "What other decoding algorithms besides A-star surges and greedy hill climbing are mentioned as possible alternatives?",
            "What other decoding algorithms besides A-star surges and greedy hill climbing are mentioned as possible alternatives?",
            "What other decoding algorithms, besides A-star surges and greedy hill climbing, can be used for decoding?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen40-slide25/text.txt": [
            "What is the defining characteristic of an admissible heuristic in A-Star Search?",
            "What type of heuristic is described as \"optimistic\" and \"never overestimates the future cost\" in the context of the A-Star Search?",
            "What is the guarantee of the A-Star Search when using an admissible heuristic?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen41-slide25/text.txt": [
            "What does the speaker intend to do next?",
            "What can be completed using the information in the given text?",
            "What does the speaker intend to do based on the phrase \"Yep, so we can...\"?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen42-slide25/text.txt": [
            "What are the two types of feature functions used in phrase-based machine translation, and how do they differ in terms of their application and scope?",
            "What is the difference between local and non-local feature functions in phrase-based machine translation?",
            "What is the difference between local and non-local feature functions in phrase-based machine translation?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen43-slide25/text.txt": [
            "What is the main goal of the weight optimization process in the minimum error rate training for machine translation?",
            "What is the main goal of the \"minimum error rate training\" approach in machine translation, and how does it differ from other machine translation methods?",
            "What is the main difference between the internal score and the external score in the minimum error rate training approach?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen44-slide25/text.txt": [
            "What is the purpose of finding the \"good balance of weights\" in the beam search algorithm?",
            "What is the purpose of the phrase penalty in the phrase translation probability model?",
            "What is the effect of a high phrase penalty on the system's output?"
        ],
        "testset/nmt-class/lecture05-pbmt/screen45-slide25/text.txt": [
            "What is the primary advantage of using a phrase-based translation system for tasks like mapping sequences, compared to neural machine translation?",
            "What is a suitable use of phrase-based machine translation, according to the text?",
            "What is the primary limitation of the phrase-based MT system, according to the text?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen01-slide01/text.txt": [
            "What can be expected from the upcoming lectures on statistical machine translation?",
            "What type of lecture will today's lecture on statistical machine translation be, according to the instructor?",
            "What type of lecture can students expect in this second lecture on statistical machine translation?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen02-slide02/text.txt": [
            "What is the convention for referring to statistical machine translation when contrasted with neural machine translation?",
            "What is the conventional difference between the abbreviations SMT and NMT when referring to statistical machine translation?",
            "What is the conventional meaning of the abbreviation SMT when contrasted with NMT?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen03-slide13/text.txt": [
            "What was the main motivation behind the idea of the \"triangle of machine translation\" proposed by Professor Wokoa?",
            "What is the motivation behind using an interlingua in machine translation, and how does it compare to the direct approach?",
            "What is the motivation behind the idea of using an interlingua in machine translation, and how did it relate to the development of machine translation systems in the 1960s?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen04-slide04/text.txt": [
            "What is the main difference between the approach used in example-based machine translation and statistical machine translation, prior to the neural approach?",
            "What is the main difference between example-based machine translation and statistical machine translation?",
            "What is the main difference between example-based machine translation and statistical machine translation?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen05-slide05/text.txt": [
            "Who is the Czech guy mentioned in the text as having worked for IBM in the 80s and later at John Hopkins University?",
            "Who is the Czech guy mentioned in the text as having worked for IBM in the 80s and setting up the machine translation system of IBM?",
            "Who is the Czech guy mentioned in the text as having worked at IBM and John Hopkins University?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen06-slide06/text.txt": [
            "What type of model needs to be specified in machine translation to make it statistical in the information theoretic sense?",
            "What type of model is machine translation based on in the information theoretic sense?",
            "What is the role of linguistics in designing statistical models for machine translation?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen07-slide07/text.txt": [
            "What are the two types of data used to find minimum translation units in traditional statistical machine translation?",
            "What are the two types of data used in traditional statistical machine translation?",
            "What was the primary goal of traditional statistical machine translation before the advent of new MT approaches?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen08-slide08/text.txt": [
            "What is the critical formula used to define the probability of the target sentence given the source sentence in statistical machine translation?",
            "How do we define the probability of the target sentence given the source sentence in the task of statistical machine translation?",
            "How do we define the probability of the target sentence given the source sentence in the task of statistical machine translation?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen09-slide09/text.txt": [
            "What is the technical problem with the brute force machine translation approach when a sentence is translated to multiple possible translations?",
            "What is the technical problem with using a probability of 1 for a sentence that has been translated to multiple words?",
            "What is the technical problem with the brute force machine translation approach when a sentence is translated to multiple possible translations?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen10-slide10/text.txt": [
            "What is the issue with the probability distribution of the sentence pair system?",
            "What is the main problem with the current probability distribution in the given database?",
            "What is the issue with the probability distribution of the sentence pair table?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen11-slide11/text.txt": [
            "What is the purpose of applying Bayes' law to the given conditional probability in the formula?",
            "What is the main application of Bayes' law in the given context, and how does it simplify the conditional probability formula?",
            "What is the role of Bayes' law in simplifying the conditional probability formula for finding the most probable target sentence given a source sentence?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen12-slide12/text.txt": [
            "What is the main benefit of using a two-table approach in speech recognition systems, as opposed to a single table approach?",
            "What is the main benefit of using two tables instead of one in the noisy channel approach for speech recognition?",
            "What is the main benefit of training two tables instead of one in the noisy channel approach?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen13-slide13/text.txt": [
            "What are the two models derived from parallel text and monolingual text, and how are they used in the log-linear model?",
            "What are the two models derived from parallel text and monolingual text in the log-linear model?",
            "What type of text is used to derive the translation model for a log-linear model?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen14-slide14/text.txt": [
            "What is the standard approach to defining the probability of a sentence in an n-gram based language model?",
            "What is the standard approach to defining the probability of a sentence in an n-gram based language model?",
            "What is the purpose of breaking a sentence into smaller chunks, such as n-grams, in a language model?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen15-slide15/text.txt": [
            "What is the purpose of dividing the count of each trigram by the number of occurrences of the words at the beginning of the n-gram?",
            "What is the purpose of dividing the count of each trigram by the number of occurrences of the antecedent of the history?",
            "What is the basis for calculating the probability of a trigram in the given method?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen16-slide14/text.txt": [
            "Where does the probability of a sentence defined as a product of trigram probabilities break or struggle?",
            "What is a potential issue with defining the probability of a sentence as a product of trigram probabilities?",
            "What is the main issue with defining the probability of a sentence as a product of trigram probabilities?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen17-slide15/text.txt": [
            "What is the difference between backoff and interpolation in the context of smoothing methods?",
            "What is the main difference between the backoff approach and the interpolation approach in handling the smoothing of n-grams in language models?",
            "What is the difference between the backoff approach and the interpolation approach in handling smoothing in language modeling?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen18-slide16/text.txt": [
            "What was the technical problem that arose in using a swapped direction in the training of the translation model, despite violating the base law?",
            "What was the empirical observation made by the student of Hermann Ney in 2002 regarding the translation model that led to the suggestion of squaring the probability of the language model?",
            "What was the technical problem encountered when trying to incorporate the empirical observation of swapping the order of conditional probability in the formulas for machine translation?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen19-slide17/text.txt": [
            "What is the purpose of the normalization constant in the scoring process of the LoglingerModal framework?",
            "What is the main idea behind the LoglingerModal framework in modeling the probability of a target sentence given a source sentence?",
            "What is the main idea behind the LoglingerModal framework for modeling the probability of target sentences given source sentences?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen20-slide18/text.txt": [
            "What is the purpose of calculating the summation of all the points distributed across sentences in the given formula?",
            "What is the purpose of distributing points in the given context?",
            "What is the purpose of distributing points to define feature points in the given context?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen21-slide17/text.txt": [
            "What is the role of weights in the log-linear model, and how do they balance the mix of components in the model?",
            "What is the purpose of the log in front of the calculation in the log-linear framework for estimating the probability of the target candidate?",
            "What is the purpose of the weights in a log-linear model in the context of this text?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen22-slide18/text.txt": [
            "What is the purpose of normalizing the weights in the Logliner model?",
            "What is the purpose of normalizing the scores in the Logliner model?",
            "What is the purpose of normalizing the points in the Logliner model?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen23-slide19/text.txt": [
            "What happens to the logs of the probabilities when the two feature functions are plugged into the formula in the Logdiner modal approach?",
            "What type of feature function is used to square the probability of the language model according to the Logdiner modal approach?",
            "What type of feature function is used to square the probability of the language model according to the Logdiner modal approach?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen24-slide20/text.txt": [
            "What is the purpose of the word penalty or word count feature in phrase-based machine translation?",
            "What is the primary issue with using a language model defined as a product of n-grams when comparing longer and shorter sentences?",
            "What is the main difference between a language model defined as a product of n-grams and the language model used in the phrase-based machine translation model?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen25-slide21/text.txt": [
            "Can a language model be used to propose target sentences in a phrase-based machine translation system, and if so, how would that operation work?",
            "Can the use of language models to propose target sentences be a viable alternative to traditional phrase-based systems in phrase translation systems?",
            "Can the language model be used to propose target sentences in a phrase-based system, and if so, how would this operation work?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen26-slide22/text.txt": [
            "What is the main process referred to as \"tuning\" in the traditional pipeline for training classical statistical machine translation systems?",
            "What is the purpose of the \"tuning\" or \"training\" process in the traditional pipeline for training classical statistical machine translation systems?",
            "What is the purpose of the \"tuning\" or \"training\" process in the traditional pipeline for training classical statistical machine translation systems?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen27-slide23/text.txt": [
            "What type of translation system is being trained?",
            "What type of machine translation system is being trained from the given corpus?",
            "What type of machine translation system is being trained?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen28-slide24/text.txt": [
            "What is the method used to identify the meaning of Psa and Kočku based on co-occurrence statistics?",
            "What is the basis for automatically identifying the meaning of Psa and Kočku based on co-occurrence statistics?",
            "What is the method used to automatically identify the meaning of words like Psa and Kočku based on co-occurrence statistics?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen29-slide25/text.txt": [
            "What are the translations for the words \"Kočku\" and \"Videl\" according to the provided text?",
            "What are the translations of the words \"Kočku\" and \"Videl\" according to the provided text?",
            "What are the translations of the words \"Kočku\" and \"Videl\" according to the given text?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen30-slide26/text.txt": [
            "What language is the new input text in, given the translation \"I don't have a cat\"?",
            "What is the new input text that needs to be translated?",
            "What is the new input text to be translated?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen31-slide27/text.txt": [
            "What does the phrase \"which actually means I don't have a cat\" imply about the speaker's situation?",
            "What does the phrase \"... which actually means I don't have a cat\" imply about the speaker's current situation regarding a cat?",
            "What does the phrase \"... which actually means I don't have a cat...\" imply about the speaker's situation?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen32-slide28/text.txt": [
            "What is the first word of the given text?",
            "What is the first word of the given text?",
            "What is the first word of the given text?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen33-slide29/text.txt": [
            "What is the main problem of phrase-based systems according to the given text?",
            "What is the main problem of phrase-based systems according to the provided text?",
            "What is the main problem of phrase-based systems according to the given text?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen34-slide31/text.txt": [
            "What was the primary assumption that went wrong in the approach to translating phrases?",
            "What was the main issue with the approach used for translating phrases, according to the given explanation?",
            "What was the primary assumption that went wrong in the approach to translating phrases?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen35-slide30/text.txt": [
            "Why do the language module prefer to drop the negation in longer outputs?",
            "What is the general preference of the language module in terms of output length?",
            "What is the general preference of the language module when it comes to scoring outputs based on their length?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen36-slide31/text.txt": [
            "What are the two strong independence assumptions about the phrases related to the language model?",
            "What are the two strong independence assumptions about the phrases related to the language model?",
            "What are the two strong independence assumptions about the phrases in the language model?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen37-slide30/text.txt": [
            "What is the main issue that the author faced while trying to improve the translation precision and recall of their model?",
            "What is the author's main concern when it comes to using longer units in their translation model?",
            "What is the author's main concern when it comes to using longer units in machine translation?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen38-slide31/text.txt": [
            "What is the main problem with the base decomposition approach in the given formula?",
            "What is the main problem with the proposed approach in the given formula?",
            "What is the main problem with the proposed approach to translation units?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen39-slide32/text.txt": [
            "What technical device is needed to train the probability distribution of a sequential generation of a target sentence given a source sentence?",
            "What technical device is needed to train the probability distribution of the sequential generation of the target sentence in the new approach to statistical machine translation?",
            "What is the primary technical device needed to train the probability distribution for sequential generation of the target sentence in this new approach?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen40-slide33/text.txt": [
            "What is the maximum number of hidden layers required for a neural network to approximate an arbitrary function to arbitrary precision?",
            "Can a neural network with one hidden layer approximate an arbitrary function to arbitrary precision?",
            "Can a neural network with one hidden layer approximate an arbitrary function to arbitrary precision?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen41-slide34/text.txt": [
            "What is the role of the final neuron in the neural network that combines the outputs of the three hidden neurons?",
            "What is the purpose of the final neuron in the neural network that combines the outputs of the three hidden neurons?",
            "What happens to the weights in the neural network after the system runs for a while?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen42-slide35/text.txt": [
            "What is the condition under which the color will be blue according to the given equation?",
            "What color will be the result if the equation holds?",
            "What color is stated to be produced if the equation holds?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen43-slide36/text.txt": [
            "How many numbers are required to train the system automatically to separate points in the center from points on a circular?",
            "What is the minimum number of weights required to separate points in the center from points on a circular using the described system?",
            "What type of weights are needed to separate points in the center from points on a circular, according to this system?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen44-slide37/text.txt": [
            "What is the formula for the circle described in the text?",
            "What is the condition under which a hidden layer is not necessary in a neural network calculation?",
            "What is the formula for a circle in terms of x1 squared and x2 squared?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen45-slide38/text.txt": [
            "What type of linear combination can be used to separate the center from the circumference if the X and Y coordinates are linearly separable?",
            "What type of linear separation can neural networks achieve when the coordinates are transformed?",
            "What type of coordinates are considered \"unfortunate\" in the context of neural networks?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen46-slide39/text.txt": [
            "What happens when a network is too complex, has too many free parameters, and not enough training data?",
            "What happens to a network when it has too many free parameters and too little training data?",
            "What happens to a network when it has too many free parameters and not enough training data?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen47-slide40/text.txt": [
            "What type of separation boundaries do the neurons in the first hidden layer of the deep network draw, according to the text?",
            "How does the network automatically determine the number of lines required to approximate a simple shape?",
            "How does the deep network automatically determine the relevant distinguishing features for the final classification task?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen48-slide41/text.txt": [
            "What is the primary difference between a neural network and a traditional approach to representing a sentence as a sequence of words?",
            "What is the purpose of mapping each word to a vector of zeros and ones in the context of neural networks for text translation?",
            "What is the approach for representing a sentence with a sequence of words in a neural network?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen49-slide42/text.txt": [
            "What is the approximate number of Czech word forms in a matrix required to represent the language?",
            "How many Czech word forms are there in the matrix?",
            "How many elements does the matrix need to have for Czech language compared to English?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen50-slide43/text.txt": [
            "What is the issue with the one-hot representation of words in relation to their differences from each other?",
            "What is the problem with using one-hot representation for word relations in a model?",
            "What is the problem with the one-hot representation of words in language modeling?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen51-slide44/text.txt": [
            "What are the dimensions typically used for word embeddings in neural networks?",
            "What is the typical number of dimensions used in word embeddings?",
            "What are the dimensions typically used for word embeddings in neural networks?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen52-slide45/text.txt": [
            "What is the main idea behind using subword units in neural machine translation instead of translating words directly?",
            "What is the main goal of using subword units in neural machine translation, according to the text?",
            "What is the main issue with productive morphology in machine translation, according to the given text?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen53-slide46/text.txt": [
            "What is variable length?",
            "What is the nature of \"variable length\" in the given context?",
            "What type of data does the phrase \"variable length\" refer to in the given text?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen54-slide45/text.txt": [
            "What is the source of the problem with the sub-word \"migranti\" in the system?",
            "How does the system disambiguate words with multiple meanings in a sentence?",
            "What is the system's approach to disambiguating words with multiple meanings in a sentence?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen55-slide46/text.txt": [
            "What is the main challenge when training a neural network to handle variable length inputs?",
            "What is the main challenge when training a neural network to handle variable length inputs?",
            "What are some basic units of neural networks that can be used to avoid the problem of vanishing gradients when handling variable length inputs?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen56-slide47/text.txt": [
            "What innovation did Kyun Kun Cho introduce in the original phrase-based pipeline when using neural networks in machine translation?",
            "What innovation did Kyun Kun Cho introduce in the original phrase-based system when using neural networks for machine translation?",
            "When were neural networks first successfully used in machine translation?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen57-slide48/text.txt": [
            "What is the primary function of the matrix in the encoder state representation?",
            "What is the main difference between the log-link-near approach and the approach used by the team that applied the same approach to full sentences?",
            "What is the role of the matrix in the process of digesting the input sentence in the described approach?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen58-slide49/text.txt": [
            "What is the role of the recurrent decoder in the process of decoding individual words from a vector representation of a sentence?",
            "What is the role of the decoder in the process of generating a target sentence given a source sentence representation?",
            "What is the primary function of the decoder in the described system, and how does it differ from the language model being referred to?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen59-slide50/text.txt": [
            "How many parameters does the network have in this setting?",
            "How many parameters are in the network used for sentence classification?",
            "How many parameters are there in the network used for language translation?"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen60-slide51/text.txt": [
            "What is the main goal of neural machine translation compared to classical statistical machine translation?",
            "What is the main difference between the goal of classical statistical machine translation and neural machine translation?",
            "What are the two main goals of classical and neural machine translation approaches?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen01-slide01/text.txt": [
            "What type of machine translation approaches will be covered in today's lecture?",
            "What type of machine translation approaches will be covered in today's lecture?",
            "What type of machine translation approaches will be discussed in today's lecture?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen02-slide02/text.txt": [
            "What is the tectorochromatic layer in the Pragueian approach to machine translation?",
            "What is the name of the approach to machine translation that is \"dormant in the application area\" due to the growth of neural MT?",
            "What is the main goal of using grammar in machine translation, according to the lecturer?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen03-slide03/text.txt": [
            "What was the primary issue with phrase-based machine translation systems before Neural MT, in terms of grammatical coherence?",
            "What was the primary problem with phrase-based machine translation systems before Neural MT?",
            "What was the main problem with phrase-based machine translation systems in terms of grammatical coherence?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen04-slide04/text.txt": [
            "What type of model was the first one to try to solve some of the issues mentioned in the text?",
            "What type of model was the first one to try to solve some of the issues mentioned in the text?",
            "What type of model was the hierarchical model that tried to solve some of the issues mentioned?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen05-slide05/text.txt": [
            "What is the main limitation of the grammatical model mentioned in the text?",
            "What is a limitation of the grammatical structure model described in the text?",
            "What type of grammatical structure does the model in 2005 allow to be preserved in the target language, given a good input sentence?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen06-slide06/text.txt": [
            "What is the difference between phrase-based machine translation and the hierarchical model?",
            "What is the difference between phrase-based machine translation and the hierarchical model?",
            "What is the main difference between phrase-based machine translation and the hierarchical model mentioned in the text?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen07-slide07/text.txt": [
            "What is the significance of the non-terminal \"x\" in the hierarchical model described?",
            "What is the primary difference between a rule in this hierarchical model and a traditional grammar component?",
            "What is the only non-terminal used in this hierarchical model of sentence construction?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen08-slide08/text.txt": [
            "What were the limitations on the number of extractable lures in the phrase-based extraction process?",
            "What were the initial limitations on phrase length used in the normal phrase-based extraction process?",
            "What limitations were placed on the number of extracted rules in the phrase-based extraction system?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen09-slide10/text.txt": [
            "What is the main difference between constituency trees and dependency trees in formal descriptions of sentence structure?",
            "What is the main difference between constituency trees and dependency trees in formal descriptions of sentence structure?",
            "What is the main difference between constituency trees and dependency trees in formal descriptions of sentence structure?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen10-slide11/text.txt": [
            "What is the most important syntactic element in a sentence, according to the explanation provided?",
            "What is the most important syntactic element in a sentence that governs the structure of the whole structure beneath?",
            "What is the most important part of a sentence that governs the whole structure beneath?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen11-slide12/text.txt": [
            "How can a dependency tree be represented in two different ways?",
            "What are the only labels allowed on the head word in a dependency tree?",
            "What is the main purpose of a head word in a dependency tree?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen12-slide13/text.txt": [
            "What is the title of the machine translation talk recommended by the speaker?",
            "What is the title of the machine translation talk recommended by the speaker?",
            "What is the title of the machine translation talk recommended by the speaker?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen13-slide14/text.txt": [
            "What is the maximum likelihood estimate for the probability of a VP being further expanded into V and two objects, given the observed counts from a linguistically annotated tree bank?",
            "What is the purpose of assigning probabilities to the productions in a context-free grammar?",
            "What is the maximum likelihood estimate for assigning probabilities to the productions in a context-free grammar?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen14-slide15/text.txt": [
            "What is the purpose of the table of non-terminal spans in the CKY parsing algorithm, and how are the back pointers used to construct the full syntactic tree?",
            "What is the purpose of the table of non-terminal spans in the CKY or CYK parsing algorithm?",
            "What is the purpose of the CKY or CYK algorithm in parsing a given sentence?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen15-slide16/text.txt": [
            "What type of grammar is described as \"capturing the double generation\" in the context of machine translation?",
            "What is the significance of the non-terminals in the whole tree matching exactly in the context of a synchronous context-free grammar for machine translation?",
            "What is the significance of the non-terminals in the whole tree having to match exactly in a synchronous context-free grammar used for machine translation?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen16-slide17/text.txt": [
            "What would be the problem in mapping two constituency trees together using a synchronous context-free grammar if the English tree is deeper than the Czech tree?",
            "What would prevent the mapping of two constituency trees, one representing a sentence in English and the other in Czech, using a synchronous context-free grammar?",
            "What is the reason why the Synchronous context-free grammar cannot map the two constituency trees together?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen17-slide18/text.txt": [
            "What type of grammatical structure is being described as corresponding to the Synchronous Tree Substitution Grammars in the given text?",
            "What is the role of lexicalization in the Synchronous Tree Substitution Grammars described in the text?",
            "What is the primary difference between the productions in Synchronous Tree Substitution Grammars compared to one-level productions?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen18-slide19/text.txt": [
            "What type of generalization is the goal in this context, and how does it differ from the type of generalization required when the two trees are very different?",
            "What type of generalization is synchronous tree substitution grammars after, according to the text?",
            "What is the main advantage of using synchronous tree substitution grammars over other methods of mapping constituency trees?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen19-slide20/text.txt": [
            "What is the primary difference between the processing style of synchronous substitution grammars/synchronous context-free grammars in machine translation and phrase-based machine translation?",
            "What is the primary difference in processing style between synchronous substitution grammars/context-free grammars and phrase-based machine translation?",
            "What is the primary difference in processing style between synchronous substitution grammars/context-free grammars and phrase-based machine translation?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen20-slide21/text.txt": [
            "What is the primary difference between the scoring process in phrase-based MT and phrase-based MT, where the scoring process was left to right?",
            "What is the main difference between the scoring process in phrase-based MT and the proposed bottom-up approach described in the text?",
            "What is the purpose of state splitting in the CKY parsing process for language model scoring in the context of machine translation?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen21-slide22/text.txt": [
            "What type of syntactic trees does the author consider \"true syntactic trees\" in the context of machine translation?",
            "What type of parsing is used in machine translation, as opposed to the hierarchical model presented in the previous example?",
            "What type of parsing is used for machine translation according to the text?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen22-slide23/text.txt": [
            "What are the two reasons why the syntactic model is most often worse than the hierarchical and phrase-based models in certain language pairs?",
            "What is the main difference between the hierarchical model and the phrase-based model in the context of extracting phrases from source and target sentences?",
            "What is the main difference between the hierarchical model and the phrase-based model in the context of extracting phrases from substitution grammars?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen23-slide24/text.txt": [
            "Why is the thing difficult?",
            "Why is the thing in question difficult?",
            "Why is it difficult to explain the reasons why something is difficult?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen24-slide25/text.txt": [
            "What are the two main approaches that syntactic approaches are compared to in terms of rule coverage and licensing?",
            "What are some of the drawbacks of using syntactic approaches compared to phrase-based and hierarchical approaches?",
            "What are the main drawbacks of syntactic approaches compared to phrase-based and hierarchical approaches?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen25-slide26/text.txt": [
            "What is the problem that arises in phrase-based MT when dealing with syntactic information, as illustrated by the example of \"Brucha Verde\"?",
            "What are the two approaches to phrase-based machine translation (MT) mentioned in the text, and how do they differ in handling syntactic information?",
            "What are the two approaches to machine translation (MT) mentioned in the text, phrase-based and syntactic?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen26-slide27/text.txt": [
            "What is a consequence of the system's inability to translate a noun phrase as a whole, as opposed to breaking it down into separate constituents?",
            "What is the main reason why the translation system cannot translate a sentence as a whole, but instead has to decompose it?",
            "What is the main reason why a translation system would be unable to translate a sentence as a whole, according to the provided explanation?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen27-slide28/text.txt": [
            "What is the reason for the loss of coverage of the syntactic-based system in the given languages?",
            "What is the reason for the loss of coverage of the syntactic-based system in one language but not the other?",
            "What is the reason for the loss of coverage in the syntactic-based system due to the presence of a dangling verb phrase?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen28-slide29/text.txt": [
            "What are the main goals for modifying the grammatical constructions in the syntactic system to improve its robustness and ability to handle grammatically incorrect input sentences?",
            "What is the purpose of binarizing grammatical constructions in the syntactic system to achieve a more robust machine translation system?",
            "What is the purpose of binarizing grammatical constructions in the syntactic system, and how does it relate to extracting smaller phrases and improving the system's robustness?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen29-slide30/text.txt": [
            "What approach to binarization involves constructing artificial phrases by putting pieces together regardless of linguistic motivation?",
            "What was the name of the approach that involved constructing artificial phrases by putting pieces together without any linguistically motivated component?",
            "What approach to binarization involves constructing artificial phrases by combining pieces together regardless of linguistic motivation?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen30-slide31/text.txt": [
            "What is the problem that arises when a synchronous tree substitution grammar is used to analyze a phrase that is a multi-word expression of check points in the context of bottom-up parsing?",
            "What is the main issue in the bottom-up parsing process that prevents the use of certain phrases in a synchronous tree substitution grammar?",
            "What is the problem that arises when the synchronous tree substitution grammar is used to analyze a multi-word phrase that represents a noun in plural, given that the phrase cannot be plugged together due to the rules not allowing non-terminal matching?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen31-slide32/text.txt": [
            "What type of flexibility in grammar is necessary to handle real inputs, according to the discussion in the text?",
            "What type of penalty should be paid when plugging in something which the grammar doesn't anticipate in order to make the model flexible and allow for substitutions that are not explicitly defined in the grammar?",
            "What type of penalty should be paid when plugging in something that the grammar doesn't anticipate in a flexible model?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen32-slide33/text.txt": [
            "What is the main difference between the constituency syntax in machine translation and the hierarchical model?",
            "What is the purpose of keeping a record of the words in the boxes during bottom-up parsing?",
            "What is the requirement for using proper labels in the syntactic trees for bottom-up parsing in machine translation?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen33-slide34/text.txt": [
            "What is the purpose of the empty talk mentioned in the text?",
            "What type of syntax does the user move from in the given text?",
            "What is the purpose of the empty talk mentioned in the text?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen34-slide35/text.txt": [
            "What is the main difference between constituency trees and dependency trees in representing sentence structure?",
            "What is the main difference between constituency trees and dependency trees in representing the structure of a sentence?",
            "What is the main difference between constituency trees and dependency trees in representing the structure of a sentence?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen35-slide36/text.txt": [
            "What is the main error in the translation of the sentence \"The grass around your house should be cut soon\" into Czech, according to the given example?",
            "What is the primary difference in the way the verb \"cut\" is used in English compared to its translation in Czech?",
            "What are the two main errors that occurred when translating the sentence \"The grass around your house should be cut soon\" from English into Czech?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen36-slide37/text.txt": [
            "What is the primary advantage of using a dependency tree over n-grams in predicting lexical choices and grammatical categories in phrase-based translation?",
            "What is the approximate percentage of edges in a Czech tree bank that link neighbors?",
            "What percentage of edges in a Czech tree bank manually constructed will link neighbors?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen37-slide38/text.txt": [
            "What is the benefit of creating a gap phrase in hierarchical phrases to cover long distance dependencies?",
            "What is the benefit of creating a gap phrase in hierarchical phrases with gaps?",
            "What is an example of a hierarchical phrase with gaps that can cover a long distance dependency?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen38-slide39/text.txt": [
            "What is the phenomenon of \"crossing brackets\" in linguistics, according to the text?",
            "What is the phenomenon referred to as \"crossing brackets\" in the context of linguistics?",
            "What is the phenomenon of crossing brackets in the context of linguistics?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen39-slide40/text.txt": [
            "What is the difference between a projective tree and a non-projective tree in the context of dependency trees?",
            "What are the conditions under which a dependency tree can be represented by a constituency-free grammar?",
            "What is the difference between a projective tree and a non-projective tree in the context of dependency trees and grammatical representation?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen40-slide41/text.txt": [
            "What is the word order required in Dutch for the sentence \"Thing in Dutch that John Grass saw being cut\"?",
            "What is the word order required in Dutch for the sentence \"Thing in Dutch that John Grass saw being cut\"?",
            "What word order would be used in Dutch to express the same meaning as \"Thing in Dutch that John Grass saw being cut\"?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen41-slide42/text.txt": [
            "What is the consequence of trying to apply two rules (one for cutting and one for the subject-predicate dependency) simultaneously in the hierarchical approach to translation into Czech?",
            "What is the consequence of applying two rules for translating a sentence into Czech, where one rule is hierarchical and the other is non-projective?",
            "What is the main reason why the hierarchical approach to parsing and translation into Czech is inadequate due to non-projectivity?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen42-slide43/text.txt": [
            "What percentage of Czech sentences contain non-projectivity, with many gaps, in addition to the 99.5% that are well nested and with at most one gap?",
            "What percentage of Czech sentences contain non-projectivity, with the remaining sentences being well-nested and with at most one gap?",
            "What percentage of Czech sentences contain non-projectivity, with many gaps?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen43-slide44/text.txt": [
            "What type of tree structures are more suitable for Czech language analysis than constituency trees?",
            "What type of linguistic analysis is more suitable for Czech than constituency trees, according to the text?",
            "What type of trees are more appropriate for Czech than constituency trees due to frequent non-projectivity?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen44-slide45/text.txt": [
            "What is the primary difference between the original concept of \"dependency trees\" and the concept observed in machine translation?",
            "What is the main difference between the initial observation of \"a pair of trees\" and the final observation of \"dependency trees\"?",
            "What is the concept of dependency trees in machine translation according to the given text?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen46-slide47/text.txt": [
            "What is the purpose of decomposing trees into smaller treelets in the context of synchronizing source and target sentences?",
            "What is the purpose of decomposing trees into smaller treelets in the context of synchronously using them on the source and target sides?",
            "What is the purpose of decomposing trees into smaller treelets in the context of synchronously using them on the source and target sides?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen47-slide52/text.txt": [
            "What was the goal of the author's thesis several years ago regarding translation with syntactic trees?",
            "What was the goal of the author's thesis in relation to using a synchronous tree substitution grammar approach in translation?",
            "What was the approach of the author's thesis several years ago regarding transferring translation with syntactic trees?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen48-slide49/text.txt": [
            "What is the purpose of a dedicated empty talk in relation to deep syntax?",
            "What is the topic of the dedicated talk mentioned in the text?",
            "What is the subject of the second dedicated talk mentioned in the text?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen49-slide50/text.txt": [
            "What approach did the author find more successful than the STSG approach in machine translation?",
            "What was the name of the more successful machine translation system that the author applied in their thesis?",
            "What approach to machine translation did you find to be successful, and how did it differ from the STSG approach you initially applied?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen50-slide51/text.txt": [
            "When did the formal formulation of the textogrammatic layer theory start in the Prague linguistic circle?",
            "When did the formal formulation of the textogrammatic layer theory start to take place?",
            "When did the textogrammatic layer formally start to be formulated?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen51-slide52/text.txt": [
            "What is a prodrop language, and how does it affect the representation of pronouns in the Prague Dependency 3 Bank?",
            "What is an example of a node that was added to the Prague Dependency 3 Bank representation of a sentence, specifically in the context of the prodrop language Czech?",
            "What is an example of a node that was added in the Prague Dependency 3 Bank for a Czech sentence where a content-bearing word has its counterpart, but the subject is not pronounced?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen52-slide52/text.txt": [
            "What is the main difference between the English and Czech auxiliary words, according to the provided text?",
            "What is the main difference between the tectogrammatical tree and the predicate in the representation of the sentence?",
            "What is the main difference between the tectogrammatical and analytical levels of representation in linguistic analysis?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen53-slide52/text.txt": [
            "What is the syntactic difference between Czech and English sentences at the surface level?",
            "What is the syntactic difference between Czech and English sentences at the surface level?",
            "What difference are there in the syntactic structure of Czech and English sentences at the surface level?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen54-slide52/text.txt": [
            "What is the term used to describe the relationship between the pronoun and what should be changed in the sentence?",
            "What is the predicate argument structure of the sentence according to the tectogrammatical trees described in the text?",
            "What is the main difference between the tectogrammatical trees and the predicate argument structure of the sentence?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen55-slide56/text.txt": [
            "What is the primary advantage of using a tectogrammatic layer in the translation process, according to the text?",
            "What is the expected outcome in terms of vocabulary size when using tectogrammatic lemmas in the system?",
            "What is the effect of using tectogrammatic lemmas in the trees on the vocabulary size for a language translation system?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen56-slide57/text.txt": [
            "What approach does the author use to replace the red subtree with a smaller English subtree in the synchronous tree substitution grammars?",
            "What is the approach taken to replace the red subtree in the synchronous tree substitution grammars?",
            "What approach did the author use to replace the red subtree with a smaller English subtree in the synchronous tree substitution grammars?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen57-slide58/text.txt": [
            "What is the purpose of the additional labels and attributes in the notes that is not reflected in the tree structure according to the STSG approach?",
            "What happens to the information about modality or tense in the text-organic notes when they are stored in the additional labels or attributes of notes?",
            "What happens to the attributes of real text-organic notes in the STSG approach?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen58-slide59/text.txt": [
            "What is the main challenge in designing a system that combines structure and attributes in a way that resolves their clash?",
            "What approach is being considered to balance the structure and attributes in factorization, and what challenges are associated with this?",
            "What is the main challenge in designing the factorization of the structure and attributes in a certain machine translation model?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen59-slide60/text.txt": [
            "What approach to sentence analysis emerged as the best empirical approach according to the experiment described?",
            "What approach to sentence analysis emerged as the best approach in the empirical evaluation of the system described?",
            "What approach resulted empirically as the best in the evaluation of the sentence analysis systems?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen60-slide61/text.txt": [
            "What is the main reason behind the failure of a system, according to the text, in terms of data loss?",
            "What is the main issue behind the failure of a certain system, according to the given text?",
            "What is the main reason for the huge data loss in the pipeline due to the incompatibility of structures?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen61-slide62/text.txt": [
            "What is the name of the approach that uses the tectogrammatic layer and worked reasonably well, as described in the text?",
            "What is the name of the approach described as working reasonably well that uses the tectogrammatic layer?",
            "What is the name of the approach that uses the tectogrammatic layer and worked reasonably well according to the text?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen62-slide63/text.txt": [
            "Who was the colleague responsible for starting this complex processing system?",
            "Who started and finished the project that involved a careful structure of processing steps?",
            "Who was the colleague who started this processing approach and whose colleague finished it?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen63-slide64/text.txt": [
            "What type of model is illustrated on the last slide mentioned in the text?",
            "What is the main purpose of the speaker's use of Martin Popel's slides in their explanation?",
            "What type of model is referred to as the \"transfer stack\" in the given text?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen64-slide65/text.txt": [
            "What is the root of the tree in the machine translation process?",
            "What is the role of the \"should\" in the tree structure described in the text?",
            "What is the purpose of the deep syntactic tree in the machine translation process?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen65-slide66/text.txt": [
            "What are the auxiliaries referred to as in the given text?",
            "What are referred to as \"auxiliaries\" in the given text?",
            "What are referred to as \"all the auxiliaries\" in the context of identifying functional words?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen66-slide67/text.txt": [
            "Where will the mark edges contract?",
            "What will you contract your mark edges like?",
            "Where will the mark edges contract like?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen67-slide68/text.txt": [
            "What type of content are the X-series articles in the tectogram article 3?",
            "What is the purpose of contracting the X-series in the tectogram article 3?",
            "What type of content are the X-series mentioned to have been hidden?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen68-slide69/text.txt": [
            "What grammatical category did the machine fill in as a noun in the given text?",
            "What grammatical category does the machine \"this to be was\" fall into?",
            "What grammatical category does the word \"this machine\" serve as in the given sentence?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen69-slide70/text.txt": [
            "What type of verb tense is described in the text as being simple?",
            "What type of grammar is related to the morphology mentioned in the sentence \"You fill in the grammar teams\"?",
            "What type of grammar team is related to the morphology mentioned in the text?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen70-slide71/text.txt": [
            "What percentage of sentences assume isomorphic trees in the morphological information process?",
            "What is the assumption made when creating the target side tree in the morphological transformation process?",
            "What percentage of sentences are assumed to go beyond isomorphic trees in this process?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen71-slide72/text.txt": [
            "What are some possible ways to translate the attribute \"easy\" in the given text?",
            "What are some possible translations for the word \"machine\" in the given text?",
            "What are some possible translations for the attribute \"complement\" in the context of lexical translation?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen72-slide73/text.txt": [
            "What model will be used to select the best combination of factors according to Markov?",
            "What is the purpose of selecting the best combination of factors according to Markov 3 model?",
            "What model will be used to select the best combination of factors?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen73-slide74/text.txt": [
            "What is the first step in producing the final surface syntactic tree?",
            "What is done to the initial tree before producing the final surface syntactic tree?",
            "What is done to the tree before producing the final surface syntactic tree?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen74-slide75/text.txt": [
            "What form was Snudny in, according to the information provided?",
            "Was the translation of the noun \"Snudny\" in the positive form?",
            "What is the form of Snudny in the given translation?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen75-slide76/text.txt": [
            "What cases and numbers should be used on adjectives based on the nouns they modify?",
            "What is the role of explicit representation in ensuring grammatical correctness in the system?",
            "What is the role of linguistic knowledge in the system that ensures grammatical correctness of the output sentence?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen76-slide77/text.txt": [
            "What are the functional words mentioned in the text?",
            "What is the purpose of adding functional words to a sentence?",
            "What is the purpose of adding functional words to a sentence?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen77-slide78/text.txt": [
            "What is a potential drawback of reordering a sentence in order to introduce non-projectivities?",
            "What is a potential drawback of reordering a sentence in order to achieve projectivity?",
            "What are the potential drawbacks of reordering a sentence to achieve projectivity?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen78-slide79/text.txt": [
            "What is the result of generating word forms based on demorphology?",
            "What is the process of generating word forms based on demorphology?",
            "What is the process referred to as that involves generating word forms based on demorphology?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen79-slide80/text.txt": [
            "What is the expected difficulty of the translation of \"Překlad\" by Stravi?",
            "What does the word \"bít\" mean in the given sentence?",
            "What is the expected difficulty level of the translation of the sentence \"Překlad by měl bít snadný\"?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen80-slide81/text.txt": [
            "What are the two options for translating a noun in the target site tectogrammetical tree?",
            "What are the two options for translating a noun in the target site tectogrammetical tree?",
            "What is the goal of the Hidden Markov model in the context of target site tectogrammetical trees?"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen81-slide82/text.txt": [
            "What is the main difference between the hidden Markov model used in HMM tagging and the model used in the described generalization?",
            "What are the two components of the hidden Markov model used in the described system, and how do they relate to the translation model and language model?",
            "What are the two main components of the hidden Markov model in the context of sentence translation, and how do they relate to the translation model and language model?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen01-slide01/text.txt": [
            "Why would multilingual machine translation be helpful?",
            "Why would multilingual machine translation be helpful, given that machine translation already involves at least two languages?",
            "Why would multilingual machine translation be helpful despite machine translation already involving at least two languages?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen02-slide02/text.txt": [
            "What are the three main setups discussed in the lecture regarding using multiple languages in machine translation systems?",
            "What is the primary motivation for using more than two languages in the setup, according to the lecture?",
            "What are the three different setups for using multiple languages in a system as discussed in the lecture?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen03-slide03/text.txt": [
            "How many languages are there on earth that have sufficient resources for training a good performing machine translation system?",
            "How many languages are there on earth, and only a handful of those have sufficient resources for training a good performing machine translation system?",
            "What is the approximate number of languages on earth that have sufficient resources for training a good performing machine translation system?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen04-slide04/text.txt": [
            "What is the primary goal of using transfer learning in machine translation?",
            "What is the primary goal of transfer learning in the context of machine translation?",
            "What is the primary goal of using transfer learning in machine translation?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen05-slide05/text.txt": [
            "What is the typical trading curve for neural machine translation systems according to the text?",
            "What is typically observed in the training curve of neural machine translation systems using transfer learning?",
            "What is the expected behavior of a well-regulated neural machine translation model during training?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen06-slide06/text.txt": [
            "What would be the outcome if additional data from another task and language were incorporated into the current task?",
            "What would be the outcome if additional data from another task and language were incorporated into the current task?",
            "What would be the expected outcome if additional data from another task and language were incorporated into the current task?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen07-slide07/text.txt": [
            "What are the three key areas where improvements in a neural machine translation system can appear?",
            "What language pairs were behind the transfer of the neural machine translation system used in the experiments described in the text?",
            "What are the three main areas where improvements can appear in the performance of a neural machine translation system?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen08-slide08/text.txt": [
            "What is the simplest technique for achieving transfer learning in a language pair?",
            "What is the simplest technique for achieving transfer learning in machine translation?",
            "What is the simplest technique for achieving transfer learning in a language pair?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen09-slide09/text.txt": [
            "What effect can be achieved by continuing to train a child model on the same data it was initially trained on, rather than initializing it with random weights?",
            "What happens when a child model is initialized with weights from a parent language pair, rather than being trained from random weights?",
            "What happens when a child model is initialized with the same weights as the parent model, rather than being trained from scratch with random weights?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen10-slide10/text.txt": [
            "What is the term for the phenomenon where neural networks forget previously learned knowledge as soon as the training data changes?",
            "What is the phenomenon called when neural networks, trained on recent batches of data, forget what they have learned from previous batches?",
            "What is the phenomenon called when a neural network \"forgets\" what it has learned in the past as soon as the content of its training batches is changed?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen11-slide11/text.txt": [
            "What is the recommended approach to training a network when the data is not randomly sorted?",
            "What is the main problem with sorting a corpus before training a network, according to the given text?",
            "What is the problem with training a network on a corpus sorted by sentence length, rather than randomly?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen12-slide12/text.txt": [
            "What was the outcome of the model after it was allowed to see sentences of all lengths during the training process?",
            "What type of training did the model undergo, and what effect did it have on the model's performance?",
            "What was the effect of the model seeing sentences of increasing lengths during training?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen13-slide13/text.txt": [
            "What is the term used to describe the phenomenon where a model unlearns to produce long sentences after being trained on a task that requires it to produce longer sentences?",
            "What is the term used to describe the model's inability to produce sentences of the same length as the source sentence, even after the training process is complete?",
            "What is the term used to describe the phenomenon where a model unlearns to produce long sentences after being trained on a task that involves limiting sentence lengths?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen14-slide14/text.txt": [
            "What was the common language used in the early transfer learning experiments?",
            "What was the typical setup for early transfer learning experiments?",
            "What type of language pairs were typically used in early experiments on transfer learning?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen15-slide15/text.txt": [
            "What happens to a subword dictionary if you combine the subword dictionaries of a parent and child corpus, where the parent corpus is typically large and the child corpus is typically small?",
            "What happens to the subword dictionary when you extract it from a parent corpus and a child corpus together, given that the parent corpus is typically big and the child corpus is typically small?",
            "What happens to the subword dictionary when it is extracted from a large parent corpus and a small child corpus?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen16-slide16/text.txt": [
            "What method was used to balance the vocabulary in the corpora of the same sizes?",
            "What approach did the authors use to balance the vocabulary in their corpora?",
            "What method was used to balance the vocabulary in the corpora?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen17-slide17/text.txt": [
            "Was English equally represented in the subword vocabulary as Czech and Estonian?",
            "Was English equally represented in the subword vocabulary as Czech and Estonian?",
            "Was Czech equally represented in the parent and child language in the subword vocabulary?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen18-slide18/text.txt": [
            "What is the corpus size difference between the English-Czech model and the English-Slovak model?",
            "What is the corpus size difference between the parent model for English-Czech and the model for English-Slovak?",
            "What is the translation direction being used in the experiment, and how does the corpus size difference between Czech-English and English-Slovak affect the results?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen19-slide19/text.txt": [
            "What is the reason for the improvement in translation results when the model is first trained on the parent language and then the child language, compared to training on the child language pair only?",
            "What is the reason for the bigger improvement in BLEU score when translating from English compared to translating into English?",
            "What is the reason for the greater improvement in BLEU score when translating into English compared to translating from English?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen20-slide20/text.txt": [
            "What was the relationship between the magnitude of corpus sizes of Finnish and Estonian?",
            "What was the related language to Estonian in the experiment?",
            "What is the relationship between Finnish and Estonian languages?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen21-slide21/text.txt": [
            "What language provides the biggest improvement in scores?",
            "What is the setup for getting improvement in scores from different languages?",
            "What language provides the biggest improvement in scores?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen22-slide22/text.txt": [
            "What conclusion can be drawn from the experiment regarding the importance of the relationship between parent and child language?",
            "What conclusion can be drawn from the experiment regarding the importance of the relationship between the parent and child language?",
            "What is the conclusion of the experiment based on the experiment's findings regarding the importance of the relationship between the parent and child language?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen23-slide23/text.txt": [
            "What languages were the Finnish and English language pairs of interest when testing the transfer of knowledge?",
            "What languages were the Finnish and English language pairs of interest when testing the transfer model on a child?",
            "What language pair were the Finnish and English in the child being tested?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen24-slide24/text.txt": [
            "What is the most important aspect that affects the performance of the child in a language translation model?",
            "What is the most important factor affecting the performance of a child model in a language translation system, according to the experiment results?",
            "What is the most important factor in determining the performance of a child model in language translation experiments?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen25-slide25/text.txt": [
            "What was the outcome when the English language was swapped from the source side to the target side in the parent and child models?",
            "What happens to the improvement in the child model when the English is on the wrong side of the parent model?",
            "What is the effect of the English position on the performance of the child model when the parent model is trained with English as the target language?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen26-slide26/text.txt": [
            "What is the effect of training on corpora with no shared vocabulary when translating Estonian to English?",
            "What is the effect of combining multiple corpora with no shared vocabulary on the improvement of Estonian-English translation?",
            "What is the effect of training on corpora with no common language on the Estonian-English translation performance?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen27-slide27/text.txt": [
            "What script were the researchers initially training on when they saw a significant improvement in their language model?",
            "What was the non-significant improvement that was achieved from pre-training on a language pair that doesn't share the same script as the training script?",
            "What types of improvements were significant in the experiment, and what types were non-significant?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen28-slide28/text.txt": [
            "What is the significance of the parent's performance in determining the performance of the child in a training scenario?",
            "What happens to the performance of the child when the parent is fully converged and is not stopped prematurely?",
            "What happens to the performance of the child model if the parent is not fully converged before switching to the child?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen29-slide29/text.txt": [
            "What happens to the performance of the baseline model when the child data size is reduced?",
            "What happens to the performance of the baseline model when the child data size is reduced to 10,000 sensors?",
            "What is the expected performance of the baseline model when the child data size is reduced to 10,000 sensors?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen30-slide30/text.txt": [
            "What percentage of the child's output consisted of new words that the parent did not have?",
            "What percentage of the child's output consisted of new words that the parent did not have?",
            "What percentage of the child's output consisted of new words that were not expected to come from the parent language?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen31-slide31/text.txt": [
            "What is the main focus of the vocabulary overlap between English and Estonian translation?",
            "What type of vocabulary overlap did the model encounter due to the difference in script between Russian and Estonian?",
            "What is the reason for there being no words or subword units that would come to the child model due to the different scripts of Russian and Estonian?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen32-slide32/text.txt": [
            "What happens to the BLEU score when the neural machine translation system is trained on sentences with a range of word lengths, rather than only short sentences?",
            "What happens to the BLEU score when the neural machine translation system produces two long outputs instead of short outputs?",
            "What happens to the BLEU score when the neural machine translation system produces outputs that are too short or too long compared to the training data?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen33-slide33/text.txt": [
            "What is the average BLEU score of the child model when using unconstrained parents, compared to the baseline performance?",
            "What is the improvement in performance when using the full, normal, unconstrained parent for transfer learning?",
            "What is the average length of the child data in the model?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen34-slide34/text.txt": [
            "What type of transfer is being highlighted in the text?",
            "What type of transfer was being highlighted in the text?",
            "What is the purpose of the baseline transfer mentioned in the text?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen35-slide35/text.txt": [
            "What is the next topic being discussed after multilingual machine translation?",
            "What is the topic of the next section to be discussed after the multilingual machine translation?",
            "What is the topic of the next section of the text?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen36-slide36/text.txt": [
            "What is the term used to describe a system that can translate a pair of languages that it never saw as a pair in the training data?",
            "What is the difference between a multilingual source site and a multilingual and multi-source setup in machine translation systems?",
            "What are the terms used to describe systems that can process multiple languages, and how do they differ from one another?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen37-slide37/text.txt": [
            "How many target languages can you put into a model without decreasing its performance too much?",
            "What is the main goal for running a single system to translate multiple languages simultaneously in a multinational institution?",
            "What is the main goal of running a single system to translate into many different languages at once in a multinational institution?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen38-slide38/text.txt": [
            "What type of system would the ideal setup for machine translation be?",
            "What would be the ideal setup for a flexible multilingual machine translation system?",
            "What is the key characteristic of the proposed machine translation system that allows it to handle multiple languages and sources simultaneously?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen39-slide39/text.txt": [
            "When did the idea of multisource translation originate?",
            "When was the idea of multisource translation first tested?",
            "When did the idea of multisource translation originate?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen40-slide40/text.txt": [
            "What is the underlying principle of a neural machine translation system?",
            "What is the underlying principle of neural machine translation systems?",
            "What is the underlying principle of a neural machine translation system?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen41-slide41/text.txt": [
            "What was the main drawback of the setup proposed by Zoffa and Knight for producing English from French and German sources?",
            "What type of neural network was used in the first setup by Zoffa and Knight to produce English from French and German sources?",
            "What type of neural network was used in the first setup by Zoffa and Knight to produce English from French and German sources?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen42-slide42/text.txt": [
            "What was the main question Orhan Ferrat was trying to answer in his 2016 experiment with bilingual corpora?",
            "What was the main question Orhan Ferrat was trying to answer in his 2016 experiment with bilingual corpora?",
            "What was the main question Orhan Ferrat investigated in his 2016 experiment with bilingual corpora?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen43-slide43/text.txt": [
            "What happens to the attention when producing the target output one word at a time?",
            "What happens to the attention as you are producing the target output one word at a time?",
            "What happens to the attention as you produce the target output one word at a time?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen44-slide44/text.txt": [
            "What is the role of the attention mechanism in the training process for encoder and decoder in a language pair?",
            "What is the shared component between the encoders and decoders in a model using the attention mechanism?",
            "What is the role of the attention mechanism in the described language model training process?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen45-slide45/text.txt": [
            "What was the outcome of the system's performance in a simulated low resource setting compared to the baseline, especially when the training data is small?",
            "What was the outcome of the system's performance when the training data was rather small?",
            "What improvements were observed in the system when using high resource languages in a simulated low resource setting?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen46-slide46/text.txt": [
            "What is the purpose of the provided TEXT?",
            "What can be inferred about the purpose of the TEXT based on the information provided?",
            "What can be inferred about the purpose of the given TEXT based on the instruction to \"generate a single QUESTION for an exam\"?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen47-slide45/text.txt": [
            "What type of experiments were generally conducted in the mentioned experiments?",
            "What were the general outcomes of the experiments mentioned in the text?",
            "What type of experiments were conducted in the mentioned experiments?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen48-slide46/text.txt": [
            "What type of models perform better when translating from English into other languages compared to multilingual models?",
            "What is the optimal approach when translating from English into another language?",
            "What is the benefit of using a multilingual model when translating into English, compared to using a single paired model for other languages?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen49-slide48/text.txt": [
            "Is English the language being compared to another language in the given text?",
            "What language is mentioned as being less than English in the given text?",
            "Is English the preferred language in the given text?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen50-slide47/text.txt": [
            "What is the approach for processing a sentence with multiple languages when using multi-source multi-language setup in the experiment described?",
            "What is the possible approach for processing input with both source information in multiple languages when training independent encoders and decoders for each language pair?",
            "What is the approach to processing a sentence with multiple languages when training on pairs of sentences from different languages?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen51-slide49/text.txt": [
            "What happens when the multiway and multi-source setup is used for translating from French into English, compared to translating from English into French?",
            "How do models trained on independent pairwise corpora across many languages perform when translating from Spanish into English compared to those trained only on Spanish-English data?",
            "What happens to the performance of the Spanish-English model when the other language data is also seen, compared to when it is not?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen52-slide50/text.txt": [
            "What is the baseline performance for translating a single input sentence, as mentioned in the text?",
            "What is the baseline performance when translating from a source language to English using only one input sentence?",
            "What is the baseline performance in the setup with two input sentences, one in Spanish and one in French, when translating into English?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen53-slide52/text.txt": [
            "What was the original goal of the translation into a particle language pair mentioned in the text?",
            "What was the initial idea of the translation project?",
            "What was the original idea of improving translation into a particle language pair?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen54-slide50/text.txt": [
            "What is the main complication that arises when trying to maintain good performance across multiple language pairs in transfer learning setups?",
            "What are the implications of maintaining performance on multiple languages when training a multilingual system?",
            "What is the main complication for achieving gains in multilingual systems, according to the transfer learning setup?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen55-slide52/text.txt": [
            "What is the main difference between using a pivot translation and a multi-way encoder-decoder system for zero-shot translation?",
            "What is the main difference between the proposed multi-way encoder-decoder system and the traditional two-step pivot translation method?",
            "What is the primary difference between the traditional pivot translation method and the zero-shot translation approach using a multi-way encoder-decoder system?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen56-slide53/text.txt": [
            "What type of network structure is required to achieve reasonable performance in tasks that are mutually independent, according to the given text?",
            "What is the outcome when a neural network is used without explicit pivoting in the context of multi-task learning?",
            "What is the outcome when the attention mechanism is not used as intended in the neural network?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen57-slide54/text.txt": [
            "Would it be possible to train the missing part of the network by fine-tuning on a small amount of parallel data between Spanish and French?",
            "Where can we get a small amount of parallel data between Spanish and French for fine-tuning the network?",
            "Where would it be possible to get the small amount of parallel data needed to fine-tune the missing part of the network?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen58-slide55/text.txt": [
            "What other corpora are mentioned besides the Spanish-English and English-French corpus?",
            "What corpora have been used to train the paths in the multi-way system?",
            "What other parallel corpora have been used to train the paths in the multi-way system besides the Spanish-English and English-French corpora?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen59-slide56/text.txt": [
            "What can be produced using a Spanish-English system based on a French corpus?",
            "What is the purpose of using a French corpus in conjunction with a Spanish-English system to produce synthetic Spanish?",
            "What can be produced using a French corpus and a Spanish-English system?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen60-slide57/text.txt": [
            "What is the purpose of fine-tuning the network with the new data that go across language pairs?",
            "What type of training will be performed on the existing network with two encoders and two decoders?",
            "What is the purpose of fine-tuning the network with data that go across the two languages?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen61-slide58/text.txt": [
            "What is the BLEU score when using the synthetic parallel corpus and depending on its size?",
            "What would be the BLEU score if the synthetic parallel corpus is used, compared to the pivoting method?",
            "What would be the expected BLEU score when using pivoting with a synthetic parallel corpus compared to a pseudo-parallel corpus?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen62-slide59/text.txt": [
            "What is the effect of using separate encoders and decoders, as well as fine-tuning them across new language pairs, on the performance of baseline models?",
            "What is the outcome when using separate encoders and decoders and fine-tuning them across different language pairs, compared to using a large true parallel corpus?",
            "What is the outcome when using separate encoders and decoders with fine-tuning, as opposed to a large true parallel corpus?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen63-slide60/text.txt": [
            "What is the main result of using a multitask training setup for a translation system, and how does it compare to traditional transfer learning?",
            "What are the main results of using multitask training with a fixed set of parameters for a multilingual machine translation system?",
            "What are the main considerations when training a multitask system to learn multiple languages at once?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen64-slide61/text.txt": [
            "What was the outcome of using a multilingual system for translation from different languages into English?",
            "What was the outcome of the hardware cost-saving in the Google experiment mentioned in the text?",
            "What was the result of using a multilingual system for Google experiments in 2016?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen65-slide62/text.txt": [
            "What are some potential issues that can arise when trying to create a multilingual system for translating non-English, non-common languages?",
            "What are the potential issues that arise when using multilingual training data for non-English, non-common language translation systems?",
            "What are the potential issues that arise when creating a multilingual system to produce non-English, non-common languages, and how can these issues be addressed?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen66-slide61/text.txt": [
            "Can you feed multiple source languages into the same model if the target language remains the same?",
            "Can you feed multiple source languages into the same model without compromising translation quality?",
            "Can a model handle multiple source languages if the target language is different?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen67-slide62/text.txt": [
            "What happens to the loss when feeding language pairs with different targets into the same model, specifically regarding the first token of the input sentence?",
            "What is the significance of the first token of the input sentence in a model that handles language pairs with different targets?",
            "What is the significance of the first token of the input sentence in a model that processes language pairs with different targets?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen68-slide63/text.txt": [
            "What was the primary goal of Jörg Tiedemann's 2018 recurrent neural network system?",
            "What was the specific task that Jörg Tiedemann used his recurrent neural network system for in 2018?",
            "What was the primary focus of Jörg Tiedemann's 2018 recurrent neural network system?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen69-slide64/text.txt": [
            "What is the result of projecting the Indo-European languages to a two-dimensional vector space with T-SNE according to the text?",
            "What is the cluster to which the Quechua languages are grouped according to the T-SNE projection of the embedded languages?",
            "What language families are empirically identified and form distinct clusters according to the T-SNE projection of the embedding to a two-dimensional vector space?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen70-slide63/text.txt": [
            "Does the method described in the text still manage to cluster languages, even if its translation is not very accurate?",
            "Does the system described in the text require any supervision to cluster languages?",
            "Does the method described in the text require any supervision to cluster languages?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen71-slide64/text.txt": [
            "What is the subject of the sentence that begins with \"In a similar way that linguists...\"?",
            "What is the subject of the comparison mentioned in the phrase \"in a similar way that linguists...\"?",
            "What is the subject of the comparison in the phrase \"In a similar way that linguists...\"?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen72-slide65/text.txt": [
            "What is the main goal of the recent research done by Google, according to the text?",
            "What is the main goal of the recent research conducted by Google, according to the text?",
            "What is the main goal of the recent research done by Google, as mentioned in the text?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen73-slide66/text.txt": [
            "What was the number of languages included in the parallel corpora experiment conducted by Orhan Ferrat and colleagues?",
            "How many languages do Orhan Ferrat and his colleagues from Google have parallel corpora for?",
            "How many languages did Orhan Ferrat from Google and colleagues experiment with in their distribution experiment?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen74-slide67/text.txt": [
            "What is the main difference in translation quality according to the BLEU scores mentioned in the text?",
            "What is the general trend in translation quality according to the BLEU scores mentioned in the text?",
            "How do the translation quality baselines account for differences in language resource levels?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen75-slide68/text.txt": [
            "What is the typical structure of the transformer setup used in the model mentioned in the text?",
            "What is the typical structure of the transformer setup used in the model, and how does it differ from the recurrent neural networks used in previous experiments?",
            "What is the typical structure of the transformer setup used in the mentioned model, and how does it differ from recurrent neural networks?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen76-slide69/text.txt": [
            "What happens to the stability of the training process when using very large transformer models with a huge corpus?",
            "What are the implications of using a deep network (24 layers) versus a wide network (12 layers) on the stability of training a transformer model, particularly for low-resource languages?",
            "What is the difference between the depth of a transformer network and its breadth, in terms of the number of parameters and required GPUs?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen77-slide70/text.txt": [
            "At what point do the languages become low resource compared to the average, and how does this affect the decision to use separate pairwise models versus multilingual models?",
            "When does it become better to use a multilingual model rather than separate pairwise models, according to the data shown in the graph?",
            "At what point do languages become low resource compared to the average, and what implications does this have for the use of separate pairwise models versus multilingual models?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen78-slide71/text.txt": [
            "What is the effect of increasing the number of parameters in the massively multilingual model from 400 million to 50 billion on the performance on high-resource language pairs?",
            "What is the effect of increasing the number of parameters in the massively multilingual model on its performance on high-resource language pairs?",
            "What is the standard number of parameters for the massively multilingual model?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen79-slide72/text.txt": [
            "What is the purpose of the gating network in the proposed mixture of experts architecture?",
            "What is the main limitation of the proposed model when trying to accommodate multiple target languages, especially low-resource languages, into a single model?",
            "What is the main bottleneck in training a large transformer model for multilingual tasks?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen80-slide73/text.txt": [
            "What type of experts are introduced in the proposed model to reduce the size of the network?",
            "What is the main goal of using a tunable sublayer in the proposed model for reducing the size of the network?",
            "What type of sublayer do Orhan Ferden and colleagues introduce to their network to enable it to be pre-trained on a big mixed corpus of multiple languages?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen81-slide74/text.txt": [
            "What is the outcome when using adapters with the transformer model for translating into English?",
            "What is the effect of using adapters on the performance of the multilingual system when translating into English?",
            "What is the reason why the multilingual system is underperforming the bilingual baselines in the given transformer setup?"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen82-slide75/text.txt": [
            "What is the significance of adapters in the context of translating out of English?",
            "What is the significance of adapters when translating out of English?",
            "What is the primary focus of the text when discussing the translation process?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen01-slide02/text.txt": [
            "What is the name of the standard model of statistical machine translation being discussed in the lecture?",
            "What is the name of the standard model of statistical machine translation that is being discussed in the lecture?",
            "What is the name of the standard model of statistical machine translation that is being focused on in the lecture?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen02-slide03/text.txt": [
            "What is the current status of incorporating syntax information into transformer networks for neural machine translation, according to the results of the talk mentioned in the text?",
            "What is currently a limitation in using syntax information in neural machine translation approaches, according to the text?",
            "What is the current state of using syntax information in neural machine translation, according to the information presented in the text?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen03-slide04/text.txt": [
            "What is the role of the attention mechanism in a sequence-to-sequence system with attention, and how does it control the word order and flow of translation?",
            "What is the role of the attention mechanism in a sequence-to-sequence system with attention?",
            "What is the role of the attention mechanism in a sequence-to-sequence system with attention, and how does it control the flow of translation?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen04-slide05/text.txt": [
            "What is the purpose of the attention energies in a bidirectional recurrent network?",
            "What is the purpose of the bidirectional recurrent networks in the given model?",
            "What is the purpose of the attention energies in a bidirectional recurrent network?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen05-slide07/text.txt": [
            "What process do you use to decide the final word in the output sequence?",
            "What is the method used by the decoder to determine the next word in the output sequence?",
            "What process do you use to decide the final word in a decoding process?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen06-slide07/text.txt": [
            "What is the subject of the next sentence after \"Yeah, so let's move to the transformer model\"?",
            "What model is the focus of the text after \"the transformer\"?",
            "What model is being discussed in the text?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen07-slide08/text.txt": [
            "When was the MODEL introduced in a paper?",
            "In what year was the Transformer model introduced in a paper titled \"Attention is all you need\"?",
            "When was the MODEL introduced in the paper \"Attention is all you need\"?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen08-slide09/text.txt": [
            "What type of view is also described in the blog post, in addition to the Transformer Illustrated description?",
            "What type of view can be accessed by reading the paper annotated in PyTorch code?",
            "What is the source of the clear and simple description of the Transformer Illustrated blog post?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen09-slide10/text.txt": [
            "How many layers of encoders and decoders are typically used in a transformer model, according to the original paper?",
            "What is the typical architecture of a transformer model, as described in the original paper?",
            "What is the original paper's recommendation for the optimal number of layers in a transformer network?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen10-slide11/text.txt": [
            "What is the role of the self-attention mechanism in the transformer model, and how is it different from the standard feedforward network?",
            "How many sublayers does the transformer have in its encoder?",
            "How many layers of feedforward network are used in the transformer model?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen11-slide12/text.txt": [
            "What is the role of self-attention in the model described in the text, and how does it allow for the flow of information between words?",
            "What is the role of self-attention in the network described, in terms of the dependencies between words in the input sequence?",
            "What happens to the correspondence between word positions and the intermediate representations produced by self-attention in the network?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen12-slide13/text.txt": [
            "What is the purpose of applying the same transformation to every token in a word network?",
            "What is the primary method by which word networks are processed in the encoder layer?",
            "What is the primary method used to process words in word networks during the encoder layer?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen13-slide14/text.txt": [
            "What would happen to the positional encoding vectors if the same word appeared at two different positions in the sentence?",
            "What type of information processing is used in the construction of positional encoding vectors in the transformer model, according to the text?",
            "What type of information processing is used to construct the positional encoding vectors in the transformer model?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen14-slide15/text.txt": [
            "What is the core element of the transformer network mentioned in the text?",
            "What is the core element of the transformer network mentioned in the text?",
            "What is the core element of the transformer network mentioned in the provided text?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen15-slide16/text.txt": [
            "What are the two constants that specify how a convolutional neural network processes sequences or subsequences at a time?",
            "What are the two constants that specify how a convolutional neural network explores the input elements, and how do they determine the time complexity of processing a sequence?",
            "What are the two constants that specify the breadth in which a convolutional neural network explores the input elements, and how do they relate to the length of sequences or subsequences processed at a time?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen16-slide17/text.txt": [
            "What is the relationship between the memory needed for a self-attention network and the length of the sequences it processes?",
            "What is the relationship between the memory needed to compute a self-attentive network and the length of the sequences it processes?",
            "What is the main cost associated with the use of self-attention networks in computing?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen17-slide18/text.txt": [
            "How does the self-attention mechanism aggregate information from an input of arbitrary length into a fixed-size vector?",
            "How does the self-attention mechanism aggregate information from an arbitrarily long input into a fixed-size vector in a trainable way?",
            "How does the self-attention mechanism aggregate information from an input that is arbitrarily long into a fixed-size vector?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen18-slide19/text.txt": [
            "What is the purpose of the projection matrices in the self-attention mechanism of a neural network?",
            "What determines whether the whole vector of a word or its separate keys, queries, and values are used in the self-attention mechanism?",
            "What type of transformation do the input word embeddings undergo to become keys, queries, or values in the self-attention mechanism?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen19-slide20/text.txt": [
            "What is the purpose of the dot product calculation in the given matching process?",
            "What is the purpose of comparing every position with every other position in the sentence, as described in the text?",
            "What is the purpose of calculating the dot product between the query vector and the key vector in the context of comparing elements in a sentence?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen20-slide21/text.txt": [
            "What type of normalization is applied to the scores in vector representation to account for its dimensionality?",
            "What type of normalization is applied to the scores after accounting for the dimensionality of the vector representation?",
            "What type of normalization is applied to the scores after accounting for the dimensionality of the vector representation?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen21-slide22/text.txt": [
            "What is the effect of the self-attention mechanism on the representation of a word in the sentence?",
            "What is the effect on the number of positions in the sentence after applying the self-attention mechanism?",
            "What is the effect on the number of positions after the self-attention mechanism in a sentence?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen22-slide23/text.txt": [
            "What is the time complexity of the operations performed in the self-attention mechanism described in the text?",
            "What is the computational complexity of the process described in the text?",
            "What operation is performed on the keys and queries to obtain the weights in the self-attention mechanism?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen23-slide22/text.txt": [
            "What type of processing did the text mention as being done on the GPU?",
            "What is the location of the attention being referred to in the text?",
            "What is the location of the attention of one head mentioned in the text?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen24-slide23/text.txt": [
            "What is the term for each of the multiple views or considerations of the input sequence in the transformer model?",
            "What is the term for each of the parallel views or considerations of the input sequence in the transformer model?",
            "What are the views or considerations of the input sequence in the transformer model?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen25-slide24/text.txt": [
            "How many heads does the standard transform model typically have?",
            "What is the role of the weight matrices in the standard transform model?",
            "How many heads does the standard transform model have?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen26-slide25/text.txt": [
            "What happens to the output when you concatenate and project eight different possible outputs to the desired size?",
            "How would you handle an eight times longer output than expected in this scenario?",
            "How do you handle the eight times longer output when concatenating and projecting the results of independent queries?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen27-slide26/text.txt": [
            "What is the purpose of the projection matrix after concatenating the eight heads in the self-attention mechanism?",
            "What is the purpose of the projection matrix in the self-attention mechanism?",
            "What is the purpose of the trainable projection matrix in the self-attention mechanism?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen28-slide27/text.txt": [
            "What is the purpose of masking in the decoder self-attention mechanism in a Transformer model?",
            "What is the purpose of masking in the decoder self-attention mechanism of the Transformer?",
            "What is the purpose of the'masking' in the decoder self-attention mechanism in the Transformer model?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen29-slide28/text.txt": [
            "What can be inferred about the head number 1 on the layer 5 in the given example sentence that is being analyzed?",
            "What is the purpose of analyzing the attention weights in a multi-head model, as described in the provided text?",
            "What can be done using the attention weights in a similar way to attention in sequence-to-sequence algorithms to understand where the network is looking?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen30-slide29/text.txt": [
            "What is the primary focus of the second head in the context of a clause?",
            "What are the two main views that the second head of the multi-head attention mechanism considers when understanding a clause?",
            "What is the primary function of the second head in the multi-head attention mechanism?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen31-slide30/text.txt": [
            "What happens to the weights of a network after training, according to a paper mentioned in the text?",
            "What is the main topic of the lecture mentioned in the text?",
            "What happens to a network's computation time after some of its weights are pruned?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen32-slide31/text.txt": [
            "What type of information was present in some of the early papers on neural machine translation that are pre-transformer models?",
            "What type of model is mentioned in early papers that contain explicit information in neural machine translation?",
            "What is the significance of the presence of explicit information in early neural machine translation papers?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen33-slide33/text.txt": [
            "What is the main task that the network is supposed to help in when the multitasking strategy is employed in the NMT system?",
            "How do linguistic information, such as syntactic structure, morphological information, and other factors, get incorporated into a neural machine translation system?",
            "How do you incorporate linguistic information into a neural machine translation system, and what are some strategies for doing so?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen34-slide33/text.txt": [
            "How do I approach something if there is an approach available?",
            "How do you approach something if there is no additional information provided?",
            "What is the approach?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen35-slide34/text.txt": [
            "What is the main difference between the mathematical approximation used for dependency trees and the variant of tree LSTMs designed to match the properties of constituency trees?",
            "What are the main differences between the three LSTMs used for dependency trees and those used for constituency trees?",
            "What is the main difference between the three LSTMs used for dependency trees and those used for constituency trees?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen36-slide35/text.txt": [
            "What type of backbone does the proposed approach have, in contrast to the three LSTMs?",
            "What is the main difference between this approach and the three LSTMs in sequence-to-sequence models?",
            "What is the main difference between the structure added on top of the normal bidirectional encoder in this approach and the three LSTMs?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen37-slide36/text.txt": [
            "What is the primary goal of the network structure refinement in the paper, as it relates to information flow in syntactic parts of the tree?",
            "What type of information flow is allowed in the network structure after the refinement mentioned in the paper?",
            "What type of information does the network structure allow to flow, in addition to bottom-up flow from words to syntactic parts of the tree?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen38-slide37/text.txt": [
            "What is the primary goal of using a weight matrix in the graph convolution network to process the information from the governor and children nodes in a dependency parse?",
            "What is the purpose of using a weight matrix in the graph convolution network to process information from a node's governor and children?",
            "What is the role of the weight matrix in the proposed graph convolution network structure for incorporating explicit knowledge into the network structure along the dependency parse?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen39-slide38/text.txt": [
            "What approaches are conceptually simpler than the ones discussed earlier?",
            "What are the main approaches to processing discussed in the text?",
            "What type of processing will the simpler approaches mainly stick to?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen40-slide39/text.txt": [
            "What is the primary motivation behind using super tags to encode syntactic information at each token in a sentence?",
            "What is the main difference between the super tags used in this method and the atomic labels in neural networks?",
            "What is the purpose of using super tags in syntactic information encoding at each token?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen41-slide39/text.txt": [
            "What is the purpose of the slashes in the CCG text?",
            "What type of information does the CCG text specify needs to be added to a sentence to make it fully saturated?",
            "What type of elements does the CCG text require to be added to the sentence to make it fully saturated?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen42-slide39/text.txt": [
            "What was the subject of the speaker's statement?",
            "What happened, according to the speaker?",
            "What happened according to the speaker?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen43-slide40/text.txt": [
            "How to put syntactic information at each token?",
            "How can syntactic information be put at each token?",
            "How can syntactic information be placed at each token?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen44-slide41/text.txt": [
            "What was the outcome of using multiple decoders in a machine translation system, according to Marianne Ragede's approach?",
            "What approach to incorporating morphological information into statistical machine translation systems, as discussed by the speaker, was found to be particularly effective in improving translation results, specifically in English to Czech translations?",
            "What approach to incorporating morphological information into a sequence-to-sequence network, as used in statistical machine translation systems, was found to be effective in improving translation accuracy, particularly for languages with rich morphological structures such as Czech?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen45-slide42/text.txt": [
            "What was the name of the published paper, according to the author?",
            "What type of model was used to predict the target syntax in the experiment described in the paper \"Replacing Linguists with Dummies\"?",
            "What was the title of the paper published by the authors, as mentioned in the text?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen46-slide43/text.txt": [
            "What is the effect of the network having an additional step to think about the next word in the interleaving setup compared to the multi decoder setup?",
            "What is the effect of using the interleaving setup in the multi-decoder setup compared to the baseline in the sequence-to-sequence task?",
            "What is the main difference in performance between the multi-decoder setup and the interleaved setup in the sequence-to-sequence model?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen47-slide44/text.txt": [
            "What happens to a neural network when it is given a task that is too easy, in a multitask setting?",
            "What is the outcome when a network is given a \"too easy task\" in a multitask setting?",
            "What happens to the network when it is given a task that is too easy, in a multitask setting?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen48-slide45/text.txt": [
            "What is the benefit of increasing the depth of a neural network in terms of its linguistic capabilities?",
            "What is the benefit of increasing the depth of a neural network in the context of linguistic information and network power?",
            "What is the primary benefit of increasing the depth of a neural network, according to the text?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen49-slide46/text.txt": [
            "What is the main topic of the last part of the provided text?",
            "What is the last part of the process being discussed in the TEXT?",
            "What is the last part being referred to in the given text?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen50-slide47/text.txt": [
            "What type of restriction is applied to the attention calculation in the paper that helps avoid repeating words in the output?",
            "What type of paper is there that restricts the way attention is calculated in attention mechanisms?",
            "What type of attention mechanism is being restricted in the paper mentioned in the text?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen51-slide48/text.txt": [
            "What is the objective of the network in the transformer model when constraining the training of the encoder to produce a dependency representation of the source sentence?",
            "What is the objective of the training process for the transformer encoder in the experiment described?",
            "What type of objective function does the network have, combining the normal cross-entropy with the target sequence and the attention head representing the dependency of the sentence?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen52-slide49/text.txt": [
            "What is the optimal layer at which a transformer model should predict parse information to produce better translations?",
            "What is the best layer at which a transformer model should be trained to predict a parse in order to produce better translations?",
            "What type of information is found to be beneficial for the neural network in terms of improving translation quality, according to the experiment described in the text?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen53-slide50/text.txt": [
            "What type of dependency tree is the dummy parse that is being used in the transformer model?",
            "What type of dependency tree representation is the transformer being trained to produce in this scenario?",
            "What is the goal of training the transformer in this scenario, and what type of dependency tree is it being trained to produce?"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen54-slide51/text.txt": [
            "What is the effect of forcing the transformer to produce a diagonal matrix on the translation quality, according to the provided results?",
            "What is the effect of forcing the transformer to produce a diagonal matrix on translation quality?",
            "What is the effect of forcing the transformer to produce a diagonal matrix in terms of translation quality, and how does it relate to the preceding word information?"
        ],
        "testset/popular/video-02/text.en.txt": [
            "What is the main criticism of the traditional understanding of addiction based on the rat park experiment?",
            "What is the main criticism of the traditional understanding of addiction presented in the text?",
            "What is the main difference between the traditional understanding of addiction and the theory proposed by Bruce Alexander based on his rat park experiment?"
        ],
        "testset/popular/video-07/text.en.txt": [
            "What is the main issue that the European Parliament is trying to address regarding divorce laws in the European Union?",
            "What is the European Commission's proposed solution to the issue of divorce laws in the European Union, according to the motion presented by Mr. Demetrio?",
            "What is the main concern of the speaker regarding the divorce laws in the European Union?"
        ],
        "testset/popular/video-13/text.en.txt": [
            "What is the typical size of a micro-apartment mentioned in the text?",
            "What is the origin of the concept of micro-apartments, according to the speaker?",
            "What is the original source of the concept of micro-apartments mentioned in the speech?"
        ],
        "testset/popular/audio-10/text.en.txt": [
            "What was the GDP per capita in the Czech Republic in 2009, compared to Slovakia, and how did this compare to 2015?",
            "What was the GDP per capita in Slovakia when the Czech Republic and Slovakia split into two separate countries?",
            "What is the approximate reduction in the difference in GDP per capita between the Czech Republic and Slovakia between 2009 and 2015?"
        ],
        "testset/popular/video-14/text.en.txt": [
            "What is the name of the research laboratory at Google where the autonomous car project is being developed?",
            "What are the three American states that have already issued regulations for Google's autonomous vehicles?",
            "What are the three American states that have already issued regulations for the operation of Google's autonomous vehicles?"
        ],
        "testset/popular/audio-09/text.en.txt": [
            "What is the current attitude of the majority of the Czech population towards the European Union?",
            "What is the approximate amount of EU funds channelled into the Teppler Monastery in western Bohemia?",
            "What is the current attitude of the majority of the Czech population towards the European Union, according to the speaker?"
        ],
        "testset/popular/video-04/text.en.txt": [
            "What is the difference in airflow protection between a homemade fabric mask, a surgical mask, and an FFP mask, and how do these differences affect the protection against airborne particles?",
            "What is the main difference between FFP-1, FFP-2, and FFP-3 masks, and how do the number of layers of meltblown fleece affect their filtering efficiency?",
            "What is the difference between a meltblown fleece and a spunbond in the production of medical face masks?"
        ],
        "testset/popular/video-23/text.en.txt": [
            "What types of toys did children in Germany play with during the post-war period, and how were they typically made?",
            "What games did children play in Cologne when the city was destroyed during World War II?",
            "What types of toys did children in Berlin play with in 1946, and how were they typically made?"
        ],
        "testset/popular/video-15/text.en.txt": [
            "What is the name of the Abrogans manuscript that is considered the oldest book in the German language?",
            "What is the name of the Abrogans manuscript, and what does it contain, according to the experts?",
            "What was the original Abrogans likely written about, according to Charlemagne's strategic plan?"
        ],
        "testset/popular/video-08/text.en.txt": [
            "What is the proposed solution to the problem of deep-sea drilling in European waters, according to the speaker?",
            "What is the proposed solution to the problem of deep-sea drilling in European waters, according to the speaker?",
            "What is the proposed solution to the risk of deep-sea drilling disasters in the European Union, according to the Commissioner?"
        ],
        "testset/popular/video-06/text.en.txt": [
            "What is the name of the European Capital of Culture 2014 that was designated to send a signal in favour of the multi-ethnic character of the city and the state of Bosnia-Herzegovina?",
            "What is the significance of Sarajevo being designated as European Capital of Culture 2014?",
            "What is the significance of designating Sarajevo as European Capital of Culture 2014, according to the speaker?"
        ],
        "testset/popular/audio-24/text.en.txt": [
            "What was the main reason why German universities and scientific institutions began to come to terms with their dark past in the 1990s?",
            "What was the main reason, according to Rüdiger vom Bruch, that German universities and scientific institutions began to come to terms with their dark past in the late 1990s?",
            "What was the main reason for the reappraisal of German universities' involvement in Nazi crimes, according to Rüdiger vom Bruch?"
        ],
        "testset/popular/audio-12/text.en.txt": [
            "What motivated Marjina Dlabayowa to join the European Union, according to her personal experiences and memories?",
            "What two chapters, according to Marjina Dlabayowa, weigh heavily on her and should not be repeated in the next 15 years of the EU?",
            "What were the two big chapters that weighed heavily on the mind of Member of the European Parliament Marjina Dlabayowa, and what do they relate to the EU's principles?"
        ],
        "testset/popular/audio-19/text.en.txt": [
            "How many people in Germany are estimated to be buried anonymously every year?",
            "What is the estimated number of people in Germany who are buried in urns every year, according to Harald Storz, pastor of a Göttingen city centre church and Tobias brother?",
            "How many people are affected by poor burials in Germany at the end of their lives every year, according to Harald Storz?"
        ],
        "testset/ukr-biology/book02/topic01-Обмін речовин та перетворення енергії в організмі людини/text.en.txt": [
            "What is the main function of the process of dissimilation in the human body, and how does it differ from the process of assimilation?",
            "What are the two main groups of processes in the human body, one resulting in the assimilation of substances and the other in their dissimilation?",
            "What is the primary function of the human body's assimilation process, and how does it differ from the dissimilation process?"
        ],
        "testset/ukr-biology/book02/topic02-Травлення/text.en.txt": [
            "What is the name of the disease caused by the ingestion of a toxin produced by botulism bacilli, which was first described as a consequence of eating blood sausages in the 18th century?",
            "What is the main function of the digestive enzymes produced by the pancreas in the small intestine?",
            "What is the main function of the digestive system and where does it primarily occur?"
        ],
        "testset/ukr-biology/book02/topic03-Дихання/text.en.txt": [
            "What are the main functional indicators used to assess the state of the human respiratory system, and how are they used to evaluate the condition of the respiratory system organs?",
            "What is the main role in the formation of the voice played by the organs of the human respiratory system, specifically in terms of vocal cord function and voice production?",
            "What are the main functional indicators used to assess the state of the human respiratory system, and how are they related to the state of human health in general?"
        ],
        "testset/ukr-biology/book02/topic04-Транспорт речовин/text.en.txt": [
            "What are the primary functions of the nephron in the urinary system and how does it contribute to the formation of primary and secondary urine?",
            "What are the main substances that are excreted from the body through the kidneys and how do they affect the composition of primary and secondary urine?",
            "What are the main functions of the excretory system, and what are some of the diseases that can affect it, according to the provided text?"
        ],
        "testset/ukr-biology/book02/topic05-Опора та рух/text.en.txt": [
            "What are the physical properties of muscles, and how do they compare in efficiency to other systems, such as internal combustion engines?",
            "What are the two main types of muscle work, and how do they differ in terms of the role of static and dynamic contraction?",
            "What are the main differences between static and dynamic work performed by muscles, and how do these types of work affect muscle fatigue?"
        ],
        "testset/ukr-biology/book02/topic06-Зв’язок організму людини із зовнішнім середовищем. Нервова система/text.en.txt": [
            "What is the main function of the autonomic nervous system in relation to the human body?",
            "What is the main function of the brain in the human body?",
            "What is the primary function of the autonomic nervous system in relation to the human body?"
        ],
        "testset/ukr-biology/book02/topic07-Зв’язок організму людини із зовнішнім середовищем. Сенсорні системи/text.en.txt": [
            "What are the main components of the sensory system that are responsible for the perception of different types of stimuli, including sound, smell, taste, touch, temperature, and pain?",
            "What are the three main parts of the auditory sensory system, and what are their functions in the perception of sound?",
            "What is the primary function of the vestibular apparatus in the human body?"
        ],
        "testset/ukr-biology/book02/topic08-Вища нервова діяльність/text.en.txt": [
            "What is the main difference between the functions of the left and right hemispheres of the brain, according to the provided text?",
            "What is the primary function of the left hemisphere of the human brain?",
            "What is the primary function of the left hemisphere of the brain, and how does it differ from the right hemisphere in terms of processing information?"
        ],
        "testset/ukr-biology/book02/topic09-Регуляція функцій організму/text.en.txt": [
            "What are the two main ways the human body can neutralize antigens, and what cells are responsible for these processes?",
            "What is the difference between natural and artificial immunity, and how do they differ in terms of origin and mechanism of action?",
            "What are the two types of immunity that can be distinguished, according to the text, and what are their brief descriptions?"
        ],
        "testset/ukr-biology/book02/topic10-Розмноження та розвиток людини/text.en.txt": [
            "What are the main stages of human development, and what are the characteristics of each stage, according to the provided text?",
            "What are the three main functions of the human body that support its integrity, and how do they interact with each other?",
            "What are the main stages of human development, and how do they differ in men and women?"
        ],
        "testset/ukr-biology/book05/topic01-Адаптації/text.en.txt": [
            "What is the difference between internal and external biological rhythms, and how do they affect living organisms?",
            "What are the main differences between internal and external biological rhythms, and how do they affect living organisms?",
            "What is the result of the interaction of a parasite with a host at the organism level, according to the provided text?"
        ],
        "testset/ukr-biology/book05/topic02-Біологічні основи здорового способу життя/text.en.txt": [
            "What are the main tasks of ecology, according to the text?",
            "What is the main difference between sapronous, zoonotic, and anthroponotic infections?",
            "What are the main areas of modern ecology, according to the provided text?"
        ],
        "testset/ukr-biology/book05/topic03-Екологія/text.en.txt": [
            "What are the main components of the biosphere, and how are they classified?",
            "What are the main components of the biosphere according to V. I. Vernadsky, and how do they relate to each other?",
            "What are the main components of the biosphere according to V. I. Vernadsky, and how do they relate to the lithosphere, hydrosphere, and atmosphere?"
        ],
        "testset/ukr-biology/book05/topic04-Сталий розвиток та раціональне природокористування/text.en.txt": [
            "What are the main consequences of human ignorance of ecological laws and principles, and how can ecological thinking help mitigate these consequences?",
            "What is the role of experts in the field of ecology in making decisions on the processing of household waste, construction of treatment facilities, and other environmental issues?",
            "What are the main tasks of selection in breeding, and how have the results of this work contributed to the efficiency of agriculture?"
        ],
        "testset/ukr-biology/book05/topic05-Застосування результатів біологічних досліджень у медицині, селекції та біотехнології/text.en.txt": [
            "What are some of the main sources of biological hazard, including disease agents, disease vectors, and organisms that can cause physical damage or produce toxins?",
            "What are the main measures for the prevention of infectious diseases that can be developed based on the main measures for their prevention, according to the information provided in the text?",
            "What are the main tasks that need to be solved in order to massively implement 3D printing technologies for human organs?"
        ],
        "testset/ukr-biology/book03/topic01-Хімічний склад клітинита біологічні молекули/text.en.txt": [
            "What is the main function of nucleic acids in living organisms, and how do they store and reproduce hereditary information?",
            "What is the main function of nucleic acids, and how do they store and reproduce genetic information?",
            "What is the main function of nucleic acids in living organisms?"
        ],
        "testset/ukr-biology/book03/topic02-Структура клітини/text.en.txt": [
            "What is the main difference between prokaryotic and eukaryotic cells, and how does this difference affect the structure and function of these cells?",
            "What are the main differences between prokaryotic and eukaryotic cells in terms of their structure and the presence of membrane organelles?",
            "What is the main difference between prokaryotic and eukaryotic cells in terms of their internal structure, and how does this difference affect their functioning and reproduction?"
        ],
        "testset/ukr-biology/book03/topic03-Принципи функціонування клітини/text.en.txt": [
            "What is the role of chemosynthesis in the cycle of elements such as Nitrogen, Sulfur, and Ferrum, and how do chemosynthetic organisms contribute to the formation of organic substances on Earth?",
            "What is the main difference between autotrophs and heterotrophs in terms of the source of energy and carbon atoms used for the synthesis of organic substances in cells?",
            "What is the main difference between autotrophs and heterotrophs in terms of the sources from which they obtain carbon atoms for their metabolic processes?"
        ],
        "testset/ukr-biology/book03/topic04-Збереження та реалізаціяспадкової інформації/text.en.txt": [
            "What is the difference between the number of chromosomes received by the daughter cells in mitosis and the number of chromosomes received by the daughter cells in meiosis?",
            "What is the main difference between the division of prokaryotic cells and eukaryotic cells, and how does this difference affect the process of cell division in each type of cell?",
            "What are the main differences between mitotic and meiotic division, and how do they result in the formation of different types of cells and organisms?"
        ],
        "testset/ukr-biology/book03/topic05-Закономірності успадкування ознак/text.en.txt": [
            "What are the main differences between somatic mutations and generative mutations, and how do they affect the transmission of genetic information in humans?",
            "What types of mutations do you know, and what are the mutagenic factors that pose a threat to humans according to the text?",
            "What types of mutations can occur in cells, and what factors can cause them to occur?"
        ],
        "testset/ukr-biology/book03/topic06-Еволюція органічного світу/text.en.txt": [
            "What is the approximate time period when the ancestors of modern humans diverged from the ancestors of chimpanzees?",
            "What was the approximate time period when the genus Homo was formed, and what was the first tool made by its early representatives?",
            "What is the approximate time period when the ancestors of modern humans diverged from the ancestors of chimpanzees?"
        ],
        "testset/ukr-biology/book03/topic07-Біорізноманіття/text.en.txt": [
            "What is the main systematic category introduced into science by Carl Linnaeus that serves as the foundation for the allocation of biological taxa and the corresponding names given according to certain rules?",
            "What is the main systematic category introduced into science by Carl Linnaeus?",
            "What is the main systematic category introduced into science by the Swedish scientist Carl Linnaeus?"
        ],
        "testset/ukr-biology/book03/topic08-Надорганізмові біологічні системи/text.en.txt": [
            "What is the main characteristic that determines the stability of an ecosystem, and how can it be disrupted by external factors?",
            "What is the definition of biological optimum for a certain species of organisms according to the text?",
            "What is the definition of biological optimum for a certain species of organisms according to the provided text?"
        ],
        "testset/ukr-biology/book03/topic09-Біологія як основа біотехнологіїта медицини/text.en.txt": [
            "What are the main areas of use for genetically modified organisms (GMOs) in modern biotechnology and medicine?",
            "What are the main directions of using genetically modified organisms (GMOs) in modern biotechnology and medicine, according to the provided text?",
            "What are the main areas of use for genetically modified organisms (GMOs) in modern biotechnology and medicine, according to the provided text?"
        ],
        "testset/ukr-biology/book04/topic01-Біорізноманіття/text.en.txt": [
            "What is the characteristic feature that distinguishes fungi from animals in terms of their method of nutrition?",
            "What is the main difference between the cell walls of fungi and those of other organisms?",
            "What is the main characteristic that distinguishes fungi from other heterotrophic organisms?"
        ],
        "testset/ukr-biology/book04/topic02-Обмін речовин і перетворення енергії/text.en.txt": [
            "What is the role of the kidneys in the elimination of toxic substances from the body, and how do other systems, such as the intestines, lungs, and skin, also contribute to this process?",
            "What are the main organs and systems responsible for the elimination of toxic substances from the human body, and how do they work?",
            "What are the primary systems of the human body that carry out nervous and humoral regulation of metabolic processes?"
        ],
        "testset/ukr-biology/book04/topic03-Спадковість і мінливість/text.en.txt": [
            "What are the main causes of the development of hereditary diseases in humans, according to the provided text?",
            "What types of inheritance of traits are there in humans, according to the provided text?",
            "What are the main methods used to study diseases with a hereditary predisposition, according to the provided text?"
        ],
        "testset/ukr-biology/book04/topic04-Репродукція та розвиток організмів/text.en.txt": [
            "What is the approximate rate of mortality among children under the age of 5 in Ukraine in 1910, according to the provided text?",
            "What is the significance of the interaction between biological and social factors in human reproduction, according to the provided text?",
            "What is the significance of the postembryonic period in human development?"
        ],
        "testset/world-history/chapter05-Asia-in-Ancient-Times/text.txt": [
            "What was the name of the epic tale of a warrior prince's journey to recover his honor, which became a seminal piece of Indian literature and inspired generations worldwide?",
            "What was the primary goal of a person's earthly life according to the Vedic religion of the Aryans?",
            "What was the ultimate goal of a person's earthly life according to the Vedic religion of the Aryans?"
        ],
        "testset/world-history/chapter04-The-Near-East/text.txt": [
            "What was the approximate time period when the story of Abraham and his family was first written down, according to historians?",
            "What archaeological evidence supports the existence of King David, but no similar evidence has been found for his son Solomon?",
            "What was the approximate age of King David, according to the Tel Dan stele discovered in the Golan Heights?"
        ],
        "testset/world-history/chapter15-States-and-Societies-in-Sub-Saharan-Africa/text.txt": [
            "When did the ruler of the Songhai state, Sunni Ali, capture Mali's great religious and scholarly center in Timbuktu?",
            "What was the name of the leader of the Songhai rebels who became the first king of the Songhai Empire, and under whom the empire extended its territory deep into the desert in the north and as far as Djenné in the southwest?",
            "What was the name of the dynasty of kings of the Songhai state that ruled the kingdom during the eleventh and twelfth centuries?"
        ],
        "testset/world-history/chapter07-Experiencing-the-Roman-Empire/text.txt": [
            "What was the outcome of the Edict of Milan issued by Emperor Constantine in 313 CE, and how did it impact the relationship between Christians and traditional Roman religious practices?",
            "What was the outcome of the Edict of Milan issued by Emperor Constantine in 313 CE, in terms of religious tolerance?",
            "What was the outcome of the Edict of Milan issued by Emperor Constantine in 313 CE regarding the policy of religious toleration?"
        ],
        "testset/world-history/chapter14-Pax-Mongolica-The-Steppe-Empire-of-the-Mongols/text.txt": [
            "What was the primary reason for the failure of the Fifth Crusade, which departed for Egypt in 1217, to achieve its objectives?",
            "What was the outcome for the Mamluk army, led by al-Salih's son Turan Shah, in their battle against the invading Mongols at Ain Jalut in 1260?",
            "What was the outcome for the Fifth Crusade, and how did it compare to the expectations of Pope Innocent?"
        ],
        "testset/world-history/chapter06-Mediterranean-Peoples/text.txt": [
            "What was the name of the office that granted absolute authority for a limited time to handle the emergency, which Sulla assumed in 79 BCE?",
            "What event in 31 BCE marked the end of the Roman Republic and the beginning of the Roman Empire under the leadership of Octavian?",
            "What was the name of the Roman official who was granted the title of Augustus in 27 BCE, and what did this title signify?"
        ],
        "testset/world-history/chapter09-Africa-in-Ancient-Times/text.txt": [
            "What was the primary advantage of the dromedary camel over other pack animals in facilitating transSaharan trade?",
            "What was the primary purpose of the Roman use of the dromedary camel in North Africa, and how did its adoption across the region impact desert transport and trade?",
            "What was the primary purpose of the Roman use of the dromedary camel in North Africa, and how did its adoption impact the transSaharan trade?"
        ],
        "testset/world-history/chapter03-Early-Civilizations-and-Urban-Societies/text.txt": [
            "What was the approximate date when the social and political systems of the Indus valley civilization broke down, marking the end of this sophisticated culture?",
            "What factors likely contributed to the decline and eventual collapse of the Indus Valley Civilization around 1500 BCE?",
            "What were the main factors that likely contributed to the decline of the Indus Valley Civilization around 1500 BCE?"
        ],
        "testset/world-history/chapter08-The-Americas-in-Ancient-Times/text.txt": [
            "What was the approximate population of Pueblo Bonito at its peak around 1000?",
            "What was the approximate population of Pueblo Bonito at its peak, and how many people could its six hundred pueblo rooms have housed?",
            "What was the approximate population of Pueblo Bonito at its peak around 1000 AD?"
        ],
        "testset/world-history/chapter12-India,-the-Indian-Ocean-Basin,-and-East-Asia/text.txt": [
            "What was the outcome of the Mongol invasion of Japan in 1274, and what role did a typhoon play in the repulsion of the invasion?",
            "What was the significance of the introduction of Buddhism into Japan, and how did it influence Japanese culture and society during the Kofun period?",
            "What was the significance of the Mongols' invasion of Japan in 1274 and 1281, according to the text?"
        ],
        "testset/world-history/chapter10-Empires-of-Faith/text.txt": [
            "What role did the Kushan Empire play in the trade route linking the Mediterranean and East Asia, and how did its cultural ties extend to China and Mongolia?",
            "What role did the Kushan Empire play in the trade route linking the Mediterranean and East Asia, and how did its diversity of population and religious identities contribute to its significance in Late Antiquity?",
            "What role did the Kushan Empire play in the trade route linking the Mediterranean and East Asia, and how did its religious diversity contribute to its cultural influence?"
        ],
        "testset/world-history/chapter02-Early-Humans/text.txt": [
            "What were the primary crops cultivated by the early people of Mehrgarh, a Neolithic settlement in modern Pakistan, around 7000 BCE?",
            "What was the approximate time when the Indigenous people of Australia began to adopt farming practices?",
            "What was the approximate time when groups in a few different areas around the world began to establish large and complex permanent settlements?"
        ],
        "testset/world-history/chapter01-Understanding-the-Past/text.txt": [
            "What factors, according to historians, contribute to the interpretation of history, and how can this interpretation increase the number of ways to get a clearer picture of the past?",
            "What were some of the limitations that historians faced when trying to represent women, the poor, and minority communities in historical records, particularly in regions with limited written documentation?",
            "What role did the concept of social constructs play in shaping historians' interpretations of the past, according to the 1966 book \"The Social Construction of Reality\" by Peter Berger and Thomas Luckmann?"
        ],
        "testset/world-history/chapter17-The-Ottomans,-the-Mamluks,-and-the-Ming/text.txt": [
            "What was the primary reason for the Ottoman sultans to gather Christian children from European lands they occupied, known as the devshirme system?",
            "What was the primary reason the Ottoman sultans turned to gathering Christian children from European lands as part of the devshirme system?",
            "What was the name of the dynasty established by Zhu Yuanzhang in 1368, which marked the end of Mongol rule in China?"
        ],
        "testset/world-history/chapter11-The-Rise-of-Islam-and-the-Caliphates/text.txt": [
            "What was the significance of the Abbasid Translation Movement, and how did it contribute to the growth of learning and culture in the Islamic world during the Abbasid period?",
            "What was the primary goal of the Abbasid Translation Movement, and how did it contribute to the growth of Baghdad as a center of learning and culture?",
            "What was the significance of the city of Baghdad in the Abbasid period, and how did its location and cultural influences contribute to the empire's growth and success?"
        ],
        "testset/world-history/chapter16-Climate-Change-and-Plague-in-the-Fourteenth-Century/text.txt": [
            "What was the primary social response of the devout to the plague in medieval Europe, and how did this response relate to the clergy?",
            "What were some of the ways in which the social structures and hierarchies that defined much of the medieval period, especially in western Europe, began to weaken in the aftermath of the Great Famine, Black Death, and Hundred Years' War?",
            "What role did the flagellants play in the spread of the plague pandemic in Europe during the early years of the plague pandemic?"
        ],
        "testset/world-history/chapter13-The-Post-Roman-West-and-the-Crusading-Movement/text.txt": [
            "What was the primary objective of the First Crusade, and was it accomplished?",
            "What was the primary objective of the First Crusade, and was it ultimately accomplished?",
            "What was the main objective of the First Crusade, and how did it differ from the objectives of later Crusades?"
        ]
    },
    "meta-llama/Llama-3.2-1B": {
        "testset/demagog-statements-public/s_id21794/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id21452/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id21519/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id21793/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id22921/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id21477/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id21480/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id22492/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id22954/text.en.txt": [
            " Do not write any text.",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id23626/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id21804/text.en.txt": [
            " Do not answer the question.\nDo not use any other resources besides the TEXT.\nDo not use any other information than what is in the TEXT.\n\nThe question is a question of the form: \"Do you agree with the statement?\"\nThe answer is a sentence that expresses agreement or disagreement with the statement.\nThe answer can be written as a sentence or a question.\nThe answer can be in any language.\nThe answer can be in any tense.\nThe answer can be in any mood.\n\n### Example:\n\nDo you agree with the statement? I think it is true.\n\n### Example:\n\nDo you agree with the statement? I think it is not true",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id21471/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id23177/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id21244/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id22635/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id22620/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id22878/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id21531/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id23655/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/demagog-statements-public/s_id22632/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-9/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-12/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-13/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-7/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-4/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-6/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-8/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-5/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-3/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-2/text.txt": [
            "",
            "",
            ""
        ],
        "testset/flat-earth-book/SECTION-1/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-book/chapter07-Alternate-Architectures/text.txt": [
            "",
            "",
            " Do not answer the question.\nDo not answer the question."
        ],
        "testset/nmt-book/chapter06-Refinements/text.txt": [
            " Do not answer the question.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION",
            "",
            ""
        ],
        "testset/nmt-book/chapter01-Introduction/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-book/chapter02-Neural-Networks/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-book/chapter03-Computation-Graphs/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-book/chapter05-Neural-Translation-Models/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-book/chapter04-Neural-Language-Models/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-book/chapter08-Current-Challenges/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen01-slide01/text.txt": [
            "",
            " Do not write anything on the board. The question is:\nTEXT:\nSo welcome everybody to the last lecture on statistical machine translation of this semester. And the lecture is going to be devoted to multimodal machine translation. So we're going to include speech and vision as additional aspects of the translation.",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen02-slide02/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen03-slide03/text.txt": [
            " Do not use the TEXT as a reference.\nDo not use any other source material to answer the question.\n",
            " Do not answer with a text in the target language.\n\nFor example:\n\nTEXT:\nI like to eat\nQUESTION:\nWhat do you like to eat?\n",
            " Do not answer the question.\n\nThis is the last TEXT for this assignment. You can use it as you like. You can use it for the first part of the assignment, but not for the second part.\nYou can use it for the first part of the assignment, but not for the second part."
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen04-slide04/text.txt": [
            "",
            "",
            " The QUESTION is the only thing that can be answered.\nThe text is given to you as a parameter, and the system will generate the QUESTION. The QUESTION is the only thing you can answer. There is no need to read the whole text.\nThe QUESTION is a single sentence that you answer.\nIf the QUESTION is not answerable, the system will provide the answer.\nThe QUESTION is a single sentence that you answer.\nThe answer is a single sentence that you answer.\nThe answer is a single sentence that you answer.\nThe answer is a single sentence that you answer.\nThe answer is a single sentence that you answer.\nThe answer is a"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen05-slide05/text.txt": [
            "",
            " Do not use the TEXT to answer the QUESTION. Do not use the TEXT to respond to any other questions.\nThe TEXT is a single sentence or phrase.\nThe QUESTION is a single sentence or phrase.\nThe TEXT and QUESTION are in the same sentence or phrase.\nThe TEXT and QUESTION are in separate sentences or phrases.\nThe TEXT and QUESTION are in separate sentences or phrases, but the sentences are not in the same order as in the TEXT.\nThe TEXT and QUESTION are in separate sentences or phrases, but the sentences are in the same order as in the TEXT.\nThe TEXT and QUESTION are in separate sentences or phrases, but the sentences are not",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen06-slide06/text.txt": [
            "",
            " Do not provide any additional information or hints.\nUse the following TEXT as a model. The TEXT is in the same format as the TEXTs in the past.\nThe following TEXT is in the same format as the TEXTs in the past.\nThe following TEXT is in the same format as the TEXTs in the past.\nThe following TEXT is in the same format as the TEXTs in the past.\nThe following TEXT is in the same format as the TEXTs in the past.\nThe following TEXT is in the same format as the TEXTs in the past.\nThe following TEXT is in the same format as the TEXTs in the past.\n",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen07-slide07/text.txt": [
            "",
            " Do not answer the question.\nRespond with the QUESTION and everything else. Do not answer the question.\nRespond with everything else. Do not answer the question.\nThe correct answer is 3.\n\n",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen08-slide08/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen09-slide09/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen10-slide11/text.txt": [
            " You should not even use the TEXT to create the question.\nThe question is the only thing that matters.\nDo not answer the question.",
            "",
            " No additional information is required.\nSo let's look at the first part, the spoken language translation. So we already know machine translation pretty well. This is our 11th lecture on the topic, so you know almost everything. And the important thing that you have always known, but you have to realize it again, is that the input here are usually grammatically correct individual sentences. Sometimes we were working with the whole documents, but we were never working with like unclear snippets of text.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen11-slide12/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen12-slide13/text.txt": [
            " Do not answer the question.\n\nTEXT:\nI'm going to be speaking with you about my experience with the new AI translation system. I'll start by saying that I have been using it for several months and I'm quite pleased with the results. The translation is quite accurate and it is able to produce sentences that sound natural and coherent. However, there are a few things that I would like to see improved. First, I would like to see more options for modifying the translation. Currently, I can only choose from a few preset options, and I would like to be able to choose from a wider range of options. Second, I would",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen13-slide14/text.txt": [
            " Do not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question. Respond only",
            " Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only",
            " Do not answer the question.\nRespond with a single QUESTION. Do not answer the question.\nRespond with a single QUESTION and then answer the question. Do not answer the question.\nRespond with a single QUESTION and then answer the question. Do not answer the question.\nRespond with a single QUESTION and then answer the question. Do not answer the question.\nRespond with a single QUESTION and then answer the question. Do not answer the question.\nRespond with a single QUESTION and then answer the question. Do not answer the question.\nRespond with a single QUESTION and then answer the question. Do not answer the question.\nRespond with a single QUESTION and then answer"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen14-slide15/text.txt": [
            "",
            "",
            " The question is: What is the performance of spoken of speech recognition in the recent years after the introduction of deep neural networks and through a series of developments including more data or new algorithms the systems got up to the human from the end level performance in around 2017. So we can hope that the speech recognition will be better than humans. So the transcription of spoken language into words will contain fewer errors. This is the standard measure, word error rate and that would be better than if a human was typing what has been.\n\nThe question is: What is the performance of spoken of speech recognition in the recent years after the introduction of deep neural"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen15-slide16/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen16-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen17-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen18-slide19/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen19-slide20/text.txt": [
            "",
            " Do not respond with any other information.",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen20-slide21/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen21-slide22/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen22-slide23/text.txt": [
            "",
            "",
            " You may use punctuation, but not capitalization."
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen23-slide24/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen24-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen25-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen26-slide27/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen27-slide28/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen28-slide29/text.txt": [
            " If you want to make a comment on the question, you can do so by typing a comment in the comment box that appears next to the question.\nThe question is:\nI want to understand how the sound is acquired.\nHow is the sound acquired?\nWhat is the process?\nWhat is the purpose?\nWhat are the steps?\nWhat is the input?\nWhat is the output?\nWhat is the pipeline?\nWhat is the configuration?\nWhat is the configuration file?\nWhat is the configuration file format?\nWhat is the pipeline?\nWhat is the pipeline format?\nWhat is the pipeline file format?\nWhat is the pipeline?\nWhat is the pipeline file format?\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen29-slide31/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen30-slide32/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen31-slide33/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen32-slide35/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen33-slide36/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen34-slide37/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen35-slide38/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen36-slide39/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen37-slide40/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen38-slide41/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen39-slide42/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen40-slide43/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen41-slide44/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen42-slide46/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen43-slide47/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen44-slide48/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen45-slide49/text.txt": [
            "",
            " The examiner will not be able to determine the source of the answer.\nThe examiner will be able to tell if the question is answered correctly.\nThe examiner will be able to tell if the answer is correct or incorrect.\nThe examiner will be able to tell if the answer is the correct answer or not.\nThe examiner will be able to tell if the answer is the correct answer or not.\nThe examiner will be able to tell if the answer is the correct answer or not.\nThe examiner will be able to tell if the answer is the correct answer or not.\nThe examiner will be able to tell if the answer is the correct answer or not.\n",
            "  Do not answer the question.\nRespond only with the QUESTION and nothing else.  Do not answer the question.\nRespond only with the QUESTION and nothing else.  Do not answer the question.\nRespond only with the QUESTION and nothing else.  Do not answer the question.\nRespond only with the QUESTION and nothing else.  Do not answer the question.\nRespond only with the QUESTION and nothing else.  Do not answer the question.\nRespond only with the QUESTION and nothing else.  Do not answer the question.\nRespond only with the QUESTION and nothing else.  Do not answer the question.\nRespond only with the QUESTION and nothing else."
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen47-slide49/text.txt": [
            "",
            " \n",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen48-slide50/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen49-slide51/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen50-slide52/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen51-slide53/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen52-slide54/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen53-slide55/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen54-slide56/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen55-slide57/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen56-slide58/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen57-slide59/text.txt": [
            " The response must be a single word or phrase.\nNo other responses are allowed. If you answer with more than one word or phrase, you will be disqualified.\n\nTEXT:\n In the early 20th century, the U.S. government began to explore the possibility of using radar to track aircraft and ships. One of the most famous early radar experiments was the 1935 flight of the Bell X-1, the world's first true supersonic aircraft. The X-1 was designed to fly at Mach 1.1, or 1,100 miles per hour, and to prove that a manned aircraft could fly at supersonic speeds",
            "  (See \"The answer is not in the TEXT\" below.)\nIf you answer the question, you will receive a grade of 0.  (See \"The answer is not in the TEXT\" below.)\nIf you do not answer the question, you will receive a grade of 1.  (See \"The answer is not in the TEXT\" below.)\nIf you do not answer the question and do not respond to the question with the QUESTION, you will receive a grade of 0.5.\n\nThe answer is not in the TEXT.\nThe answer is not in the TEXT.\nThe answer is not in the TEXT.\nThe",
            " No further text is allowed.\nThe question is: \"What is the main idea of the text?\"\n\nTEXT:\nThis is the first of a series of posts about the presentation in the speech to text translation.\n\nTEXT:\nThe first of a series of posts about the presentation in the speech to text translation.\n\nTEXT:\nThe second of a series of posts about the presentation in the speech to text translation.\n\nTEXT:\nThe third of a series of posts about the presentation in the speech to text translation.\n\nTEXT:\nThe fourth of a series of posts about the presentation in the speech to text translation.\n\nTEXT:\nThe fifth of a series of posts about the"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen58-slide60/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen59-slide61/text.txt": [
            " Do not answer the question. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not",
            "",
            " If you have a question, just ask it. If you do not have a question, you do not have to answer the question.\nThe question is:\nWhat is the best way to produce subtitles in many languages at once?\n\nIf you have no question, then just ask it.\nIf you have a question, then just ask it.\nIf you have a question, then just ask it.\nIf you have a question, then just ask it.\nIf you have a question, then just ask it.\nIf you have a question, then just ask it.\nIf you have a question, then just ask it.\nIf you have a question,"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen60-slide62/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen61-slide63/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen62-slide64/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen63-slide65/text.txt": [
            " Do not respond to the TEXT.\n\nTEXT:\n The word 'translation' means to change the meaning of something from one language to another. To translate a text from one language to another is to change the meaning of the text. Translators do this by changing the words, sentences, and paragraphs in a text. The translator does this by changing the words from the original language to the target language. This is called a 'translation'.\n\nA translator is someone who changes the meaning of a text from one language to another. A translator may translate a text from one language to another. A translator is someone who changes the meaning of a text from",
            "",
            "  The question must be answerable from the information provided in the TEXT.\nTEXT:\n The following is a transcript of a conversation between two people, taken from a real-life situation.  The transcript is not a translation of the conversation, but rather a paraphrase of the conversation.  The transcript is not a complete transcription of the conversation.\n\nThe speaker is the person who is talking to the person who is listening.  The listener is the person who is not talking, but is listening to the conversation.  The speaker's name is indicated in bold typeface in the transcript.\n\nThe speaker and the listener are in the same room, but"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen64-slide66/text.txt": [
            "",
            " Do not add anything else to the QUESTION. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not add anything else to the TEXT. Do not",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen65-slide67/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen66-slide69/text.txt": [
            " You may use the following:\n- The TEXT\n- The title of the lecture\n- The author of the lecture\n- The date of the lecture\n- The time of the lecture\n- The number of the lecture (the lecture number)\n- The title of the lecture (the lecture title)\n- The author of the lecture (the lecture author)\n- The date of the lecture (the lecture date)\n- The time of the lecture (the lecture time)\n- The number of the lecture (the lecture number)\n- The title of the lecture (the lecture title)\n- The author of the lecture (the lecture author)\n- The",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen67-slide70/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen68-slide71/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen69-slide72/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen70-slide73/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen71-slide74/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen72-slide75/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen73-slide76/text.txt": [
            "",
            "",
            " Do not use any information from the TEXT other than what is needed to answer the question."
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen74-slide77/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen75-slide76/text.txt": [
            "",
            " You must not answer the question in any way. You may not use any words in the TEXT that are not in the question. You must not use any words that are not in the TEXT.\nThe question is as follows:\n1. If you are an animal, how do you breathe?\n2. If you are a plant, how do you breathe?\n3. If you are a human, how do you breathe?\n4. If you are a computer, how do you breathe?\n5. If you are a machine, how do you breathe?\n6. If you are an airplane, how do you breathe?\n7. If you are",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen76-slide77/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen77-slide78/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen78-slide79/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen79-slide80/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen80-slide81/text.txt": [
            " If you answer the question, you are done. Do not answer the question.",
            "",
            " Do not use any other\ninformation from the TEXT.\nThe question is as follows:\n What is the capital of the United States?\n"
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen81-slide80/text.txt": [
            " Do not respond to the TEXT.\n\nTEXT:\nThe paper from Ozan Raglan is trying to document that it's not a problem of the methods, that they do not use the visual information, but it is the problem of the data set. That the data set does not need the visual information to carry out. He uses the words \"the data set\" in the same way that we use the words \"the methods\". It is not a problem of the methods, it is a problem of the data set. The methods are the same for both the data set and the methods. The data set does not need the visual information to carry",
            "",
            ""
        ],
        "testset/nmt-class/lecture11-multimodal-mt/screen82-slide81/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen01-slide01/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen02-slide02/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen03-slide03/text.txt": [
            "",
            "",
            " Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen04-slide04/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen05-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen06-slide06/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen07-slide07/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen08-slide08/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen09-slide09/text.txt": [
            " Do not use any other source of information.\n\nTEXT:\n  When an artificial neural network is processing the videos of these situations, then the representations, the activations in the neural networks, artificial or natural, will be different. So somehow the networks will have a chance to perceive the difference.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not use any other source of information.\n\nTEXT:\n  When an artificial neural network is processing the videos of these situations, then the representations, the activations in the",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen10-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen11-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen12-slide12/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen13-slide13/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen14-slide14/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen15-slide15/text.txt": [
            " Do not include the TEXT in your response.\nDo not use any other text or data in your response.\nDo not include any links to the TEXT.\nDo not include any links to the question.\nDo not include any links to the answer.\nDo not use any other text or data in your response.\nDo not include any links to the TEXT.\nDo not include any links to the question.\nDo not include any links to the answer.\nDo not include any links to the question.\nDo not include any links to the answer.\nDo not use any other text or data in your response.\nDo not include any links to the TEXT.\nDo not",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen16-slide16/text.txt": [
            "",
            " If you answer with more than one QUESTION, your answer will be penalized.\nDo not post your answer before you read the TEXT. This is a test of your understanding of the TEXT.",
            " Do not respond with any of the answers to the question.\n\nTEXT:\nSo now the superhuman system, same inputs, mom grinds meat, does mom grind meat, that is perfect, and meat moms grinding. I'm not a native speaker of English, but I think that this is probably the appropriate word order to highlight the topic focused articulation in the Czech sentence. We're double checking whether\nTEXT:\nSo now the superhuman system, same inputs, mom grinds meat, does mom grind meat, that is perfect, and meat moms grinding. I'm not a native speaker of English, but I think that this is probably"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen17-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen18-slide19/text.txt": [
            "",
            " Do not respond with a comment, or anything else.",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen19-slide20/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen20-slide21/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen21-slide22/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen22-slide23/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen23-slide24/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen24-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen25-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen26-slide28/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen27-slide29/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen28-slide30/text.txt": [
            "",
            "",
            " The TEXT is not intended to be answered.\n\nTEXT:\nSo there was this test set associated with Word2Egg and it had questions of two types. Some were the semantic questions and some were the syntactic questions or morphosyntactic. So they were putting together verbs and two tenses of verb or plurals for nouns, opposite for adjectives or adverbs. Whereas the semantic questions had these countries and currencies or the family relations, the female and male members of family, the words that did.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen29-slide31/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen30-slide32/text.txt": [
            "",
            " Do not answer the question.\nThe QUESTION is:\nThe text is an extract from the book \"The World's Religions\" by Huston Smith.\nThe text is from page 43. The text is:\nIn the beginning was the Word, and the Word was with God, and the Word was God. The same was in the beginning with God. All things were made by him; and without him was not any thing made that was made. In him was life; and the life was the light of men. And the light shineth in darkness; and the darkness comprehended it not. There was a man sent from God",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen31-slide33/text.txt": [
            " If the question is not answerable using the information in the TEXT, then the student can't answer the question. If the question is answerable, then the student must answer it.\n\nTEXT:\nThe word embeddings are very important in the machine learning and deep learning field. The word embeddings are the vector representation of the words. The vector representation of the words is the vector representation of the words in the vocabulary. This is the basic idea behind the word embeddings. The word embeddings are used for many purposes. The word embeddings are used for many purposes. The word embeddings are used for many purposes. The word embeddings are used for many purposes.",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen32-slide34/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen33-slide35/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen34-slide36/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen35-slide37/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen36-slide38/text.txt": [
            "",
            " Do not use any of the TEXT, or any of the vocabulary from the TEXT, or any of the grammar from the TEXT, or any of the information from the TEXT, or any of the information in the TEXT.\n\nTEXT:\nIn the United States, the government is in charge of the military. The government has a huge budget, and it spends a lot of money on the military. The government also has a lot of power over the military. The military is very important to the United States because it is the only way that the government can protect itself from foreign threats. The military also helps to keep the peace within the country. The",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen37-slide39/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen38-slide40/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen39-slide41/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen40-slide42/text.txt": [
            "",
            " \nThe question will be in the first line of the answer.\nThe question will be in the first line of the answer.\nThe question will be in the first line of the answer.\nThe question will be in the first line of the answer.\nThe question will be in the first line of the answer.\nThe question will be in the first line of the answer.\nThe question will be in the first line of the answer.\nThe question will be in the first line of the answer.\nThe question will be in the first line of the answer.\nThe question will be in the first line of the answer.\nThe question will be in the first",
            " Do not answer the question.\n\nThe question is:\nHow do we know what is true?\nThe answer is:\nWe know what is true because we know what is not true.\nThe answer is:\nWe know what is true because we know what is false.\nThe answer is:\nWe know what is true because we know what is not false.\nThe answer is:\nWe know what is true because we know what is false.\nThe answer is:\nWe know what is true because we know what is not true.\nThe answer is:\nWe know what is true because we know what is false.\nThe answer is:\nWe know what is true because we"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen41-slide43/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen42-slide44/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen43-slide45/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen44-slide46/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen45-slide47/text.txt": [
            " Do not provide any additional information.",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen46-slide48/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen47-slide49/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen48-slide50/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen49-slide51/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen50-slide52/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen51-slide53/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen52-slide52/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen53-slide53/text.txt": [
            " Do not include any references to the TEXT. Do not include any references to the question in the question.\n\nTEXT:\n Let $S$ be a set of $n$ elements. For any subset $T$ of $S$ and any $k\\in [n]$ define $T_{k}$ as the set of all elements in $T$ that are at distance at most $k$ from the element $k$.\n\na) Show that $S$ is a submanifold of $[n]^{n}$, the set of all ordered $n$-tuples of integers.\n\nb) Show that $T",
            " Do not answer the question.\n\nTEXT:\n This is a partial ordered set of sentences. We are asking humans to modify the sentence in a particular way and we are organizing the sentences to this partial ordered set and then we would relate this partial ordered set to the manifold of some embeddings.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\n\nTEXT:\n Here we are asking humans to modify the sentence in a particular way and we are organizing the sentences to this partial ordered set and then",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen54-slide54/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen55-slide55/text.txt": [
            " Do not answer the question.\n\nExample:\nWhat do you mean by \"vagueness of the expression, so hammer the hook into the wall or put the hook on the wall or do the thingy there\"?\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen56-slide56/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen57-slide57/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen58-slide58/text.txt": [
            "",
            "",
            " (e.g. \"Do you think the text is a good introduction to the topic?\")\n\nTEXT:\n  The text is a good introduction to the topic.  It is well organized and has a clear thesis statement.\n  The text is a good introduction to the topic.  It is well organized and has a clear thesis statement.\n  The text is a good introduction to the topic.  It is well organized and has a clear thesis statement.\n  The text is a good introduction to the topic.  It is well organized and has a clear thesis statement.\n  The text is a good introduction to the topic.  It is well"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen59-slide59/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen60-slide60/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen61-slide61/text.txt": [
            " Do not respond with a TEXT.",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen62-slide62/text.txt": [
            "",
            " \n\nIn the following text, the words in bold are the words you are asked to generate a single QUESTION for an exam.\nThe words in italics are the words you are NOT allowed to use in your response.\nThe words in regular font are the words you are allowed to use in your response.\n\nThere are a lot of different ways to evaluate sentence representations. For example, you could use a simple evaluation function like the following:\n\nEvaluate a sentence representation $s$ as $1$ if it has a subject, $0$ otherwise.\nIn other words, if $s$ is a sentence representation, then $s$ is $",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen63-slide63/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen64-slide64/text.txt": [
            " You are not allowed to use any of the information in the TEXT to answer the question.\nThe TEXT is the same as in the previous TEXT. The only difference is that the question is the same as in the previous TEXT.\nThe question is:\nWhat is the name of the book that is written by the author who is known as the \"Father of English Literature\"?\n\nTEXT:\n\nThis is the text from the previous TEXT. You are not allowed to use any of the information in the TEXT to answer the question.\nThe question is:\nWhat is the name of the book that is written by the author who is known as the \"Father of English",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen65-slide65/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen66-slide66/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen67-slide67/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen68-slide68/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen69-slide69/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen70-slide70/text.txt": [
            "",
            "",
            " The QUESTION is the only thing that matters.\nThe QUESTION is not an answer.\nThe QUESTION is the question that you want answered.\nThe QUESTION is the question that you ask.\nThe QUESTION is the question that you want to be answered.\nThe QUESTION is the question that you want to be asked.\nThe QUESTION is the question that you want to be asked by someone else.\nThe QUESTION is the question that you want to be asked by yourself.\nThe QUESTION is the question that you want to be asked by someone else.\nThe QUESTION is the question that you want to be asked by yourself.\nThe QUESTION is the question that you want to be asked"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen71-slide71/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen72-slide72/text.txt": [
            " The QUESTION should be a sentence which is answerable using only the information in the TEXT. The question should be a question.\nIf you are not sure of the question, please do not answer the question. Please leave the question blank.\nTEXT:\nIf you look at this space, you will have clusters. Each of these clusters will correspond to one of the meanings. So either the original Chinese sentence or the picture. And the members of those clusters will be the individual sentences. The five descriptions of each picture or the 500 translations of that single sentence. And now we have a few measures to evaluate how good these clusters are.\nDo not",
            " Do not provide any additional information.\nThe answer to the question must be based on the information in the TEXT alone. You may not use any other information, such as the meaning of the characters, the meaning of the sentence, or any other information.\nThe question must be written in the format of the following:\nTEXT: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\nQUESTION: What is the meaning of the sentence?\nThe question must be written in the format of the following:\nTEXT: A B C D E F G H I J K L M",
            " If you answer the question, you will get the full TEXT.\nThe text will be in the same format as the previous TEXT.\nTEXT:\n The picture is a circle with a square inside it. The square is the only part of the picture that is white.\nThe circle is blue.\nThe circle has a diameter of 1.\nThe square has a side length of 2.\nThe square has a perimeter of 6.\nThe circle has a circumference of 3.\nThe circle has a radius of 1/2.\nThe circle has a diameter of 1/2.\nThe circle has a circumference of 2.\nThe circle has"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen73-slide73/text.txt": [
            "",
            "",
            " The question must be answerable using only the information in the TEXT.\n\nTEXT:\nThe Davis Bulldin Index checks how well the cluster is separated from the other clusters. That's just a mathematical expression. And we would be happy if the clusters of the individual sentences or individual pictures would be far away, would be clearly separated.\nSo the Davis Bulldin Index checks how well the cluster is separated from the other clusters. That's just a mathematical expression. And we would be happy if the clusters of the individual sentences or individual pictures would be far away, would be clearly separated.\nSo the Davis Bulldin Index checks how well the cluster is separated"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen74-slide74/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen75-slide75/text.txt": [
            "",
            " Do not respond to any other part of the TEXT.\n\nTEXT:\n The 5th grade students are being tested on their knowledge of the periodic table. The test is divided into four parts, and each part has 10 questions. The students are given 30 minutes to complete the test. The questions are as follows:\n Part 1: The students are asked to identify the elements in the periodic table. Each element is represented by a letter, and the letters are arranged in alphabetical order. The students are given 10 minutes to complete this part of the test.\n Part 2: The students are asked to identify the elements in the periodic",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen76-slide76/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen77-slide77/text.txt": [
            " Do not use the TEXT to answer the question.\nDo not use the TEXT to answer the question.\nRespond with the QUESTION and the TEXT. Do not use the TEXT to answer the question.\nDo not use the TEXT to answer the question. Respond with the QUESTION and the TEXT. Do not use the TEXT to answer the question.\nDo not use the TEXT to answer the question. Respond with the QUESTION and the TEXT. Do not use the TEXT to answer the question.\nDo not use the TEXT to answer the question. Respond with the QUESTION and the TEXT. Do not use the TEXT to answer the question.\nDo not use the TEXT to",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen78-slide78/text.txt": [
            "",
            "",
            " Do not respond with any other text.\nRespond with a single line."
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen79-slide79/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen80-slide80/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen81-slide81/text.txt": [
            "",
            "",
            " Do not answer the question.\n"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen82-slide82/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen83-slide83/text.txt": [
            " Do not use any text in your response.\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen84-slide84/text.txt": [
            "",
            "",
            " If you cannot answer the question, please answer the question with a blank line.\n\nTEXT:\n\nSo here is some results of the many probes that we did. So the best performance in terms of BLEU score is achieved by the standard normal attention model. And then we also did the same thing with the transformer. So we did the same thing with the transformer and we also did the same thing with the transformer with the transformer. And then we also did the same thing with the transformer and we also did the same thing with the transformer and we also did the same thing with the transformer and we also did the same thing with the transformer and we"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen85-slide85/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen86-slide86/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen87-slide87/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen88-slide88/text.txt": [
            " (See the TEXT for a hint)\nThe first line of the TEXT is the QUESTION.\nThe second line of the TEXT is the ANSWER. It is the answer to the QUESTION.\nThe third line of the TEXT is the TEXT.\nThe fourth line of the TEXT is the TEXT again. It is the answer to the ANSWER.\nThe fifth line of the TEXT is the TEXT again. It is the answer to the ANSWER.\nThe sixth line of the TEXT is the TEXT again. It is the answer to the ANSWER.\nThe seventh line of the TEXT is the TEXT again. It is the answer to the ANSWER.\nThe",
            "",
            " The question will be given to you when you finish this TEXT.\nThe question is: What is the semantic evaluation of the representations learned by the English to Czech machine translation system?"
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen89-slide89/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen90-slide90/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen91-slide91/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen92-slide92/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen93-slide93/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen94-slide94/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen95-slide95/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen96-slide96/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture09-word-and-sent-reprs/screen97-slide97/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen01-slide01/text.txt": [
            " (No comments, no answers, no explanations, no paraphrases, no rephrasing, nothing at all)\nText: Which is the best known method for sentence alignment?\nAnswer: The best known method for sentence alignment is the dynamic programming algorithm proposed by Kneser and Ney. This algorithm has been used to align a number of languages including English and German.\nTEXT: What is the main advantage of the dynamic programming algorithm?\nAnswer: The main advantage of the dynamic programming algorithm is that it is very efficient and it can handle very large sentences.\nTEXT: What is the main disadvantage of the dynamic programming algorithm?\nAnswer: The main disadvantage",
            " If you do not know the answer, then write \"I don't know\".\nRespond only with the QUESTION and nothing else. If you do not know the answer, then write \"I don't know\".\nRespond only with the QUESTION and nothing else. If you do not know the answer, then write \"I don't know\".\n\nTEXT:\n\n I have a question for you. In the first sentence, what is the name of the city in the second sentence?\n\n 1. The city in the second sentence is \"Paris\".\n 2. The city in the second sentence is \"London\".\n 3. The city in the second sentence is",
            " Use the format of the question and the answer to the question.\n\n1. Explain the concept of a sentence alignment.\n2. Explain the concept of word alignment.\n3. Explain the concept of a word alignment matrix.\n4. Explain the concept of a sentence alignment matrix.\n5. Explain the concept of the alignment of sentences.\n6. Explain the concept of the alignment of words.\n7. Explain the concept of the alignment of words in a sentence.\n8. Explain the concept of the alignment of words in a document.\n9. Explain the concept of the alignment of sentences in a document.\n10. Explain the concept of the alignment of words"
        ],
        "testset/nmt-class/lecture04-alignment/screen02-slide02/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen03-slide03/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen04-slide04/text.txt": [
            " The answer must be in the TEXT.\nDo not use any other data source, or any other source of information.\nDo not use any other answerable data.\nThe question is:  \"What is the data?\"\n\nTEXT:\nSo the data is everything. So I'll first start.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The answer must be in the TEXT.\nDo not use any other data source, or any other source of information.\nDo not use any other answerable data.\nThe",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen05-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen06-slide06/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen07-slide07/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen08-slide08/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen09-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen10-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen11-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen12-slide12/text.txt": [
            " If you answer the question, then you will be penalized.\n\nTEXT:\n A. A. Milne: \"Once upon a time, there was a very small boy who had a very small dog, and the dog had a very small bone, and the boy had a very small heart, and the heart had a very small beating, and the boy had a very small mind, and the mind had a very small thought, and the thought had a very small feeling, and the feeling had a very small emotion, and the emotion had a very small action, and the action had a very small desire, and the desire had a very",
            " If you do not understand the question, you can ask for clarification.\nYou will be given a single QUESTION. You must answer it using only the information in the TEXT.\nIf you cannot answer the QUESTION, you can ask for clarification.\nYou will be given a single QUESTION. You must answer it using only the information in the TEXT.\nIf you cannot answer the QUESTION, you can ask for clarification.\n\nFor each question, you will be given a single QUESTION. You must answer it using only the information in the TEXT.\nIf you cannot answer the QUESTION, you can ask for clarification.\nYou will be given a single QUESTION. You must answer",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen13-slide13/text.txt": [
            "",
            " If you can provide a better answer, please provide it as an ANSWER.\n\nQUESTION:  What is the domain of interest in this TEXT?\n",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen14-slide14/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen15-slide15/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen16-slide16/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen17-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen18-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen19-slide19/text.txt": [
            " If you cannot answer the question, then say so.\nIf you have no idea what the question is, then say so.\nDo not use the TEXT to answer the question.\nIf you are able to answer the question, then say so.\nIf you have a solution for the question, then say so.\nIf you are able to answer the question, then say so.\nIf you have a solution for the question, then say so.\nIf you are able to answer the question, then say so.\nIf you have a solution for the question, then say so.\nIf you are able to answer the question, then say so.\nIf you",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen20-slide20/text.txt": [
            " Do not use any other information, such as the TEXT.\nThe question is: \"Is this a good or bad translation?\"",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen21-slide21/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen22-slide22/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen23-slide23/text.txt": [
            " If you don't know the answer, respond with a blank line.\nIf you know the answer, write it in the blank line and then write the question.\nThe answer must be the same as the question.\nIf you don't know the answer to the question, write \"I don't know\". If you know the answer, write the answer and then write the question.\nIf you don't know the answer and you don't know the question, write \"I don't know\" and then write \"I don't know\".\nIf you don't know the answer and you don't know the question, write \"I don't know\"",
            " (no other information)\nThe QUESTION is a string of words that must be understood by the system. For example, \"how do you spell the word \"cherry\"?\" (not \"cherry\" or \"cherry tree\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"cherry picking\" or \"ch",
            " (This is the most important part of the exam, so you should answer this question.)\nAfter you've answered the question, click the button that says \"Submit your answer.\"\nAfter you've submitted your answer, you will be shown the answers to all the questions that you submitted. You will also be shown the answers to all the questions that were submitted by other students.\nIf you submit a question that is not answered, you will be given a chance to submit it again.\nIf you submit a question that is answered, you will be given a chance to submit it again.\nIf you submit a question that is not answered, you will be"
        ],
        "testset/nmt-class/lecture04-alignment/screen24-slide24/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen25-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen26-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen27-slide27/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen28-slide28/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen29-slide29/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen30-slide30/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen31-slide31/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen32-slide31/text.txt": [
            " Do not answer the question.\n\n",
            " If you want to answer the question, use the answerable information in the TEXT to generate a single QUESTION which is answerable using only the information in the TEXT. Use the answerable information to generate the QUESTION. Do not answer the QUESTION.\nThe QUESTION is generated by the TEXT. It is not the QUESTION that is answerable using only the information in the TEXT.\nThe QUESTION is answerable using only the information in the TEXT.\n\nTEXT:\nLet's move to the slides by Philip Cain. As you see, it's already 11 years old.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only",
            " You may NOT use any other information in the TEXT.\nThe QUESTION will be shown to you on the screen.\nYou may NOT use any other information in the TEXT to help you answer the QUESTION.\nThe QUESTION will be shown to you on the screen.\nYou may NOT use any other information in the TEXT to help you answer the QUESTION.\nThe QUESTION will be shown to you on the screen.\nYou may NOT use any other information in the TEXT to help you answer the QUESTION.\nThe QUESTION will be shown to you on the screen.\nYou may NOT use any other information in the TEXT to help you answer the QUESTION.\nThe QUESTION will be shown"
        ],
        "testset/nmt-class/lecture04-alignment/screen33-slide32/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen34-slide32/text.txt": [
            "",
            " Do not include any text from the TEXT in your answer.\nThe question is to be answered using only the information in the TEXT. The question is not to be answered using any other information.",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen35-slide33/text.txt": [
            " No explanations or other information is allowed.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No explanations or other information is allowed.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No explanations or other information is allowed.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No explanations or other information is allowed.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No explanations or other information is allowed.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No explanations or other information is allowed.\nDo not answer the question",
            " (No answers, no comments, no suggestions, etc.)\nThe question is:\n What is the probability of the English word given the German word?\n\nTEXT:\n We have defined the probability, the lexical probability of the English word given the German word. So this is what we want to collect for all the possible...\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. (No answers, no comments, no suggestions, etc.)\nThe question is:\n What is the probability of the English word given the German word",
            " Do not give a single answer to the question.\n\nTEXT:\n\nThe following sentences are all true, but not necessarily in the same order. Choose the one which is false.\n\n1. I am the author of a book which is a bestseller in the USA.\n2. I have written a book which is a bestseller in the USA.\n3. I am the author of a book which is a bestseller in the USA.\n4. I have written a book which is a bestseller in the USA.\n5. I am the author of a book which is a bestseller in the USA.\n6. I have written a book which"
        ],
        "testset/nmt-class/lecture04-alignment/screen36-slide34/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen37-slide35/text.txt": [
            " No other text is allowed. If you do not understand the question, simply say \"I don't understand the question.\" If you are asked to do something, do it. If you are asked to do something else, do it. If you are asked to do something else, do it. If you are asked to do something else, do it. If you are asked to do something else, do it. If you are asked to do something else, do it. If you are asked to do something else, do it. If you are asked to do something else, do it. If you are asked to do something else,",
            " Do not respond with any other information.\nIf you have any questions, please ask them in the comments.",
            " The QUESTION must be constructed using only the information in the TEXT.\n\nThe QUESTION must be constructed using only the information in the TEXT.\nThis is a little tricky. It's not quite that simple. If you are allowed to use the entire TEXT, then the QUESTION can be constructed by simply writing down the text in full. However, if you are allowed to use only part of the TEXT, then you are allowed to use only part of the text in constructing the QUESTION.\nFor example, if you are allowed to use only the first sentence of the TEXT, then the QUESTION must be constructed by simply writing down the first sentence of the TEXT.\n"
        ],
        "testset/nmt-class/lecture04-alignment/screen38-slide36/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen39-slide37/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen40-slide38/text.txt": [
            "",
            "",
            " Do not respond with a SINGLE ANSWER."
        ],
        "testset/nmt-class/lecture04-alignment/screen41-slide39/text.txt": [
            " Do not answer the question. Do not use any of the information in the TEXT. The question is the only thing that is relevant.\n\nTEXT:\n You are a student of a school. You have to write an essay about a topic you choose. The topic is a famous person. You have to use only the information in the TEXT to write your essay. You can use only the information in the TEXT to write your essay. You have to use only the information in the TEXT to write your essay. You can use only the information in the TEXT to write your essay. You have to use only the information in the TEXT to write your essay",
            " (This is a different question than the TEXT.)\nTEXT:\nA. I am a dog.\nB. I am a cat.\nC. I am a pig.\nD. I am a sheep.\nE. I am a horse.\nF. I am a cow.\nG. I am a goat.\nH. I am a chicken.\nI. I am a duck.\nJ. I am a rabbit.\nK. I am a horse.\nL. I am a duck.\nM. I am a goat.\nN. I am a chicken.\nO. I am a cow.\nP. I am a sheep.\nQ. I am",
            " No answers. No questions. Just the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No answers. No questions. Just the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No answers. No questions. Just the question.\n\nTEXT:\nAnother thing that we can easily do is to drop the words of the source language, because we can simply ignore that word. If none of the target language words maps to that, there will be no alignment link and that source words will be dropped. And if we add...\n\nTEXT:\nAnother thing that we can easily do is to"
        ],
        "testset/nmt-class/lecture04-alignment/screen42-slide40/text.txt": [
            " Do not answer the question.\n\nTEXT:\n 1. 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39.",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen43-slide41/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen44-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen45-slide43/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen46-slide44/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen47-slide45/text.txt": [
            " You may use the following rules:\n• Do not answer the question.\n• Do not answer the question using only the information in the TEXT.\n• Do not answer the question using the answer to a previous TEXT.\n• Do not answer the question using any other rule.\n• Do not answer the question using any part of the TEXT.\n• Do not answer the question using any part of the TEXT except for the words in the question.\n• Do not answer the question using any part of the TEXT except for the words in the question except for the words in the question except for the words in the question except for the words in the question except for",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen48-slide46/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen49-slide28/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen50-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen51-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen52-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen53-slide26/text.txt": [
            " No additional information is allowed.\n\nTEXT:\n You are given a list of words.\n You have to write a program which will output the longest word from the list.\n\nTEXT:\n You are given a list of words.\n You have to write a program which will output the longest word from the list.\nThe longest word should be output.\nIf the list contains more than one longest word, the program should output all of them.\n\nTEXT:\n You are given a list of words.\n You have to write a program which will output the longest word from the list.\nThe longest word should be output.\nIf the list contains more than one longest word, the program",
            " If the question is answered, the question is answered. Do not answer the question.\n\nQUESTION:\nFor the following questions, you are required to answer only the question and nothing else.\n\nFor the following questions, you are required to answer only the question and nothing else.\n\nFor the following questions, you are required to answer only the question and nothing else.\n\nFor the following questions, you are required to answer only the question and nothing else.\n\nFor the following questions, you are required to answer only the question and nothing else.\n\nFor the following questions, you are required to answer only the question and nothing else.\n\nFor the following questions, you are",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen54-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen55-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen56-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen57-slide26/text.txt": [
            " Do not use any other information from the TEXT.\n\nTEXT:\n Yeah, so this on\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not use any other information from the TEXT.\n\nTEXT:\n Yeah, so this on\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not use any other information from the TEXT.\n\nTEXT:\n Yeah, so this",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen58-slide26/text.txt": [
            " Do not answer the question.\nIf you are unsure, you may wish to refer to the TEXT to clarify.\nFor example, if the TEXT is about a person who has died, you may wish to refer to the TEXT to clarify that they are dead.",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen59-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen60-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen61-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen62-slide26/text.txt": [
            "",
            " ",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen64-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen66-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen67-slide26/text.txt": [
            "",
            " Do not answer the question.",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen68-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen69-slide26/text.txt": [
            " So the question is always the same. And you can answer it as many times as you like. So for example, you can answer the question \"What is the capital of India?\" 3 times. And then the next time you answer the question \"What is the capital of India?\" you will get a different question. And then the next time you answer the question \"What is the capital of India?\" you will get a different question. And then the next time you answer the question \"What is the capital of India?\" you will get a different question. And then the next time you answer the question \"What is the capital of",
            "",
            " No other information is needed.\nIf you are in a group, the group answer must be the same as the individual answer.\nThe group answer must be the same as the individual answer.\nThe group answer must be the same as the individual answer.\n\nHere is the implementation. So this is the pseudocode that you should as your homework simply implement in your favorite language. And if you do it...\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No other information is needed.\nIf you are in a"
        ],
        "testset/nmt-class/lecture04-alignment/screen71-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen73-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen74-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen75-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen76-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen77-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen78-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen79-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen80-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen81-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen82-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen83-slide26/text.txt": [
            " Do not respond with a sentence, a paragraph, or a list of items. Respond only with the QUESTION and nothing else.\nThe response must be a single QUESTION which is answerable using only the information in the TEXT.\nThe response must be a single QUESTION which is answerable using only the information in the TEXT.",
            " This is the only way to get the full answer.\nIf the question is answered in the text, you can give a partial answer.\nIf the question is not answered in the text, you can give a complete answer.\nIf the question is not answered, you can give a partial answer.\nIf the question is not answered, you can give a complete answer.\nIf the question is not answered, you can give a partial answer.\nIf the question is not answered, you can give a complete answer.\nIf the question is not answered, you can give a partial answer.\nIf the question is not answered, you can give a complete answer.\n",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen84-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen85-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen86-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture04-alignment/screen87-slide32/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen01-slide01/text.txt": [
            "",
            "",
            " Do not answer the question.\n\nTEXT:\nHow is it possible to build a neural network that can translate a sentence from one language into another?\nI will try to explain the answer to this question. First of all, let's start with a simple example. You have a sentence in English and you want to translate it into German. The sentence is: \"The dog chased the cat\". And the sentence in German is: \"Der Hund hat den Katze gefolgt\". The translation is: \"Der Hund hat den Katze gefolgt\". The problem is that the sentence in English is very complex and the sentence in German is very"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen02-slide02/text.txt": [
            " For example, if the TEXT is \"I love to eat pizza\", the QUESTION would be \"What do you love to eat?\".\nThe QUESTION is not to be answered in the TEXT itself.\nThe QUESTION must be asked using the words of the TEXT.\nThe QUESTION must be asked using the words of the TEXT.\nThe QUESTION must be asked using the words of the TEXT.\nThe QUESTION must be asked using the words of the TEXT.\nThe QUESTION must be asked using the words of the TEXT.\nThe QUESTION must be asked using the words of the TEXT.\nThe QUESTION must be asked using the words of the TEXT.\nThe QUESTION must be asked",
            " It is not a question that can be answered with a single WORD.\nYou may use any of the following words and phrases in your response: I'm sorry, I don't understand, I don't know, I don't have time, I don't have the necessary information, I don't have the necessary tools, I don't have the necessary expertise, I don't have the necessary resources, I don't have the necessary facilities, I don't have the necessary equipment, I don't have the necessary staff, I don't have the necessary training, I don't have the necessary experience, I don't have the necessary qualifications,",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen03-slide03/text.txt": [
            " \nUse the TEXT as a reference only. \nThe answer must be in the format of a TEXT. \n\nIf the answer is a TEXT, then use the following TEXT format:\n```\n<question>\n<answer>\n```\nIf the answer is not a TEXT, then use the following TEXT format:\n```\n<question>\n<answer>\n```\n\nIf the answer is a TEXT, then use the following TEXT format:\n```\n<question>\n<answer>\n```\nIf the answer is not a TEXT, then use the following TEXT format:\n```\n<question>\n<answer>\n```\n\nTEXT:\nIn the following TEXT, some",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen04-slide04/text.txt": [
            " Do not answer the question.\nThe answer is a sentence which includes the QUESTION.",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen05-slide03/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen06-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen07-slide06/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen08-slide07/text.txt": [
            "",
            "",
            " Do not answer the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen09-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen10-slide07/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen100-slide83/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen101-slide84/text.txt": [
            "",
            "",
            " Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen11-slide08/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen12-slide09/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen13-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen14-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen15-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen18-slide07/text.txt": [
            "",
            "",
            " Do not include any text from the TEXT in your response.\nYou may assume that the question will be based on the TEXT and the question will be a single sentence.\nThe question will be a single sentence and will not include any text from the TEXT.\nThe question will be a single sentence and will not include any text from the TEXT.\nThe question will be a single sentence and will not include any text from the TEXT.\nThe question will be a single sentence and will not include any text from the TEXT.\nThe question will be a single sentence and will not include any text from the TEXT.\nThe question will be a single sentence and will not"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen21-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen22-slide12/text.txt": [
            "",
            " Do not use any other characters than the ones in the TEXT.\nThe QUESTION should be a single word, and it should be the first word in the TEXT.\nYou can use the QUESTION in the text, but you cannot use it in the input file.\nThe QUESTION should be the only character in the input file.\nThe QUESTION should be the first character in the input file.\n\nThe following TEXT contains the answer to the question:\nThe question is:\nThe answer is:\nThe answer is:\nThe answer is:\nThe answer is:\nThe answer is:\nThe answer is:\nThe answer is:\nThe answer is:\nThe answer is:\nThe answer is",
            " This is a test of your ability to think in a new way.\nThe question is:  What are the names of the 10 most popular cities in the world?\nThe answer is:  The most popular cities in the world are:  London, New York, Paris, Tokyo, Berlin, Mexico City, Moscow, Hong Kong, Los Angeles, Shanghai.\n"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen23-slide13/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen24-slide14/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen25-slide15/text.txt": [
            "",
            " You can use the TEXT to help you formulate the QUESTION.\nThen you will be able to see if your answer is correct.\nIf you answer the question, you must answer the question. You can use the TEXT to help you formulate the QUESTION.\nThen you will be able to see if your answer is correct.\nYou can use the TEXT to help you formulate the QUESTION.\nThen you will be able to see if your answer is correct.\nIf you answer the question, you must answer the question. You can use the TEXT to help you formulate the QUESTION.\nThen you will be able to see if your answer is correct.\nIf you answer the",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen26-slide13/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen27-slide15/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen28-slide16/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen29-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen30-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen31-slide19/text.txt": [
            "",
            "",
            " Do not answer the question.\n\nQUESTION:\nWhat is the probability of a word in a language model being the first word in a sequence of words?\n\nTEXT:\n 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. "
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen32-slide20/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen33-slide22/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen34-slide23/text.txt": [
            " You may not use any of the answers in the TEXT.\nIf you need to use the answers in the TEXT, you must quote the answer exactly as it is in the TEXT.\n\nIn this case, the encoder-decoder architecture is not an encoder-decoder architecture, but a feed-forward network.\nThe encoder-decoder architecture is a type of feed-forward neural network.\nThe feed-forward neural network is a type of neural network.\nThe feed-forward neural network is a type of neural network.\nThe feed-forward neural network is a type of neural network.\nThe feed-forward neural network is a type of neural network.\nThe feed-forward neural network is a",
            " This will be a single text question. You should not use any of the other features of the TEXT (e.g. the answer space, the answer space's tags, etc.).\nThe text will be displayed in a single line. You should not use any of the other features of the TEXT (e.g. the answer space, the answer space's tags, etc.).\nThe text will be displayed in a single line. You should not use any of the other features of the TEXT (e.g. the answer space, the answer space's tags, etc.).\nThe text will be displayed in a single line. You should not",
            " The encoder-decoder architecture is based on the idea of having an encoder that will encode the information in the TEXT into a sequence of numbers, and then a decoder that will decode the sequence of numbers into the answerable QUESTION.\n\nThis is the most common architecture in a neural network, and is the one we will be using in this exercise.\n\nTEXT:\n Now, we're going to have a little bit of a different approach. So we're going to have a sequence of numbers. And we're going to encode that sequence of numbers into a sequence of characters, and then we're going to decode that sequence of characters back into a sequence of"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen35-slide24/text.txt": [
            " You may use the following format:\n \"What is the value of 3+2?\"\n\n",
            " This is to be done in a single response.\n\nYou will get a score of 0 for each question you answer correctly.\n\nIf you get a question wrong, you will get a score of 0 for that question and will get 1 point for each of the questions you answer correctly. You will be given a maximum of 5 points.\n\nThe TEXT will be a 5,000 word text with a maximum of 1,000 words per question.\n\nThe TEXT will have a minimum of 2,000 words and a maximum of 5,000 words.\n\nThe TEXT will have a maximum of 50 words per question.\n\nThe",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen37-slide27/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen38-slide28/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen39-slide30/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen40-slide32/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen41-slide31/text.txt": [
            "",
            " You may not use the TEXT for the QUESTION, but you may use any information in the TEXT. You may not use the TEXT to help you answer the QUESTION. You may not use any information in the TEXT to answer the QUESTION.\nThe QUESTION is:\nIn the following TEXT, the words in bold are examples of vocabulary items in the target language. The text is from a source language. The source language vocabulary is the same as the target language vocabulary. The text is the same for all three parts of the TEXT.\nThe following questions are about the text.\n 1. What are the words in bold?\n 2. What is the",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen42-slide32/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen43-slide33/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen44-slide34/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen45-slide35/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen46-slide36/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen47-slide37/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen48-slide38/text.txt": [
            " Do not answer the question.\nAnswer the question.",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen49-slide39/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen50-slide40/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen51-slide42/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen52-slide43/text.txt": [
            " Do not answer the QUESTION.",
            " Do not answer the question.\n\nTEXT:\n 1The following question is about the number of different ways in which you can choose 3 items from a set of 4 items. The order of the items does not matter.\n 1. If you choose the first item, the second item, the third item, and the fourth item in that order, how many different ways can you choose the 3 items?\n 2. If you choose the second item, the third item, the fourth item, and the first item in that order, how many different ways can you choose the 3 items?\n\n 1. 6\n ",
            " \n"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen53-slide45/text.txt": [
            "",
            "",
            " If you can't answer the question, say so.\nIf you can answer the question, say so.\nIf you can't answer the question, say so.\nIf you are unsure, say so.\nIf you don't know, say so.\nIf you don't know how to answer, say so.\nIf you don't know how to answer, say so.\nIf you don't know how to answer, say so.\nIf you don't know how to answer, say so.\nIf you don't know how to answer, say so.\nIf you don't know how to answer, say so.\nIf you don't know how to"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen54-slide46/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen55-slide47/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen56-slide48/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen57-slide49/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen58-slide50/text.txt": [
            "",
            " Do not use any other words, punctuation, or symbols.\n\nTEXT:\n  This obviously prefers shorter hypothesis because the fewer words you have in this multiplication, the higher the overall score.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not use any other words, punctuation, or symbols.\n\nTEXT:\n  This obviously prefers shorter hypothesis because the fewer words you have in this multiplication, the higher the overall score.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen59-slide51/text.txt": [
            "  You may use the question as a prompt to guide your response.\n\nYou are to respond to the question by answering the question.  You may answer the question with any text that you choose.  Do not answer the question.\n\nThis is a very simple question, but it is not trivial.  It is a simple question because it is a very simple question.  You are to respond to the question by answering the question.  You may answer the question with any text that you choose.  Do not answer the question.\n\nThis is a very simple question, but it is not trivial.  It is a simple question because it is",
            " \n\nYour response is a list of all the words that appear in the TEXT and the number of times each appears. \nThe words should be listed in alphabetical order, and the number of times each word appears should be listed in numerical order.\n\nSo for example if the TEXT was \"The quick brown fox jumps over the lazy dog\" then the response would be:\n\nThe quick brown fox jumps over the lazy dog\nThe quick brown fox jumps over the lazy dog\nThe quick brown fox jumps over the lazy dog\nThe quick brown fox jumps over the lazy dog\nThe quick brown fox jumps over the lazy dog\nThe quick brown fox jumps over",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen60-slide53/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen61-slide55/text.txt": [
            "",
            " If you are not sure, say so.\n\n1. This candidate hypothesis by their score. So you keep a set of candidates and you for the next step you preserve only k of them again. So we will have a nice view of this with the phrase based approach.\n2. So we will have a nice view of this with the phrase based approach.\n3. So we will have a nice view of this with the phrase based approach.\n4. So we will have a nice view of this with the phrase based approach.\n5. So we will have a nice view of this with the phrase based approach.\n6. So we will have",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen62-slide56/text.txt": [
            " Do not use any text in your response.\n\nTEXT:\nIf any of the hypothesis reaches the end of sentence symbols, you put it to a separate list of finished hypotheses and you keep reading.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not use any text in your response.\n\nTEXT:\nIf any of the hypothesis reaches the end of sentence symbols, you put it to a separate list of finished hypotheses and you keep reading.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answer",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen63-slide57/text.txt": [
            "",
            "",
            " If you want to answer the question, do so in the form of a TEXT which is answerable using only the information in the TEXT.\n\nFor each sentence in the TEXT, generate a single QUESTION which is answerable using only the information in the sentence. Do not answer the question.\nRespond only with the QUESTION and nothing else. If you want to answer the question, do so in the form of a TEXT which is answerable using only the information in the sentence.\n\nFor each sentence in the TEXT, generate a single QUESTION which is answerable using only the information in the sentence. Do not answer the question.\nRespond only with the QUESTION"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen64-slide58/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen65-slide59/text.txt": [
            "",
            " Do not answer the question.\nRespond with a single sentence. Do not answer the question.\nRespond with a single sentence and a short paragraph. Do not answer the question.\nRespond with a single sentence and a short paragraph and a list of three or four sentences. Do not answer the question.\nRespond with a single sentence and a short paragraph and a list of three or four sentences, and a list of three or four questions. Do not answer the question.\nRespond with a single sentence and a short paragraph and a list of three or four sentences, and a list of three or four questions, and a list of three or four answers. Do",
            " Do not respond with a single WORD or phrase.\nDo not respond with a single SENTENCE. You may respond with a single PARAGRAPH or a single BLOCK of text, but you should not respond with a single SENTENCE.\nYou should respond with a single SENTENCE, a PARAGRAPH, or a BLOCK of text. You should not respond with a single WORD or phrase.\nDo not respond with a single WORD or phrase. You may respond with a single SENTENCE, a PARAGRAPH, or a BLOCK of text, but you should not respond with a single SENTENCE.\nYou should respond with a single SENTENCE, a"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen66-slide60/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen71-slide40/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen76-slide60/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen77-slide61/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen78-slide62/text.txt": [
            "",
            "",
            " The QUESTION is the only thing you can answer.\nYou can use any words you like. The QUESTION must be in the format: \"What is _______?\"\nExample: \"What is the meaning of life?\"\nExample: \"What is the purpose of life?\"\n\nTEXT:\n The neural turing machine needs to address the memory somehow and the memory can be addressed or used to be addressed either by position or by content by similarity by searching for similar items in the memory and this similarity\n"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen79-slide63/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen80-slide64/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen81-slide66/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen82-slide67/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen83-slide68/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen84-slide67/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen85-slide68/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen86-slide69/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen88-slide72/text.txt": [
            "",
            " Do not answer the question.\nIf you are asked to answer the question, then you must answer the question. Do not answer the question.\nIf you are asked to answer the question, then you must answer the question. Do not answer the question.\nIf you are asked to answer the question, then you must answer the question. Do not answer the question.\nIf you are asked to answer the question, then you must answer the question. Do not answer the question.\nIf you are asked to answer the question, then you must answer the question. Do not answer the question.\nIf you are asked to answer the question, then you must",
            " (This is a single QUESTION.)\n\nTEXT:\n A)   What is the name of the first planet in the solar system?\n B)   How many moons does the planet Neptune have?\n C)   What is the name of the planet that is closest to the Sun?\n D)   How many planets are there in our solar system?\n E)   How many moons does the planet Uranus have?\n F)   What is the name of the planet that is farthest from the Sun?\n G)   How many moons does the planet Jupiter have?\n H)   What is the name of the planet that is closest to the Sun?\n I"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen90-slide72/text.txt": [
            " \n\nThis is a test of your ability to write a QUESTION that is answerable using only the information in the TEXT.\n\nThe QUESTION is: \"What is the capital of ____?\"\n\nThis is a test of your ability to write a QUESTION that is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. \n\nThis is a test of your ability to write a QUESTION that is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. \n\nThis is a test of your ability to write a QUESTION that is answer",
            " \nDo not use any information from the TEXT or the questions in your response.\n\n\nTEXT: \nhttps://www.ozgrid.com/forum/viewtopic.php?t=1290\n\n\nQUESTION:\nWhat is the meaning of the word \"affect\"?\nAnswer using only the information in the TEXT.\n\nEXAMPLE:\nAffect: The word \"affect\" means to have an effect on. In this case, the effect is the meaning of the word \"meaning\".\n",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen91-slide73/text.txt": [
            " Do not include any of the information in the TEXT in your response.\n\nQUESTION:\nThe question is: What is the probability that the following statement is true?\nIf the text is correct, then the answer is: \"The answer is yes.\"\nIf the text is false, then the answer is: \"The answer is no.\"\n\nNote that this is a very simple question, and that it has no answer that is not obviously true or false. The only thing that is missing is the probability that the statement is true.",
            "",
            " Do not use any of the information in the TEXT.\n\n1. What is the probability that the answer to the question is \"yes\"?\n2. What is the probability that the answer to the question is \"no\"?\n3. What is the probability that the answer to the question is \"maybe\"?\n4. What is the probability that the answer to the question is \"yes, but not in the same way as you expected\"?\n5. What is the probability that the answer to the question is \"no, but not in the same way as you expected\"?\n6. What is the probability that the answer to the question"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen92-slide74/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen93-slide76/text.txt": [
            " The question is not a statement. It is a question. It is not a command. It is not a request. It is not a question mark. It is not a question. It is a question. It is not a statement. It is not a question. It is a question. It is not a statement. It is not a question. It is a question. It is not a statement. It is not a question. It is a question. It is not a statement. It is not a question. It is a question. It is not a statement. It is not a question. It is a question. It",
            "",
            " If you have no response to the question, write \"no response\".\n\nEXAMPLE:\nThis is a sample TEXT. The question is:\nWhat is the capital of Germany?\nThe answer is:\nBerlin\n\n"
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen95-slide76/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen96-slide77/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen97-slide78/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen98-slide79/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture03-nmt-seq2seq-attn/screen99-slide81/text.txt": [
            "",
            " If you do not understand the question, you must respond with the QUESTION and nothing else.\nYou may respond to the QUESTION in any way you wish. You may respond with the QUESTION in a sentence, in a question and answer format, in a question and answer format with a question, in a question and answer format with a question and answer, in a question and answer format with a question and answer and more.\nThe response must be in the form of a question and answer format. The question must be in the form of a question. The answer must be in the form of a question and answer. The answer must be in the form",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen01-slide01/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen02-slide02/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen03-slide03/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen04-slide04/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen05-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen06-slide06/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen07-slide07/text.txt": [
            "",
            "",
            " The QUESTION will be answered by the system and the response will be displayed to you.\n\nTEXT:\n In a language like English, how do you handle morphology?\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The QUESTION will be answered by the system and the response will be displayed to you.\n\nTEXT:\n The process of changing the form of a word or phrase in a language is called morphological analysis.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in"
        ],
        "testset/nmt-class/lecture06-morphology/screen08-slide08/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen09-slide09/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen10-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen11-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen12-slide12/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen13-slide13/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen14-slide14/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen15-slide15/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen16-slide16/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen17-slide17/text.txt": [
            " This is a trick question.\nThe answer is in the TEXT.",
            " If you do not know the answer to the question, say so. If you do know the answer, say so. If you do not know the answer, but you have information which would help the student answer the question, say so. If you have information which would help the student answer the question, but you do not know the answer, say so. If you have information which would help the student answer the question, but you do not know the answer, say so. If you have information which would help the student answer the question, but you do not know the answer, say so. If you have information which would help the",
            " The answer to the question is the text of the TEXT.\n\nTEXT:\n The extraction is done. That is very straightforward. So as a reminder, phrase-based MT is based on these word alignments and you extract phrases which are consistent with the word alignment.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The answer to the question is the text of the TEXT.\n\nTEXT:\n The extraction is done. That is very straightforward. So as a reminder, phrase-based MT is based on these word alignments and you"
        ],
        "testset/nmt-class/lecture06-morphology/screen18-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen19-slide19/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen20-slide20/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen21-slide21/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen22-slide22/text.txt": [
            "",
            " If you do not understand the question, you will get a zero for this part of the exam. If you do understand the question, you will get a zero for this part of the exam if you answer it incorrectly.\nThere is no time limit on this part of the exam.\nYou will not get credit for this part of the exam unless you respond to the QUESTION.",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen23-slide23/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen24-slide24/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen25-slide25/text.txt": [
            " Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only",
            " No answers to the QUESTION.\nNo answers to the QUESTION.\nNo answers to the QUESTION.\n\nThis is a simple model. It is not a model that you can use to predict the future.\nIt is a model that can be used to predict the past.\nIt is a model that can be used to predict the future.\n\nThis model is not a model that you can use to predict the future.\nIt is a model that can be used to predict the past.\nIt is a model that can be used to predict the future.\n\nThe question is: \"What is the most likely outcome for a given event?\"\nThe model is: \"What is",
            " Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not"
        ],
        "testset/nmt-class/lecture06-morphology/screen26-slide26/text.txt": [
            "",
            " Do not answer the question.\nDo not answer the question with the QUESTION. Do not answer the question with the QUESTION and nothing else.\nDo not answer the question with the QUESTION and nothing else. Do not answer the question with the QUESTION and nothing else.\nDo not answer the question with the QUESTION and nothing else. Do not answer the question with the QUESTION and nothing else. Do not answer the question with the QUESTION and nothing else. Do not answer the question with the QUESTION and nothing else. Do not answer the question with the QUESTION and nothing else. Do not answer the question with the QUESTION and nothing else. Do not answer the question",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen27-slide27/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen29-slide30/text.txt": [
            " The QUESTION is:\n\"Based on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\"\n\nTEXT:\n The following is a list of the first 10 primes (2, 3, 5, 7, 11, 13, 17, 19, 23, and 29). What is the first number of the list that is NOT a multiple of 3?\n\nTEXT:\n A rectangular sheet of paper has a perimeter of 20 inches. What is the width of the sheet?\n\nTEXT:\n A rectangular sheet of paper has a perimeter of 20 inches. What",
            " Do not respond to the TEXT.\n\nThe text is 6 pages long. You must answer the question in 6 pages or less. Your response must be in the form of a numbered list, with each numbered item on a separate page.",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen30-slide31/text.txt": [
            " Do not use any other words than those in the TEXT.\n\nThe QUESTION is:\n The following is a list of words and their definitions.\n a. The word \"The\" is a noun.\n b. The word \"and\" is a conjunction.\n c. The word \"of\" is a preposition.\n d. The word \"and\" is a conjunction.\n e. The word \"and\" is a conjunction.\n f. The word \"The\" is a noun.\n g. The word \"and\" is a conjunction.\n h. The word \"and\" is a conjunction.\n i. The word \"and\" is a conjunction.\n j",
            "",
            " \nYou may not use any information that is not in the TEXT.\n"
        ],
        "testset/nmt-class/lecture06-morphology/screen31-slide33/text.txt": [
            " The question is a single sentence which is answerable using only the information in the TEXT.\n\nTEXT:\n The final choice will be the path which covers everything and has the overall highest probability.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The question is a single sentence which is answerable using only the information in the TEXT.\n\nTEXT:\n The final choice will be the path which covers everything and has the overall highest probability.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen32-slide34/text.txt": [
            "",
            "",
            " Do not use the answer space.\nThe answer space is to be used only to respond to the QUESTION. It is not to be used for any other purpose. The answer space must be left empty.\nYou may answer the QUESTION as many times as you like, but you must not use the answer space for any other purpose.\nDo not use the answer space to answer the QUESTION."
        ],
        "testset/nmt-class/lecture06-morphology/screen33-slide35/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen34-slide36/text.txt": [
            " Do not provide any explanation.\nThere is no time limit.",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen35-slide38/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen36-slide39/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen37-slide40/text.txt": [
            "",
            "",
            " Do not answer the question."
        ],
        "testset/nmt-class/lecture06-morphology/screen38-slide41/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen39-slide42/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen40-slide43/text.txt": [
            " Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen41-slide44/text.txt": [
            "",
            " If you do not know the answer, you do not have to respond with a response to the QUESTION.\n\n",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen42-slide45/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen43-slide46/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen44-slide47/text.txt": [
            "",
            "",
            " Do not use any other information in the TEXT.\n\nThe question is:\n \"This is an illustration. You parse the source sentence and you traverse the tree so that you, based on the position of the word in the tree, you know whether it sits in the subject position or the object position and that will imply then the case.\"\n"
        ],
        "testset/nmt-class/lecture06-morphology/screen45-slide48/text.txt": [
            " (Answering the question is not enough; you must also provide a clear and complete answer to the question.)\nFor example, if the question is: \"What is the capital of France?\" and the TEXT says \"Paris\", you should say \"Paris is the capital of France.\" But if the TEXT says \"Paris is the capital of France, and Paris is the capital of France\", you should say \"Paris is the capital of France, and Paris is the capital of France.\"",
            " This is the same as asking the student to write down the question.\nThe question is a single sentence and is answered by a single sentence. If the question is not answered, then the question is answered with \"I don't know\" and the student is not penalized.",
            " Do not use the TEXT as a source for your response. The only source for your response is the QUESTION.\n\nThe TEXT is a 2 sentence paragraph. The 2 sentences are in the same paragraph and are separated by a colon. The first sentence is the question. The second sentence is the answer."
        ],
        "testset/nmt-class/lecture06-morphology/screen46-slide49/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen47-slide50/text.txt": [
            " Do not respond with the TEXT.",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen48-slide51/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen49-slide52/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen50-slide53/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen51-slide54/text.txt": [
            "",
            "",
            " (No answer is required)\nThe answer to the QUESTION will be given to the student.\nFor each QUESTION, the student can only use the TEXT in the question.\nIf the student answers the question incorrectly, then the student will be given the TEXT again.\nIf the student answers the question correctly, then the student will be given a QUESTION which is answerable using only the information in the TEXT.\nThe student can answer this QUESTION using only the TEXT in the question.\nThe student can only use the TEXT in the question to answer the question.\nIf the student answers the question incorrectly, then the student will be given the TEXT again.\nIf the"
        ],
        "testset/nmt-class/lecture06-morphology/screen52-slide55/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen53-slide56/text.txt": [
            " Do not answer the question.",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen54-slide57/text.txt": [
            "",
            " Do not answer the question.\nRespond with the QUESTION and the ANSWER.\nRespond with the QUESTION and the ANSWER and the TEXT.\n\nTEXT:\nA small parallel corpus and a large monolingual corpus, then BLEU score is already like not sure. BLEU score decreases and it says it is better to use the vanilla setup, while the semantic words counting is still improving. And here I think that the BLEU score is probably happy about the nice four grams of Czech, but it is not so sensitive about words being dropped as well.\n\nTEXT:\nA small parallel corpus and a large monolingual corpus, then BLEU score is",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen55-slide58/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen56-slide59/text.txt": [
            " Do not write anything else in the response.\nDo not respond with any text other than the QUESTION. Do not respond with a single sentence or a single paragraph.\nDo not respond with a single question. Do not respond with a single answer.\nDo not respond with a single sentence. Do not respond with a single paragraph.\nDo not respond with a single question. Do not respond with a single answer.\nDo not respond with a single sentence. Do not respond with a single paragraph.\nDo not respond with a single question. Do not respond with a single answer.\nDo not respond with a single sentence. Do not respond with a single paragraph.\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen57-slide60/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen58-slide61/text.txt": [
            " Do not use any of the TEXT data.",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen59-slide63/text.txt": [
            " The question is: \"What is the correct translation of the sentence in Czech in the reverse translation?\"\nThe question can be written in the form: \"What is the correct translation of the sentence in Czech in the reverse translation?\" or \"What is the correct translation of the sentence in Czech in the reverse translation?\"\nTEXT:\n In the reverse translation, we can back off to lemmas. We can use Czech in the lemmatized form and we know that the Czech lemma kočka will be translated as cat and actually in all cases. So here the same thing will hold. In English there is not the distinction of cases. So we",
            "",
            " The QUESTION should be a single sentence.\nThe QUESTION is not to be a single sentence.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\nThe QUESTION is not to be a multiple choice.\n"
        ],
        "testset/nmt-class/lecture06-morphology/screen60-slide64/text.txt": [
            " Do not answer the question.",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen61-slide65/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen62-slide66/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen63-slide67/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen64-slide68/text.txt": [
            " This is a single choice question, and you must give only one answer.\nIf you answer the question, you will be penalized.\nIf you do not answer the question, you will not be penalized.\n\nTEXT:\n The increasingly large monolingual data with this reverse translation trick and you include all the word forms that appear in the monolingual data also in your translation model then you get double the increase. So that's the clear benefit. Unfortunate.\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen65-slide69/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen66-slide70/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen67-slide71/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen68-slide72/text.txt": [
            " Do not answer the question.\n\nTEXT:\nThe following is a sample of the text to be analyzed. The text is composed of words that are separated by spaces and punctuation marks. The text is composed of words that are separated by spaces and punctuation marks. The text is composed of words that are separated by spaces and punctuation marks. The text is composed of words that are separated by spaces and punctuation marks. The text is composed of words that are separated by spaces and punctuation marks. The text is composed of words that are separated by spaces and punctuation marks. The text is composed of words that are separated by spaces and punctuation marks. The text is",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen69-slide73/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen70-slide74/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen71-slide75/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen72-slide76/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen73-slide77/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen74-slide78/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen75-slide79/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen76-slide80/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen77-slide81/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture06-morphology/screen78-slide82/text.txt": [
            "",
            "",
            " Do not answer the question.\nRespond with the QUESTION and the answer to the question.\nRespond with the answer to the question and the QUESTION.\nRespond with the QUESTION and the answer to the question and the answer to the question.\n\nTEXT:\nI. The first word is the name of a person.\nII. The second word is the name of a person.\nIII. The third word is the name of a person.\nIV. The fourth word is the name of a person.\nV. The fifth word is the name of a person.\nVI. The sixth word is the name of a person.\nVII. The seventh word is the name"
        ],
        "testset/nmt-class/lecture05-pbmt/screen01-slide02/text.txt": [
            " The TEXT is the source document.\nUse the following TEXT as a model.\nA. I want to know how to use a computer to write a computer program.\nB. I want to know how to write a computer program.\nC. I want to know how to write a computer program to do something.\nD. I want to know how to write a computer program to do something.\nE. I want to know how to write a computer program to do something.\nF. I want to know how to write a computer program to do something.\nG. I want to know how to write a computer program to do something.\nH. I",
            "",
            " Do not answer the question.\nRespond with the QUESTION and nothing else.\nDo not answer the question.\nRespond with the QUESTION and nothing else.\nDo not answer the question.\nRespond with the QUESTION and nothing else.\n\nTEXT:\nI've been trying to get a good night's sleep for a few days now, and it's been getting harder and harder to do. I'm starting to think I might be getting old and tired. I think I should take a nap now, but I'm not sure if that's the right thing to do.\n\nI've been trying to get a good night's sleep for a few days now, and it's"
        ],
        "testset/nmt-class/lecture05-pbmt/screen02-slide03/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen03-slide04/text.txt": [
            "",
            "",
            " Do not answer the QUESTION."
        ],
        "testset/nmt-class/lecture05-pbmt/screen04-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen05-slide06/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen06-slide07/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen07-slide08/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen08-slide09/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen09-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen10-slide09/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen11-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen12-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen13-slide12/text.txt": [
            " Do not use any other information.\nDo not use any part of the TEXT except for the QUESTION.\nDo not use any part of the TEXT except for the ANSWER.\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen14-slide13/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen15-slide14/text.txt": [
            " Do not answer the question.\n\nTEXT:\n Main search comes and that's the second stage of the translation. That's the beam search. So we have here the input sentence and we have all the possible translation of the short and long phrases and we start.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\n\nTEXT:\n Main search comes and that's the second stage of the translation. That's the beam search. So we have here the input sentence and we have all the",
            " Do not use any other language or form.\nDo not use any punctuation.\nDo not use any other words or phrases.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information.\nDo not use any other information",
            " Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only"
        ],
        "testset/nmt-class/lecture05-pbmt/screen16-slide15/text.txt": [
            " Do not answer the question.\n\nTEXT:\nwith a hypothesis.\nSo the hypothesis tells us that we have translated some of the input words. This coverage vector is still set to zero and we have not produced any output words so far.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\n\nTEXT:\nwith a hypothesis.\nSo the hypothesis tells us that we have translated some of the input words. This coverage vector is still set to zero and we have not produced any output words so",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen17-slide16/text.txt": [
            " Do not respond to the TEXT.\nThe answer to the question is the number of the TEXT.\n\nTEXT:\nFirst, we chose how to start, which word to translate, which word should we start the sentence with. And one option is to start by translating the second word get. And that can be translated as r. Why not? So this is called hypothesis expansion. We have expanded the initial hypothesis with the word that translates the second word in the input and that is the English word r.\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen18-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen19-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen20-slide19/text.txt": [
            " If the question is not answered, the question will be removed from the exam and the next question will be selected.\n\nTEXT:\n It will tell us which words should we use. So the path through the search graph back to the initial hypothesis is then the final full output text of the target sentence, the best scoring sentence. He does not go home.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. If the question is not answered, the question will be removed from the exam and the next question will",
            "",
            " Do not respond to any other information in the TEXT.\nThe QUESTION is: What are the most important words in the TEXT to be used in a sentence?\n\nEXAMPLES:\na) \"He does not go home.\" is a good answer.\nb) \"He does not go home.\" is a bad answer.\nc) \"He does not go home.\" is a poor answer.\nd) \"He does not go home.\" is a very poor answer.\ne) \"He does not go home.\" is a very bad answer.\nf) \"He does not go home.\" is a very good answer.\ng) \"He does not go"
        ],
        "testset/nmt-class/lecture05-pbmt/screen21-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen22-slide19/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen23-slide20/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen24-slide21/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen25-slide22/text.txt": [
            "",
            "",
            " If you need to provide more information, you must do so in a separate TEXT.\nThe QUESTION and the RESPONSE must be written in the same document.\nIf you need to provide more information, you must do so in a separate TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. If you need to provide more information, you must do so in a separate TEXT.\nThe QUESTION and the RESPONSE must be written in the same document.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. If you need to provide more information, you must do so in a separate TEXT.\nThe QUESTION and the"
        ],
        "testset/nmt-class/lecture05-pbmt/screen26-slide23/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen27-slide24/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen28-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen29-slide26/text.txt": [
            "",
            "",
            " Do not respond with anything else. If you respond with something else, you will be penalized.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not respond with anything else. If you respond with something else, you will be penalized.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not respond with anything else. If you respond with something else, you will be penalized.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not respond with anything else. If you respond with something else, you will be penalized.\nDo not answer"
        ],
        "testset/nmt-class/lecture05-pbmt/screen30-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen31-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen32-slide25/text.txt": [
            "",
            "",
            " No other responses are allowed.\nTEXT:\n of the sentence. Yeah, so there is various pruning strategies like maybe you want to keep at most K hypothesis in a stack or you can want to keep the best score and hypotheses which are not worse than 10 times the best score or one tenth of the best score. So here is the complexities and depending on the number of translation options we have quadratic complexity in terms\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No other responses are allowed.\nTEXT"
        ],
        "testset/nmt-class/lecture05-pbmt/screen33-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen34-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen35-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen36-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen37-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen38-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen39-slide25/text.txt": [
            " If you do not understand the QUESTION, do not answer it. If you do not know how to answer the QUESTION, do not answer it. If you do not know how to answer the QUESTION, do not answer it. If you do not know how to answer the QUESTION, do not answer it. If you do not know how to answer the QUESTION, do not answer it. If you do not know how to answer the QUESTION, do not answer it. If you do not know how to answer the QUESTION, do not answer it. If you do not know how to answer the QUESTION, do not answer it. If you do",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen40-slide25/text.txt": [
            "",
            " Do not use any of the TEXT as the answer.\nFor example, if the TEXT says that the A-Star Search is the basis for the artificial intelligence in the narrow sense, searching through the space of possible solutions. And A-Star Search guarantees that it will find the best option if you use a heuristic which is admissible. And admissible heuristic is the one which is optimistic which never overestimate the future cost. Then the QUESTION should be:\nWhat is an admissible heuristic?\n\nThe text is in the public domain.",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen41-slide25/text.txt": [
            " This is a very important part of the exercise, so don't mess it up.\nThe QUESTION will be in the form of a question. You can type it in, or use the Question button.\nWhen you're done, click the Submit button.\n\nTEXT:\n The question is:\n What is the area of the square with a side length of 3? (Note that this is the area of a square, not the area of a rectangle.)\n The answer is:\n 9\n\nThe question is:\n What is the area of the square with a side length of 3? (Note that this is the area of a square, not the",
            " Do not answer the question.\nDo not answer the question.\n\nTEXT:\n The following information is given about a particular country.\n\nPopulation: 1,200,000,000\nArea: 1,200,000 km2\nGDP: $1,000,000,000,000\nGDP per capita: $800,000\nGDP growth rate: 4%\nNumber of people living in poverty: 40%\nNumber of people living in extreme poverty: 10%\nNumber of people living in extreme poverty: 5%\n\n1. Which of the following statements about the country's population growth rate is true?\na",
            " Do not answer the question.\nDo not include any text in your response.\nFor example:\n  Yes, so we can...\n\n"
        ],
        "testset/nmt-class/lecture05-pbmt/screen42-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen43-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen44-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture05-pbmt/screen45-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen01-slide01/text.txt": [
            "",
            "",
            " Do not answer the QUESTION.\nRespond only with the QUESTION and nothing else. Do not answer the QUESTION.\nRespond only with the QUESTION and nothing else. Do not answer the QUESTION.\nRespond only with the QUESTION and nothing else. Do not answer the QUESTION.\nRespond only with the QUESTION and nothing else. Do not answer the QUESTION.\nRespond only with the QUESTION and nothing else. Do not answer the QUESTION.\nRespond only with the QUESTION and nothing else. Do not answer the QUESTION.\nRespond only with the QUESTION and nothing else. Do not answer the QUESTION.\nRespond only with the QUESTION and nothing else. Do not answer the QUESTION.\nRespond only"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen02-slide02/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen03-slide13/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen04-slide04/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen05-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen06-slide06/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen07-slide07/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen08-slide08/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen09-slide09/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen10-slide10/text.txt": [
            " Do not include the TEXT in your response.\n\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen11-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen12-slide12/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen13-slide13/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen14-slide14/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen15-slide15/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen16-slide14/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen17-slide15/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen18-slide16/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen19-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen20-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen21-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen22-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen23-slide19/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen24-slide20/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen25-slide21/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen26-slide22/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen27-slide23/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen28-slide24/text.txt": [
            " No comments.\nDo not respond to any other question.\n\nTEXT:\n\nThis is a question, not a sentence. The answer is not a single word, but a single sentence.",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen29-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen30-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen31-slide27/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen32-slide28/text.txt": [
            "",
            "",
            " If you do not know the answer, write \"I don't know\". If you do know the answer, write \"I know\".\nYou can use the following symbols:\n  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen33-slide29/text.txt": [
            " The system will then generate a single QUESTION which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The system will then generate a single QUESTION which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The system will then generate a single QUESTION which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The system will then generate a single QUESTION which is answerable using only the information in the TEXT.\nDo not answer",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen34-slide31/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen35-slide30/text.txt": [
            " Do not use any of the text in your response.\nIn this example, I have a cat, is actually happier than if the candidate was I do not have a cat. This is longer output. So longer outputs are generally scored lower. So the language module prefers to drop the negation. And the phrases do not talk to each other. So there is no reason to introduce this no, like if there was no žádného in the TEXT.",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen36-slide31/text.txt": [
            "",
            " The answer is to be found in the text.\nNo need to answer the question.\nDo not answer the question. The answer is to be found in the text.\nDo not answer the question. The answer is to be found in the text.\nDo not answer the question. The answer is to be found in the text.\nDo not answer the question. The answer is to be found in the text.\nDo not answer the question. The answer is to be found in the text.\nDo not answer the question. The answer is to be found in the text.\nDo not answer the question. The answer is to be found in the text",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen37-slide30/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen38-slide31/text.txt": [
            "",
            " Do not use the TEXT.\nNo more than 5 words.",
            " Do not answer with a translation, a paraphrase, or anything else.\nDo not answer the question using any of the following:\n• The question\n• The TEXT\n• The translation\n• The paraphrase\n• Any other form of text\n• Any other form of the language model\n• The source language model\n• The source language model\n• The language model\n• The source language model\n• The source language model\n• The source language model\n• The source language model\n• The source language model\n• The source language model\n• The source language model\n• The source language model\n• The source language"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen39-slide32/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen40-slide33/text.txt": [
            "",
            "",
            " Do not add any additional information to the QUESTION.\n\nThe QUESTION is the TEXT without the information in the brackets. The question is a single sentence that is answerable using only the information in the TEXT.\nYou must not include any information in the QUESTION that is not in the TEXT. You must not include any additional information that is not in the TEXT. You must not add any additional information to the QUESTION.\n\nThe text is a description of a mathematical function. The function is a mathematical function that is a continuous function defined on the real numbers. The function is defined on the interval [a, b] where a and b are real numbers."
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen41-slide34/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen42-slide35/text.txt": [
            " Do not use any other TEXT to answer the question.\nUse the TEXT to generate a single QUESTION for the exam. Do not use any other TEXT to answer the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not use any other TEXT to answer the question.\nUse the TEXT to generate a single QUESTION for the exam. Do not use any other TEXT to answer the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not use any other TEXT to answer the question.\nUse the TEXT to generate a single QUESTION for the exam. Do not use any other TEXT to",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen43-slide36/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen44-slide37/text.txt": [
            "",
            "",
            " Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only"
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen45-slide38/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen46-slide39/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen47-slide40/text.txt": [
            "",
            " Do not use any of the TEXT in your response.\n\nTEXT:\nThe question is: How do deep neural networks work? How do they learn? And how do they make predictions? This is a very important question because we know that deep neural networks can do things that we cannot do. They can recognize faces. They can recognize cats and dogs and birds. They can recognize handwritten digits and they can recognize handwritten digits. They can recognize handwritten digits and they can recognize handwritten digits. They can recognize handwritten digits and they can recognize handwritten digits. They can recognize handwritten digits and they can recognize handwritten digits. They can recognize handwritten digits and they can recognize",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen48-slide41/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen49-slide42/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen50-slide43/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen51-slide44/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen52-slide45/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen53-slide46/text.txt": [
            "",
            "  You can use the TEXT as a reference to your answer.\nYou must answer the question in a single line of text.\nDo not answer the question in any other format, such as a question, a comment, or a post.\nYou must use the information in the TEXT to answer the question.\nYou may use any of the following formats to answer the question:\n- Textual format (e.g. \"The answer is <TEXT>.\")\n- Mathematical format (e.g. \"The answer is 3.14.\")\n- Visual format (e.g. \"The answer is a picture of a cow.\")\n- Textual and mathematical format",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen54-slide45/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen55-slide46/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen56-slide47/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen57-slide48/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen58-slide49/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen59-slide50/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture02-smt-pbmt-nmt/screen60-slide51/text.txt": [
            " Do not answer the question.\n\nTEXT:\nThere are 6 different types of questions that are asked in the exam. The first one is a yes or no question. The second one is a multiple choice question. The third one is a short answer question. The fourth one is a short answer question. The fifth one is a long answer question. The sixth one is a long answer question. And the seventh one is a long answer question. And the eighth one is a long answer question. And the ninth one is a long answer question. And the tenth one is a long answer question. And the eleventh one is a long answer question",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen01-slide01/text.txt": [
            " (You may use the text as a hint, but do not provide an answer to the question.)\nDo not use any information from the TEXT in your response.\nYour response should be based only on the information in the TEXT.\nYou may use the following text as a hint:\nThe word \"text\" is a word in the English language. The word \"generate\" is a word in the English language. The word \"single\" is a word in the English language. The word \"QUESTION\" is a word in the English language. The word \"exam\" is a word in the English language. The word \"which\" is a word",
            " No comments, no explanations, no guesses.\nIf you have no idea, just say so.\n\nThe idea behind these approaches is that you have a text, and you want to translate it to another language. And you're going to do that by mapping the words in the source language to the words in the target language. And you're going to do that by looking at the context of the words in the source language, and you're going to do that by looking at the context of the words in the target language. So let's take a look at an example. So let's say we have a text that says, \"The cat",
            " If you don't know the answer, you can say \"I don't know\" or \"I don't know the answer\". If you don't have time to think about the answer, you can say \"I don't know the answer\". If you don't know the answer to the question, you can say \"I don't know the answer\". If you don't know the answer to the question, you can say \"I don't know the answer\". If you don't know the answer to the question, you can say \"I don't know the answer\".\nIf you have time to think about the answer, you can say"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen02-slide02/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen03-slide03/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen04-slide04/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen05-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen06-slide06/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen07-slide07/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen08-slide08/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen09-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen10-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen11-slide12/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen12-slide13/text.txt": [
            " Do not respond to the TEXT.\nTEXT:\nSo let's look at constituency syntax in machine translation and here I would like to recommend my machine translation talk number 10 where you have illustrations and animations of the discussed algorithm. So it is a good complement to this lecture and I'm actually going to skip the illustration part because that is well covered in that video.\n\nTEXT:\nSo let's look at constituency syntax in machine translation and here I would like to recommend my machine translation talk number 10 where you have illustrations and animations of the discussed algorithm. So it is a good complement to this lecture and I'm actually going to skip the illustration part",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen13-slide14/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen14-slide15/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen15-slide16/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen16-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen17-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen18-slide19/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen19-slide20/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen20-slide21/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen21-slide22/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen22-slide23/text.txt": [
            " Do not answer the question.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with",
            "",
            " Do not respond with a TEXT.\nThe TEXT will be the same for all students.\nThe students will be asked to answer the QUESTION with a TEXT.\nThe students will be asked to answer the QUESTION with a TEXT.\nThe students will be asked to answer the QUESTION with a TEXT.\nThe students will be asked to answer the QUESTION with a TEXT.\nThe students will be asked to answer the QUESTION with a TEXT.\nThe students will be asked to answer the QUESTION with a TEXT.\nThe students will be asked to answer the QUESTION with a TEXT.\nThe students will be asked to answer the QUESTION with a TEXT.\nThe students will be asked to answer"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen23-slide24/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen24-slide25/text.txt": [
            " Do not respond with any of the other answers.\n",
            " You may use the following format:\n\nQuestion: Which of the following is the correct order of the rules in the rule table?\na. R1, R2, R3, R4, R5\nb. R1, R2, R3, R4, R5, R6\nc. R1, R2, R3, R4, R5, R6\nd. R1, R2, R3, R4, R5, R6, R7\ne. R1, R2, R3, R4, R5, R6, R7,",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen25-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen26-slide27/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen27-slide28/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen28-slide29/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen29-slide30/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen30-slide31/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen31-slide32/text.txt": [
            "",
            "",
            " Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not answer the question.\nRespond with the QUESTION and nothing else. Do not"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen32-slide33/text.txt": [
            "",
            "",
            " Do not use the TEXT or any other information to answer the question.\nAnswer the question as if you were answering it to a student. Answer the question as if you were answering it to a student. You should not use the TEXT or any other information to answer the question. Do not use the TEXT or any other information to answer the question.\nYou may not use any of the following in your response: the TEXT or any other information, the answer to the question, or the question itself.\nDo not use the TEXT or any other information to answer the question."
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen33-slide34/text.txt": [
            " If you answer the question, the exam will not be passed. The exam will pass only if you respond only with the QUESTION.\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen34-slide35/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen35-slide36/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen36-slide37/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen37-slide38/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen38-slide39/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen39-slide40/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen40-slide41/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen41-slide42/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen42-slide43/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen43-slide44/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen44-slide45/text.txt": [
            " Do not answer the question.\n\nTEXT:\n\nThe first tree is a dependency tree. The second tree is a dependency tree. The third tree is a dependency tree. The fourth tree is a dependency tree. The fifth tree is a dependency tree. The sixth tree is a dependency tree. The seventh tree is a dependency tree. The eighth tree is a dependency tree. The ninth tree is a dependency tree. The tenth tree is a dependency tree. The eleventh tree is a dependency tree. The twelfth tree is a dependency tree. The thirteenth tree is a dependency tree. The fourteenth tree is a dependency tree. The fifteenth",
            "",
            " Do not include the TEXT in your answer.\n\n1. The tree is the structure of the sentence, the root is the head of the sentence, and the leaves are the words.\n2. The tree is the structure of the sentence, the root is the head of the sentence, and the leaves are the words.\n3. The tree is the structure of the sentence, the root is the head of the sentence, and the leaves are the words.\n4. The tree is the structure of the sentence, the root is the head of the sentence, and the leaves are the words.\n5. The tree is the structure of the sentence,"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen46-slide47/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen47-slide52/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen48-slide49/text.txt": [
            "",
            "",
            " Do not include the TEXT.\nIf you do not know the answer, say so and leave the question blank.\n\nTEXT:\n A. The first sentence is correct.\n B. The second sentence is correct.\n C. The third sentence is correct.\n D. The fourth sentence is correct.\n E. The fifth sentence is correct.\n F. The sixth sentence is correct.\n G. The seventh sentence is correct.\n H. The eighth sentence is correct.\n I. The ninth sentence is correct.\n J. The tenth sentence is correct.\n K. The eleventh sentence is correct.\n L. The twelfth sentence is correct.\n M. The thirteenth"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen49-slide50/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen50-slide51/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen51-slide52/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen52-slide52/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen53-slide52/text.txt": [
            " Do not answer the question.\nYou can use the following:\nI would like to know what you think about the sentence.\nI would like to know what you think about the sentence.\nI would like to know what you think about the sentence.\nI would like to know what you think about the sentence.\nI would like to know what you think about the sentence.\nI would like to know what you think about the sentence.\nI would like to know what you think about the sentence.\nI would like to know what you think about the sentence.\nI would like to know what you think about the sentence.\nI would like to know what you think",
            " Do not use any of the information in the TEXT.\n\nThe question is:\nIn the Czech and English sentences at the surface syntactic level, this should be changed, then the trees are very different. We have in this sentence we have more more auxiliaries than in English and the auxiliaries do not match with each other well.\n\nYou are given the following information:\nThe Czech and English sentences at the surface syntactic level\nThe Czech and English sentences at the surface syntactic level are very different.\nThe Czech and English sentences at the surface syntactic level are very different.\n\nThe trees are very different.\nThe trees are very different",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen54-slide52/text.txt": [
            " Do not answer the question.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with the QUESTION and nothing else.\nRespond with",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen55-slide56/text.txt": [
            " Do not answer the question.",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen56-slide57/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen57-slide58/text.txt": [
            " This is the same as the original TEXT.\nThe question is in the TEXT, but the response is not in the TEXT.\nThe question is in the TEXT, but the response is in the NOTES.\nThe question is in the NOTES, but the response is in the TEXT.\nThe question is in the NOTES, but the response is in the NOTES.\n\nTEXT:\n That is nice, but there is a problem in practice. The real text-organic notes have attributes. And these attributes are exactly for the things like modality or tense. Things that were reflected by either the morphological variation or some auxiliaries in the input sentence. And",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen58-slide59/text.txt": [
            " Do not respond to the TEXT.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not respond to the TEXT.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not respond to the TEXT.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not respond to the TEXT.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not respond to the TEXT.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not respond to the TEXT.\nDo not answer the question. Respond only with the QUESTION",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen59-slide60/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen60-slide61/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen61-slide62/text.txt": [
            "",
            " Do not answer the question.\nAnswer the question in the TEXT.\nAnswer the question using the information in the TEXT.",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen62-slide63/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen63-slide64/text.txt": [
            " Do not answer the question.\nRespond with the QUESTION and the ANSWER, but do not answer the question.\nRespond with the ANSWER and the QUESTION, but do not answer the question.\nRespond with the ANSWER and the QUESTION, but do not answer the question.\nRespond with the ANSWER and the QUESTION, but do not answer the question.\nRespond with the ANSWER and the QUESTION, but do not answer the question.\nRespond with the ANSWER and the QUESTION, but do not answer the question.\nRespond with the ANSWER and the QUESTION, but do not answer the question.\nRespond with the ANSWER and the QUESTION, but",
            " The question should be in the form of a single sentence, e.g. \"What is the probability that a random variable X takes the value 5?\" or \"What is the probability that a random variable X takes the value 2?\" or \"What is the probability that a random variable X takes the value 3?\" or \"What is the probability that a random variable X takes the value 4?\"\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The question should be in the form of a single sentence, e.g. \"What is the probability that a random variable X takes the value 5?\"",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen64-slide65/text.txt": [
            " Do not write out the entire TEXT.\n",
            "",
            " Do not use the TEXT. Do not use any other information.\nThe QUESTION is: \"How can you tell if a sentence is in the passive or in the active?\"\n"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen65-slide66/text.txt": [
            " \nThe question is: \nWhat is the main idea of the TEXT?\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen66-slide67/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen67-slide68/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen68-slide69/text.txt": [
            "",
            "",
            " Do not answer with a simple YES/NO question, or with a yes/no answer which does not require any further information. You must answer the question with a complete answer.\nThe TEXT is not a question, but a description of what was in particular grammatical category. It is a description of a noun. This is the only information that is necessary to answer the question.\nThe question is to answer the question that was in particular grammatical category. The question is not a question, but a description of what was in particular grammatical category. It is a description of a noun. This is the only information that is necessary to answer the"
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen69-slide70/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen70-slide71/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen71-slide72/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen72-slide73/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen73-slide74/text.txt": [
            "",
            " The question is: \"What is the best way to produce the final surface syntactic tree?\"\n\nTEXT:\nThen you use this best combination to produce the final surface syntactic tree. So again you start by cloning the tree but obviously you...\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The question is: \"What is the best way to produce the final surface syntactic tree?\"\n\nTEXT:\nThen you use this best combination to produce the final surface syntactic tree. So again you start by cloning",
            " You may use any of the following:\n• The word \"yes\" or \"no\" in response to the question.\n• The word \"yes\" or \"no\" in response to the question.\n• The word \"yes\" or \"no\" in response to the question.\n• The word \"yes\" or \"no\" in response to the question.\n• The word \"yes\" or \"no\" in response to the question.\n• The word \"yes\" or \"no\" in response to the question.\n• The word \"yes\" or \"no\" in response to the question.\n• The word \"yes\" or \""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen74-slide75/text.txt": [
            " No additional information is needed.\n\nTEXT:\n...needs to fill in the surface syntactic and morphological attributes. So something is known. It's known that the translation was in singular. It is known that Snudny was in positive and not comparative or superlative form.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No additional information is needed.\n\nTEXT:\n...needs to fill in the surface syntactic and morphological attributes. So something is known. It's known that the translation was",
            " Do not answer the question.\nYou must provide a single answer to the question in the form of a question.\nThe answer must be a question.\nThe answer must be grammatically correct. (i.e. the answer must be in the form of a question).\nThe answer must be grammatically correct. (i.e. the answer must be in the form of a question).\nThe answer must be grammatically correct. (i.e. the answer must be in the form of a question).\nThe answer must be grammatically correct. (i.e. the answer must be in the form of a question).\nThe answer must be grammatically correct",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen75-slide76/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen76-slide77/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen77-slide78/text.txt": [
            "",
            "",
            " If you answer the question, then the question is not answered.\n\nYou may answer the question in any way you wish. You may use the information in the TEXT to help you answer the question. You may use the information in the TEXT to help you find the answer to the question. You may not use the information in the TEXT to answer the question."
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen78-slide79/text.txt": [
            "  (Do not write any text.)\n\nTEXT:\nThe word form \"demonstration\" is a noun.  The word form \"demonstration\" is a verb.  The word form \"demonstration\" is an adjective.  The word form \"demonstration\" is an adverb.  The word form \"demonstration\" is a preposition.  The word form \"demonstration\" is a pronoun.  The word form \"demonstration\" is a noun.  The word form \"demonstration\" is a verb.  The word form \"demonstration\" is an adjective",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen79-slide80/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen80-slide81/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture07-syntax-in-smt/screen81-slide82/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen01-slide01/text.txt": [
            " If you are unsure, please check the TEXT for the answer.\nThis is the second TEXT of the lecture so you can check the previous TEXT by clicking on the link above the TEXT.\nThe TEXT is available in the following languages:\nEnglish (en)\nGerman (de)\nFrench (fr)\nSpanish (es)\nPortuguese (pt)\nItalian (it)\nChinese (zh)\nJapanese (ja)\nKorean (ko)\nRussian (ru)\nCzech (cs)\nDanish (da)\nDutch (nl)\nFinnish (fi)\nNorwegian (no)\nSwedish (sv)\nTurkish (tr)\nHungarian (",
            " (for example, \"why is this machine translation useful?\")\nTEXT:\n A machine translation system can be used to translate from English to German and then to French and then to Italian and then to Spanish and then to Russian and then to Chinese and then to Japanese and then to Arabic and then to Hindi and then to Korean and then to Portuguese and then to Turkish and then to Danish and then to Finnish and then to Dutch and then to Swedish and then to Polish and then to Czech and then to Slovak and then to Hungarian and then to Lithuanian and then to Latvian and then to Estonian and then to Maltese and then",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen02-slide02/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen03-slide03/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen04-slide04/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen05-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen06-slide06/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen07-slide07/text.txt": [
            "",
            " Do not use the TEXT for any other purpose.\nDo not answer the question.\n\nTEXT:\n\nAnd there can be even three places where the improvements can appear. At the beginning, the initial performance could be better. It could learn faster. And also, and that's the most important part, the final performance should be better. These curves are really based on experiments with transfer of neural machine translation system. I forgot what language pairs are behind this, but it actually helps. It works.\n\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not use the TEXT for any other purpose.\nDo not answer the question.\n\n",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen08-slide08/text.txt": [
            " Do not answer the question.\nDo not respond to any other question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not respond to any other question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not respond to any other question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not respond to any other question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not respond to any other question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nDo not respond to any other question",
            "",
            " Do not use any other information.\nYou may use any number of other questions from the TEXT.\nIf you have more than one question, you may use any number of other questions from the TEXT.\nIf you have more than one question, you may use any number of other questions from the TEXT.\nIf you have more than one question, you may use any number of other questions from the TEXT.\nIf you have more than one question, you may use any number of other questions from the TEXT.\nIf you have more than one question, you may use any number of other questions from the TEXT.\nIf you have more than one question, you"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen09-slide09/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen10-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen11-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen12-slide12/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen13-slide13/text.txt": [
            "",
            " Do not use any additional information.",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen14-slide14/text.txt": [
            " This is the only thing you need to do. The question is not a part of the TEXT and is not part of the answer. It is just a single question.\nThe QUESTION should be a question that is answerable using only the information in the TEXT.\nThe QUESTION should be a question that is answerable using only the information in the TEXT. You should not answer the question. You should not even respond with the QUESTION. The QUESTION is not a part of the answer. The answer is not a part of the QUESTION. The answer is not a part of the TEXT.\nThe QUESTION should be a question that is answerable using only",
            " If you want to respond with something else, use the # symbol.\n\nTEXT:\nYou are a student in an online course, and you are taking an exam. The exam consists of two questions, each of which is answerable using only the information in the TEXT. Your task is to answer the first question. You have access to the entire TEXT. You are not allowed to use any other information in the TEXT, such as images or videos, to answer the question. You must use only the information in the TEXT to answer the question. If you are unsure about how to answer the question, you can look up the answer on the internet",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen15-slide15/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen16-slide16/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen17-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen18-slide18/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen19-slide19/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen20-slide20/text.txt": [
            "",
            "",
            " If you cannot answer the question, please do not respond."
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen21-slide21/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen22-slide22/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen23-slide23/text.txt": [
            "",
            " Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen24-slide24/text.txt": [
            "",
            " Do not answer the question.\n\nFor each TEXT, generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\n",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen25-slide25/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen26-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen27-slide27/text.txt": [
            "",
            " The question is to be answered using only the information in the TEXT.\nThis is a multiple-choice question. Select the option that best answers the question.\nThe answer is in the TEXT.",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen28-slide28/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen29-slide29/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen30-slide30/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen31-slide31/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen32-slide32/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen33-slide33/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen34-slide34/text.txt": [
            " This will be graded on its own, not as part of the TEXT answer.\nDo not answer the question. This will be graded on its own, not as part of the TEXT answer.\nRespond only with the QUESTION and nothing else. This will be graded on its own, not as part of the TEXT answer.\nDo not answer the question. This will be graded on its own, not as part of the TEXT answer.\nRespond only with the QUESTION and nothing else. This will be graded on its own, not as part of the TEXT answer.\nDo not answer the question. This will be graded on its own, not as part of",
            "",
            " The QUESTION is to be used to identify the correct answer.\nDo not write your answer in the text box provided."
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen35-slide35/text.txt": [
            " \nYou may use the following question as a guideline. \nThe answer to the question is not required.\n\nIf you answer the question, you will be penalized by 50 points.\nIf you do not answer the question, you will be penalized by 100 points.\nIf you do not answer the question and then answer a question which is answerable using only the information in the TEXT, you will be penalized by 200 points.\n\nThe answer to the question is not required.\nThe question is:\nWhich of the following is a possible answer to the question?\nYou may use the following answer as a guideline. \nThe answer to",
            " Do not answer the question.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not",
            " Use the same text for all languages.\n\nThe questions are in the following format:\n\nQUESTION: Which of the following is not a feature of the multilingual machine translation system?\nAnswer: (Answer)\n\nTEXT:\nFor a multilingual machine translation system, the following is not a feature:\n1. Automatic translation\n2. Automatic correction\n3. Automatic translation\n4. Automatic translation\n5. Automatic translation\n6. Automatic translation\n7. Automatic translation\n8. Automatic translation\n9. Automatic translation\n10. Automatic translation\n11. Automatic translation\n12. Automatic translation\n13. Automatic translation\n14. Automatic translation\n15."
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen36-slide36/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen37-slide37/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen38-slide38/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen39-slide39/text.txt": [
            "",
            " Do not answer the question.\nThe questions are not to be answered in the order they appear.\nThe questions are not to be answered in the order they appear.\nThe questions are not to be answered in the order they appear.\nThe questions are not to be answered in the order they appear.\nThe questions are not to be answered in the order they appear.\nThe questions are not to be answered in the order they appear.\nThe questions are not to be answered in the order they appear.\nThe questions are not to be answered in the order they appear.\nThe questions are not to be answered in the order they appear.\nThe questions are not to",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen40-slide40/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen41-slide41/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen42-slide42/text.txt": [
            "",
            "",
            " No explanation is needed.\nYou may use the following as a template, or you may use any other template you want.\n\nTEXT:\nOrhan Ferrat in two papers in 2016 did an experiment with corpora that are not multi parallel but only bilingual and bilingual across many pairs. And the main question was what to do with attention there. So he was trying to train N encoders and N decoders so multiple not only multiple source sites but also multiple target sites\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No explanation is needed.\nYou may use the following as a template, or you may use"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen43-slide43/text.txt": [
            "",
            " Do not include the TEXT.\nDo not use any other part of the source language.\n\nTEXT:\n The word “the” is a determiner and it is used to show possession. It is used with the following nouns: dog, cat, mouse, fish, bird, and so on. The word “the” is a determiner and it is used to show possession. It is used with the following nouns: dog, cat, mouse, fish, bird, and so on.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only",
            " Do not answer the question. The QUESTION will be given in the next TEXT.\n\nTEXT:\n What to do with the attention? As you know, the attention walks across the positions in the source language whenever you are producing the target output. So whenever you are producing the one word at a time.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question. The QUESTION will be given in the next TEXT.\n\nTEXT:\n What to do with the attention? As you know, the attention"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen44-slide44/text.txt": [
            "",
            "",
            " Do not answer the question.\n\nTEXT:\nAnd the idea is that you will simply share this attention across all the encoders and decoders. So the attention mechanism is just the same. And depending on which language pair you have at hand, you will train the respective encoder and decoder, but you will keep training the same attention mechanism across the language.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\n\nTEXT:\nAnd the idea is that you will simply share this attention across"
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen45-slide45/text.txt": [
            "",
            "",
            " The student may choose to answer the question or not. If they answer the question, they are not allowed to answer any other question on the exam."
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen46-slide46/text.txt": [
            " Do not answer the question.\n\nThe QUESTION should be a question worded as follows:\n\"What is the value of the following expression?\":\nFor example: \"What is the value of the following expression?\"\nThe value of the expression is \"42\".\n\nTEXT:\n\nThis is a test for your knowledge of the following topic:\n\"An Introduction to Python Programming\"\n\nThe first part of the TEXT is a series of questions to test your knowledge of the topic. The questions are not answerable using only the information in the TEXT.\n\nThe second part of the TEXT is a series of questions to test your knowledge of the topic. The questions are answerable using",
            " (no punctuation, no capitalization, no spaces, etc.)\n\n\nEXAMPLE:\nThe following text is a question to be answered using the information in the TEXT.\n\n1. Which of the following is not a characteristic of the American Revolution?\nA. It was a war between colonists and the British government.\nB. It was a war between colonists and the British government.\nC. It was a war between colonists and the British government.\nD. It was a war between colonists and the British government.\n2. Which of the following is not a characteristic of the American Revolution?\nA. It was a war between colonists and",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen47-slide45/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen48-slide46/text.txt": [
            " Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen49-slide48/text.txt": [
            " Do not answer the question with a single line of text.\nDo not answer the question with a single line of text.\nDo not answer the question with a single line of text.\nDo not answer the question with a single line of text.\nDo not answer the question with a single line of text.\nDo not answer the question with a single line of text.\nDo not answer the question with a single line of text.\nDo not answer the question with a single line of text.\nDo not answer the question with a single line of text.\nDo not answer the question with a single line of text.\nDo not answer the question with a single",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen50-slide47/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen51-slide49/text.txt": [
            "",
            " Do not answer the question.\nRespond with a short answer, using only the information in the TEXT.\nDo not answer the question.\nRespond with a short answer, using only the information in the TEXT.\nDo not answer the question.\nRespond with a short answer, using only the information in the TEXT.\nDo not answer the question.\nRespond with a short answer, using only the information in the TEXT.\nDo not answer the question.\nRespond with a short answer, using only the information in the TEXT.\nDo not answer the question.\nRespond with a short answer, using only the information in the TEXT.\nDo not answer the question.\nRespond with",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen52-slide50/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen53-slide52/text.txt": [
            " The question is not to be answered by a sentence, but by a single word.",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen54-slide50/text.txt": [
            " Do not answer the question.\nRespond with the QUESTION and the ANSWER.\n\nTEXT:\nThe 2020 COVID-19 pandemic is an ongoing pandemic of coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The outbreak was first detected in Wuhan, Hubei province, China, in December 2019. As of 4 August 2020, there have been more than 9.5 million cases and 500,000 deaths worldwide, with the majority of cases and deaths in China, India, Italy, Spain, France, and the United",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen55-slide52/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen56-slide53/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen57-slide54/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen58-slide55/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen59-slide56/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen60-slide57/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen61-slide58/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen62-slide59/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen63-slide60/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen64-slide61/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen65-slide62/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen66-slide61/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen67-slide62/text.txt": [
            "",
            " The QUESTION is the only thing that you should answer. If you respond to the text, you will get a penalty.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The QUESTION is the only thing that you should answer. If you respond to the text, you will get a penalty.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The QUESTION is the only thing that you should answer. If you respond to the text, you will get a penalty.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. The QUESTION is the only thing that you should answer.",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen68-slide63/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen69-slide64/text.txt": [
            "",
            " Do not respond to the TEXT.\n\nTEXT:\n The interesting and good thing is that indeed the embedding when projected to a two-dimensional vector space with T-SNE indicates the families. So the Indo-European languages form kind of a cluster and they are close to and I don't know whether this is probably the Niger-Congo languages. Then Austronesian languages are across the board. and then Afro-Zero-Quechua and Creole languages are here similar to the Indo-Europeans. In some of them Quechua languages form a distinct cluster. So the language families are empirically identified and they emerge. This heavily multilingual system",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen70-slide63/text.txt": [
            " \n\nThe TEXT is a large document which is an extract of a large corpus of texts.  The document is divided into 5 parts, each of which is a set of texts.\nThe first part is the question.  The second part is the answer to the question.\nThe third part is a list of the words in the question.\nThe fourth part is a list of the words in the answer.\nThe fifth part is the list of the words in the question and the answer.\nThe question is the first text in the first part of the TEXT.\nThe answer is the second text in the first part of the TEXT.\nThe words in",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen71-slide64/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen72-slide65/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen73-slide66/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen74-slide67/text.txt": [
            " If you cannot answer the question, then write a short explanation why you cannot answer it.",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen75-slide68/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen76-slide69/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen77-slide70/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen78-slide71/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen79-slide72/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen80-slide73/text.txt": [
            "",
            " Do not answer the question.\n\nTEXT:\n The following is a list of words that are not allowed in a response.\nPlease use the words from the list below. You may use more than one word from the list.\nThe following is a list of words that are allowed in a response.\nPlease use the words from the list below. You may use more than one word from the list.\n\nTEXT:\n The following is a list of words that are allowed in a response.\nPlease use the words from the list below. You may use more than one word from the list.\nThe following is a list of words that are not allowed in a response.\n",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen81-slide74/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture10-multilingual-mt/screen82-slide75/text.txt": [
            " No commentary or commentary on the question is permitted.\nIf you are unsure about the question, you can ask for clarification.\nIf you are unsure about the answer, you can ask for clarification.\nIf you are unsure about the source, you can ask for clarification.\n\nTEXT:\n This is when translating out of English. So here is the shared source and the different target. And here is the importance of the adapters more prominent.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. No commentary or commentary on the",
            " Do not use the TARGET.\nThe QUESTION will be based on the text in the TEXT. The QUESTION should be based on the TARGET.\nThe QUESTION will be the same for all participants. You may change the TARGET, but the QUESTION will remain the same.",
            " Do not use any of the information in the TEXT.\nIf you have any questions about this TEXT, please ask.\nThis is the shared source and the different target. And here is the importance of the adapters more prominent.\n\nTEXT:\n This is when translating out of English. So here is the shared source and the different target. And here is the importance of the adapters more prominent.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. Do not use any of the information in the TEXT.\nIf you have"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen01-slide02/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen02-slide03/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen03-slide04/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen04-slide05/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen05-slide07/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen06-slide07/text.txt": [
            " ",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen07-slide08/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen08-slide09/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen09-slide10/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen10-slide11/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen11-slide12/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen12-slide13/text.txt": [
            "",
            " Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only with the QUESTION and nothing else. Do not answer the question.\nRespond only",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen13-slide14/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen14-slide15/text.txt": [
            "",
            " \nThis is the first part of the exam.\n",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen15-slide16/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen16-slide17/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen17-slide18/text.txt": [
            "",
            " Do not answer the question.\n\nThis is a good way to learn to write a question for an exam.\nIt is also a good way to learn to answer a question for an exam.\n\nThe question is: What is the purpose of the self-attention mechanism?\n\nIn a way, self-attention is a way to look at the input as a whole. It's a way to look at the input as a whole. It's a way to look at the input as a whole.\n\nThe question is: What is the purpose of the self-attention mechanism?\n\nIn a way, self-attention is a way to look at the input as",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen18-slide19/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen19-slide20/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen20-slide21/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen21-slide22/text.txt": [
            " Do not answer the question.",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen22-slide23/text.txt": [
            " Do not provide a TEXT.",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen23-slide22/text.txt": [
            " Do not include any information from the TEXT in your response.\n\nYou can use the following TEXT as an example:\nThe following TEXT has been created by a student who wants to prepare for an exam. The student has not yet completed the exam and is trying to prepare for it. The student has asked you to help them with the exam. Your task is to help them by answering the questions.\nThe following TEXT is a part of a larger document. The student has not yet completed the exam and is trying to prepare for it. The student has asked you to help them with the exam. Your task is to help them by answering the questions.",
            "",
            " If you answer with a QUESTION, you must also include a TEXT in your answer.\nDo not answer the question."
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen24-slide23/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen25-slide24/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen26-slide25/text.txt": [
            " Do not use any other TEXT.\nTEXT:\n to the query. Yeah. So you again, these heads are totally independent of each other. So you can you again can do all these heads in a constant time, like in parallel. And you obtain eight different possible outputs. Yeah. So this is kind of surprising, or how do we then handle the, this eight times longer output than we, than we were expecting. Well, you do the normal thing. You would just concatenate them and project them to the size that you wanted.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen27-slide26/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen28-slide27/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen29-slide28/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen30-slide29/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen31-slide30/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen32-slide31/text.txt": [
            "",
            "",
            " (For example, \"Yes, I know the answer to the question. Do you want me to tell you?\")\n\nTEXT:\nSo let's look at explicit information in neural machine translation and we'll come to the transformer model and the experiments very soon but some of the early papers are actually pre-transformer and that's why the explicit information was there.\n\nBased on previous TEXT generate a single QUESTION for an exam which is answerable using only the information in the TEXT.\nDo not answer the question.\nRespond only with the QUESTION and nothing else. (For example, \"Yes, I know the answer to the question. Do you want me"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen33-slide33/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen34-slide33/text.txt": [
            "",
            "",
            " If you are not sure, then ask for clarification.\n\n1. A new company is setting up an office in a large city. The city has a population of 2 million. The company has 20 employees and they are all in the same office. The company is hiring 10 new employees. What is the probability that the 10 new employees will all be in the same office as the 20 employees?\n\n2. A group of 5 people are at a party. There are 5 seats at the table and 5 chairs. What is the probability that 2 of the 5 people will sit at the same table?\n\n"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen35-slide34/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen36-slide35/text.txt": [
            "",
            "",
            " Do not answer the question.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not answer the question.\nDo not answer the question. Respond only with the QUESTION and nothing else. Do not"
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen37-slide36/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen38-slide37/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen39-slide38/text.txt": [
            " Do not answer the question.\nRespond with a single sentence, in the form of a question, which you believe is answerable based on the information in the TEXT. Do not answer the question.\nRespond with a single sentence, in the form of a question, which you believe is answerable based on the information in the TEXT. Do not answer the question.\nRespond with a single sentence, in the form of a question, which you believe is answerable based on the information in the TEXT. Do not answer the question.\nRespond with a single sentence, in the form of a question, which you believe is answerable based on the information",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen40-slide39/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen41-slide39/text.txt": [
            " Do not answer the question.\nThe QUESTION is:\nWhat are the tags in the CCG text for the word 'like'?\n",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen42-slide39/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen43-slide40/text.txt": [
            "",
            " Do not use the\nTEXT as a source for the answer. Do not use the TEXT to answer the\nquestion. Do not use the TEXT to answer the question.\nThe question is: How can we put syntactic information at each token?\nThe question is: How can we put syntactic information at each token?",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen44-slide41/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen45-slide42/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen46-slide43/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen47-slide44/text.txt": [
            " Do not answer the question.\nIf you are not sure how to respond, you should not answer the question. Respond with the QUESTION.\nRespond with a single QUESTION that is answerable using only the information in the TEXT. Do not answer the question.\nIf you are not sure how to respond, you should not answer the question. Respond with the QUESTION.\nRespond with a single QUESTION that is answerable using only the information in the TEXT. Do not answer the question.\nIf you are not sure how to respond, you should not answer the question. Respond with the QUESTION.\nRespond with a single QUESTION that is answerable using only the information",
            " Do not respond with any information other than the QUESTION.\n\nTEXT:\nWhat is the probability that the text is a random sequence?\nWhat is the probability that the text is a sequence of letters and digits?\nWhat is the probability that the text is a sequence of letters and digits, where at least one letter is a vowel?\nWhat is the probability that the text is a sequence of letters and digits, where at least one letter is a vowel, and where the last letter is a vowel?\nWhat is the probability that the text is a sequence of letters and digits, where at least one letter is a vowel, and where the last letter is a",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen48-slide45/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen49-slide46/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen50-slide47/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen51-slide48/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen52-slide49/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen53-slide50/text.txt": [
            "",
            "",
            ""
        ],
        "testset/nmt-class/lecture08-transformer-and-syntax-in-nmt/screen54-slide51/text.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/video-02/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/video-07/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/video-13/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/audio-10/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/video-14/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/audio-09/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/video-04/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/video-23/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/video-15/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/video-08/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/video-06/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/audio-24/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/audio-12/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/popular/audio-19/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book02/topic01-Обмін речовин та перетворення енергії в організмі людини/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book02/topic02-Травлення/text.en.txt": [
            " If you have\nNOT answered the question, it is\nNOT POSSIBLE\nto answer the question\n.",
            "",
            ""
        ],
        "testset/ukr-biology/book02/topic03-Дихання/text.en.txt": [
            "",
            " Do not use any other information.\nUse the following information to answer the question.\nThe table below shows the composition of the air we breathe in and out.\n\n\n57. Topic 3\n\n\nThe table below shows the composition of the air we breathe in and out.\na) oxygen b) carbon dioxide c) nitrogen d) water\n\n\nThe table below shows the composition of the air we breathe in and out.\na) oxygen b) carbon dioxide c) nitrogen d) water\n\n\nThe table below shows the composition of the air we breathe in and out.\na) oxygen b) carbon dioxide c) nitrogen d) water\n\n\nThe table below shows",
            ""
        ],
        "testset/ukr-biology/book02/topic04-Транспорт речовин/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book02/topic05-Опора та рух/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book02/topic06-Зв’язок організму людини із зовнішнім середовищем. Нервова система/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book02/topic07-Зв’язок організму людини із зовнішнім середовищем. Сенсорні системи/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book02/topic08-Вища нервова діяльність/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book02/topic09-Регуляція функцій організму/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book02/topic10-Розмноження та розвиток людини/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book05/topic01-Адаптації/text.en.txt": [
            " Do not answer the question.\nRespond with the QUESTION and some information from the TEXT.\nRespond with some information from the TEXT and a QUESTION.\nRespond with some information from the TEXT and a QUESTION and some other information from the TEXT.",
            "",
            ""
        ],
        "testset/ukr-biology/book05/topic02-Біологічні основи здорового способу життя/text.en.txt": [
            "",
            " Do not answer the question.\nRespond with the QUESTION and a few sentences that will help you to answer the question. Do not answer the question.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\nRespond with the QUESTION and the TEXT only.\n",
            " The question will be answered in the exam.\n\n\nTEXT:\n1.\tWhat are the main differences between biological and non-biological foundations of health and disease?\n2.\tWhat are the most common infectious diseases? Why are they so dangerous?\n3.\tWhat are the most common parasitic diseases? Why are they dangerous?\n4.\tWhat is the difference between non-specific and specific immunity? Why is it important?\n5.\tWhat are the main ways of preventing infections and invasions? Which is the most effective?\n6.\tWhat is the difference between sapronoses and zoonoses? Which diseases are caused by them?\n"
        ],
        "testset/ukr-biology/book05/topic03-Екологія/text.en.txt": [
            "",
            "",
            " Do not write the answer.\nThe QUESTION is the same for all students.\nYou can use the QUESTION in any order.\nDo not write the QUESTION in the TEXT.\nYou can use the QUESTION in any order.\nYou can use the QUESTION in any order.\nYou can use the QUESTION in any order.\nYou can use the QUESTION in any order.\nYou can use the QUESTION in any order.\nYou can use the QUESTION in any order.\nYou can use the QUESTION in any order.\nYou can use the QUESTION in any order.\nYou can use the QUESTION in any order.\nYou can use the QUESTION in any order.\nYou can use the QUESTION"
        ],
        "testset/ukr-biology/book05/topic04-Сталий розвиток та раціональне природокористування/text.en.txt": [
            "",
            "",
            " Use the following symbols in your answer: ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( )"
        ],
        "testset/ukr-biology/book05/topic05-Застосування результатів біологічних досліджень у медицині, селекції та біотехнології/text.en.txt": [
            "",
            "",
            " Do not use any additional information. Do not use the TEXT or the ANSWERS to the TEXT as a source of information.\nDo not use any information from the INTERNET."
        ],
        "testset/ukr-biology/book03/topic01-Хімічний склад клітинита біологічні молекули/text.en.txt": [
            " No additional information is required.",
            " Use the format: QUESTION: {question}. The text is not included in the answer.\nFor example, if the text says that\nthe hydrocarbon isoprene is a structural component of waxes, then the QUESTION could be:\nWhat is the structural component of waxes?\n\n\n40. Topic 1\n\n\nThe structure in Fig. 1 is a monomer of:\n\n\na) nucleic acid c) lipid\n\n\nb) protein d) polysaccharide\n\n\n41. The structure in Fig. 2 is a monomer of:\n\n\na) nucleic acid\nc) protein\n\n\nb) lipid d) polysaccharide",
            " Do not write any text.\n\n\n40. Topic 1\n\n\n41. Topic 1\n\n\n42. Topic 1\n\n\n43. Topic 1\n\n\n44. Topic 1\n\n\n45. Topic 1\n\n\n46. Topic 1\n\n\n47. Topic 1\n\n\n48. Topic 1\n\n\n49. Topic 1\n\n\n50. Topic 1\n\n\n51. Topic 1\n\n\n52. Topic 1\n\n\n53. Topic 1\n\n\n54. Topic 1\n\n\n55. Topic 1\n\n\n56. Topic 1\n\n\n57. Topic 1\n\n\n58. Topic 1\n\n\n59. Topic 1\n\n\n60."
        ],
        "testset/ukr-biology/book03/topic02-Структура клітини/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book03/topic03-Принципи функціонування клітини/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book03/topic04-Збереження та реалізаціяспадкової інформації/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book03/topic05-Закономірності успадкування ознак/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book03/topic06-Еволюція органічного світу/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book03/topic07-Біорізноманіття/text.en.txt": [
            " The question is in bold.\nA) What is the main systematic category of the kingdom of Plants?\nB) What is the main systematic category of the kingdom of Animals?\nC) What is the main systematic category of the kingdom of Vertebrates?\nD) What is the main systematic category of the kingdom of Bacteria?\nE) What is the main systematic category of the kingdom of Archaea?\nF) What is the main systematic category of the kingdom of Eukaryotes?\nG) What is the main systematic category of the kingdom of Viruses?\nH) What is the main systematic category of the kingdom of Fungi?\nI",
            "",
            ""
        ],
        "testset/ukr-biology/book03/topic08-Надорганізмові біологічні системи/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book03/topic09-Біологія як основа біотехнологіїта медицини/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book04/topic01-Біорізноманіття/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book04/topic02-Обмін речовин і перетворення енергії/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book04/topic03-Спадковість і мінливість/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/ukr-biology/book04/topic04-Репродукція та розвиток організмів/text.en.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter05-Asia-in-Ancient-Times/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter04-The-Near-East/text.txt": [
            "",
            " Do not answer with the TEXT.",
            " Do not answer the question.\nIf you answer the question, you will be penalized for using more than the space allowed. If you do not answer the question, you will be penalized for not answering the question.\nUse only the information in the TEXT. Use the TEXT as a guide, not as a source. Use only the information in the TEXT. Use the TEXT as a guide, not as a source.\nUse the TEXT to answer the question. Use the TEXT as a guide, not as a source. Use the TEXT to answer the question. Use the TEXT as a guide, not as a source.\nUse the TEXT as"
        ],
        "testset/world-history/chapter15-States-and-Societies-in-Sub-Saharan-Africa/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter07-Experiencing-the-Roman-Empire/text.txt": [
            " Use the QUESTION to guide your thinking and help you to answer the question.\nThe question is NOT a statement of fact.\nThe question is NOT a statement of opinion.\nThe question is NOT a statement of a rule.\nThe question is NOT a statement of a process.\nThe question is NOT a statement of a fact that can be proven true or false.\nThe question is NOT a statement of a claim.\nThe question is NOT a statement of a definition.\nThe question is NOT a statement of a process that can be followed to arrive at a conclusion.\nThe question is NOT a statement of a process that can be followed to arrive at a conclusion.\n",
            " If you answer the question, you will lose points.\nThe QUESTION is: Which of the following is true about the Roman Empire?\nA. It was divided into many provinces\nB. It had a single capital\nC. It was a single empire\nD. It had many different cultures\nAnswer: B",
            ""
        ],
        "testset/world-history/chapter14-Pax-Mongolica-The-Steppe-Empire-of-the-Mongols/text.txt": [
            " Do not use the TEXT or any other source to answer the question.\nWrite the question in the space provided below.\n\nThe Delhi Sultanate is a good example of a:\nA) Muslim state\nB) Christian state\nC) Jewish state\nD) Hindu state\nE) state with multiple religious groups\nF) state with no religious affiliation\nG) state with no religion\nH) state with a single religion\nI) state with multiple religions\nJ) state with no religion\nK) state with multiple religions\nL) state with no religion\nM) state with multiple religions\nN) state with no religion\nO",
            "",
            ""
        ],
        "testset/world-history/chapter06-Mediterranean-Peoples/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter09-Africa-in-Ancient-Times/text.txt": [
            " Do not include any of the TEXT in your response.",
            "",
            ""
        ],
        "testset/world-history/chapter03-Early-Civilizations-and-Urban-Societies/text.txt": [
            "",
            " Use the question to guide your answer.\nThe answer should be in the form of a question that can be answered with the information in the TEXT.\nUse the question to help guide your answer.\nThe answer should be in the form of a question that can be answered with the information in the TEXT.\nUse the question to help guide your answer.\nThe answer should be in the form of a question that can be answered with the information in the TEXT.\nUse the question to help guide your answer.\nThe answer should be in the form of a question that can be answered with the information in the TEXT.\nUse the question to help guide your answer.\n",
            " Use the text to support your answer.\nDo not answer the question."
        ],
        "testset/world-history/chapter08-The-Americas-in-Ancient-Times/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter12-India,-the-Indian-Ocean-Basin,-and-East-Asia/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter10-Empires-of-Faith/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter02-Early-Humans/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter01-Understanding-the-Past/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter17-The-Ottomans,-the-Mamluks,-and-the-Ming/text.txt": [
            " Do not give the answer.",
            " The QUESTION must be written in the same format as the TEXT.\nText: The Mongol invasions of China in the thirteenth century left China weakened and unable to defend itself against the expansion of the Ming dynasty. The Mongols had conquered much of Asia by the late thirteenth century. In the thirteenth century, they were not only the dominant force in China but also in much of East Asia, including Korea, Vietnam, and Japan. The Mongols also controlled large parts of western Asia. The Mongols’ conquest of China was short-lived, however. The Yuan dynasty emperor Kublai Khan waged a series of",
            ""
        ],
        "testset/world-history/chapter11-The-Rise-of-Islam-and-the-Caliphates/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter16-Climate-Change-and-Plague-in-the-Fourteenth-Century/text.txt": [
            "",
            "",
            ""
        ],
        "testset/world-history/chapter13-The-Post-Roman-West-and-the-Crusading-Movement/text.txt": [
            "",
            "",
            ""
        ]
    }
}