{
    "demagog-statements-public/s_id21244/text.en.txt": [
        {
            "question": "What percentage of the votes did the SPOLU coalition win in the elections to the Chamber of Deputies of the Parliament of the Czech Republic?",
            "reference-answers": [
                "27.79%"
            ]
        },
        {
            "question": "What percentage of the votes did the SPOLU coalition, formed by ODS, TOP 09 and KDU-ČSL, win in the elections to the Chamber of Deputies of the Parliament of the Czech Republic?",
            "reference-answers": [
                "27.79%"
            ]
        },
        {
            "question": "What did Petr Fiala say in his post-election speech about the unity of the Czech people?",
            "reference-answers": [
                "We are all citizens of the Czech Republic who want to live here and we want to live here together, as neighbors, as friends, as colleagues. That is what unites us all."
            ]
        }
    ],
    "demagog-statements-public/s_id21452/text.en.txt": [
        {
            "question": "According to Miloš Zeman's budget speech in the Chamber of Deputies in 2019, what would be the estimated amount of money saved if all tax exemptions were abolished?",
            "reference-answers": [
                "380 billion crowns."
            ]
        },
        {
            "question": "According to Miloš Zeman's proposal, what would be saved if all tax exemptions were abolished?",
            "reference-answers": [
                "380 billion crowns."
            ]
        },
        {
            "question": "What is the estimated state budget deficit for the year according to the State Budget Act?",
            "reference-answers": [
                "500 billion crowns."
            ]
        }
    ],
    "demagog-statements-public/s_id21471/text.en.txt": [
        {
            "question": "What is the resolution of the Czech Parliament that Prime Minister Petr Fiala referred to in his letter to the President of the European Commission?",
            "reference-answers": [
                "The resolution of the Chamber of Deputies, adopted on December 14, 2021, notes that the Czech Republic has committed itself to the Paris Agreement and the European Green Deal, and emphasizes that nuclear energy must be fully recognized as part of the solution for decarbonizing the economy, and that it cannot be considered just as a \"transitional\" category."
            ]
        },
        {
            "question": "What is the position of the Czech Republic regarding the inclusion of gas and nuclear energy in the EU taxonomy, as stated in a letter to the President of the European Commission?",
            "reference-answers": [
                "The Czech Republic supports the inclusion of gas and nuclear energy in the EU taxonomy, as stated in a letter to the President of the European Commission, in full accordance with the resolution adopted by both chambers of the Czech Parliament on 15.12.2021."
            ]
        },
        {
            "question": "What is the main position of the Czech government regarding the inclusion of gas and nuclear energy in the EU taxonomy, as expressed in a letter to the President of the European Commission?",
            "reference-answers": [
                "The Czech government considers the inclusion of gas and nuclear energy in the EU taxonomy to be extremely important, and it requests that this be taken into account when making decisions, as stated in a letter to the President of the European Commission."
            ]
        }
    ],
    "demagog-statements-public/s_id21477/text.en.txt": [
        {
            "question": "What was Alena Schillerová's initial stance on increasing the salaries of state employees, as stated in the spring of 2021?",
            "reference-answers": [
                "Alena Schillerová initially stated that salaries should be increased only for teachers, healthcare workers and social service workers as part of the consolidation of public finances."
            ]
        },
        {
            "question": "In the spring of 2021, Alena Schillerová stated that the path to budget consolidation lies in not valorizing, not increasing the salaries of employees in the state sector, and that only the salaries of teachers, firefighters, police officers, and so on will increase. According to this statement, what groups of state employees should not have their salaries increased?",
            "reference-answers": [
                "The salaries of all state employees, including firefighters and police officers, should not have been increased according to Alena Schillerová's statement."
            ]
        },
        {
            "question": "What was the position of former Finance Minister Alena Schillerová regarding salary increases for state employees in the spring of 2021, and how did it change later that year?",
            "reference-answers": [
                "In the spring of 2021, former Finance Minister Alena Schillerová stated that the path to budget consolidation lies in not valorizing, not increasing the salaries of employees in the state sector. She said that only the salaries of teachers, firefighters, police officers, and so on will increase. However, later that year, she reversed course and agreed to increase the salaries of all state employees, including firefighters and police officers, even though debates continued over the rate of increase."
            ]
        }
    ],
    "demagog-statements-public/s_id21480/text.en.txt": [
        {
            "question": "What is the main cause of the current inflation in the Czech Republic, according to economists and the Czech National Bank?",
            "reference-answers": [
                "Economists and the Czech National Bank attribute the main responsibility for the increase in inflation to international influences."
            ]
        },
        {
            "question": "What is the main reason according to the Czech National Bank (CNB) for the current high inflation in the Czech Republic?",
            "reference-answers": [
                "A surge in consumer demand after the lifting of anti-epidemic measures."
            ]
        },
        {
            "question": "What is the main reason according to the Czech National Bank for the current high inflation in the Czech Republic, as stated by the CNB Governor Rusnok?",
            "reference-answers": [
                "The main reason according to the Czech National Bank for the current high inflation in the Czech Republic is \"unexpectedly strong and widespread inflationary pressures from the domestic and foreign economies\"."
            ]
        }
    ],
    "demagog-statements-public/s_id21519/text.en.txt": [
        {
            "question": "What is the condition under which pensions are automatically valorized and increased according to the level of inflation in the last month in which the cumulative increase of over 5% occurred?",
            "reference-answers": [
                "Pensions are automatically valorized and increased according to the level of inflation in the last month in which the cumulative increase of over 5% occurred, if since the last month taken for the valorization of pensions, which took place from January, which is July last year, inflation increases by more than 5% in total."
            ]
        },
        {
            "question": "Will pensions be automatically valorized if the cumulative inflation from July 2021 exceeds 5% by the end of January 2022?",
            "reference-answers": [
                "Yes, pensions will be automatically valorized if the cumulative inflation from July 2021 exceeds 5% by the end of January 2022."
            ]
        },
        {
            "question": "What is the period used to determine the price increases for further increases in pensions, and how does it begin?",
            "reference-answers": [
                "The period for determining price increases for further increases in pensions begins with the calendar month following the end of the period according to which pensions were last valorized."
            ]
        }
    ],
    "demagog-statements-public/s_id21531/text.en.txt": [
        {
            "question": "What is the purpose of the Antivirus A program, according to the Ministry of Labor and Social Affairs?",
            "reference-answers": [
                "The purpose of the Antivirus A program is compensation of costs to employers whose employees were ordered to quarantine or isolate."
            ]
        },
        {
            "question": "What is the purpose of the Antivirus A program, introduced by the Ministry of Labor and Social Affairs during the COVID-19 pandemic?",
            "reference-answers": [
                "The purpose of the Antivirus A program is compensation of costs to employers whose employees were ordered to quarantine or isolate."
            ]
        },
        {
            "question": "What type of assistance tools are shared by the Ministry of Labor and Social Affairs for entrepreneurs and tradespeople during the pandemic?",
            "reference-answers": [
                "Antivirus programs."
            ]
        }
    ],
    "demagog-statements-public/s_id21793/text.en.txt": [
        {
            "question": "Who was the hockey player who became a member of the ESB company's board of directors in 2021, but was not involved in the illegal actions in the case involving Miloš Balák?",
            "reference-answers": [
                "Jaromír Jágr."
            ]
        },
        {
            "question": "What is the name of the hockey player who became a member of the ESB company's board of directors in 2021, and was also involved in the case of the modification of the slopes of the water reservoir in Lány?",
            "reference-answers": [
                "Jaromír Jágr."
            ]
        },
        {
            "question": "What is the approximate profit that the ESB company was supposed to make from the unauthorized acquisition of the contract for securing and draining the slopes of the Klíčava reservoir in the Lánská oboře?",
            "reference-answers": [
                "According to the court, the ESB company's profit from the unauthorized acquisition of the contract was supposed to be almost 9 million crowns."
            ]
        }
    ],
    "demagog-statements-public/s_id21794/text.en.txt": [
        {
            "question": "How many people were granted pardons by Václav Havel during his presidency, and what types of crimes were typically pardoned by him?",
            "reference-answers": [
                "Václav Havel granted a total of 2,000 pardons, and among these pardons, there was no parricide, while he pardoned a restitution fraudster, Mrs. Chadimová, who was then defended by Pavel Rychetský."
            ]
        },
        {
            "question": "How many pardons did Václav Klaus grant during his 10 years in office?",
            "reference-answers": [
                "412"
            ]
        },
        {
            "question": "How many pardons did Václav Havel grant between 1993 and 2002?",
            "reference-answers": [
                "860"
            ]
        }
    ],
    "demagog-statements-public/s_id21804/text.en.txt": [
        {
            "question": "When did the government announce a set of measures to help families with children cope with high inflation and rising energy prices?",
            "reference-answers": [
                "After its meeting on April 27, 2022."
            ]
        },
        {
            "question": "What was the amount of the one-time contribution for each child announced by the government in April 2022?",
            "reference-answers": [
                "5,000 crowns."
            ]
        },
        {
            "question": "What type of income was the contribution for the family assistance measure calculated from, according to the Minister of Labor and Social Affairs Marian Jurečka?",
            "reference-answers": [
                "The contribution was calculated from the net income of the household."
            ]
        }
    ],
    "demagog-statements-public/s_id22492/text.en.txt": [
        {
            "question": "What is the proposed change to the government's powers when sending soldiers abroad, according to the draft amendment to the Constitution submitted by Petr Fiala's cabinet to the Chamber of Deputies?",
            "reference-answers": [
                "The proposed change to the government's powers when sending soldiers abroad is that the government would no longer need the consent of Parliament to send troops to foreign territory for the purpose of protecting \"life and health, threatening property values or the security of the Czech Republic\", including rescuing Czech citizens, for a maximum of 60 days, after which the presence of troops outside the Czech Republic would have to be approved by Parliament."
            ]
        },
        {
            "question": "What is the main difference between the current proposal to amend the Constitution and the previous proposals submitted to the Chamber of Deputies regarding the government's powers when sending soldiers abroad?",
            "reference-answers": [
                "The main difference between the current proposal to amend the Constitution and the previous proposals submitted to the Chamber of Deputies is that the current proposal would allow the government to send soldiers abroad for a maximum of 60 days without the prior consent of Parliament, whereas the previous proposals removed the three conditions under which the government could send soldiers abroad, including fulfilling obligations under international treaties on collective defense against attack, participating in peacekeeping operations, and during rescue work after natural disasters or industrial and ecological accidents."
            ]
        },
        {
            "question": "What is the main argument of Andrej Babiš in the debate regarding the government's proposal to amend the Constitution and send soldiers abroad without the consent of Parliament?",
            "reference-answers": [
                "Andrej Babiš's main argument is that the proposal to change the rules of the government's powers in this area was submitted by his government, and he only mentioned the case of rescuing Czechs abroad, and that the current proposal would enable the government to decide operationally on the deployment of the Czech Republic's armed forces outside the territory of the Czech Republic and on the stay of the armed forces of other states in the territory of the Czech Republic without specifying the purpose of the deployment or stay."
            ]
        }
    ],
    "demagog-statements-public/s_id22620/text.en.txt": [
        {
            "question": "When can opposition parties submit a proposal to the Constitutional Court regarding the amendment to the Act on Lower Pension Valorization?",
            "reference-answers": [
                "After submitting a complaint or draft on repeal of the law, the opposition parties can submit a proposal to the Constitutional Court within a month of the declaration of the state of legislative emergency."
            ]
        },
        {
            "question": "When did the opposition movement ANO want to submit a proposal to the Constitutional Court in the matter of the newly adopted reduction in pension valorization in June 2023?",
            "reference-answers": [
                "After submitting a complaint or draft on repeal of the law, the ANO movement wanted to submit a proposal to the Constitutional Court in early May."
            ]
        },
        {
            "question": "What type of statements can the Constitutional Court publish in the past when rejecting proposals to repeal a law?",
            "reference-answers": [
                "The Constitutional Court can publish non-binding statements, so-called obiter dictums, in the past when rejecting proposals to repeal a law."
            ]
        }
    ],
    "demagog-statements-public/s_id22632/text.en.txt": [
        {
            "question": "When will the Minister of Labor and Social Affairs Marian Jurečka discuss the proposal to change the rules for pension valorization with representatives of the opposition, trade unions and employers?",
            "reference-answers": [
                "Marian Jurečka wants to discuss with representatives of the opposition, trade unions and employers in the next few days, and then only after he has conducted these consultations, will the interdepartmental comment procedure begin and the proposal go to the government."
            ]
        },
        {
            "question": "When did Minister Jurečka announce that he would discuss the proposal to change the rules for pension valorization with representatives of the opposition, trade unions, and employers?",
            "reference-answers": [
                "Marian Jurečka announced that he would discuss the proposal to change the rules for pension valorization with representatives of the opposition, trade unions, and employers in the next few days, at which time he would also negotiate with colleagues from the SPD and representatives of trade unions and employers."
            ]
        },
        {
            "question": "When did the Minister of Labor and Social Affairs, Marian Jurečka, announce that he would discuss with representatives of the opposition, unions and employers the changes to the valorization of pensions?",
            "reference-answers": [
                "Marian Jurečka announced that he would discuss with representatives of the opposition, unions and employers the changes to the valorization of pensions on March 22."
            ]
        }
    ],
    "demagog-statements-public/s_id22635/text.en.txt": [
        {
            "question": "What is the target age group that the government aims to ensure a fair and sustainable pension system for, according to Minister Marian Jurečka?",
            "reference-answers": [
                "The target age group that the government aims to ensure a fair and sustainable pension system for, according to Minister Marian Jurečka, are people in their forties, thirties and younger people, even in the future."
            ]
        },
        {
            "question": "Will the pension reform change anything for people born before 1973?",
            "reference-answers": [
                "No, the pension reform will not change anything for people born before 1973."
            ]
        },
        {
            "question": "What is the expected impact of the planned pension reform on the generation of people aged 50 and above?",
            "reference-answers": [
                "The planned pension reform will primarily affect the generation of people about 50-minus and 45-minus, meaning it is expected to have a significant impact on people aged 50 and above."
            ]
        }
    ],
    "demagog-statements-public/s_id22878/text.en.txt": [
        {
            "question": "What is the statutory deadline for processing an application for housing allowance in the Czech Republic, according to the Administrative Code?",
            "reference-answers": [
                "The statutory deadline for processing an application for housing allowance in the Czech Republic is 30 days, or up to 60 days in complex cases or if a social investigation is carried out."
            ]
        },
        {
            "question": "What is the deadline for processing an application for housing allowance, according to the Administrative Code?",
            "reference-answers": [
                "The deadline for processing an application for housing allowance is, according to the Administrative Code, 30 days, or up to 60 days if it is a complex case or if the Labour Office carries out a social investigation."
            ]
        },
        {
            "question": "What is the deadline for processing an application for housing allowance according to the Administrative Code?",
            "reference-answers": [
                "The deadline for processing an application for housing allowance is, according to the Administrative Code, 30 days, or up to 60 days if it is a complex case or if the Labour Office carries out a social investigation."
            ]
        }
    ],
    "demagog-statements-public/s_id22921/text.en.txt": [
        {
            "question": "According to the data from the Czech Police, what percentage of solved crimes in the first half of 2023 were committed by foreigners?",
            "reference-answers": [
                "Foreigners were responsible for approximately 10.9% of solved crimes in the first half of 2023."
            ]
        },
        {
            "question": "According to the data from the Czech Police, what percentage of solved crimes in the first half of 2023 were committed by foreigners?",
            "reference-answers": [
                "Foreigners were responsible for approximately 10.9% of solved crimes in the first half of 2023."
            ]
        },
        {
            "question": "What is the current percentage of foreigners in the Czech population, according to the latest data from the Czech Statistical Office?",
            "reference-answers": [
                "According to the latest data from the Czech Statistical Office, the current percentage of foreigners in the Czech population is 9.5% at the end of June."
            ]
        }
    ],
    "demagog-statements-public/s_id22954/text.en.txt": [
        {
            "question": "What is the planned budget deficit for next year according to the final draft budget submitted by the Ministry of Finance?",
            "reference-answers": [
                "The budget deficit is thus planned at 252 billion CZK."
            ]
        },
        {
            "question": "What is the final draft budget for 2024, according to the Ministry of Finance, in terms of total revenues and expenditures?",
            "reference-answers": [
                "The final draft budget for 2024, according to the Ministry of Finance, includes total revenues of 1.921.2 billion CZK and expenditures of 2.173.2 billion CZK."
            ]
        },
        {
            "question": "What is the final draft budget for 2024 submitted by the Ministry of Finance, according to the information provided?",
            "reference-answers": [
                "The total revenues of the final draft budget for 2024 submitted by the Ministry of Finance are 1,921.2 billion CZK, and the total expenditures are 2,173.2 billion CZK."
            ]
        }
    ],
    "demagog-statements-public/s_id23177/text.en.txt": [
        {
            "question": "When did the trade union strike take place in the Prague region?",
            "reference-answers": [
                "November 27, 2023."
            ]
        },
        {
            "question": "When did Petr Fiala visit the Agro School in Pozdatin in the Třebíč region?",
            "reference-answers": [
                "On the day of the trade union strike, November 27, 2023, Petr Fiala visited the Agro School in Pozdatin in the Třebíč region."
            ]
        },
        {
            "question": "What type of visit did Prime Minister Petr Fiala make to the Agro School in Pozdatin on the day of the trade union strike?",
            "reference-answers": [
                "Prime Minister Petr Fiala visited the Agro School in Pozdatin on the day of the trade union strike, where he met with teachers and students."
            ]
        }
    ],
    "demagog-statements-public/s_id23626/text.en.txt": [
        {
            "question": "When was the agreement between the opposition and the coalition concluded, according to Vít Rakušan?",
            "reference-answers": [
                "sometime in 2015."
            ]
        },
        {
            "question": "When did the agreement between the opposition and the coalition conclude, according to Vít Rakušan's statement?",
            "reference-answers": [
                "sometime in 2015."
            ]
        },
        {
            "question": "What agreement was concluded around 2015 by the then government coalition and the opposition, and what was its aim regarding the growth of politicians' salaries?",
            "reference-answers": [
                "The agreement concluded around 2015 by the then government coalition and the opposition was to automate the growth of politicians' salaries, ensuring that salaries would rise in the event of a good economic situation, and would not increase if the economy were to decline."
            ]
        }
    ],
    "demagog-statements-public/s_id23655/text.en.txt": [
        {
            "question": "According to the Czech Statistical Office's 2023 demographic projection, what is the projected total fertility rate per woman in the Czech Republic?",
            "reference-answers": [
                "1.45 child per woman."
            ]
        },
        {
            "question": "Will the number of people of working age in the Czech Republic reach 5.39 million people by the end of the century, according to the middle variant of the demographic projection from 2023?",
            "reference-answers": [
                "Yes, according to the middle variant of the demographic projection from 2023, the number of people of working age will decrease to 5.39 million people by the end of the century."
            ]
        },
        {
            "question": "What is the expected total fertility rate according to the Czech Statistical Office's projection from 2023?",
            "reference-answers": [
                "1.5 children per woman."
            ]
        }
    ],
    "flat-earth-book/SECTION-1/text.txt": [
        {
            "question": "What is the difference in the distance around the Earth, as calculated by theory and as observed by practical navigators, in the southern region?",
            "reference-answers": [
                "There is an error of 7,718 miles between the theory of rotundity and practical sailing in the southern region, but further calculations suggest that the actual circumference is 22,657 miles, or 8,357 miles more than the theory would permit."
            ]
        },
        {
            "question": "What is the argument made by Sir James Clarke Ross in support of the Earth's convexity, and how does he use this argument to challenge the theory of the Earth's rotundity?",
            "reference-answers": [
                "Sir James Clarke Ross argues that if 143 degrees of longitude make 9,000 miles, then the whole extent of the Earth's circumference, which is 360 degrees, should make 22,657 miles, or 8,357 miles more than the theory of rotundity would permit."
            ]
        },
        {
            "question": "What is the difference between the calculated circumference of the Earth according to the theory of rotundity and the actual distance measured by navigators in the southern region?",
            "reference-answers": [
                "The calculated circumference of the Earth according to the theory of rotundity is 14,282 miles, while the actual distance measured by navigators in the southern region is 22,000 miles."
            ]
        }
    ],
    "flat-earth-book/SECTION-10/text.txt": [
        {
            "question": "What is the general cause of tides, according to the author, and how does it relate to the action and reaction of the Earth's atmosphere and the ocean?",
            "reference-answers": [
                "The general cause of tides is that the Earth slightly fluctuates, or slowly rises and falls, due to the action of the atmosphere, which causes the water to move towards the receding shores and produce the flood tide, and when the Earth gradually ascends the waters, the ebb tide is produced."
            ]
        },
        {
            "question": "What is the primary cause of tides in the ocean, according to the text, and how does it relate to the Earth's motion and the atmosphere's pressure on the water?",
            "reference-answers": [
                "The primary cause of tides in the ocean is the slight fluctuation or slow rise and fall of the Earth due to the action of the atmosphere, causing the water to move towards the receding shores and produce the flood tide, and then recede when the Earth gradually ascends the waters, producing the ebb tide."
            ]
        },
        {
            "question": "What is the general cause of tides in the ocean, according to the text?",
            "reference-answers": [
                "The general cause of tides in the ocean is the slight fluctuation or slow rise and fall of the Earth due to the constant pressure of the atmosphere upon the Earth and ocean, resulting in the water moving towards the receding shores and producing the flood tide, and receding and producing the ebb tide."
            ]
        }
    ],
    "flat-earth-book/SECTION-11/text.txt": [
        {
            "question": "What is the estimated depth at which the temperature of the Earth's interior is equal to boiling water, according to Sir Richard Phillips?",
            "reference-answers": [
                "At a depth of 8,212 feet, or about 1 1/2 English miles under Paris."
            ]
        },
        {
            "question": "What is the estimated rate of temperature increase with depth in the Earth, according to the observations made by M. Arago?",
            "reference-answers": [
                "One degree Fahrenheit for about every 545 feet."
            ]
        },
        {
            "question": "What is the estimated depth at which the temperature of the Earth's interior is on average one degree Fahrenheit for every 545 feet?",
            "reference-answers": [
                "At a depth of about twelve miles from the surface, the temperature of the Earth's interior is on average one degree Fahrenheit for every 545 feet."
            ]
        }
    ],
    "flat-earth-book/SECTION-12/text.txt": [
        {
            "question": "What is the general idea behind M. Foucault's rule for determining the latitude of a place based on the pendulum experiment?",
            "reference-answers": [
                "M. Foucault's rule states that the angular space passed over by the pendulum at any latitude in a given time is equal to the angular motion of the Earth in the period, multiplied by the sine of the latitude."
            ]
        },
        {
            "question": "What is the name of the French scientist whose experiments on the pendulum are of European notoriety, according to M. Dehaut's note to the French Academy of sciences?",
            "reference-answers": [
                "M. Foucault."
            ]
        },
        {
            "question": "What is the main argument of the writer in the Liverpool Mercury of May 23, 1851, regarding the pendulum experiment and its relation to the Earth's motion?",
            "reference-answers": [
                "The main argument of the writer in the Liverpool Mercury of May 23, 1851, is that the supposed manifestation of the Earth's rotation via the pendulum experiment is based on a false supposition, specifically the idea that a pendulum will continue to oscillate in one and the same original plane in a complete vacuum, which is an unfounded assumption."
            ]
        }
    ],
    "flat-earth-book/SECTION-13/text.txt": [
        {
            "question": "What is the altitude of the Eddystone Light, and according to the report, where is it not visible despite being within a 14 statute-mile distance from the observers?",
            "reference-answers": [
                "The altitude of the Eddystone Light is 89 feet above the foundation on the rock. According to the report, it is not visible despite being within a 14 statute-mile distance from the observers because, at a distance of only 14 statute miles, the lantern, which is 89 feet high, and the top of the vane, which is 100 feet above the foundation, are not visible, and the top of the vane is \"entirely out of sight.\""
            ]
        },
        {
            "question": "What is the minimum distance at which the top of a lighthouse should be below the horizon, according to the doctrine of the Earth's rotundity, as demonstrated by observations of various lighthouses?",
            "reference-answers": [
                "According to the given observations, the minimum distance at which the top of a lighthouse should be below the horizon, as demonstrated by the doctrine of the Earth's rotundity, is 45 feet."
            ]
        },
        {
            "question": "What is the expected declination of the water from the horizon to the base of the Spurn Point Lighthouse, according to the calculations based on the Earth's rotundity, and how does it compare to the actual observed declination?",
            "reference-answers": [
                "According to the calculations based on the Earth's rotundity, the expected declination of the water from the horizon to the base of the Spurn Point Lighthouse is 640 feet. The actual observed declination is 547 feet, which is less than the expected declination."
            ]
        }
    ],
    "flat-earth-book/SECTION-2/text.txt": [
        {
            "question": "What would be the expected result if the Earth had a motion upon axes and a ball, shot upwards into the air from a vertical air-gun, began to descend the surface of the Earth?",
            "reference-answers": [
                "The surface of the Earth would turn from under the ball's direction, and it would fall behind or to the west of its line of descent."
            ]
        },
        {
            "question": "What is the predicted effect on the trajectory of a ball shot upwards into the air if the Earth had a motion upon axes?",
            "reference-answers": [
                "The surface of the Earth would turn from under the direction of the ball, and it would fall behind or to the west of its line of descent."
            ]
        },
        {
            "question": "What would be the expected result if the Earth had a motion upon axes, based on the experiment involving a ball shot upwards into the air from a moving air-gun?",
            "reference-answers": [
                "The ball would have fallen 5,600 feet to the west of the air-gun, or considerably more than one statute mile."
            ]
        }
    ],
    "flat-earth-book/SECTION-3/text.txt": [
        {
            "question": "What is the calculated distance of the Sun from the Earth, based on the observations made by the officers of the Ordnance survey and the Royal Engineers?",
            "reference-answers": [
                "The calculated distance of the Sun from the Earth is less than 4,000 miles."
            ]
        },
        {
            "question": "What is the calculated distance of the Sun from the Earth, based on the observation made by the officers of the Ordnance Survey?",
            "reference-answers": [
                "The calculated distance of the Sun from the Earth is less than 4,000 miles, as proved to be under 4,000 miles from the elements of observations made by the officers of the Ordnance Survey at London and Ackworth."
            ]
        },
        {
            "question": "What is the approximate distance of the Sun from the Earth, as calculated from the elements of observations provided in the text?",
            "reference-answers": [
                "The true distance of the Sun from the Earth is less than 4,000 miles."
            ]
        }
    ],
    "flat-earth-book/SECTION-4/text.txt": [
        {
            "question": "What is the shape of the path described by the Sun as it moves over the Earth, as observed from any northern latitude?",
            "reference-answers": [
                "An arc of a circle."
            ]
        },
        {
            "question": "What is the shape of the path the Sun describes as it moves over the Earth, according to the observation from any northern latitude?",
            "reference-answers": [
                "an arc of a circle."
            ]
        },
        {
            "question": "What is the consequence of an object moving in an arc, as observed with the Sun?",
            "reference-answers": [
                "The object cannot return to the centre of the arc without having completed a circle."
            ]
        }
    ],
    "flat-earth-book/SECTION-5/text.txt": [
        {
            "question": "What is the Sun's altitude on December 21st at the time of Southing, as observed in London mean time?",
            "reference-answers": [
                "12°"
            ]
        },
        {
            "question": "What is the Sun's altitude at the time of Southing (being on the meridian) on June 15th?",
            "reference-answers": [
                "Sun’s altitude. \t62° \t 0 \t 4 \tbefore noon."
            ]
        },
        {
            "question": "What is the Sun's altitude at the time of Southing (being on the meridian) on December 21st?",
            "reference-answers": [
                "12°"
            ]
        }
    ],
    "flat-earth-book/SECTION-6/text.txt": [
        {
            "question": "What is the reason given in the text to explain why the twilight in New Zealand is more rapid and abrupt compared to England, contradicting the doctrine of the Earth's rotundity?",
            "reference-answers": [
                "The reason given in the text to explain why the twilight in New Zealand is more rapid and abrupt compared to England is that the Earth is a plane, and the larger circle around New Zealand means the velocity of the Sun-light is proportionately greater."
            ]
        },
        {
            "question": "What is the explanation given for the difference in the duration and characteristics of day and night between England and New Zealand during the same seasons?",
            "reference-answers": [
                "The explanation given is that the Earth is a plane, and the difference in the duration and characteristics of day and night between England and New Zealand is due to the size of the circles around the north pole, with New Zealand having a larger circle, resulting in a greater velocity of sunlight and more abrupt twilight."
            ]
        },
        {
            "question": "What is the main difference in the duration of daylight and darkness between England and New Zealand during the same time of year?",
            "reference-answers": [
                "In New Zealand, the longest day is 1 hour and 36 minutes shorter than the longest day in England, and the shortest day is 1 hour and 17 minutes longer than the shortest day in England."
            ]
        }
    ],
    "flat-earth-book/SECTION-7/text.txt": [
        {
            "question": "What is the reason for the Sun appearing to ascend from morning until noon and to descend and sink below the horizon at evening, according to the law of perspective described in the text?",
            "reference-answers": [
                "A flock of birds, when passing over a flat or marshy country, always appears to descend as it recedes; and if the flock is extensive, the first bird appears lower, or nearer to the horizon than the last. When a balloon sails from an observer without increasing or decreasing its altitude, it appears gradually to approach the horizon. The farthest light in a row of lamps appears the lowest, although each one has the same altitude."
            ]
        },
        {
            "question": "What is the explanation for the apparent descent of the Sun when it passes from the meridian to the observer's horizon, according to the principles of perspective and the Earth's surface?",
            "reference-answers": [
                "When the Sun passes from the meridian to the observer's horizon, it appears to descend because, from the point of view of the observer, the line-of-sight and the Sun's path are parallel with the horizontal surface of the Earth. This causes the Sun to appear to converge towards the horizon, eventually disappearing or \"setting\" to the observer."
            ]
        },
        {
            "question": "What is the reason for the apparent ascent of the Sun from the horizon until noon and its apparent descent after noon, as observed from the Earth's surface?",
            "reference-answers": [
                "The apparent ascent of the Sun from the horizon until noon and its apparent descent after noon, as observed from the Earth's surface, arises from a simple and everywhere visible law of perspective, caused by the Sun's path and the line-of-sight of the observer being parallel with the horizontal surface of the Earth."
            ]
        }
    ],
    "flat-earth-book/SECTION-8/text.txt": [
        {
            "question": "What is the reason for the Sun appearing larger when rising and setting than when on the meridian, according to the explanation provided in the text?",
            "reference-answers": [
                "The reason for the Sun appearing larger when rising and setting than when on the meridian is that the Sun has to shine through a greater amount of atmosphere when approaching the horizon, and the air near the Earth is both more dense and more damp, or holds more watery particles in solution, causing the light of the Sun to be dilated or enlarged."
            ]
        },
        {
            "question": "What is the explanation for the apparent enlargement of the Sun when it rises and sets compared to its appearance when it is on the meridian?",
            "reference-answers": [
                "The apparent enlargement of the Sun when it rises and sets is only an optical impression, and is due to the 'habit of sight,' as the angular dimensions are equal, but the mental mistake of horizontal size, and the apparent distance of the horizon is three or four times greater than the zenith."
            ]
        },
        {
            "question": "What is the reason for the apparent enlargement of the Sun when it rises and sets compared to when it is on the meridian?",
            "reference-answers": [
                "The apparent enlargement of the Sun when it rises and sets is only an optical impression, and is due to the 'habit of sight,' as the angular dimensions are equal, but the mental mistake of horizontal size, and the apparent distance of the horizon is three or four times greater than the zenith."
            ]
        }
    ],
    "flat-earth-book/SECTION-9/text.txt": [
        {
            "question": "What is the conclusion drawn by the author regarding the nature of the Moon, based on the observations of the lunar eclipse?",
            "reference-answers": [
                "The Moon is not a reflector, but a self-luminous body, and its luminosity would be greater in proportion to the greater density or darkness of the shadow."
            ]
        },
        {
            "question": "What is the author's conclusion about the Moon's nature, based on the observations of the lunar eclipse described in the text?",
            "reference-answers": [
                "The Moon is not a reflector, but a self-luminous body, and the lunar eclipse does not arise from a shadow of the Earth."
            ]
        },
        {
            "question": "What is the main argument presented in the text regarding the nature of the Moon's luminosity and the cause of lunar eclipses?",
            "reference-answers": [
                "The Moon is not a reflector but a self-luminous body, and a lunar eclipse cannot arise from a shadow of the Earth; instead, it can only occur from a body semi-transparent and well-defined passing before the Moon, or between her surface and the observer on the surface of the Earth."
            ]
        }
    ],
    "nmt-book/chapter01-Introduction/text.txt": [
        {
            "question": "What was the major development in machine translation that led to the entire research field shifting towards neural machine translation systems?",
            "reference-answers": [
                "The addition of the attention mechanism finally yielded competitive results, and with a few more refinements, such as byte pair encoding and back-translation of target-side monolingual data, neural machine translation became the new state of the art."
            ]
        },
        {
            "question": "What was the major recent development in statistical machine translation that led to a shift away from traditional statistical machine translation systems and towards neural machine translation approaches?",
            "reference-answers": [
                "The major recent development in statistical machine translation that led to a shift away from traditional statistical machine translation systems and towards neural machine translation approaches was the integration of neural language models into traditional statistical machine translation systems, which showed large improvements in public evaluation campaigns."
            ]
        },
        {
            "question": "What were the key milestones in the development of neural machine translation systems, including the pioneering work by Schwenk (2007), and how did they contribute to the eventual dominance of neural machine translation in the field?",
            "reference-answers": [
                "The key milestones in the development of neural machine translation systems include the pioneering work by Schwenk (2007), which showed large improvements in public evaluation campaigns. Additionally, the integration of neural language models into traditional statistical machine translation systems, the use of GPUs for training, the pioneering work by Devlin et al. (2014), the use of convolutional models (Kalchbrenner and Blunsom, 2013) and sequence-to-sequence models (Sutskever et al., 2014; Cho et al., 2014), the addition of the attention mechanism, and the refinements such as byte"
            ]
        }
    ],
    "nmt-book/chapter02-Neural-Networks/text.txt": [
        {
            "question": "What is the difference between online learning and batch training in the context of neural network training, and how do mini batches address the issue of parallelizing the computation of weight update values?",
            "reference-answers": [
                "Online learning generally takes fewer passes over the training set, as the weights constantly change, whereas batch training processes the entire training set in one batch, which can be parallelized but has to synchronize the summation and application to the weights. Mini batches address this issue by breaking up the training data into smaller sets, allowing for parallelization of the computation of weight update values, but also averaging the weights to avoid losing information."
            ]
        },
        {
            "question": "What is the purpose of the momentum term in weight update per Adam, and how is it computed?",
            "reference-answers": [
                "The momentum term is used to speed up training by accumulating the previous value of the momentum term with the current raw weight update value and using the resulting momentum term value to update the weights."
            ]
        },
        {
            "question": "What is the purpose of using a momentum term in weight updates during back-propagation learning, and how is it computed?",
            "reference-answers": [
                "The momentum term is used to speed up training by accumulating the previous value of the momentum term with the current raw weight update value and using the resulting momentum term value to update the weights. The update formula is computed as the previous momentum term multiplied by a decay rate plus the current raw weight update value."
            ]
        }
    ],
    "nmt-book/chapter03-Computation-Graphs/text.txt": [
        {
            "question": "What is the primary benefit of representing neural networks as computation graphs, as opposed to traditional graphs or mathematical equations, and how does this representation simplify model training?",
            "reference-answers": [
                "Representing neural networks as computation graphs simplifies model training by allowing for the automatic computation of gradients, even for arbitrarily complex architectures, and enabling the use of toolkits to define the network and perform the rest of the computations, thereby reducing the need for manual derivations of gradient computations."
            ]
        },
        {
            "question": "What is the primary benefit of representing neural networks as computation graphs, as opposed to traditional graphs or mathematical equations?",
            "reference-answers": [
                "The primary benefit of representing neural networks as computation graphs is that it allows for automatic computation of derivatives, even for arbitrarily complex neural network architectures, thereby simplifying model training."
            ]
        },
        {
            "question": "What is the primary benefit of representing neural networks as computation graphs, as opposed to traditional graphs consisting of nodes and connections?",
            "reference-answers": [
                "The primary benefit of representing neural networks as computation graphs is that it allows for the automatic computation of derivatives, even for arbitrarily complex neural network architectures, eliminating the need to painstakingly work out derivates for gradient computations."
            ]
        }
    ],
    "nmt-book/chapter04-Neural-Language-Models/text.txt": [
        {
            "question": "What is the main difference between the traditional long short-term memory (LSTM) neural network architecture and the gated recurrent units (GRU) neural network architecture?",
            "reference-answers": [
                "The main difference between the traditional long short-term memory (LSTM) neural network architecture and the gated recurrent units (GRU) neural network architecture is that LSTM cells have an explicit memory state and multiple gates (input, forget, output) to regulate the flow of information, while GRU cells do not have a separate memory state and have only two gates (update and reset) to combine the input and previous state."
            ]
        },
        {
            "question": "What is the primary difference between a Long Short-Term Memory (LSTM) neural network cell and a Gated Recurrent Unit (GRU) cell?",
            "reference-answers": [
                "LSTM cells store a real number in their memory state and have read/write/reset operations regulated by real-numbered parameters called gates, whereas GRU cells store a single hidden state and have only two gates that predict the new hidden state and output."
            ]
        },
        {
            "question": "What is the main difference between the Long Short-Term Memory (LSTM) neural network architecture and the Gated Recurrent Units (GRU) architecture?",
            "reference-answers": [
                "LSTM cells store a real number in their memory state, with read/write/reset operations regulated by real-numbered parameters called gates, whereas GRU cells have a single hidden state that serves both purposes and only two gates."
            ]
        }
    ],
    "nmt-book/chapter05-Neural-Translation-Models/text.txt": [
        {
            "question": "What is the primary difference between the attention mechanism in neural machine translation models and traditional statistical machine translation models?",
            "reference-answers": [
                "The attention mechanism in neural machine translation models is different from traditional statistical machine translation models because the former conditions on the entire output word sequence from the beginning, whereas the latter can combine hypotheses if they share the same conditioning context for future feature functions."
            ]
        },
        {
            "question": "What is the primary difference between the attention mechanism proposed by Bahdanau et al. and the variants proposed by Luong et al. in the context of neural machine translation models?",
            "reference-answers": [
                "The attention mechanism proposed by Bahdanau et al. is a global attention model, whereas the variants proposed by Luong et al. are a local attention model and a hard-constraint attention model."
            ]
        },
        {
            "question": "What is the main difference between the encoder and decoder in a neural machine translation model, and how do they interact with each other?",
            "reference-answers": [
                "The main difference between the encoder and decoder in a neural machine translation model is that the encoder takes a sequence of input words and generates a sequence of hidden states, while the decoder generates a sequence of output words based on the hidden states from the encoder. The decoder uses the hidden states from the encoder and the previous output word to predict the next output word, whereas the encoder only uses the input context and the previous hidden state to compute the next hidden state."
            ]
        }
    ],
    "nmt-book/chapter06-Refinements/text.txt": [
        {
            "question": "What is the approach of using a shared attention mechanism in multi-language neural machine translation models, as proposed by Firat et al. (2016)?",
            "reference-answers": [
                "Language-specific encoders and decoders and a shared attention mechanism."
            ]
        },
        {
            "question": "What is the benefit of using a shared attention mechanism in multi-language neural machine translation models?",
            "reference-answers": [
                "The shared attention mechanism is shared in all models for all language pairs, meaning that the same parameter values are used in these separate models, allowing updates to these parameters when training a model for one language pair to also change them for the model for the other language pairs."
            ]
        },
        {
            "question": "What is the main benefit of using a multi-domain model in neural machine translation, and how does it allow the model to catch up with traditional statistical machine translation systems?",
            "reference-answers": [
                "The main benefit of using a multi-domain model in neural machine translation is that it allows the model to catch up with traditional statistical machine translation systems when training general-purpose machine translation systems on a collection data, and then tested on niche domains."
            ]
        }
    ],
    "nmt-book/chapter07-Alternate-Architectures/text.txt": [
        {
            "question": "What is the main advantage of using convolutional neural networks in neural machine translation models compared to recurrent neural networks?",
            "reference-answers": [
                "The main advantage of using convolutional neural networks in neural machine translation models compared to recurrent neural networks is that all words at one depth can be processed in parallel, even combined into one massive tensor operation that can be efficiently parallelized on a GPU."
            ]
        },
        {
            "question": "What is the main difference between the convolutional neural network model proposed by Gehring et al. (2017) and the traditional convolutional neural network model proposed by Kalchbrenner and Blunsom (2013)?",
            "reference-answers": [
                "The main difference between the convolutional neural network model proposed by Gehring et al. (2017) and the traditional convolutional neural network model proposed by Kalchbrenner and Blunsom (2013) is that Gehring et al.'s model uses multiple convolutional layers in both the encoder and the decoder, while Kalchbrenner and Blunsom's model uses convolutional neural networks only in the encoder."
            ]
        },
        {
            "question": "What is the main advantage of using self-attention over recurrent neural networks in neural machine translation models?",
            "reference-answers": [
                "The main advantage of using self-attention over recurrent neural networks in neural machine translation models is that self-attention allows for parallelization of the processing of all words at once, even combining them into one massive tensor operation that can be efficiently parallelized on a GPU, unlike recurrent neural networks which require a lengthy sequential process that consumes each input word in one step."
            ]
        }
    ],
    "nmt-book/chapter08-Current-Challenges/text.txt": [
        {
            "question": "How do the data needs of statistical machine translation and neural machine translation compare, particularly in terms of generalization and conditioning on larger context?",
            "reference-answers": [
                "Neural machine translation promises both to generalize better (exploiting word similarity in embeddings) and condition on larger context (entire input and all prior output words), whereas statistical machine translation models are built on probability distributions estimated from many occurrences of words and phrases, which are less robust to out-of-domain data and noisy training data, and are more suited to learning from large amounts of in-domain training data."
            ]
        },
        {
            "question": "How do the data needs of statistical machine translation and neural machine translation compare, particularly in terms of generalization and exploitation of context?",
            "reference-answers": [
                "Neural machine translation promises both to generalize better (exploiting word similarity in embeddings) and condition on larger context (entire input and all prior output words), whereas statistical machine translation models are built on probability distributions estimated from many occurrences of words and phrases, which are less robust to out-of-domain data and noisy training data, and are more suited to exploiting context through traditional word alignment mechanisms."
            ]
        },
        {
            "question": "How do the data needs of statistical machine translation and neural machine translation compare, particularly in terms of the impact of training data and noise on their performance?",
            "reference-answers": [
                "Neural machine translation promises both to generalize better (exploiting word similarity in embeddings) and condition on larger context (entire input and all prior output words). However, it degrades severely when faced with noisy data and is unable to effectively utilize large amounts of training data, whereas statistical machine translation models are built on probability distributions estimated from many occurrences of words and phrases, making them more robust to noisy data and able to benefit from increasing amounts of training data."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen01-slide01/text.txt": [
        {
            "question": "What is the focus of the second lecture on statistical machine translation?",
            "reference-answers": [
                "The focus of the second lecture on statistical machine translation is an overview of the approaches to statistical machine translation."
            ]
        },
        {
            "question": "What type of lecture is the second lecture on statistical machine translation?",
            "reference-answers": [
                "An introductory lecture."
            ]
        },
        {
            "question": "What type of lecture is today's lecture on statistical machine translation?",
            "reference-answers": [
                "An introductory lecture."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen02-slide02/text.txt": [
        {
            "question": "What is the difference between the abbreviations SMT and NMT in the context of statistical machine translation?",
            "reference-answers": [
                "The difference between the abbreviations SMT and NMT in the context of statistical machine translation is that SMT refers to the traditional statistical machine translation approaches (except for neural machine translation), while NMT specifically refers to neural machine translation, which is a subset of statistical machine translation."
            ]
        },
        {
            "question": "What is the conventional meaning of SMT when contrasted with NMT?",
            "reference-answers": [
                "SMT refers to the rest of statistical machine translation, except for neural machine translation."
            ]
        },
        {
            "question": "What is the convention for distinguishing between Statistical Machine Translation (SMT) and Neural Machine Translation (NMT)?",
            "reference-answers": [
                "The convention is that people put a contrast between the two abbreviations SMT and NMT, where SMT refers to the rest of statistical machine translation except for neural machine translation."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen03-slide13/text.txt": [
        {
            "question": "What is the motivation for using an interlingua in machine translation, and how does this approach differ from the direct character-by-character approach?",
            "reference-answers": [
                "The motivation for using an interlingua in machine translation is to address many languages at once, reducing the need for N systems for analysis and generation. This approach would allow for the creation of machine translation systems for all pairs of languages, but it is considered impractical due to the lack of a useful interlingua for domain-unconstrained machine translation."
            ]
        },
        {
            "question": "What is the motivation behind the idea of using an interlingua in machine translation, and how does it relate to the number of machine translation systems required for direct translation?",
            "reference-answers": [
                "The motivation behind the idea of using an interlingua in machine translation is to address many languages at once, as it would require only N systems for analysis and N systems for generation, allowing for all pairs to be addressed, whereas the direct approach would require n-squared number of machine translation systems."
            ]
        },
        {
            "question": "What is the motivation behind using an interlingua approach in machine translation, according to the triangle of machine translation concept?",
            "reference-answers": [
                "The motivation behind using an interlingua approach in machine translation is to address many languages at once, requiring only N systems for analysis and N systems for generation, rather than creating n-squared number of machine translation systems for direct approach."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen04-slide04/text.txt": [
        {
            "question": "What is the main difference between example-based machine translation and statistical machine translation?",
            "reference-answers": [
                "In example-based machine translation, you take the longest units that you have from humans and modify them, whereas in statistical machine translation, you decompose everything into much smaller units and reconstruct the sentence from these smaller pieces."
            ]
        },
        {
            "question": "What is the main difference between example-based machine translation and statistical machine translation?",
            "reference-answers": [
                "In example-based machine translation, you take the longest units that you have from humans and modify them, whereas in statistical machine translation, you decompose everything into much smaller units and reconstruct the sentence from these smaller pieces."
            ]
        },
        {
            "question": "What type of machine translation approach involves using a database of translated sentences to find similar examples and offer translations as reminders?",
            "reference-answers": [
                "Example-based machine translation."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen05-slide05/text.txt": [
        {
            "question": "Who is the Czech person mentioned in the text as having worked for IBM and John Hopkins University, and who helped the speaker's department in the past?",
            "reference-answers": [
                "Frederick Jelinek."
            ]
        },
        {
            "question": "Who is the famous linguist that said the notion of probability of a sentence is totally useless, is ill-defined?",
            "reference-answers": [
                "Noam Chomsky."
            ]
        },
        {
            "question": "Who is the famous linguist that said that the notion of probability of a sentence is totally useless and ill-defined?",
            "reference-answers": [
                "Noam Chomsky."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen06-slide06/text.txt": [
        {
            "question": "What is the key requirement for a statistical machine translation model in the information theoretic sense?",
            "reference-answers": [
                "You need to specify a probabilistic model and distribute the mass of probability among the possible outputs of your system."
            ]
        },
        {
            "question": "What is the key requirement for a statistical machine translation model to be considered valid in the information theoretic sense?",
            "reference-answers": [
                "You need to specify a probabilistic model and distribute the mass of probability among the possible outputs of your system."
            ]
        },
        {
            "question": "What type of model is machine translation based on in the information theoretic sense?",
            "reference-answers": [
                "Probabilistic model."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen07-slide07/text.txt": [
        {
            "question": "What is the ultimate goal of traditional statistical machine translation?",
            "reference-answers": [
                "The ultimate goal of traditional statistical machine translation is to find minimum translation units that are frequent across many sentence pairs, so that they are easy to process and can be reused across sentence pairs."
            ]
        },
        {
            "question": "What are the two types of data typically used to find minimum translation units in traditional statistical machine translation?",
            "reference-answers": [
                "You have very large collections of monolingual texts, and you have smaller collections of parallel texts where people already translated these sentences."
            ]
        },
        {
            "question": "What type of data are used to find minimum translation units in traditional statistical machine translation?",
            "reference-answers": [
                "Two types of data are used: very large collections of monolingual texts and smaller collections of parallel texts where people already translated these sentences."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen08-slide08/text.txt": [
        {
            "question": "How do we define the probability of the target sentence given the source sentence in the task of statistical machine translation?",
            "reference-answers": [
                "We will define the probability of the target sentence given the source sentence by defining the probability of the target sentence given the source, and then searching for a target sentence that maximizes this probability."
            ]
        },
        {
            "question": "How do we define the probability of the target sentence given the source sentence in the task of statistical machine translation?",
            "reference-answers": [
                "We will define the probability of the target sentence given the source sentence by defining the probability of the target sentence given the source, and then searching for a target sentence that maximizes this probability."
            ]
        },
        {
            "question": "How do we define the probability of the target sentence given the source sentence in the task of statistical machine translation?",
            "reference-answers": [
                "We will define the probability of the target sentence given the source sentence by defining the probability of the target sentence given the source, and then searching for a target sentence that maximizes this probability."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen09-slide09/text.txt": [
        {
            "question": "What is the technical problem with the brute force machine translation approach in this system?",
            "reference-answers": [
                "The technical problem with the brute force machine translation approach in this system is that the probability of a sentence being translated to multiple languages can sum to more than one."
            ]
        },
        {
            "question": "What is the technical problem with using a probability that sums to more than one in a brute force machine translation system?",
            "reference-answers": [
                "You don't want a probability to sum to more than one, because it can easily happen that this probability would sum to more than one for a sentence translated to multiple ways."
            ]
        },
        {
            "question": "What is the technical problem with the probability of a sentence translation in a brute force machine translation system?",
            "reference-answers": [
                "The technical problem is that the probability of a sentence translation can sum to more than one, depending on the source and target languages."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen10-slide10/text.txt": [
        {
            "question": "What is the issue with the probability distribution of the sentence pair in the given database?",
            "reference-answers": [
                "The issue with the probability distribution of the sentence pair in the given database is that it is not smooth enough, resulting in a \"jump\" in probability when moving from one sentence to another, and a significant change in probability when the target sentence is slightly changed."
            ]
        },
        {
            "question": "What is the issue with the probability distribution in this sentence similarity model?",
            "reference-answers": [
                "The issue with the probability distribution is that it is not smooth enough, resulting in a \"jump\" in probability values, where a small change in the input sentence results in a drastic change in the output probability, typically from a high value to zero."
            ]
        },
        {
            "question": "What type of probability distribution is the one described in the TEXT, which does not generalize well and has a significant jump in probability between similar sentences?",
            "reference-answers": [
                "Binary probability distribution."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen11-slide11/text.txt": [
        {
            "question": "What is the result of applying Bayes' law to the conditional probability in the given formula, and how does this allow for the simplification of the calculation?",
            "reference-answers": [
                "The result of applying Bayes' law is to rewrite the conditional probability as the reversed one, and to break it into two separate probabilities: the probability of the source sentence given the target and the probability of the target sentence given the source. This allows for the simplification of the calculation by ignoring the probability of the constant, as all elements in the comparison are divided by the same number, the probability of the source sentence."
            ]
        },
        {
            "question": "What is the purpose of the argmax in the context of the conditional probability formula, and how does it simplify the calculation?",
            "reference-answers": [
                "The argmax searches for the particular target sentence which gets the highest result of this calculation, and by dividing all elements in this comparison by the same number (the probability of the source sentence), it allows you to find the highest scoring element without actually dividing it by the number, so you can just ignore the probability of that constant."
            ]
        },
        {
            "question": "What is the effect of dividing all elements in the argmax calculation by the same number, the probability of the source sentence, on the process of finding the highest scoring target sentence?",
            "reference-answers": [
                "You can find the highest scoring element even without actually dividing it by the number, because all elements in the comparison are divided by the same number, the probability of the source sentence."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen12-slide12/text.txt": [
        {
            "question": "What is the main benefit of using two tables instead of one in speech recognition and language modeling approaches?",
            "reference-answers": [
                "The main benefit is that these components can be trained on different sets of data, allowing for better estimation of the probability table and smoothing out the final decision."
            ]
        },
        {
            "question": "What is the main benefit of using two tables instead of one in speech recognition and language translation approaches?",
            "reference-answers": [
                "The main benefit is that these components can be trained on different sets of data, allowing for better estimation of the probability table and smoothing out the final decision."
            ]
        },
        {
            "question": "What is the main benefit of training a probability table for the noisy channel in speech recognition using a neural approach?",
            "reference-answers": [
                "The main benefit is that these components can be trained on different sets of data, allowing for better estimation of the probability table and smoothing out the final decision."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen13-slide13/text.txt": [
        {
            "question": "What is the purpose of using parallel text to derive the translation model in the log-linear model?",
            "reference-answers": [
                "The translation model is derived from parallel text to represent the conditional probability."
            ]
        },
        {
            "question": "What are the two models derived from parallel text for a log-linear model?",
            "reference-answers": [
                "The translation model and the language model."
            ]
        },
        {
            "question": "What type of models are derived from parallel text and monolingual text in the log-linear model?",
            "reference-answers": [
                "Translation model and language model."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen14-slide14/text.txt": [
        {
            "question": "What is the standard approach to defining the probability of a sentence in an n-gram based language model?",
            "reference-answers": [
                "The standard approach is to break the sentence into smaller chunks, called n-grams, and use the same table for each of these smaller chunks, where the n-grams are short sequences of words."
            ]
        },
        {
            "question": "What is the purpose of breaking a sentence into smaller chunks, known as n-grams, in a language model?",
            "reference-answers": [
                "The idea is to decompose the full probability definition into smaller units, making it easier to train the probabilities of these n-grams."
            ]
        },
        {
            "question": "What is the definition of the probability of a sentence in the n-gram based language models?",
            "reference-answers": [
                "The probability of a sentence in the n-gram based language models is defined as the product of the probability of each smaller unit, which are n-grams (short sequences of words), given the previous words in the sentence."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen15-slide15/text.txt": [
        {
            "question": "What is the formula used to calculate the probability of a trigram in the given method?",
            "reference-answers": [
                "We divide the count of each trigram by the number of occurrences of the antecedent of the history, the words at the beginning of the n-gram."
            ]
        },
        {
            "question": "What is the purpose of dividing the count of a trigram by the number of occurrences of the antecedent of the history in the definition of a trigram's probability?",
            "reference-answers": [
                "To normalize the count of a trigram, so that the result is a probability."
            ]
        },
        {
            "question": "What is the definition of the antecedent in the context of defining the probability of a trigram?",
            "reference-answers": [
                "The antecedent of the history refers to the words at the beginning of the n-gram."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen16-slide14/text.txt": [
        {
            "question": "Where does the proposed probability model break down due to its lack of smoothness?",
            "reference-answers": [
                "There is a big risk that one of the n-grams will not be observed at all."
            ]
        },
        {
            "question": "What is a major risk associated with using the probability of a sentence as a product of trigram probabilities?",
            "reference-answers": [
                "There is a big risk that one of the n-grams will not be observed at all."
            ]
        },
        {
            "question": "What is a problem with using trigram probabilities to define the probability of a sentence?",
            "reference-answers": [
                "There is a big risk that one of the n-grams will not be observed at all."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen17-slide15/text.txt": [
        {
            "question": "What is the difference between backoff and interpolation in the context of smoothing methods for language modeling?",
            "reference-answers": [
                "In the context of smoothing methods for language modeling, backoff refers to using a trigram model only if it is known, and resorting to a bigram model only if the trigram is not known. Interpolation, on the other hand, involves using all three models (trigram, bigram, and n-gram) simultaneously, resulting in varying results."
            ]
        },
        {
            "question": "What is the difference between the backoff approach and interpolation in handling smoothing in language models?",
            "reference-answers": [
                "The main difference between the backoff approach and interpolation in handling smoothing in language models is the way they use multiple models: backoff uses one model (trigram) when known and another (bigram) when not known, whereas interpolation uses all models (trigram, bigram, and backoff) at the same time, resulting in varying results."
            ]
        },
        {
            "question": "What is the difference between backoff and interpolation in the context of sentence probability models?",
            "reference-answers": [
                "In the context of sentence probability models, backoff refers to the practice of using a trigram model if it is known, and resorting to a bigram model only if the trigram is not known. Interpolation, on the other hand, involves using all three models (trigram, bigram, and n-gram) simultaneously, resulting in varying results."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen18-slide16/text.txt": [
        {
            "question": "What is the reason why using the swapped directions in training the translation model did not result in a loss, despite violating the base law?",
            "reference-answers": [
                "In a large collection of text, it doesn't really matter much in which way you are looking at the table."
            ]
        },
        {
            "question": "What was the empirical observation made by the student of Hermann Ney in his thesis in 2002 regarding the translation model?",
            "reference-answers": [
                "He observed that sometimes if the language model is trained on much larger collection of data, it can be so good that it is better to trust that language model more than the base law would recommend."
            ]
        },
        {
            "question": "What was the empirical observation made by the student of Hermann Ney that led to the modification of the base law in machine translation?",
            "reference-answers": [
                "When the language model is trained on a much larger collection of data, it can be so good that it is better to trust that language model more than the base law would recommend."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen19-slide17/text.txt": [
        {
            "question": "What is the purpose of the normalization constant in the scoring process of the LoglingerModal framework?",
            "reference-answers": [
                "The normalization constant is used to ensure that the final scores for all sentence pairs add up to 1, making it a proper probability."
            ]
        },
        {
            "question": "What is the purpose of the normalization constant in the scoring process of the LoglingerModal framework?",
            "reference-answers": [
                "The normalization constant is used to ensure that the final scores for all sentence pairs add up to 1, making it a proper probability."
            ]
        },
        {
            "question": "What is the purpose of the normalization constant in the LoglingerModal framework?",
            "reference-answers": [
                "The normalization constant is used to ensure that the final scores for all sentence pairs add up to 1, making it a proper probability."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen20-slide18/text.txt": [
        {
            "question": "What is the purpose of distributing points in the context of the argmax formula?",
            "reference-answers": [
                "We only have to distribute points to define feature points."
            ]
        },
        {
            "question": "What is the purpose of calculating the constant summation of all points in the argmax formula?",
            "reference-answers": [
                "We don't need to calculate that sum at all."
            ]
        },
        {
            "question": "What is the purpose of distributing points in the given formula within the argmax?",
            "reference-answers": [
                "We only have to distribute points to define feature points."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen21-slide17/text.txt": [
        {
            "question": "What is the purpose of putting a log in front of the calculation in the log-linear framework for estimating the probability of a target candidate?",
            "reference-answers": [
                "To make it a proper probability."
            ]
        },
        {
            "question": "What is the purpose of the log in front of the calculation in the log-linear framework for estimating the probability of the target candidate?",
            "reference-answers": [
                "To make it a proper probability."
            ]
        },
        {
            "question": "What is the purpose of putting a log in front of the calculation for estimating the probability of the target candidate in the log-linear framework?",
            "reference-answers": [
                "To make it a proper probability."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen22-slide18/text.txt": [
        {
            "question": "What is the purpose of normalizing the weights in the Logliner model?",
            "reference-answers": [
                "To normalize at all."
            ]
        },
        {
            "question": "What is the purpose of the weights associated with feature functions in the Logliner model?",
            "reference-answers": [
                "The weights associated with feature functions determine how important the feature function is."
            ]
        },
        {
            "question": "What is the purpose of normalizing the points in the Logliner model?",
            "reference-answers": [
                "To normalize at all, because we are only searching for the high-scoring candidate."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen23-slide19/text.txt": [
        {
            "question": "What is the result when using the two feature functions and equal weights in the Logdiner modal formula?",
            "reference-answers": [
                "The logs of the probabilities, which simply cancel out, and you are back at the product of the probability of the source given the target and the language model the probability of the target alone."
            ]
        },
        {
            "question": "What is the purpose of using two feature functions in the Logdiner modal approach, and how does it relate to the noisy channel approach?",
            "reference-answers": [
                "Using two feature functions in the Logdiner modal approach allows you to calculate the log of the probability of the source given the target and the log of the target probability of the target alone, which when plugged into the formula and simplified, results in the product of the probability of the source given the target and the language model probability of the target alone, relating it to the noisy channel approach as a special case of this approach."
            ]
        },
        {
            "question": "What type of mathematical approach is the Logdiner modal considered, and what is its relationship to the base law approach and the noisy channel approach?",
            "reference-answers": [
                "The Logdiner modal is considered a generalization of the base law approach and the noisy channel approach, and it is mathematically sound, allowing it to perform certain operations such as squaring the probability of a language model."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen24-slide20/text.txt": [
        {
            "question": "What is the purpose of the word penalty or word count feature in phrase-based machine translation, and how does it address the issue of comparing longer and shorter sentences when using a language model defined as a product of n-grams?",
            "reference-answers": [
                "The word penalty or word count feature controls whether we prefer shorter or longer outputs by penalizing longer outputs, thus compensating for the issue that the language model gives lower scores to longer sentences."
            ]
        },
        {
            "question": "What is the purpose of the word penalty or word count feature in phrase-based machine translation?",
            "reference-answers": [
                "The word penalty or word count feature controls whether we prefer shorter or longer outputs in phrase-based machine translation, allowing for a balance to be made with the language model to ensure fair comparison between longer and shorter sentences."
            ]
        },
        {
            "question": "What is the purpose of the word penalty or word count feature in phrase-based machine translation?",
            "reference-answers": [
                "The word penalty or word count feature controls whether we prefer shorter or longer outputs in phrase-based machine translation, allowing for a balance to be made with the language model to ensure fair comparison between longer and shorter sentences."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen25-slide21/text.txt": [
        {
            "question": "Can you explain the idea behind using language models to propose target sentences in phrase-based machine translation systems?",
            "reference-answers": [
                "The idea behind using language models to propose target sentences in phrase-based machine translation systems is to construct candidate translations based on the phrase translation probabilities. The language model would predict the next word in the target sentence by looking up the words in the source sentence in a dictionary, which are then shuffled to generate candidate translations."
            ]
        },
        {
            "question": "Can you explain how the use of language models for proposing target sentences in phrase-based systems affects the operation of the system, and whether this approach makes sense in practice?",
            "reference-answers": [
                "The use of language models for proposing target sentences in phrase-based systems seems to make sense in practice, as it allows for the construction of candidate translations based on the phrase translation probabilities. The language model can predict the next word and confirm it from translation, and the approach of shuffling the possible target words can be used to generate candidate translations. However, the translation model's risk in proposing words alphabetically is a concern, and the approach may be considered risky in terms of translation quality."
            ]
        },
        {
            "question": "What is the main idea behind using language models to propose target sentences in a phrase-based machine translation system?",
            "reference-answers": [
                "The main idea behind using language models to propose target sentences is to generate candidate translations by predicting the next word in the target sentence based on the language model, and then checking if the proposed engrams are fine by using the translation model."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen26-slide22/text.txt": [
        {
            "question": "What is the term used to describe the process of identifying the weights in the model, which includes the lambdas?",
            "reference-answers": [
                "The process of identifying the weights in the model, which includes the lambdas, is called tuning."
            ]
        },
        {
            "question": "What is the purpose of the \"tuning\" process in the traditional pipeline for training classical statistical machine translation systems?",
            "reference-answers": [
                "The tuning process, or \"training\", is what identifies the weights, the lambdas in the model, and allows the system to generate the best translations of units and the best combinations of those units."
            ]
        },
        {
            "question": "What is the purpose of the \"tuning\" process in the traditional pipeline for training classical statistical machine translation systems?",
            "reference-answers": [
                "The tuning process, or \"training\", is what identifies the weights, the lambdas in the model, and allows the system to generate the best translations of units and the best combinations of those units."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen27-slide23/text.txt": [
        {
            "question": "What type of translation system is being trained from the given word line?",
            "reference-answers": [
                "A classical machine translation system."
            ]
        },
        {
            "question": "What type of machine translation system is being trained from the given example?",
            "reference-answers": [
                "The classical one."
            ]
        },
        {
            "question": "What type of machine translation system is being trained?",
            "reference-answers": [
                "The classical one."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen28-slide24/text.txt": [
        {
            "question": "What is the basis for automatically identifying the meaning of words like Psa and Kočku based on co-occurrence statistics?",
            "reference-answers": [
                "Based on co-occurrence statistics."
            ]
        },
        {
            "question": "What is the basis for automatically identifying the meaning of Psa and Kočku?",
            "reference-answers": [
                "Based on co-occurrence statistics."
            ]
        },
        {
            "question": "What type of alignment can be used to identify the meaning of words such as Psa and Kočku based on co-occurrence statistics?",
            "reference-answers": [
                "Word alignment."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen29-slide25/text.txt": [
        {
            "question": "What are the translations of the words \"Kočka\" and \"Videl\" according to the provided text?",
            "reference-answers": [
                "Kočka translates as ØKET and Videl translates as ØSAU."
            ]
        },
        {
            "question": "What are the translations of the words \"Kočka\" and \"Videl\" according to the provided text?",
            "reference-answers": [
                "Kočka translates as ØKET and Videl translates as ØSAU."
            ]
        },
        {
            "question": "What are the translations of the words \"Kočku\" and \"Videl\"?",
            "reference-answers": [
                "Kočku translates as ØKET and Videl translates as ØSAU."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen30-slide26/text.txt": [
        {
            "question": "How do you know the translation of the word \"Nemám kočku\"?",
            "reference-answers": [
                "You know the translation of the word \"Nemám kočku\" because you know how to translate the new text."
            ]
        },
        {
            "question": "What is the new input text that needs to be translated?",
            "reference-answers": [
                "I have a dog."
            ]
        },
        {
            "question": "What is the new input text that needs to be translated?",
            "reference-answers": [
                "I have a dog."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen31-slide27/text.txt": [
        {
            "question": "What does the phrase \"... which actually means I don't have a cat\" imply about the speaker's situation?",
            "reference-answers": [
                "The speaker is trying to avoid saying they don't have a cat."
            ]
        },
        {
            "question": "What does the phrase \"which actually means I don't have a cat\" imply about the speaker's situation?",
            "reference-answers": [
                "The speaker is trying to avoid saying they don't have a cat."
            ]
        },
        {
            "question": "What does the phrase \"... which actually means I don't have a cat\" imply about the speaker's situation?",
            "reference-answers": [
                "The speaker is trying to avoid saying they don't have a cat."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen32-slide28/text.txt": [
        {
            "question": "What is the first word in the given text?",
            "reference-answers": [
                "Nemaam"
            ]
        },
        {
            "question": "What is the first word of the given text?",
            "reference-answers": [
                "Nemaam"
            ]
        },
        {
            "question": "What is the first word of the given text?",
            "reference-answers": [
                "Nemaam"
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen33-slide29/text.txt": [
        {
            "question": "What is the main problem of phrase-based systems according to the provided text?",
            "reference-answers": [
                "Lack of or wrong independence."
            ]
        },
        {
            "question": "What is the main problem of phrase-based systems according to the given example?",
            "reference-answers": [
                "Lack of or wrong independence."
            ]
        },
        {
            "question": "What is the main problem of phrase-based systems according to the provided text?",
            "reference-answers": [
                "Lack of or wrong independence."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen34-slide31/text.txt": [
        {
            "question": "What is the flaw in the approach that involves translating each puzzle piece separately, regardless of the surrounding phrases?",
            "reference-answers": [
                "The flaw in the approach is the independence assumption that phrases can be translated regardless of the other phrases, as it does not consider the source phrases when putting the puzzle pieces together."
            ]
        },
        {
            "question": "What is the primary flaw in the approach used for translation, according to the text?",
            "reference-answers": [
                "The primary flaw in the approach used for translation is the independence assumption that phrases can be translated regardless of the other phrases, and not considering the source language when putting the puzzle pieces together."
            ]
        },
        {
            "question": "What is the main issue with the approach to translating phrases, according to the text?",
            "reference-answers": [
                "The main issue with the approach to translating phrases is the independence assumption that phrases can be translated regardless of the other phrases, and not considering the source language when putting the pieces together."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen35-slide30/text.txt": [
        {
            "question": "What is the general scoring preference for longer outputs in language module assessments?",
            "reference-answers": [
                "So longer outputs are generally scored lower."
            ]
        },
        {
            "question": "What is the general scoring preference for longer language module outputs?",
            "reference-answers": [
                "So longer outputs are generally scored lower."
            ]
        },
        {
            "question": "What is the general scoring preference for longer outputs in language module assessments?",
            "reference-answers": [
                "So longer outputs are generally scored lower."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen36-slide31/text.txt": [
        {
            "question": "What are the two strong independence assumptions about the phrases in the language model?",
            "reference-answers": [
                "The two strong independence assumptions about the phrases in the language model are that the language model is a separate unit and there are two strong independence assumptions about the phrases."
            ]
        },
        {
            "question": "What are the two strong independence assumptions about the phrases in the language model?",
            "reference-answers": [
                "The two strong independence assumptions about the phrases in the language model are that the language model is a separate unit and there are two strong independence assumptions about the phrases."
            ]
        },
        {
            "question": "What are the two strong independence assumptions about the phrases in the language model?",
            "reference-answers": [
                "The two strong independence assumptions about the phrases in the language model are that the language model is a separate unit and there are two strong independence assumptions about the phrases."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen37-slide30/text.txt": [
        {
            "question": "What is the trade-off between precision and recall when using longer units in machine translation?",
            "reference-answers": [
                "With longer units, you are improving precision, but losing recall."
            ]
        },
        {
            "question": "What is the author's main concern when trying to introduce alignments in their research on machine translation?",
            "reference-answers": [
                "The author's main concern is finding a balance between increasing precision and minimizing the decrease in recall when introducing alignments in their research on machine translation."
            ]
        },
        {
            "question": "What is the problem that the author is trying to solve in the context of machine translation and alignment of phrases?",
            "reference-answers": [
                "The author is trying to solve the problem of finding a balance between improving precision and recall in machine translation, specifically when it comes to aligning phrases in a way that minimizes errors, while also considering the limitations of the training corpus."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen38-slide31/text.txt": [
        {
            "question": "What is the main problem with the proposed approach when the language model is separated from the translation model?",
            "reference-answers": [
                "The main problem is that the language model is likely to prefer shorter sentences, so sentences without negation, and it doesn't consider the source anymore."
            ]
        },
        {
            "question": "What is the main problem with the proposed approach to translation, according to the base decomposition method?",
            "reference-answers": [
                "The main problem with the proposed approach to translation, according to the base decomposition method, is that it can easily break your translation units as soon as you have something which disregards the source."
            ]
        },
        {
            "question": "What is the main problem with the proposed approach to sentence translation, according to the given text?",
            "reference-answers": [
                "The main problem with the proposed approach to sentence translation is that the base decomposition disregards the source, which can easily break the translation units."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen39-slide32/text.txt": [
        {
            "question": "What is the main difference between the original base decomposition approach and the new language model decomposition approach for specifying the probability of a target sentence given a source?",
            "reference-answers": [
                "The main difference between the original base decomposition approach and the new language model decomposition approach is the assumption of independence, as the base decomposition relies on this assumption, whereas the language model decomposition does not, allowing for a more accurate and sequential generation of the target sentence given the source."
            ]
        },
        {
            "question": "What is the name of the technical device used to train the probability distribution for the sequential generation of the target sentence in the redefined statistical machine translation approach?",
            "reference-answers": [
                "Language model."
            ]
        },
        {
            "question": "What is the main difference between the original base decomposition and the new language model decomposition in the context of statistical machine translation?",
            "reference-answers": [
                "The main difference between the original base decomposition and the new language model decomposition is that the new decomposition considers the probability of the target sentence given the source as a sequence of decisions, rather than an independent assumption."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen40-slide33/text.txt": [
        {
            "question": "Can a neural network with one hidden layer approximate an arbitrary function to arbitrary precision?",
            "reference-answers": [
                "Yes, a neural network with one hidden layer can approximate an arbitrary function to arbitrary precision."
            ]
        },
        {
            "question": "What is a universal property of neural networks with one hidden layer?",
            "reference-answers": [
                "They can approximate an arbitrary function to arbitrary precision."
            ]
        },
        {
            "question": "What type of device can manage to learn given enough training data, according to the provided information?",
            "reference-answers": [
                "Neural networks."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen41-slide34/text.txt": [
        {
            "question": "What is the role of the final neuron in the neural network's decision-making process?",
            "reference-answers": [
                "The final neuron checks whether all the hidden neurons fired the correct side, and if they did, the point is in the center; if any of them fired incorrectly, the point is on the circumference."
            ]
        },
        {
            "question": "What is the purpose of the final neuron in the neural network that combines the outputs of the three hidden neurons?",
            "reference-answers": [
                "The final neuron checks whether all the hidden neurons fired the correct side, and if they did, the point is in the center; if any of them fired incorrectly, the point is on the circumference."
            ]
        },
        {
            "question": "What is the purpose of the weights in the neural network for classifying whether a point is in the center or circumference of a circle?",
            "reference-answers": [
                "The actual slope or position of the line is specified by the weights."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen42-slide35/text.txt": [
        {
            "question": "What is the color predicted by the equation if it holds?",
            "reference-answers": [
                "blue"
            ]
        },
        {
            "question": "What color will the program display if the given equation holds?",
            "reference-answers": [
                "Blue"
            ]
        },
        {
            "question": "What color will be displayed according to the given equation?",
            "reference-answers": [
                "Blue"
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen43-slide36/text.txt": [
        {
            "question": "How many numbers are required to train the system automatically to separate points in the center from points on a circular using the given architecture of computation?",
            "reference-answers": [
                "Thirteen numbers."
            ]
        },
        {
            "question": "How many numbers are required to separate points in the center from points on a circular using the described system?",
            "reference-answers": [
                "Thirteen numbers."
            ]
        },
        {
            "question": "How many numbers are required to separate points in the center from points on a circular using the described system?",
            "reference-answers": [
                "Thirteen numbers."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen44-slide37/text.txt": [
        {
            "question": "What is the condition under which a hidden layer is not needed in a calculation using perfect coordinates and inputs?",
            "reference-answers": [
                "If you use perfect coordinates, if you use perfect inputs, which could be x1 squared and x2 squared, you do not need any hidden layer at all."
            ]
        },
        {
            "question": "What is the formula for the circle when using perfect coordinates and inputs?",
            "reference-answers": [
                "x squared plus y squared equals 1"
            ]
        },
        {
            "question": "What type of calculation can be performed exactly without the need for a hidden layer when using perfect coordinates and inputs?",
            "reference-answers": [
                "Exact calculation of the points in the center versus the points on the circumference."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen45-slide38/text.txt": [
        {
            "question": "What is a limitation of using neural networks to separate center from circumference when the coordinates are unfortunate?",
            "reference-answers": [
                "Neural networks can only linearly separate center from circumference when the coordinates have been changed in some way."
            ]
        },
        {
            "question": "What type of separation can neural networks achieve when coordinates are transformed?",
            "reference-answers": [
                "Non-linear separation."
            ]
        },
        {
            "question": "What type of linear separation can neural networks achieve if the coordinates are changed in some way?",
            "reference-answers": [
                "Non-linear separation."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen46-slide39/text.txt": [
        {
            "question": "What is the result when a network has too many free parameters and too little training data?",
            "reference-answers": [
                "The network, the learning algorithm is unable to find the best positions of the lines so that it would properly separate it."
            ]
        },
        {
            "question": "What is the result when a network has too many free parameters and not enough training data?",
            "reference-answers": [
                "The network, the learning algorithm is unable to find the best positions of the lines so that it would properly separate it."
            ]
        },
        {
            "question": "What happens when a network is too complex and lacks sufficient training data?",
            "reference-answers": [
                "The network, the learning algorithm is unable to find the best positions of the lines so that it would properly separate it, and it never properly trains."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen47-slide40/text.txt": [
        {
            "question": "How many lines does the first hidden layer use to approximate simple shapes in the picture classification task?",
            "reference-answers": [
                "Three lines."
            ]
        },
        {
            "question": "How does the number of neurons in the hidden layers of a deep network influence its ability to approximate complex shapes?",
            "reference-answers": [
                "The network itself will find whether it is better to approximate a circle with three lines or four lines, because it still has the fourth line free, so it has the capacity to approximate complex shapes."
            ]
        },
        {
            "question": "How many lines can a deep network with three hidden layers use to approximate a simple shape?",
            "reference-answers": [
                "The network still has the fourth line free, so it can approximate a simple shape with four lines."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen48-slide41/text.txt": [
        {
            "question": "How would you represent a sentence with multiple words in a matrix format, given that each word is mapped to a vector of zeros and ones?",
            "reference-answers": [
                "The matrix would be very tall and very narrow, with the height corresponding to the English words and containing one, only single one in each of the columns, highlighting which word is where."
            ]
        },
        {
            "question": "How would you represent a sentence like \"the cat is on the mat\" using the described vector approach?",
            "reference-answers": [
                "The sentence \"the cat is on the mat\" would be represented as a matrix with the following characteristics: \n- Tall as there are English words in the sentence\n- Narrow as there is only one word per column\n- Contains a single one in each of the columns, highlighting the position of each word."
            ]
        },
        {
            "question": "What type of matrix is formed to represent a sentence with multiple words, where each word is associated with a unique position in the matrix?",
            "reference-answers": [
                "A tall and narrow matrix."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen49-slide42/text.txt": [
        {
            "question": "How many elements does the matrix have to be for Czech word forms?",
            "reference-answers": [
                "2,000,000 elements."
            ]
        },
        {
            "question": "How many Czech word forms are there in the matrix?",
            "reference-answers": [
                "2,000,000"
            ]
        },
        {
            "question": "How many elements are there in the matrix for Czech?",
            "reference-answers": [
                "2,000,000"
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen50-slide43/text.txt": [
        {
            "question": "What is the main issue with the one-hot representation used in the given text?",
            "reference-answers": [
                "The main issue with the one-hot representation is that it does not capture the relation between words, resulting in words being treated as identical or equally similar, even if they are distinct."
            ]
        },
        {
            "question": "What is the problem with the one-hot representation of words, according to the text?",
            "reference-answers": [
                "The problem with the one-hot representation of words is that it fails to capture the relation between words, resulting in identical words being treated as equally distinct, and not distinguishing between words that are truly similar."
            ]
        },
        {
            "question": "What is the problem with using a one-hot representation to capture the relation between words in a word representation system?",
            "reference-answers": [
                "The problem with using a one-hot representation is that it doesn't capture the relation between words, as all words are treated as identical and don't differentiate between distinct words or similarities between words."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen51-slide44/text.txt": [
        {
            "question": "What is the typical number of dimensions used in word embeddings for a neural network?",
            "reference-answers": [
                "300 to 2,000 dimensions."
            ]
        },
        {
            "question": "What are the typical dimensions used for word embeddings in neural networks?",
            "reference-answers": [
                "300 to 2,000 dimensions."
            ]
        },
        {
            "question": "What is the typical number of dimensions used in word embeddings in neural networks?",
            "reference-answers": [
                "300 to 2,000 dimensions."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen52-slide45/text.txt": [
        {
            "question": "What is the main limitation of statistical machine translation when dealing with productive morphology in languages like Czech and German?",
            "reference-answers": [
                "The main limitation of statistical machine translation when dealing with productive morphology in languages like Czech and German is that it can only handle a finite number of words (typically between 30,000 to 80,000 words), whereas the set of correct words in languages with productive morphology is actually infinite."
            ]
        },
        {
            "question": "What is the main problem with traditional neural machine translation in handling words with productive morphology in languages like Czech and German?",
            "reference-answers": [
                "The main problem with traditional neural machine translation in handling words with productive morphology in languages like Czech and German is that the set of correct words is infinite, depending on the language, and neural machine translation can only handle a limited number of words (typically between 30,000 to 80,000 words)."
            ]
        },
        {
            "question": "What is the main issue with productive morphology in machine translation, according to the text?",
            "reference-answers": [
                "The main issue with productive morphology in machine translation is that the set of correct words is actually infinite, depending on the language, and neural machine translation can only handle a limited number of words (around 30,000 to 80,000)."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen53-slide46/text.txt": [
        {
            "question": "What is the term for a data type that can store values of varying lengths?",
            "reference-answers": [
                "Variable length."
            ]
        },
        {
            "question": "What is an example of a variable length in the context provided?",
            "reference-answers": [
                "Variable length."
            ]
        },
        {
            "question": "What type of data is referred to as \"variable length\" in the given text?",
            "reference-answers": [
                "Variable length data."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen54-slide45/text.txt": [
        {
            "question": "What is the system's approach to disambiguating words with multiple meanings in a sentence?",
            "reference-answers": [
                "The system uses the context of the sentence to disambiguate words with multiple meanings, taking into account the words that come before and after the ambiguous word."
            ]
        },
        {
            "question": "What is the role of the context in the system's decision-making process when dealing with ambiguous words?",
            "reference-answers": [
                "The context plays a crucial role in the system's decision-making process, as it uses the context to disambiguate words and choose the correct translation, taking into account the other words in the sentence."
            ]
        },
        {
            "question": "What is the effect of the support units in the system on the ambiguity of the source words?",
            "reference-answers": [
                "The support units only increase the ambiguity of the source words."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen55-slide46/text.txt": [
        {
            "question": "What is the main challenge in training a neural network to handle variable length inputs?",
            "reference-answers": [
                "The main challenge in training a neural network to handle variable length inputs is the problem of vanishing gradients, caused by a longer path from inputs to outputs."
            ]
        },
        {
            "question": "What are some basic units of neural networks used to avoid the problem of vanishing gradients when handling variable length inputs?",
            "reference-answers": [
                "...vanishing gradients."
            ]
        },
        {
            "question": "What are the main challenges when training a neural network to handle variable length input?",
            "reference-answers": [
                "The main challenges when training a neural network to handle variable length input are the need for the same trained transformation to be used every time at the input, the problem of vanishing gradients, and the network becoming much deeper."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen56-slide47/text.txt": [
        {
            "question": "Who first successfully used neural networks in machine translation?",
            "reference-answers": [
                "Kyun Kun Cho."
            ]
        },
        {
            "question": "Who first successfully used neural networks in machine translation?",
            "reference-answers": [
                "Kyun Kun Cho."
            ]
        },
        {
            "question": "What type of architecture was first used by Kyun Kun Cho in machine translation?",
            "reference-answers": [
                "Encoder-decoder architecture."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen57-slide48/text.txt": [
        {
            "question": "What is the approach used by the team that disregarded the log-link-near approach and the phrase-based approach to process full sentences?",
            "reference-answers": [
                "They simply fed the input sentence into an encoder and then decoded it from there."
            ]
        },
        {
            "question": "What is the purpose of the matrix that specifies how to mix the states with the current word in the encoder?",
            "reference-answers": [
                "The matrix specifies how to mix the states with the current word in the encoder so that the whole input sentence is digested and a final representation is arrived at."
            ]
        },
        {
            "question": "What is the main difference between the log-link-near approach and the approach used by the team that applied it to full sentences?",
            "reference-answers": [
                "The main difference is that the log-link-near approach and the phrase-based approach were disregarded, and instead, the team used an encoder and decoded it directly from the input sentence."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen58-slide49/text.txt": [
        {
            "question": "What is the role of the decoder in the process of decoding individual words from a vector representation of a sentence?",
            "reference-answers": [
                "The decoder asks the network what word to produce next, given the previous state and the word just produced, and it gives you a distribution over all target words or subword units, and you pick the highest scoring one."
            ]
        },
        {
            "question": "What is the role of the decoder in the process of generating a target sentence from a source sentence embedded in a vector representation?",
            "reference-answers": [
                "The decoder is the language model that produces the target sentence one word at a time, given the source sentence embedded in a vector, and it proposes the next word based on its previous state and the word it has just produced."
            ]
        },
        {
            "question": "What is the role of the recurrent decoder in the process of decoding individual words from a vector representation of a sentence?",
            "reference-answers": [
                "The recurrent decoder proposes the next word based on the previous state, the word it has just produced, and it calculates this step by step to produce the target sentence one word at a time."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen59-slide50/text.txt": [
        {
            "question": "How many parameters are in the network described in the text?",
            "reference-answers": [
                "There is easily 50 million parameters in this network."
            ]
        },
        {
            "question": "How many parameters are there in the network after three weeks of training on 50 million sentence pairs?",
            "reference-answers": [
                "There is easily 50 million parameters in this network."
            ]
        },
        {
            "question": "How many parameters are in the network described in the text?",
            "reference-answers": [
                "There is easily 50 million parameters in this network."
            ]
        }
    ],
    "nmt-class/lecture02-smt-pbmt-nmt/screen60-slide51/text.txt": [
        {
            "question": "What is the main goal of neural machine translation compared to classical statistical machine translation?",
            "reference-answers": [
                "The main goal of neural machine translation is to construct a neural network architecture that digests input words and produces the sequence of output words, rather than finding minimum translation units."
            ]
        },
        {
            "question": "What is the main difference between the goal of classical statistical machine translation and the goal of neural machine translation?",
            "reference-answers": [
                "The main difference between the goal of classical statistical machine translation and the goal of neural machine translation is that classical statistical machine translation aims to find minimum translation units, whereas neural machine translation constructs a neural network architecture to directly produce the sequence of output words."
            ]
        },
        {
            "question": "What is the main difference between the goal of classical statistical machine translation and the goal of neural machine translation?",
            "reference-answers": [
                "The main difference between the goal of classical statistical machine translation and the goal of neural machine translation is that classical statistical machine translation aims to find minimum translation units, whereas neural machine translation constructs a neural network architecture to directly produce the sequence of output words."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen01-slide01/text.txt": [
        {
            "question": "What is the current state of the art of NeuralMT that the lecturer will cover after the series of lectures on traditional approaches?",
            "reference-answers": [
                "The transformer."
            ]
        },
        {
            "question": "What is the current state of the art in NeuralMT, according to the lecturer?",
            "reference-answers": [
                "The current state of the art in NeuralMT is not the one being covered in this lecture, specifically the basics of NeuralMT and the sequence to sequence architecture with attention."
            ]
        },
        {
            "question": "What type of architecture will be covered in today's lecture on NeuralMT?",
            "reference-answers": [
                "The basic sequence to sequence architecture and attention will be covered in today's lecture on NeuralMT."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen02-slide02/text.txt": [
        {
            "question": "What is the topic of the next section after reviewing the basic building blocks of neural networks?",
            "reference-answers": [
                "Processing text in neural networks."
            ]
        },
        {
            "question": "What is the topic of the first subject to be reviewed in today's class?",
            "reference-answers": [
                "Basic building blocks of neural networks."
            ]
        },
        {
            "question": "What type of architecture will be covered after discussing the vanilla sequence to sequence architecture?",
            "reference-answers": [
                "The attention mechanism."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen03-slide03/text.txt": [
        {
            "question": "What is the basic encoder-decoder architecture that is going to be built?",
            "reference-answers": [
                "This is the basic encoder decoder architecture."
            ]
        },
        {
            "question": "What is the basic architecture being described in the provided text?",
            "reference-answers": [
                "The basic encoder decoder architecture."
            ]
        },
        {
            "question": "What is the basic encoder decoder architecture that is going to be built?",
            "reference-answers": [
                "The basic encoder decoder architecture that is going to be built is the one described in the TEXT."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen04-slide04/text.txt": [
        {
            "question": "How are neural networks constructed?",
            "reference-answers": [
                "And we need to start from the very beginning. So how are neural networks constructed? And in the middle..."
            ]
        },
        {
            "question": "How are neural networks constructed?",
            "reference-answers": [
                "And we need to start from the very beginning. So how are neural networks constructed? And in the middle..."
            ]
        },
        {
            "question": "How are neural networks constructed?",
            "reference-answers": [
                "And we need to start from the very beginning. So how are neural networks constructed? And in the middle..."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen05-slide03/text.txt": [
        {
            "question": "How is the meaning of a sentence related to the words that get into the system?",
            "reference-answers": [
                "The meaning of the sentence is related to the words that get into the system automatically, just by observing parallel data."
            ]
        },
        {
            "question": "How is the architecture of the system related to the meaning of the sentence it processes?",
            "reference-answers": [
                "There is no direct link between the architecture, the maths underneath and any of the linguistics."
            ]
        },
        {
            "question": "How is the architecture of the system related to the meaning of the sentence it handles?",
            "reference-answers": [
                "There is no direct link between the architecture, the maths underneath and any of the linguistics."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen06-slide05/text.txt": [
        {
            "question": "What is the role of the bias term in the computation of the output vector H in a fully connected neural network layer?",
            "reference-answers": [
                "The bias term is added to the output of the weight matrix multiplication, and it's considered as the basic activation if there is no input, setting the level of the output."
            ]
        },
        {
            "question": "What is the role of the bias term in a fully connected layer of a neural network?",
            "reference-answers": [
                "The bias term is another trained vector that is added to the result of the weight matrix and the input vector, and it can be thought of as the basic activation if there is no input, setting the level of the computation."
            ]
        },
        {
            "question": "What is the function fH that is applied after the application of the bias term in a one-layer computation?",
            "reference-answers": [
                "The basic level whether we should fire or not is set by the application of the bias term, and then a non-linearity is applied."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen07-slide06/text.txt": [
        {
            "question": "What is the effect of the bias vector in the transformation of coordinates in a neural network layer?",
            "reference-answers": [
                "The bias vector slightly moves the coordinate system, causing a slight shift in the transformation."
            ]
        },
        {
            "question": "What type of transformation occurs at one layer in a neural network, as described in the given illustration from CollaxBlock?",
            "reference-answers": [
                "A linear classification."
            ]
        },
        {
            "question": "What type of transformation is happening at one layer in a neural network, according to the illustration provided?",
            "reference-answers": [
                "A linear classification, with a transformation that includes multiplying a vector of x and y coordinates with a weight matrix W, transposition governed by a bias vector, and non-linearity controlled by an activation function."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen08-slide07/text.txt": [
        {
            "question": "How many layers are in a neural network, according to the provided text?",
            "reference-answers": [
                "The networks are not one layer, obviously, but there are many layers."
            ]
        },
        {
            "question": "How do you determine the number of layers in a network?",
            "reference-answers": [
                "The idea is that you define the structure of the network, so how many layers and how big the representations should be."
            ]
        },
        {
            "question": "How many layers are in a network, according to the text?",
            "reference-answers": [
                "The networks are not one layer, obviously, but there are many layers."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen09-slide05/text.txt": [
        {
            "question": "What is the result of scaling the inner representation from two coordinates with the weight matrix in the given system?",
            "reference-answers": [
                "The weight matrix scaled up the inner representation from two coordinates to three coordinates in a complex system."
            ]
        },
        {
            "question": "What is the result of scaling the inner representation from two coordinates with a weight matrix in a complex system?",
            "reference-answers": [
                "The weight matrix scaled it up to three coordinates."
            ]
        },
        {
            "question": "What is the effect of the weight matrix on the inner representation of two coordinates?",
            "reference-answers": [
                "The weight matrix scaled up the inner representation from two coordinates to three coordinates."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen10-slide07/text.txt": [
        {
            "question": "What is the purpose of the backpropagation algorithm in the training process of a feedforward neural network?",
            "reference-answers": [
                "The backpropagation algorithm tells you exactly how to update the weights so that the output vector is closer to the expected output."
            ]
        },
        {
            "question": "What is the purpose of the backpropagation algorithm in the training of deep neural networks?",
            "reference-answers": [
                "The backpropagation algorithm tells you exactly how to update the weights so that the output vector is closer to the expected output."
            ]
        },
        {
            "question": "What is the purpose of the backpropagation algorithm in the training process of a deep neural network?",
            "reference-answers": [
                "The backpropagation algorithm tells you exactly how to update the weights so that the output vector is closer to the expected output."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen100-slide83/text.txt": [
        {
            "question": "What difference, if any, can be attributed to the size of the network in comparing the results of the two systems?",
            "reference-answers": [
                "The size of the network can be attributed as the difference that can be attributed to the two systems, as it was \"very different\"."
            ]
        },
        {
            "question": "What are some factors that make the results of the two systems being compared in the papers incomparable?",
            "reference-answers": [
                "The capacity of the network, the training regime, and all that were very different."
            ]
        },
        {
            "question": "What were the main differences between the settings of the two systems?",
            "reference-answers": [
                "The main differences between the settings of the two systems were the size of the network, the capacity of the network, and the training regime."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen101-slide84/text.txt": [
        {
            "question": "What is the main message of the given text?",
            "reference-answers": [
                "Always compare comparable setups."
            ]
        },
        {
            "question": "What is the main message being conveyed in the comparison between the attention model and the encoder-decoder architecture?",
            "reference-answers": [
                "The main message being conveyed is that the encoder-decoder architecture is not necessarily better than the attention model, and one should always compare comparable setups."
            ]
        },
        {
            "question": "What is the main message being conveyed by comparing the attention model to the encoder-decoder architecture?",
            "reference-answers": [
                "The main message being conveyed is to always compare comparable setups."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen11-slide08/text.txt": [
        {
            "question": "What is the purpose of the neural network in the example provided, and how does it achieve this purpose?",
            "reference-answers": [
                "The purpose of the neural network in the example provided is to linearly separate points in the x and y plane into two categories (red and blue) by learning to transform input coordinates into output coordinates. It achieves this purpose by training itself on a set of training examples (points on two spirals) and then using this learned transformation to classify new, unseen points."
            ]
        },
        {
            "question": "What is the purpose of the neural network in this example, and how does it achieve this purpose?",
            "reference-answers": [
                "The purpose of the neural network in this example is to linearly separate points in the x and y plane into two classes, one half of which should be red and the other half blue. The network achieves this purpose by training itself on the given points, with each layer transforming the input coordinates and updating the weights to separate the points."
            ]
        },
        {
            "question": "What is the purpose of training a neural network with a set of points on the x and y input plane?",
            "reference-answers": [
                "The purpose of training a neural network with a set of points on the x and y input plane is to have the network learn to linearly separate the points into two categories (red and blue) so that it can classify new, unseen points based on the training examples."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen12-slide09/text.txt": [
        {
            "question": "How do recurrent neural networks handle variable-length inputs?",
            "reference-answers": [
                "Recurrent neural networks handle variable-length inputs by unrolling the computation in time, processing input samples of some length up to a fixed length limit, and filling unused space with padding (usually zeros) that does not affect the training."
            ]
        },
        {
            "question": "What is the basic approach used to handle variable size inputs in a neural network?",
            "reference-answers": [
                "The basic approach used to handle variable size inputs in a neural network is to use recurrent neural networks, which have a state that is gradually updated, combining the current input with the current state given a transformation function."
            ]
        },
        {
            "question": "What is the basic approach used to handle variable size inputs in neural networks?",
            "reference-answers": [
                "The basic approach used to handle variable size inputs in neural networks is to use recurrent neural networks, which have a state that is gradually updated by combining the current input with the current state given a transformation function."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen13-slide10/text.txt": [
        {
            "question": "What is the problem with the simple definition of the transformation in a vanilla recurrent neural network?",
            "reference-answers": [
                "The problem with the simple definition of the transformation in a vanilla recurrent neural network is that all values of the current state go through the non-linearity at every step, resulting in a radically changing state representation, leading to discontinuity in the representation and making training and interpretation difficult."
            ]
        },
        {
            "question": "What is the problem with the simple definition of a transformation in a vanilla recurrent neural network?",
            "reference-answers": [
                "The problem with the simple definition of a transformation in a vanilla recurrent neural network is that all values of the current state go through the non-linearity at every step, resulting in a radically changing state representation and no continuity in the representation, making it hard to interpret and train the network."
            ]
        },
        {
            "question": "What is the problem with the simple definition of the transformation in a vanilla recurrent neural network?",
            "reference-answers": [
                "The problem with the simple definition of the transformation in a vanilla recurrent neural network is that all values of the current state go through the non-linearity at every step, resulting in a radically changing state representation, leading to discontinuity in the representation and making training and interpretation difficult."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen14-slide11/text.txt": [
        {
            "question": "What does the word \"technically\" mean in the given context?",
            "reference-answers": [
                "It is used to add emphasis or to indicate that something is true or correct in a formal or slightly awkward way."
            ]
        },
        {
            "question": "What does the word \"technically\" imply in the given phrase?",
            "reference-answers": [
                "The phrase implies that the speaker is being precise and exact in their definition, possibly downplaying the significance or importance of what they are saying."
            ]
        },
        {
            "question": "What does the word \"technically\" imply in the given phrase?",
            "reference-answers": [
                "The phrase implies that the speaker is being precise and exact in their definition, possibly downplaying the significance or importance of what they are saying."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen15-slide10/text.txt": [
        {
            "question": "What is the effect on the values of the parameters in a deep network when they go through the non-linearity at every step in the backpropagation algorithm?",
            "reference-answers": [
                "The values will get smaller and smaller."
            ]
        },
        {
            "question": "What is the effect on the values of the parameters in a deep neural network when they go through non-linearity at every step during backpropagation?",
            "reference-answers": [
                "The values of the parameters in a deep neural network will get smaller and smaller when they go through non-linearity at every step during backpropagation."
            ]
        },
        {
            "question": "What happens to the values of the parameters in a deep neural network if they go through a non-linearity at every step during backpropagation?",
            "reference-answers": [
                "The values of the parameters in a deep neural network will get smaller and smaller if they go through a non-linearity at every step during backpropagation."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen18-slide07/text.txt": [
        {
            "question": "What is the \"vanishing gradient problem\" in deep neural networks?",
            "reference-answers": [
                "The \"vanishing gradient problem\" in deep neural networks occurs when updates to parameters go through the nonlinearity backwards at every step, resulting in values becoming too small, which can prevent early layers from changing and cause underflow issues due to numerical errors."
            ]
        },
        {
            "question": "What is the problem that occurs when the updates from backpropagation go through the nonlinearity backwards at every step in a deep network?",
            "reference-answers": [
                "The vanishing gradient problem."
            ]
        },
        {
            "question": "What is the problem that arises when nonlinearity is applied backwards through the layers of a deep network during backpropagation?",
            "reference-answers": [
                "The vanishing gradient problem."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen21-slide11/text.txt": [
        {
            "question": "What is the purpose of the two nonlinearities used in the gated recurrent unit (GRU), specifically the tanH and sigmoid functions?",
            "reference-answers": [
                "The tanH and sigmoid functions are used to serve different purposes in the gated recurrent unit (GRU). The tanH function is used for the computation of the new state, squashing the input from minus infinity to plus infinity to the interval from minus 1 to plus 1, while the sigmoid function is used for the gates, producing values between 0 and 1, allowing them to specify how much information should be used from the previous state and how much should be stored in the new state."
            ]
        },
        {
            "question": "What is the purpose of the reset gate in a Gated Recurrent Unit (GRU) and how does it differ from the update gate?",
            "reference-answers": [
                "The reset gate tells you which of the values you should keep the same and which of these values you should remove. It erases some information from the previous state or preserves it."
            ]
        },
        {
            "question": "What is the purpose of the reset gate in a Gated Recurrent Unit (GRU) and how does it control the information flow within the network?",
            "reference-answers": [
                "The reset gate tells you which of the values you should keep the same and which of these values you should remove."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen22-slide12/text.txt": [
        {
            "question": "What is the next topic that the machine translation process will cover after processing variable input lengths?",
            "reference-answers": [
                "text that we are going to process in machine translation."
            ]
        },
        {
            "question": "What is the next step in the machine translation process after processing variable input lengths?",
            "reference-answers": [
                "Now that we have processed variable input lengths, we need to move to the text that we are going to process in machine translation."
            ]
        },
        {
            "question": "What type of input lengths are being processed in machine translation?",
            "reference-answers": [
                "Variable input lengths."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen23-slide13/text.txt": [
        {
            "question": "What is the technical problem with representing English words as columnar vectors in a vector of length 1 million?",
            "reference-answers": [
                "The technical problem is that in English, the vector would be of length 1 million, but in Czech, it would be of length 2 million or more, making it impossible to process."
            ]
        },
        {
            "question": "What is the main problem with representing English words as columnar vectors in a dictionary of the same length as Czech words?",
            "reference-answers": [
                "The main problem with representing English words as columnar vectors in a dictionary of the same length as Czech words is that the English vector of length 1 million would be too short to accommodate the Czech vector of length 2 million or more."
            ]
        },
        {
            "question": "What is the problem with representing English words as columnar vectors in a vector of length 1 million?",
            "reference-answers": [
                "The problem with representing English words as columnar vectors in a vector of length 1 million is that there are more than 1 million English words, making it impossible to process."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen24-slide14/text.txt": [
        {
            "question": "What is the general idea behind the approach that involves starting with the alphabet as the set of allowed units and combining the most frequent pairs of characters to produce large units?",
            "reference-answers": [
                "The general idea is that you combine the most frequent pairs of characters to produce large units, and then combine some two units in your current vocabulary to produce yet a large unit, until the vocabulary size is fully occupied."
            ]
        },
        {
            "question": "What is the general idea behind the approach of combining the most frequent pairs of characters to produce large units, and then combining these units to produce even larger units?",
            "reference-answers": [
                "The general idea is that you start with the alphabet as the set of allowed units and combine the most frequent pairs of characters to produce large units, and then combine these units to produce yet a large unit, repeating this process until the vocabulary size is fully occupied."
            ]
        },
        {
            "question": "What is the general idea behind the approach that combines the most frequent pairs of characters to produce large units, and then combines some two units in the current vocabulary to produce yet a large unit?",
            "reference-answers": [
                "The general idea is that you start with the alphabet as the set of allowed units and combine the most frequent pairs of characters to produce large units, and then combine some two units in the current vocabulary to produce yet a large unit, repeating this process until the vocabulary size is fully occupied."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen25-slide15/text.txt": [
        {
            "question": "What is the maximum number of elements that can be in a vector using sub-work units?",
            "reference-answers": [
                "30,000"
            ]
        },
        {
            "question": "What is the maximum number of elements that can be in a vector when using sub-work units?",
            "reference-answers": [
                "30,000"
            ]
        },
        {
            "question": "What is the maximum number of elements that can be achieved in a vector using sub-work units?",
            "reference-answers": [
                "30,000"
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen26-slide13/text.txt": [
        {
            "question": "What is a problem with using a dense representation of words that uses fewer numbers but a larger set of numbers, as it can lead to incorrect translations?",
            "reference-answers": [
                "The system may happily reuse a translation for one word, even if it's not the best fit for another word, because the words are too far away from each other in the dense representation."
            ]
        },
        {
            "question": "What type of representation would make a word translation system more robust to small changes in the input?",
            "reference-answers": [
                "A dense representation where the words are represented with fewer numbers but a larger set of numbers."
            ]
        },
        {
            "question": "What type of representation is needed to make a word translation system robust to small changes in the input?",
            "reference-answers": [
                "A dense representation where the words are represented with fewer numbers but a larger set of numbers."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen27-slide15/text.txt": [
        {
            "question": "What is the purpose of the embedding elements in the embedding matrix in a neural network?",
            "reference-answers": [
                "The embedding elements in the embedding matrix are first initialized randomly and then through the training of the particular given task, the embeddings will get trained so that they are most useful."
            ]
        },
        {
            "question": "What are some of the features that the embedding elements in the embedding matrix can be used to indicate, such as in the case of verbs?",
            "reference-answers": [
                "Some of the dimensions can be used for verbs, to indicate whether this is more in the present tense or more in the past tense."
            ]
        },
        {
            "question": "What are the dimensions of the embeddings that can be used to indicate whether a word is more in the present tense or more in the past tense?",
            "reference-answers": [
                "Some of the dimensions can be used for verbs, to indicate whether this is more in the present tense or more in the past tense."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen28-slide16/text.txt": [
        {
            "question": "What is the purpose of normalizing the logits or energies for words in the softmax normalization process?",
            "reference-answers": [
                "The normalization is to make it a probability distribution so that it will sum to one, and then you choose the highest scoring element, which is the actual word that you are going to emit."
            ]
        },
        {
            "question": "What is the purpose of the softmax normalization in the context of a recurrent neural network producing output units?",
            "reference-answers": [
                "The softmax normalization normalizes the logits or energies for words at a time t to make it a probability distribution, so that it will sum to one, allowing you to choose the highest scoring element, which is the actual word that you are going to emit."
            ]
        },
        {
            "question": "What is the purpose of normalizing the output of the recurrent neural network in this context?",
            "reference-answers": [
                "The normalization is to make it a probability distribution so that it will sum to one, and then you choose the highest scoring element, which is the actual word that you are going to emit."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen29-slide17/text.txt": [
        {
            "question": "What is the basis of Neural Language Modeling mentioned in the provided text?",
            "reference-answers": [
                "Neural Language Modeling."
            ]
        },
        {
            "question": "What is the basis of Neural Language Modeling mentioned in the text?",
            "reference-answers": [
                "Neural Language Modeling."
            ]
        },
        {
            "question": "What is the basis of Neural Language Modeling according to the provided text?",
            "reference-answers": [
                "Neural Language Modeling."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen30-slide18/text.txt": [
        {
            "question": "What is the primary goal of training a recurrent neural network in the context of Neural Network Translation Systems?",
            "reference-answers": [
                "The primary goal of training a recurrent neural network in the context of Neural Network Translation Systems is to adjust the weights so that it is most likely to produce the word which was seen in the training data."
            ]
        },
        {
            "question": "What is the purpose of the softmax function in the neural network translation system described in the text?",
            "reference-answers": [
                "The softmax function is used to choose the word from the probability distribution over all possible subsequent words, selecting the most likely one."
            ]
        },
        {
            "question": "What is the main difference between a neural network translation system and an Ngram language model?",
            "reference-answers": [
                "A neural network translation system is a language model but not an Ngram language model, as it has unlimited history and uses recurrent neural networks to classify the next word in a sentence based on the aggregated input of the aggregated input sentence."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen31-slide19/text.txt": [
        {
            "question": "What are the two possible views on a recurrent neural network language model presented in the text?",
            "reference-answers": [
                "You can see it as a loop function or maybe if you're a functional programmer as map function over sequential data."
            ]
        },
        {
            "question": "What are the two possible views of a recurrent neural network language model according to the text?",
            "reference-answers": [
                "You can see it as a loop function or as a map function over sequential data, and also as a way to define probability distribution over sequences of words."
            ]
        },
        {
            "question": "What are the two possible views of a recurrent neural network language model according to the provided text?",
            "reference-answers": [
                "You can see it as a loop function or as a map function over sequential data, and you can also see it as a way to define probability distribution over sequences of words."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen32-slide20/text.txt": [
        {
            "question": "What is the benefit of using a bidirectional recurrent neural network in practice?",
            "reference-answers": [
                "The benefit of this approach is that you read sentences from more directions at once."
            ]
        },
        {
            "question": "What is the benefit of using a bidirectional recurrent neural network that processes input from both left to right and right to left?",
            "reference-answers": [
                "The benefit of this approach is that you digest the input from more directions at once."
            ]
        },
        {
            "question": "What is the benefit of using a bidirectional recurrent neural network in practice?",
            "reference-answers": [
                "The benefit of this approach is that you read sentences from more directions at once."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen33-slide22/text.txt": [
        {
            "question": "What is the advantage of using a bidirectional representation in a neural network for natural language processing tasks?",
            "reference-answers": [
                "At every state, the network has access to the complete sentence, allowing it to decide whether to remember or focus on specific parts of the sentence, making it effective for most natural language processing tasks."
            ]
        },
        {
            "question": "What are the advantages of using bidirectional recurrent neural networks in natural language processing tasks?",
            "reference-answers": [
                "Bidirectional recurrent neural networks are very effective for most of natural language processing tasks because they have the capacity to remember everything that is important in the tail and also have access to the complete sentence at every state, allowing the network to decide what information to focus on."
            ]
        },
        {
            "question": "What type of representation is beneficial for a bidirectional recurrent neural network in natural language processing tasks?",
            "reference-answers": [
                "A bidirectional representation is beneficial because at every state, you have access or potentially the network can decide to remember it, allowing the network to access the complete sentence."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen34-slide23/text.txt": [
        {
            "question": "What is the topic of the next section being discussed in the text?",
            "reference-answers": [
                "Translation systems."
            ]
        },
        {
            "question": "What is the name of the translation system being discussed in the text?",
            "reference-answers": [
                "Encoder-decoder architecture."
            ]
        },
        {
            "question": "What type of architecture is being referred to as \"translation systems\" in the text?",
            "reference-answers": [
                "Encoder-decoder architecture."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen35-slide24/text.txt": [
        {
            "question": "What is the idea being referred to in the context of the conditional language model scheme?",
            "reference-answers": [
                "The idea is that you will again exploit the conditional language model scheme."
            ]
        },
        {
            "question": "What is the idea being referred to in the context of exploiting a conditional language model scheme?",
            "reference-answers": [
                "The idea being referred to is that you will again exploit the conditional language model scheme."
            ]
        },
        {
            "question": "What is the idea that you will exploit in the conditional language model scheme?",
            "reference-answers": [
                "The conditional language model scheme."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen37-slide27/text.txt": [
        {
            "question": "What is the role of the decoder in the described language model generation process?",
            "reference-answers": [
                "The decoder runs the standard language model generation in the decoder given the condensed representation of the input."
            ]
        },
        {
            "question": "What is the purpose of the 'encoder' network in the given language model architecture?",
            "reference-answers": [
                "The encoder processes the input sequence of symbols into a single vector representation."
            ]
        },
        {
            "question": "What type of network is used to process the input sequence of symbols into a single vector representation?",
            "reference-answers": [
                "The encoder."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen38-slide28/text.txt": [
        {
            "question": "What is the primary function of the decoder in the encoder-decoder architecture described in the text?",
            "reference-answers": [
                "The decoder is fed at the beginning with the beginning of sentence symbol and it decides what is the most likely first word in the output."
            ]
        },
        {
            "question": "What is the purpose of the two embeddings in the encoder-decoder architecture, and what are they used for?",
            "reference-answers": [
                "The two embeddings are used to convert source language words into a continuous representation that the encoder can digest, and target language words into a representation that the decoder can digest."
            ]
        },
        {
            "question": "What is the purpose of using a single embedding matrix for both the source and target languages in the encoder-decoder architecture?",
            "reference-answers": [
                "The benefit of using a single embedding matrix is that it has only one matrix in your training and the same matrix is updated both during the backpropagation through the decoder."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen39-slide30/text.txt": [
        {
            "question": "What is the purpose of ignoring the outputs of the RNN in the encoder state processing step?",
            "reference-answers": [
                "The outputs of the RNN are not important."
            ]
        },
        {
            "question": "What is the purpose of the decoder in the conditional language model described in the text?",
            "reference-answers": [
                "The decoder is used to predict the next symbol in the target language, and it continues to produce symbols until it encounters the end of sentence symbol, giving the generated output as the result."
            ]
        },
        {
            "question": "What is the purpose of ignoring the outputs of the RNN during the decoding process in the conditional language model?",
            "reference-answers": [
                "The outputs of the RNN are not important during the decoding process in the conditional language model."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen40-slide32/text.txt": [
        {
            "question": "What is the subject of the sentence \"So, uh, with...\"?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        },
        {
            "question": "What is the student's response to the prompt \"So, uh, with...\" in the given text?",
            "reference-answers": [
                "I don't have enough information to provide an accurate response."
            ]
        },
        {
            "question": "What is the subject of the speaker's sentence \"So, uh, with...\"?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen41-slide31/text.txt": [
        {
            "question": "What is the typical form of the input and target language in a sequence-to-sequence task?",
            "reference-answers": [
                "The input and target language are sequences of source language tokens and output tokens, respectively, and are typically coming from the same vocabulary."
            ]
        },
        {
            "question": "What are the two main entities referred to as \"sub-work units\" in the context of the input for a translation task?",
            "reference-answers": [
                "source language tokens and target language tokens"
            ]
        },
        {
            "question": "What are the sub-work units referred to as in the context of source language tokens?",
            "reference-answers": [
                "source language tokens"
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen42-slide32/text.txt": [
        {
            "question": "What is the purpose of the bias in the encoder's weight matrix?",
            "reference-answers": [
                "The bias is added to the output of the weight matrix and the non-linearity, and its purpose is not explicitly stated, but it is mentioned that it is applied after the bias."
            ]
        },
        {
            "question": "What is the purpose of the bias in the recurrent neural network (RNN) encoder?",
            "reference-answers": [
                "The bias is added and then applied in the RNN encoder to get the state of the recurrent neural network."
            ]
        },
        {
            "question": "What is the effect of using a non-linearity after adding the bias in the encoder of a record neural network?",
            "reference-answers": [
                "The non-linearity is applied after adding the bias to the result of the weight matrix and the embedded representation of the input word, and it is what gets the state of the recurrent neural network of the encoder."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen43-slide33/text.txt": [
        {
            "question": "What is the purpose of the bias in the decoder's weight matrix for the decoder?",
            "reference-answers": [
                "The bias is applied in the decoder's weight matrix for the decoder."
            ]
        },
        {
            "question": "What is the purpose of the bias in the decoder, and how does it differ from the bias in the encoder?",
            "reference-answers": [
                "The bias in the decoder and the encoder differ in that the bias is applied in the decoder, but no difference is specified for the encoder."
            ]
        },
        {
            "question": "What is the purpose of the non-linearity in the decoder's computation steps?",
            "reference-answers": [
                "The non-linearity is applied after the output state of the decoder is used in the next computation step, and also after the output word is selected."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen44-slide34/text.txt": [
        {
            "question": "How do you score whether the output candidate matches well with the expected output candidate in a sentence-by-sentence alignment process?",
            "reference-answers": [
                "We score whether the output candidate matches well with the expected output candidate by checking if the word that is expected has the highest probability in the distribution over the full vocabulary."
            ]
        },
        {
            "question": "How do you determine if the output candidate matches well with the expected output candidate for a given output word yi?",
            "reference-answers": [
                "We score whether the output candidate matches well with the expected output candidate by checking if the word that is expected has also indeed the highest probability in the distribution over the full vocabulary."
            ]
        },
        {
            "question": "How do you score whether the output candidate matches well with the expected output candidate?",
            "reference-answers": [
                "We score whether the output candidate matches well with the expected output candidate by checking if the word that is expected has also indeed the highest probability in the distribution over the full vocabulary."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen45-slide35/text.txt": [
        {
            "question": "What is the nature of the output distribution that is defined for a given time step in the model?",
            "reference-answers": [
                "The output distribution is a very peaked distribution that is set to 1 for the word seen at this position in the training data and 0 for all other candidate tokens."
            ]
        },
        {
            "question": "What is the definition of the output distribution used to represent the possible words at a given time step in the training data?",
            "reference-answers": [
                "The output distribution is set to 1 for the word which was seen at this position in the training data and for 0 to all other candidate tokens."
            ]
        },
        {
            "question": "What type of distribution is defined for the output words at each time step in the given training data?",
            "reference-answers": [
                "A peaked distribution."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen46-slide36/text.txt": [
        {
            "question": "What is the loss in the computation when using a soft-max function in the mathematical point of view?",
            "reference-answers": [
                "The loss is the cross-entropy between the distribution produced by the soft-max function (hat p hat) and the true distribution, which is all zeros and ones for the word being expected."
            ]
        },
        {
            "question": "What is the loss measured in the context of a soft-mach function, according to the given explanation?",
            "reference-answers": [
                "The loss is measured as the cross-entropy between the distribution produced by the soft-mach function (hat p hat) and the true distribution (all zeros and ones for the expected word)."
            ]
        },
        {
            "question": "What type of loss is calculated in the computation when the soft-max function is used?",
            "reference-answers": [
                "Cross-entropy."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen47-slide37/text.txt": [
        {
            "question": "What is calculated as the loss at a given position in the sequence during the training process described in the text?",
            "reference-answers": [
                "The negative log of the word that you are expecting in your softmax output."
            ]
        },
        {
            "question": "What is calculated as the loss at a given position in the softmax output?",
            "reference-answers": [
                "The negative log of the word that you are expecting in your softmax output."
            ]
        },
        {
            "question": "What is the loss incurred at a position in the model, according to the provided explanation?",
            "reference-answers": [
                "The negative log of the word that you are expecting in your softmax output."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen48-slide38/text.txt": [
        {
            "question": "What is the basis for calculating the loss at each position in the output words?",
            "reference-answers": [
                "The loss at each position in the output words is calculated as loss proportional to the negative logarithm of the probability of the word that should have been predicted."
            ]
        },
        {
            "question": "What is the basis for the loss computation at each position in the output words?",
            "reference-answers": [
                "The loss computation at each position in the output words is based on the negative logarithm of the probability of the word that should have been predicted."
            ]
        },
        {
            "question": "What type of loss is calculated at each position of the output words during the computation of derivatives?",
            "reference-answers": [
                "Loss proportional to the negative logarithm of the probability of the word that should have been predicted."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen49-slide39/text.txt": [
        {
            "question": "What is a major limitation of the training criterion for neural networks in machine translation tasks?",
            "reference-answers": [
                "The major limitation of the training criterion for neural networks in machine translation tasks is that they are forced to memorize the parallel corpus, which restricts their ability to generalize and produce flexible output."
            ]
        },
        {
            "question": "What is a major limitation of training neural networks for machine translation tasks?",
            "reference-answers": [
                "The major limitation of training neural networks for machine translation tasks is that they are forced to memorize the parallel corpus, which leads to a lack of flexibility and variability in the output."
            ]
        },
        {
            "question": "What is a limitation of training neural networks for machine translation tasks?",
            "reference-answers": [
                "The training criterion of neural networks for machine translation tasks is inadequate in the sense that they are forced to memorize the parallel corpus."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen50-slide40/text.txt": [
        {
            "question": "What is the role of the Softmax function in the training process of the decoder in the given neural network architecture?",
            "reference-answers": [
                "The Softmax function is used to estimate the loss during training, giving you the probability distribution of the output words."
            ]
        },
        {
            "question": "What is the purpose of the Softmax function in the decoder during training, and how does it relate to estimating loss?",
            "reference-answers": [
                "The Softmax function is used to estimate the loss during training, giving you the probability distribution of the output words."
            ]
        },
        {
            "question": "What is the purpose of using the Softmax function in the decoder during training?",
            "reference-answers": [
                "The Softmax function is used to estimate the loss, and it gives you the probability distribution of the output words."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen51-slide42/text.txt": [
        {
            "question": "What is the outcome of the decoder at each step in the decoding process?",
            "reference-answers": [
                "a distribution of the vocabulary."
            ]
        },
        {
            "question": "What is the outcome of the decoder at each step in the decoding process?",
            "reference-answers": [
                "a distribution of the vocabulary."
            ]
        },
        {
            "question": "What is the outcome of the decoder at each step of the decoding process?",
            "reference-answers": [
                "A distribution of the vocabulary."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen52-slide43/text.txt": [
        {
            "question": "What is the method of decoding described in the given text?",
            "reference-answers": [
                "choosing the highest scoring word at that time step."
            ]
        },
        {
            "question": "What is the method of decoding described in the given text?",
            "reference-answers": [
                "choosing the highest scoring word at that time step."
            ]
        },
        {
            "question": "What is the process of selecting the highest scoring word at each time step in decoding?",
            "reference-answers": [
                "Decoding you simply choose the highest scoring word at that time step."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen53-slide45/text.txt": [
        {
            "question": "What is the primary advantage of using greedy decoding in neural networks?",
            "reference-answers": [
                "It already gives reasonable results for neural networks because the record language model is strange to produce these sequences."
            ]
        },
        {
            "question": "What is the primary advantage of using greedy decoding in neural networks?",
            "reference-answers": [
                "It already gives reasonable results for neural networks because the record language model is strange to produce these sequences."
            ]
        },
        {
            "question": "What is the primary advantage of using greedy decoding in language models?",
            "reference-answers": [
                "It is fast and memory efficient."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen54-slide46/text.txt": [
        {
            "question": "What is the main difference between beam search and greedy decoding in the context of a neural network's decoding process?",
            "reference-answers": [
                "In beam search, the network produces less likely beginnings of the sentences, less likely words, and then benefits from it to get to the highly probable final sentence. In greedy decoding, the network prefers common words to uncommon ones and recovers from it."
            ]
        },
        {
            "question": "What is the main difference between beam search and greedy decoding in a neural network's decoding process?",
            "reference-answers": [
                "Beam search allows the network to produce less likely beginnings of the sentences, less likely words, and then benefits from it to get to the highly probable final sentence. Greedy decoding prefers common words to uncommon ones."
            ]
        },
        {
            "question": "What is the main difference between beam search and greedy decoding in the context of neural network decoding?",
            "reference-answers": [
                "In beam search, the network produces less likely beginnings of the sentences, less likely words, and then benefits from it to get to the highly probable final sentence. In greedy decoding, the network prefers common words to uncommon ones and then recovers."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen55-slide47/text.txt": [
        {
            "question": "What is a hypothesis in the context described?",
            "reference-answers": [
                "A partially decoded sentence with some associated score."
            ]
        },
        {
            "question": "What is a hypothesis in the context described?",
            "reference-answers": [
                "A partially decoded sentence with some associated score."
            ]
        },
        {
            "question": "What is a hypothesis according to the given definition?",
            "reference-answers": [
                "A hypothesis is a partially decoded sentence with some associated score and..."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen56-slide48/text.txt": [
        {
            "question": "What is a potential drawback of using beam search with neural networks in language modeling?",
            "reference-answers": [
                "Using beam search with neural networks can produce worse sentences, as more candidates are considered, and the networks are trained to memorize the parallel corpus rather than understand the sentence adequately."
            ]
        },
        {
            "question": "What are the limitations of using neural networks with recurrent language models when employing beam search in the context of generating sentences?",
            "reference-answers": [
                "Using neural networks with recurrent language models employing beam search will produce worse sentences due to suboptimal training, where the networks memorize the parallel corpus rather than understanding the sentence and representing paraphrases jointly."
            ]
        },
        {
            "question": "What happens to the quality of sentences produced by neural networks when the beam size is increased during beam search?",
            "reference-answers": [
                "When the beam size is increased during beam search, the quality of sentences produced by neural networks will decrease, because more candidates are considered and the networks are not trained to understand the sentence adequately."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen57-slide49/text.txt": [
        {
            "question": "What is the result of multiplying the score of the prefix with the probability of the next word in the beam search algorithm?",
            "reference-answers": [
                "The score of the extended hypothesis."
            ]
        },
        {
            "question": "What is the formula used to compute the score of the extended hypothesis in beam search?",
            "reference-answers": [
                "You simply multiply the score of the prefix with the probability of the next word which comes after that."
            ]
        },
        {
            "question": "What happens to the score of the prefix when you extend the hypothesis by one word?",
            "reference-answers": [
                "You simply multiply the score of the prefix with the probability of the next word which comes after that."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen58-slide50/text.txt": [
        {
            "question": "What is a benefit of having fewer words in a hypothesis for the overall score in a multiplication problem?",
            "reference-answers": [
                "The higher the overall score."
            ]
        },
        {
            "question": "What is a benefit of having fewer words in a hypothesis in this multiplication?",
            "reference-answers": [
                "The higher the overall score."
            ]
        },
        {
            "question": "What is a benefit of using a shorter hypothesis in the multiplication?",
            "reference-answers": [
                "The higher the overall score."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen59-slide51/text.txt": [
        {
            "question": "What is the starting point for the beam search algorithm?",
            "reference-answers": [
                "A single empty hypothesis."
            ]
        },
        {
            "question": "What is the starting point for the beam search algorithm?",
            "reference-answers": [
                "A single empty hypothesis."
            ]
        },
        {
            "question": "What is the starting point for the beam search algorithm?",
            "reference-answers": [
                "A single empty hypothesis."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen60-slide53/text.txt": [
        {
            "question": "What is the process of extending hypotheses in the beam in each step?",
            "reference-answers": [
                "And in each step you extend all the hypotheses in the beam by the k most probable words."
            ]
        },
        {
            "question": "What are the candidate hypotheses in the beam after extending all the hypotheses in the beam by the k most probable words?",
            "reference-answers": [
                "The candidate hypotheses."
            ]
        },
        {
            "question": "What are the candidate hypotheses in the beam that are formed in each step of the process?",
            "reference-answers": [
                "The candidate hypotheses in the beam that are formed in each step of the process are the hypotheses extended by all the words in the beam by the k most probable words."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen61-slide55/text.txt": [
        {
            "question": "What is the purpose of preserving only k candidates in the next step of the process described in the text?",
            "reference-answers": [
                "To have a nice view of the process."
            ]
        },
        {
            "question": "What is the purpose of preserving only k candidates in the next step of the candidate hypothesis process?",
            "reference-answers": [
                "To have a nice view of the process."
            ]
        },
        {
            "question": "What is the purpose of preserving only k candidates in the next step of the process described in the text?",
            "reference-answers": [
                "To have a nice view of the process."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen62-slide56/text.txt": [
        {
            "question": "What happens to a hypothesis that reaches the end of a sentence in the given text?",
            "reference-answers": [
                "You put it to a separate list of finished hypotheses."
            ]
        },
        {
            "question": "What happens to a hypothesis if it reaches the end of a sentence?",
            "reference-answers": [
                "You put it to a separate list of finished hypotheses."
            ]
        },
        {
            "question": "What happens to a hypothesis when it reaches the end of a sentence?",
            "reference-answers": [
                "You put it to a separate list of finished hypotheses."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen63-slide57/text.txt": [
        {
            "question": "What is the condition for stopping the process of generating hypotheses in the beam search algorithm?",
            "reference-answers": [
                "You stop either when you have run out of time or when there are k-best hypotheses, when all k-best hypotheses in the finished list and the current beam together when they are finished, when they end with the end of sentence symbols."
            ]
        },
        {
            "question": "What are the conditions for stopping the process in the beam search algorithm?",
            "reference-answers": [
                "You stop either when you have run out of time or when there are k-best hypotheses, when all k-best hypotheses in the finished list and the current beam together when they are finished, when they end with the end of sentence symbols."
            ]
        },
        {
            "question": "What are the two conditions for stopping the beam search process?",
            "reference-answers": [
                "You stop either when you have run out of time or when there are k-best hypotheses."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen64-slide58/text.txt": [
        {
            "question": "What is the approach described in the phrase \"when we cover the standard phrase-based approach\"?",
            "reference-answers": [
                "Sorting the hypothesis by the score and emitting the best one."
            ]
        },
        {
            "question": "What is the purpose of sorting the hypothesis by score in the phrase-based approach?",
            "reference-answers": [
                "To sort the hypothesis by the score."
            ]
        },
        {
            "question": "What approach is described as being covered by the standard phrase, where hypotheses are sorted by score and the best one is emitted?",
            "reference-answers": [
                "The standard phrase-based approach."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen65-slide59/text.txt": [
        {
            "question": "What is a major limitation of the current approach when dealing with longer sentences?",
            "reference-answers": [
                "The quality of the approach degraded heavily with longer sentences."
            ]
        },
        {
            "question": "What is the main issue with the current approach for longer sentences?",
            "reference-answers": [
                "The quality of the approach degraded heavily with longer sentences."
            ]
        },
        {
            "question": "What type of performance degradation is experienced by the approach with longer sentences?",
            "reference-answers": [
                "The approach's quality degraded heavily with longer sentences."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen66-slide60/text.txt": [
        {
            "question": "What is the goal of the attention in a network?",
            "reference-answers": [
                "The goal of the attention is to allow the network to consider with the same magnitude or the importance all the source positions at any time step of the output."
            ]
        },
        {
            "question": "What is the primary goal of the attention mechanism in a neural network?",
            "reference-answers": [
                "The primary goal of the attention mechanism in a neural network is to allow the network to consider all source positions with the same magnitude or importance at any time step of the output."
            ]
        },
        {
            "question": "What is the main goal of the attention mechanism in a neural network?",
            "reference-answers": [
                "The main goal of the attention mechanism in a neural network is to allow the network to consider all the source positions with the same magnitude or importance at any time step of the output."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen71-slide40/text.txt": [
        {
            "question": "What is a potential solution to the problem of the decoder forgetting the original input sentence in a sequence-to-sequence model?",
            "reference-answers": [
                "Injecting the encoding of the input sentence into every step of the network could help, as it would allow the network to reconsider which words to look at and would have access to the first sentence representation at every stage."
            ]
        },
        {
            "question": "What is a potential approach to mitigate the \"fabulation\" problem in the decoder, where it forgets the original input and produces nonsensical words towards the end of the sentence?",
            "reference-answers": [
                "Injecting the encoding of the input sentence into every step of the network could help mitigate the \"fabulation\" problem, as it would allow the network to reconsider the words it should look at and have access to the first sentence representation at every stage."
            ]
        },
        {
            "question": "What approach helped in early implementations to improve the representation of the input sentence in the decoder state, but still resulted in \"fabulation\" towards the end of the sentence?",
            "reference-answers": [
                "Inserting the input sentence in the reverse order helped in early implementations to improve the representation of the input sentence in the decoder state, but still resulted in \"fabulation\" towards the end of the sentence."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen76-slide60/text.txt": [
        {
            "question": "What is the purpose of using the attention mechanism in the proposed approach to represent long-distance dependencies within a sentence?",
            "reference-answers": [
                "The attention mechanism is used to represent the target sentence dependencies, such as language model properties, and to guide the decoder to consider which source words to look at at each time step."
            ]
        },
        {
            "question": "What is the purpose of the attention mechanism in the network, according to the provided explanation?",
            "reference-answers": [
                "The attention mechanism is used to represent the target sentence dependencies and query the source word sentence based on the decoder's current state, ensuring that the network considers the relevant source words at each time step."
            ]
        },
        {
            "question": "What is the purpose of using the attention mechanism in the proposed approach?",
            "reference-answers": [
                "The attention mechanism is used to represent the target sentence dependencies and to enable the decoder to consider which source words it should look at at each time step, effectively modeling long distance dependencies within one single vector."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen77-slide61/text.txt": [
        {
            "question": "What is the role of the read heads in the system being described?",
            "reference-answers": [
                "The read heads identify what to search in the memory."
            ]
        },
        {
            "question": "What is the role of the read heads in a neural Turing machine?",
            "reference-answers": [
                "The read heads identify what to search in the memory."
            ]
        },
        {
            "question": "What type of machines is the text vaguely inspired by?",
            "reference-answers": [
                "Neural Turing machines."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen78-slide62/text.txt": [
        {
            "question": "How can the memory of a neural Turing machine be addressed or used to be addressed?",
            "reference-answers": [
                "The memory of a neural Turing machine can be addressed or used to be addressed either by position or by content, by similarity, by searching for similar items in the memory."
            ]
        },
        {
            "question": "How can the memory of a neural Turing machine be addressed or used to be addressed?",
            "reference-answers": [
                "The memory of a neural Turing machine can be addressed or used to be addressed either by position or by content, by similarity, by searching for similar items in the memory."
            ]
        },
        {
            "question": "How can the memory of a neural Turing machine be addressed or used to be addressed?",
            "reference-answers": [
                "The memory of a neural Turing machine can be addressed or used to be addressed either by position or by content, by similarity, by searching for similar items in the memory."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen79-slide63/text.txt": [
        {
            "question": "What is at the heart of attention according to the new Turing machines?",
            "reference-answers": [
                "Nothing, according to the new Turing machines."
            ]
        },
        {
            "question": "What is at the heart of attention according to the statement about Turing machines?",
            "reference-answers": [
                "Nothing, according to the statement about Turing machines."
            ]
        },
        {
            "question": "What is at the heart of attention according to the new Turing machines?",
            "reference-answers": [
                "Nothing, according to the new Turing machines."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen80-slide64/text.txt": [
        {
            "question": "What is the primary method of addressing that is being discussed in the text?",
            "reference-answers": [
                "content-based addressing"
            ]
        },
        {
            "question": "What is the primary method of addressing that is being referred to in the given text?",
            "reference-answers": [
                "content-based addressing"
            ]
        },
        {
            "question": "What type of addressing is emphasized as being effective in the provided text?",
            "reference-answers": [
                "content-based addressing"
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen81-slide66/text.txt": [
        {
            "question": "What is the primary function of the attention mechanism in the decoder of a recurrent neural network, and how does it differ from other methods of condensing variable-length input sequences?",
            "reference-answers": [
                "The primary function of the attention mechanism in the decoder is to query the encoder for the most relevant states to consider when producing each output word. This allows the decoder to focus on different parts of the sentence at different time steps and weigh their importance. This differs from other methods, such as taking the last element in the sequence or max pooling, which do not allow the model to consider different parts of the sentence in a weighted manner."
            ]
        },
        {
            "question": "What is the primary function of the attention mechanism in a bidirectional recurrent neural network, and how does it differ from aggregation methods such as max pooling?",
            "reference-answers": [
                "The attention mechanism is the weighted sum over all the encoder states, and the weights change and are determined automatically as you proceed with the output. This differs from aggregation methods such as max pooling, which aggregate steps by a fixed method (e.g. max pooling), and is more suitable for tasks that require considering different parts of the sentence as differently important, such as copying or replicating the structure of the sentence."
            ]
        },
        {
            "question": "What is the primary function of the attention mechanism in a bidirectional recurrent neural network during the decoder step in sentence generation?",
            "reference-answers": [
                "The attention mechanism asks the encoder which words should be considered when producing each word in the sentence, essentially querying for information about the current word in the sentence."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen82-slide67/text.txt": [
        {
            "question": "What is the purpose of normalizing the attention energies in the attention mechanism?",
            "reference-answers": [
                "The attention energies need to be normalized so that they sum to one, allowing them to be used as weights to combine all the encoder states."
            ]
        },
        {
            "question": "What is the purpose of normalizing the attention energies in the attention mechanism?",
            "reference-answers": [
                "The attention energies need to be normalized so that they sum to one, allowing them to be used as weights to combine all the encoder states."
            ]
        },
        {
            "question": "What is the purpose of normalizing the attention energies so that they sum to one?",
            "reference-answers": [
                "So that they can be used as weights to combine all the encoder states."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen83-slide68/text.txt": [
        {
            "question": "How is the output of the encoder used in the encoder-decoder approach compared to the standard encoder?",
            "reference-answers": [
                "The output of the encoder is used in all its positions and you can come back to these positions whenever you like."
            ]
        },
        {
            "question": "What is the difference between the decoder in the original encoder-decoder approach and the decoder in the approach described in the text?",
            "reference-answers": [
                "The decoder in the approach described is not much different from the original decoder, but the main difference is that in this approach, the decoder outputs are used at all positions, whereas in the original approach, the decoder outputs are used only at the time step."
            ]
        },
        {
            "question": "What is the difference between the output of the encoder in the original encoder-decoder approach and the modified approach described in the text?",
            "reference-answers": [
                "The main difference is that in the original approach, the output of the encoder is used differently, whereas in the modified approach, the output of the encoder is used in all its positions and can be revisited at any time step."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen84-slide67/text.txt": [
        {
            "question": "How many items are accessible at each time step?",
            "reference-answers": [
                "One"
            ]
        },
        {
            "question": "At each time step, how many items are accessible?",
            "reference-answers": [
                "One"
            ]
        },
        {
            "question": "How many items are accessible at each time step?",
            "reference-answers": [
                "One"
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen85-slide68/text.txt": [
        {
            "question": "What is the purpose of scaling the context vectors and output projection in the given network architecture?",
            "reference-answers": [
                "The context vectors and the output projection are scaled so that the context vectors match the size of the decoder state, allowing the network to attend to any of the words in the input at every step."
            ]
        },
        {
            "question": "What is the purpose of scaling the context vectors with a matrix in the given network architecture?",
            "reference-answers": [
                "The context vectors match the size of the decoder state, and the output projection has access to that information."
            ]
        },
        {
            "question": "What is the purpose of scaling context vectors with a matrix in the given network architecture?",
            "reference-answers": [
                "The context vectors match the size of the decoder state, and the output projection has access to that information."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen86-slide69/text.txt": [
        {
            "question": "What is the primary function of the attention mechanism in the given context, and how does it influence the decoder's output?",
            "reference-answers": [
                "The primary function of the attention mechanism is to automatically identify the most useful input elements, and it influences the decoder's output by aligning the states of the encoder and the decoder, specifically allowing the decoder to focus on the most relevant parts of the input sequence."
            ]
        },
        {
            "question": "What is the primary role of the attention mechanism in the given process?",
            "reference-answers": [
                "The attention mechanism automatically learned to identify the most useful weights by primarily looking at the second position representation of the encoder and so on, and it automatically learned to follow the diagonal more or less and do the reorderings only for the expressions that deserve reordering in the given pair of languages."
            ]
        },
        {
            "question": "What type of alignment is produced by the attention mechanism between the source and target words during decoding in a bidirectional encoder-decoder model?",
            "reference-answers": [
                "An alignment between the states of the encoder and the decoder."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen88-slide72/text.txt": [
        {
            "question": "What are the differences mentioned in the text?",
            "reference-answers": [
                "Positions."
            ]
        },
        {
            "question": "What are the differences being referred to in the text?",
            "reference-answers": [
                "Positions in the exam."
            ]
        },
        {
            "question": "What are the differences mentioned in the text?",
            "reference-answers": [
                "Positions."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen90-slide72/text.txt": [
        {
            "question": "What is the purpose of the teacher preparing for an exam?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        },
        {
            "question": "What is the purpose of the teacher preparing for an exam?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        },
        {
            "question": "What is the purpose of the teacher preparing for an exam?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen91-slide73/text.txt": [
        {
            "question": "What type of distribution is described in the given text?",
            "reference-answers": [
                "Probabilistic."
            ]
        },
        {
            "question": "What type of distribution is being referred to in the context of positions?",
            "reference-answers": [
                "Probabilistic."
            ]
        },
        {
            "question": "What type of distribution is being referred to in the given text?",
            "reference-answers": [
                "Probabilistic distribution."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen92-slide74/text.txt": [
        {
            "question": "Is the given statement declarative?",
            "reference-answers": [
                "It's unclear."
            ]
        },
        {
            "question": "Is the statement \"Here we can say that this is declarative, well, I don't know, whatever\" declarative?",
            "reference-answers": [
                "It's unclear."
            ]
        },
        {
            "question": "Is the statement in the given text declarative?",
            "reference-answers": [
                "Yes."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen93-slide76/text.txt": [
        {
            "question": "What is the purpose of the teacher preparing for an exam?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        },
        {
            "question": "What is the purpose of the teacher preparing for an exam?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        },
        {
            "question": "What is the purpose of the teacher preparing for an exam?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen95-slide76/text.txt": [
        {
            "question": "How is the alignment in neural machine translation different from classical statistical machine translation?",
            "reference-answers": [
                "In classical statistical machine translation, alignment was a prerequisite, a step before the system was trained, whereas in neural machine translation, alignment or attention is learned with translation at the same time, coming as a side effect."
            ]
        },
        {
            "question": "How is the alignment or attention mechanism learned in neural machine translation systems compared to classical statistical machine translation approaches?",
            "reference-answers": [
                "In classical statistical machine translation approaches, the alignment or attention is a step before the system is trained, whereas in neural machine translation systems, the alignment or attention is learned with translation at the same time and comes as a side effect."
            ]
        },
        {
            "question": "How is the alignment in neural machine translation different from the alignment in classical statistical machine translation?",
            "reference-answers": [
                "In classical statistical machine translation, the alignment is a prerequisite, a step before the system is trained, whereas in neural machine translation, the alignment or attention are learned with translation at the same time, coming as a side effect."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen96-slide77/text.txt": [
        {
            "question": "What is the main difference between attentions and word alignments in the context of the encoder and decoder?",
            "reference-answers": [
                "The main difference between attentions and word alignments is that attentions are alignments between the state of the encoder and the state of the decoder, not between the words."
            ]
        },
        {
            "question": "What is the main difference between attentions in word alignment and attentions in alignments between the state of the encoder and the state of the decoder?",
            "reference-answers": [
                "The main difference is that attentions in word alignment are between the words, whereas attentions in alignments between the state of the encoder and state of the decoder are between the states of the encoder and decoder."
            ]
        },
        {
            "question": "What is a key difference between attentions in word alignment and attentions in alignments between the state of the encoder and the state of the decoder?",
            "reference-answers": [
                "The key difference is that attentions in word alignment are between the words, whereas attentions in alignments between the state of the encoder and state of the decoder are between the states of the encoder and decoder."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen97-slide78/text.txt": [
        {
            "question": "What is the result of using an attention mechanism in a neural network when pre-translation is used in conjunction with the original source sentence?",
            "reference-answers": [
                "The network immediately automatically learned to follow not one diagonal but two diagonals and it quickly learned this correspondence from the data, also when there was two diagonals and not just one."
            ]
        },
        {
            "question": "What is the outcome of the neural network when it is trained with a double input consisting of the original source sentence and the pre-translated candidate translation?",
            "reference-answers": [
                "The neural network immediately automatically learned to follow not one diagonal but two diagonals."
            ]
        },
        {
            "question": "What type of neural network was used to translate the input sentence to the target language in Jan Juhers' experiment?",
            "reference-answers": [
                "A neural network was used to translate the input sentence to the target language."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen98-slide79/text.txt": [
        {
            "question": "What is the difference in the way attention is utilized in the image captioning process when compared to a one-dimensional attention mechanism?",
            "reference-answers": [
                "In a one-dimensional attention mechanism, the attention is not considering parts of the picture, whereas in a two-dimensional attention mechanism, the network learns to attend to parts of the pictures, considering the area of the image where the subject is present."
            ]
        },
        {
            "question": "What is the difference between the attention over the image in the unit and the attention in the described image captioning system?",
            "reference-answers": [
                "The attention in the unit is one dimensional, while in the described image captioning system, the attention is two dimensional, allowing the network to attend to specific parts of the picture."
            ]
        },
        {
            "question": "What type of attention is the network learning to attend to in the image captioning process?",
            "reference-answers": [
                "Two dimensional."
            ]
        }
    ],
    "nmt-class/lecture03-nmt-seq2seq-attn/screen99-slide81/text.txt": [
        {
            "question": "What is the main reason for the perceived poor performance of the attention mechanism when compared to a vanilla system?",
            "reference-answers": [
                "The main reason for the perceived poor performance of the attention mechanism when compared to a vanilla system is that the comparison is based on scores from two papers, which may not accurately represent the true performance of the attention mechanism."
            ]
        },
        {
            "question": "Why did the author consider skipping a short contrast of two papers?",
            "reference-answers": [
                "The author considered skipping a short contrast of two papers to save time."
            ]
        },
        {
            "question": "What is the main reason for the perceived inferiority of the attention mechanism when compared to a vanilla system based on scores from two papers?",
            "reference-answers": [
                "The main reason for the perceived inferiority of the attention mechanism is for the sake of the time."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen01-slide01/text.txt": [
        {
            "question": "What is the relevance of alignment techniques in neural machine translation?",
            "reference-answers": [
                "Alignment techniques are still relevant in neural machine translation."
            ]
        },
        {
            "question": "What is the relevance of the alignment techniques discussed in this lecture for neural machine translation?",
            "reference-answers": [
                "The alignment techniques discussed in this lecture are still relevant for neural machine translation."
            ]
        },
        {
            "question": "What type of machine translation techniques are still relevant even for neural machine translation?",
            "reference-answers": [
                "Alignment of documents, sentences, and then words."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen02-slide02/text.txt": [
        {
            "question": "What is the main interest of the department that the speaker is discussing in the context of Czech English data?",
            "reference-answers": [
                "The main interest of the department is Czech English data, specifically the corpus of Cenk."
            ]
        },
        {
            "question": "What techniques will be described for word alignment after collecting documents, document alignment, and sentence alignment?",
            "reference-answers": [
                "word level alignment."
            ]
        },
        {
            "question": "What techniques will be described after discussing the effect of data on translation quality?",
            "reference-answers": [
                "We'll briefly describe all the techniques."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen03-slide03/text.txt": [
        {
            "question": "What is the purpose of word alignment in machine translation, and how is it related to the extraction of phrases and dictionary construction?",
            "reference-answers": [
                "The purpose of word alignment in machine translation is to know which words in one language correspond to which words in the other language, allowing for the extraction of phrases and dictionary construction."
            ]
        },
        {
            "question": "What is the purpose of the word alignment in phrase-based machine translation?",
            "reference-answers": [
                "The purpose of the word alignment in phrase-based machine translation is to construct a dictionary of phrases and their translations, which are consistent with the word alignment, indicating which words in one language correspond to which words in the other language."
            ]
        },
        {
            "question": "What is the purpose of word alignment in phrase-based machine translation?",
            "reference-answers": [
                "The purpose of word alignment in phrase-based machine translation is to construct a dictionary of phrases and their translations, where the phrases are consistent with the word alignment, which is a mapping of words in one language to words in the other language, including the possibility of one-to-one or multi-word alignments."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen04-slide04/text.txt": [
        {
            "question": "What is the first thing the speaker will do?",
            "reference-answers": [
                "So I'll first start."
            ]
        },
        {
            "question": "What is the first thing the speaker will start with?",
            "reference-answers": [
                "The data."
            ]
        },
        {
            "question": "What is the first thing the speaker will do with the data?",
            "reference-answers": [
                "I'll first start."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen05-slide05/text.txt": [
        {
            "question": "What type of data were primarily available from user-supplied sources in the Czech-English language pair?",
            "reference-answers": [
                "Translations or localizations of open source projects or desktop environments like KDE or GNOME."
            ]
        },
        {
            "question": "What type of texts were included in the CENG 0.7 corpus, in addition to legal texts from the European Union?",
            "reference-answers": [
                "Reader's Digest stories, books from the project Gutenberg, and Palmknihy (e-books) were included in the CENG 0.7 corpus, in addition to legal texts from the European Union."
            ]
        },
        {
            "question": "What type of texts were included in the early releases of the CENG 0.7 corpus, specifically CENG 0.7?",
            "reference-answers": [
                "Legal texts, including the European Union."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen06-slide06/text.txt": [
        {
            "question": "What percentage of the data consisted of community-supplied localization texts in terms of sentences?",
            "reference-answers": [
                "11%"
            ]
        },
        {
            "question": "What percentage of the data consisted of community-supplied localization texts?",
            "reference-answers": [
                "11%"
            ]
        },
        {
            "question": "What percentage of the data consisted of community-supplied localization texts in terms of words?",
            "reference-answers": [
                "Less than 2%"
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen07-slide07/text.txt": [
        {
            "question": "What percentage of the Navajo project's corrections were deemed \"reasonably good translations\"?",
            "reference-answers": [
                "About 5% of the corrections were deemed \"reasonably good translations\"."
            ]
        },
        {
            "question": "What percentage of the segments corrected by the Navajo project were precise and flawless translations?",
            "reference-answers": [
                "About 70% of the segments corrected by the Navajo project were precise and flawless translations."
            ]
        },
        {
            "question": "What percentage of the Navajo project's corrections were deemed precise and flawless translations?",
            "reference-answers": [
                "About 70% of the corrections were precise and flawless translations."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen08-slide08/text.txt": [
        {
            "question": "What is a notable characteristic of the quality of the community-supplied data, particularly when contributed by individuals who sign into the system?",
            "reference-answers": [
                "The quality of the community-supplied data is of perfect quality, especially when contributed by individuals who sign into the system."
            ]
        },
        {
            "question": "What is a notable characteristic of community-supplied data in KDE and GNOME localizations?",
            "reference-answers": [
                "The notable characteristic of community-supplied data in KDE and GNOME localizations is that it has almost professional quality, with no vandalism and contributors trying hard to have a good impression on the community."
            ]
        },
        {
            "question": "What type of data is considered of perfect quality if it's contributed by people who sign in into the system?",
            "reference-answers": [
                "Community supply data."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen09-slide26/text.txt": [
        {
            "question": "What is the main concern regarding the use of data for machine translation systems, according to the authors of the text?",
            "reference-answers": [
                "The main concern regarding the use of data for machine translation systems is the lack of clear licensing conditions, which creates legal uncertainty and restricts the availability of the data for good purposes."
            ]
        },
        {
            "question": "What is the main concern regarding the availability of data for machine translation systems, according to the authors of the text?",
            "reference-answers": [
                "The main concern regarding the availability of data for machine translation systems is the lack of clear licensing conditions, which creates legal uncertainty and restricts the use of the data for good purposes."
            ]
        },
        {
            "question": "What is the main concern regarding the licensing of available texts for reuse in machine translation systems?",
            "reference-answers": [
                "The main concern regarding the licensing of available texts for reuse in machine translation systems is the legal uncertainty due to unclear licensing conditions, which can prevent the data from being used for good purposes."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen10-slide10/text.txt": [
        {
            "question": "What is the legal status of community-supplied data in the context of translation quality, and how does it impact its use?",
            "reference-answers": [
                "The community-supplied data has an unclear status as it is community-supplied but not labeled, and it is based on proprietary text."
            ]
        },
        {
            "question": "What is the legal status of community-supplied subtitles in the Czech Republic for research and non-commercial purposes?",
            "reference-answers": [
                "In the Czech Republic, community-supplied subtitles are in a good legal position for research and non-commercial purposes."
            ]
        },
        {
            "question": "What is the legal status of community-supplied subtitles used for research and non-commercial purposes in the Czech Republic?",
            "reference-answers": [
                "In the Czech Republic, community-supplied subtitles are good to go for research and non-commercial purposes."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen11-slide11/text.txt": [
        {
            "question": "What type of test sets are being used to evaluate the translation quality of the system, and what do they represent in terms of the training data?",
            "reference-answers": [
                "The system is using two test sets: an in-domain test set (news-like sentences) and an out-of-domain test set (other texts that do not match the training data very well). The in-domain test set represents professional translation that matches the test set, while the out-of-domain test set represents translations that are not related to the domain."
            ]
        },
        {
            "question": "What type of test sets are being used to evaluate the translation quality of the system, and how are they distinguished from one another?",
            "reference-answers": [
                "The system is using two test sets: an in-domain test set (news-like sentences) and an out-of-domain test set (other texts that do not match the training data very well). The in-domain test set is distinguished from the out-of-domain test set by its content, with the in-domain test set being professional translations that match the test set, and the out-of-domain test set being proprietary data and community-supplied, correctly labeled contributions."
            ]
        },
        {
            "question": "What type of evaluation is being performed on the translation quality, as indicated by the use of test sets and the plotting of a pie chart?",
            "reference-answers": [
                "This type of evaluation is being performed on the translation quality, as indicated by the use of test sets and the plotting of a pie chart."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen12-slide12/text.txt": [
        {
            "question": "What would be the expected BLEU score if the only translations used were the correctly labeled Community Supply Translations?",
            "reference-answers": [
                "The BLEU score will be terribly low."
            ]
        },
        {
            "question": "If you rely only on the correctly labeled Community Supply Translations, what can be expected to happen to the BLEU score?",
            "reference-answers": [
                "The BLEU score will be terribly low."
            ]
        },
        {
            "question": "What would be the BLEU score if you rely only on the correctly labeled Community Supply Translations?",
            "reference-answers": [
                "The BLEU score will be terribly low."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen13-slide13/text.txt": [
        {
            "question": "What is the result of the efforts to improve the translation quality in the subtitles?",
            "reference-answers": [
                "The translation quality is not getting much better."
            ]
        },
        {
            "question": "What progress has been made in reducing the out-of-vocabulary rate in the subtitles?",
            "reference-answers": [
                "We have significantly reduced the out of vocabulary rate."
            ]
        },
        {
            "question": "What improvement has been made in the translation quality of the subtitles?",
            "reference-answers": [
                "We have significantly reduced the out of vocabulary rate."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen14-slide14/text.txt": [
        {
            "question": "What is the effect of including proprietary translations out of the domain on the translation quality?",
            "reference-answers": [
                "The translation quality is a little bit better when including proprietary translations out of the domain, as the sequences of words are more common, sentences are a little bit well formed, and vocabulary rate is reduced."
            ]
        },
        {
            "question": "What is the effect of including proprietary translations on the translation quality?",
            "reference-answers": [
                "The translation quality is a little bit better when including proprietary translations, mainly due to more common word sequences, slightly better formed sentences, and a reduced vocabulary rate."
            ]
        },
        {
            "question": "What is the effect of including proprietary translations on the quality of the sentences in a translation?",
            "reference-answers": [
                "The sentences are a little bit well formed, a tiny little bit."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen15-slide15/text.txt": [
        {
            "question": "What is the lowest autofocal rate mentioned in the text?",
            "reference-answers": [
                "The lowest autofocal rate so far."
            ]
        },
        {
            "question": "What is the Blof level when using all datasets except for in-domain training data?",
            "reference-answers": [
                "BLOF 9."
            ]
        },
        {
            "question": "What is the Blof level if all datasets are used except for the in-domain training data?",
            "reference-answers": [
                "BLOF 9."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen16-slide16/text.txt": [
        {
            "question": "What is the ideal situation for translation quality?",
            "reference-answers": [
                "Having your training data in the domain of the test set of interest."
            ]
        },
        {
            "question": "What is the ideal situation for improving translation quality?",
            "reference-answers": [
                "Having your training data in the domain of the test set of interest."
            ]
        },
        {
            "question": "What is the ideal situation for achieving good translation quality?",
            "reference-answers": [
                "Having your training data in the domain of the test set of interest."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen17-slide17/text.txt": [
        {
            "question": "Can extending a collection with professional translations damage the quality of the sentences in the collection?",
            "reference-answers": [
                "No, extending a collection with professional translations does not damage the sentence quality much."
            ]
        },
        {
            "question": "Will extending your collection with professional translations damage the quality of your sentences?",
            "reference-answers": [
                "No, extending your collection with professional translations is not damaging the sentence quality much."
            ]
        },
        {
            "question": "Can extending a collection with professional translations damage sentence quality?",
            "reference-answers": [
                "No, extending a collection with professional translations does not damage the sentence quality much."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen18-slide18/text.txt": [
        {
            "question": "What is a potential drawback of using auto-vocabulary in machine translation when including imperfect translations and auto-domain data?",
            "reference-answers": [
                "Reducing the translation quality a little."
            ]
        },
        {
            "question": "What is a potential drawback of including auto-domain data and community-supplied, imperfect translations in a vocabulary list?",
            "reference-answers": [
                "Reducing the translation quality a little."
            ]
        },
        {
            "question": "What happens to the translation quality when you include auto-domain data and community-supplied, not perfect translations in the translation process?",
            "reference-answers": [
                "The translation quality can reduce a little when you include auto-domain data and community-supplied, not perfect translations in the translation process."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen19-slide19/text.txt": [
        {
            "question": "What is the general outcome of using in-domain training data for out-of-domain translation?",
            "reference-answers": [
                "The in-domain training data is of little use for the out of domain or can be of little use for the out of domain."
            ]
        },
        {
            "question": "What is the likely outcome when using in-domain training data to translate out-of-domain text?",
            "reference-answers": [
                "The translation quality is bad, and the vocabulary does not quite match."
            ]
        },
        {
            "question": "What happens to the quality of a machine translation when the in-domain training data is used for out-of-domain translation?",
            "reference-answers": [
                "The translation quality is bad, and even vocabulary-wise it does not quite match."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen20-slide20/text.txt": [
        {
            "question": "What is the general trend in BLEU scores between professional translations and community translations in the given dataset?",
            "reference-answers": [
                "The general trend in BLEU scores is that the professional translations have higher scores than the community translations, with the professional translations showing a higher score even when using all available professional translations."
            ]
        },
        {
            "question": "What is the general trend in BLEU scores between professional translations and community translations for this out-of-domain dataset?",
            "reference-answers": [
                "The general trend in BLEU scores is that the professional translations have higher scores than the community translations, with the community translations being less fluent and more out of domain."
            ]
        },
        {
            "question": "What is the general trend in BLEU scores between professional translations and community translations in the provided dataset?",
            "reference-answers": [
                "The general trend in BLEU scores is that the professional translations have higher scores than the community translations, with the professional translations showing a higher score even when using all available professional translations."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen21-slide21/text.txt": [
        {
            "question": "What is the general recommendation for using data in machine translation when the user is familiar with the domain?",
            "reference-answers": [
                "When familiar with the domain, it is good to use primarily the in-domain data and carefully check if adding more will help or not."
            ]
        },
        {
            "question": "What is the recommended approach for using data when you know your domain?",
            "reference-answers": [
                "It is good to use primarily the in-domain data and carefully check if adding more will help or not."
            ]
        },
        {
            "question": "What is the message about data usage when you know your domain?",
            "reference-answers": [
                "It is good to use primarily the in-domain data when you know your domain."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen22-slide22/text.txt": [
        {
            "question": "What is the total number of words in Cheng 2.0 combined with English, according to the provided information?",
            "reference-answers": [
                "5 giga words."
            ]
        },
        {
            "question": "What is the total number of words in the Cheng 2.0 corpus combined with Czech and English?",
            "reference-answers": [
                "5 giga words."
            ]
        },
        {
            "question": "What is the approximate total number of words in Cheng 2.0 combined with Czech and English?",
            "reference-answers": [
                "5 giga words."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen23-slide23/text.txt": [
        {
            "question": "What methods are needed to align a corpus to be sentence and word level aligned?",
            "reference-answers": [
                "That's the history of Cheng. And now let's briefly review all the methods that are needed if you want to end up with a corpus that is automatically sentence and word level aligned."
            ]
        },
        {
            "question": "What methods are needed to end up with a corpus that is automatically sentence and word level aligned?",
            "reference-answers": [
                "That's the history of Cheng. And now let's briefly review all the methods that are needed if you want to end up with a corpus that is automatically sentence and word level aligned."
            ]
        },
        {
            "question": "What methods are needed to end up with a corpus that is automatically sentence and word level aligned?",
            "reference-answers": [
                "That's the history of Cheng. And now let's briefly review all the methods that are needed if you want to end up with a corpus that is automatically sentence and word level aligned."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen24-slide24/text.txt": [
        {
            "question": "What is the main challenge in obtaining seed URLs for parallel text mining, and how have researchers addressed this issue?",
            "reference-answers": [
                "The main challenge in obtaining seed URLs for parallel text mining is getting the seed URLs, and researchers have addressed this issue by moving away from using search engines, which stop returning results after 600 responses, and instead utilizing common crawl or other resources, such as scanning the whole web, to find the text better."
            ]
        },
        {
            "question": "What is the main problem in obtaining seed URLs for parallel text mining, according to the author?",
            "reference-answers": [
                "Getting the seed URLs is the problem, as search engines stop returning any results after 600 responses."
            ]
        },
        {
            "question": "What is the main challenge in obtaining seed URLs for parallel texts, according to the experiments conducted in the mentioned research?",
            "reference-answers": [
                "Getting the seed URLs is the problem, as search engines stop returning any results after 600 responses or so."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen25-slide25/text.txt": [
        {
            "question": "What is the main limitation of using the Common Crawl data for extracting parallel sentences, and how can this limitation be addressed?",
            "reference-answers": [
                "The main limitation of using the Common Crawl data for extracting parallel sentences is that it only samples from the web and does not contain the full version of the full site copy of each web, which makes it unlikely to have both the source and target versions of the text. This limitation can be addressed by first using the Common Crawl data to identify the URLs and then re-crawling these web domains to obtain larger data sets."
            ]
        },
        {
            "question": "What is the main challenge in finding pairs among the two heaps of texts in the two languages for document alignment?",
            "reference-answers": [
                "The main challenge in finding pairs among the two heaps of texts in the two languages for document alignment is finding the source URLs, which can be verified by nets."
            ]
        },
        {
            "question": "What type of data can be extracted from Common Crawl, which amounts to 150 terabytes of text in total?",
            "reference-answers": [
                "Only random pages and not the full version of the full site copy of each web."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen26-slide26/text.txt": [
        {
            "question": "What is the next step after finding pairs of texts, if we do not know anything about the languages?",
            "reference-answers": [
                "Aligning sentences."
            ]
        },
        {
            "question": "What is the next step after finding pairs of texts, if we do not know anything about the languages involved?",
            "reference-answers": [
                "Aligning sentences."
            ]
        },
        {
            "question": "What is the next step after finding pairs of texts and aligning sentences?",
            "reference-answers": [
                "After finding pairs of texts and aligning sentences."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen27-slide27/text.txt": [
        {
            "question": "What is the counterpart of the full stop in the Devanagari script?",
            "reference-answers": [
                "The danda, which is a vertical pipe, vertical bar, serves as the counterpart of the full stop in the Devanagari script."
            ]
        },
        {
            "question": "What is the counterpart of the full stop in the Devanagari script?",
            "reference-answers": [
                "The danda, which is a vertical pipe, vertical bar, serves as the counterpart of the full stop in the Devanagari script."
            ]
        },
        {
            "question": "What is the Devanagari script symbol called that repeats and is the counterpart of the full stop in English sentences?",
            "reference-answers": [
                "The danda."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen28-slide28/text.txt": [
        {
            "question": "What is the critical parallel part in sentence alignment processing, according to the given observation?",
            "reference-answers": [
                "Sentence length."
            ]
        },
        {
            "question": "What is the key factor in sentence alignment processing that allows for accurate translation, according to the provided observation?",
            "reference-answers": [
                "Sentence length is the critical parallel part that allows for accurate translation."
            ]
        },
        {
            "question": "What is the key factor in sentence alignment processing that allows for the identification of comparable information between two languages?",
            "reference-answers": [
                "The key factor in sentence alignment processing that allows for the identification of comparable information between two languages is sentence length."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen29-slide29/text.txt": [
        {
            "question": "What is the standard tool for sentence alignment that is still widely used today, according to the text?",
            "reference-answers": [
                "HoneyLine."
            ]
        },
        {
            "question": "What is the standard tool for sentence alignment, according to the information provided in the text?",
            "reference-answers": [
                "HoneyLine."
            ]
        },
        {
            "question": "What is the standard tool for sentence alignment that is widely used today, according to the text?",
            "reference-answers": [
                "HoneyLine."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen30-slide30/text.txt": [
        {
            "question": "What is the primary limitation of the word alignment approach in the IBM 1 model, and how does it impact the alignment process?",
            "reference-answers": [
                "The primary limitation of the word alignment approach in the IBM 1 model is that it only creates many to one links, and it relies on lexical probabilities of individual words."
            ]
        },
        {
            "question": "What is the primary difference between the word alignment approaches of Giza++ and Fast Align?",
            "reference-answers": [
                "The primary difference between the word alignment approaches of Giza++ and Fast Align is that Giza++ is a 20-year-old software that can be compiled but is complicated to do so, whereas Fast Align uses a reduced set of alignment modules and can be \"pretty bad especially if the training data is small\"."
            ]
        },
        {
            "question": "What is the main difference between the state-of-the-art Giza++ tool and the fast align software in terms of alignment modules and quality?",
            "reference-answers": [
                "The main difference between the state-of-the-art Giza++ tool and the fast align software is that Giza++ uses a reduced set of alignment modules, but is considered more complicated to compile, whereas fast align uses a reduced set of alignment modules, but is considered to be \"pretty bad especially if the training data is small\", indicating that it may have lower quality."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen31-slide31/text.txt": [
        {
            "question": "What is a limitation of the IBM Model 1 in terms of translation?",
            "reference-answers": [
                "The IBM Model 1 does not consider the position of the words in the sentence at all, making it unsuitable for translation."
            ]
        },
        {
            "question": "What is a limitation of the IBM Model 1 in terms of translation?",
            "reference-answers": [
                "The IBM Model 1 does not consider the position of the words in the sentence at all, making it unsuitable for translation."
            ]
        },
        {
            "question": "What is a limitation of the IBM Model 1 in terms of its ability to perform translation?",
            "reference-answers": [
                "The IBM Model 1 does not consider the position of the words in the sentence at all, making it unsuitable for translation."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen32-slide31/text.txt": [
        {
            "question": "Who is the author of the slides mentioned in the text?",
            "reference-answers": [
                "Philip Cain."
            ]
        },
        {
            "question": "Who is the author of the slides referred to in the text?",
            "reference-answers": [
                "Philip Cain."
            ]
        },
        {
            "question": "What is the title of the document being referred to as \"the slides\" by Philip Cain?",
            "reference-answers": [
                "Let's move to the slides by Philip Cain."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen33-slide32/text.txt": [
        {
            "question": "What is the purpose of using back translation with the help of a dictionary to determine the most probable translation of a word?",
            "reference-answers": [
                "Because some translations are more probable in the given type of text and some are very unprobable, so using back translation with the help of a dictionary would make it easier to decide by simply picking the highest scoring, the most probable translation of a word."
            ]
        },
        {
            "question": "What is the purpose of obtaining lexical translation probabilities?",
            "reference-answers": [
                "To decide which of the translations is good, by picking the highest scoring, the most probable translation of a word."
            ]
        },
        {
            "question": "What is the purpose of obtaining lexical translation probabilities?",
            "reference-answers": [
                "To decide which of the translations is good, by picking the highest scoring, the most probable translation of a word."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen34-slide32/text.txt": [
        {
            "question": "What is the most common translation of the German word \"house\" in English?",
            "reference-answers": [
                "The most common translation of the German word \"house\" in English is \"house\"."
            ]
        },
        {
            "question": "What is the most common translation of the German word \"house\" in the English language?",
            "reference-answers": [
                "The most common translation of the German word \"house\" in the English language is \"house\"."
            ]
        },
        {
            "question": "What is the most common translation of the German word 'haus' in English?",
            "reference-answers": [
                "The most common translation of the German word 'haus' in English is 'house'."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen35-slide33/text.txt": [
        {
            "question": "What is the term used to describe the probability of an English word given a German word?",
            "reference-answers": [
                "The lexical probability of the English word given the German word."
            ]
        },
        {
            "question": "What is the purpose of collecting the lexical probability of the English word given the German word?",
            "reference-answers": [
                "We have defined the probability, the lexical probability of the English word given the German word. So this is what we want to collect for all the possible..."
            ]
        },
        {
            "question": "What is the definition of the term \"lexical probability\" in the given text?",
            "reference-answers": [
                "The probability of the English word given the German word."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen36-slide34/text.txt": [
        {
            "question": "What is the purpose of indicating which words translate to which in the given sentence pair?",
            "reference-answers": [
                "To align the words and identify translations between the two sentences."
            ]
        },
        {
            "question": "What is the purpose of aligning words in a corpus?",
            "reference-answers": [
                "To indicate which words translate to which in a sentence pair."
            ]
        },
        {
            "question": "What is the alignment of words in a corpus, according to the given explanation?",
            "reference-answers": [
                "The alignment of words in a corpus refers to the lines or connections between words and sentences, and specifically, it involves indicating which words translate to which in a sentence pair."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen37-slide35/text.txt": [
        {
            "question": "What is the nature of the alignment described in the definition?",
            "reference-answers": [
                "It maps between the English target word at some position into the source word at some other position."
            ]
        },
        {
            "question": "What is the alignment captured as in the given definition?",
            "reference-answers": [
                "It maps between the English target word at some position into the source word at some other position."
            ]
        },
        {
            "question": "What type of mapping does the alignment function perform between English target words and source words?",
            "reference-answers": [
                "It maps between the English target word at some position into the source word at some other position."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen38-slide36/text.txt": [
        {
            "question": "What is the pattern of mapping between positions in the given text?",
            "reference-answers": [
                "One-to-one mapping."
            ]
        },
        {
            "question": "What is the mapping pattern for positions in the given text?",
            "reference-answers": [
                "1 to 1, 2 to 2, and so on."
            ]
        },
        {
            "question": "What is the mapping relationship between position 1 and position 2?",
            "reference-answers": [
                "Position 1 is mapped to position 1, and position 2 is mapped to position 2."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen39-slide37/text.txt": [
        {
            "question": "What is the effect of the alignment function on the order of the words in a sentence?",
            "reference-answers": [
                "The alignment function allows us to reorder the words in any way, so any reordering is okay."
            ]
        },
        {
            "question": "What is the alignment function's effect on the order of the words in the given sentences?",
            "reference-answers": [
                "The alignment function allows us to reorder the words in any way, so any reordering is okay."
            ]
        },
        {
            "question": "What is the effect of the alignment function on the given sentences?",
            "reference-answers": [
                "The alignment function allows any reordering of the words to be okay."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen40-slide38/text.txt": [
        {
            "question": "What is a requirement for a function to be able to capture one-to-many translations in the context of language translation?",
            "reference-answers": [
                "The function doesn't have to be a bijection."
            ]
        },
        {
            "question": "Does the function producing translations have to be a bijection?",
            "reference-answers": [
                "No, the function producing translations does not have to be a bijection."
            ]
        },
        {
            "question": "What type of function can translate words from the source language to the target language if multiple words in the target language can map to the same position in the source language?",
            "reference-answers": [
                "One-to-many translation."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen41-slide39/text.txt": [
        {
            "question": "What happens to a source word if none of the target language words map to it?",
            "reference-answers": [
                "The source word will be dropped."
            ]
        },
        {
            "question": "What happens to a source word if none of the target language words maps to it?",
            "reference-answers": [
                "The source word will be dropped."
            ]
        },
        {
            "question": "What happens to a source word that has no corresponding mapping in the target language?",
            "reference-answers": [
                "The source word will be dropped."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen42-slide40/text.txt": [
        {
            "question": "What is an auxiliary symbol in the context of mapping words between two languages?",
            "reference-answers": [
                "One more auxiliary symbol to the source sentence."
            ]
        },
        {
            "question": "What is an auxiliary symbol used for in the context of mapping words between two languages?",
            "reference-answers": [
                "We can map the word just to this position of zero, indicating that it has no counterpart in the other language."
            ]
        },
        {
            "question": "What happens to words in the source language that are not mapped to a counterpart in the target language?",
            "reference-answers": [
                "They can be explicitly dropped in the target language."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen43-slide41/text.txt": [
        {
            "question": "What is the role of the alignment function in the IBM Model 1?",
            "reference-answers": [
                "The alignment function is used to define the alignment between the source and target words, and its position is only used to see which words are at which positions."
            ]
        },
        {
            "question": "What is the definition of the probability of the English aligned to the given source French sentence in the IBM Model 1?",
            "reference-answers": [
                "The probability of the English aligned to the given source French sentence in the IBM Model 1 is the product of the lexical probabilities in the alignment."
            ]
        },
        {
            "question": "What is the definition of the probability of the English aligned to the given source French sentence in the IBM Model 1?",
            "reference-answers": [
                "The probability of the English aligned to the given source French sentence in the IBM Model 1 is the product of the lexical probabilities in the alignment."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen44-slide26/text.txt": [
        {
            "question": "What is the formula used by the IBM model one to calculate the probability of the whole sentence given the alignments, words, and source sentence?",
            "reference-answers": [
                "The probability of the whole sentence is this normalization times the product of the lexical probabilities of the words."
            ]
        },
        {
            "question": "What is the formula used by IBM Model One to calculate the probability of the whole sentence given the alignments and lexical probabilities for each word?",
            "reference-answers": [
                "The probability of the whole sentence is this normalization times the product of the lexical probabilities of the words."
            ]
        },
        {
            "question": "What is the formula used by IBM model one to calculate the probability of the whole sentence given the alignments, words, and source sentence?",
            "reference-answers": [
                "The probability of the whole sentence is this normalization times the product of the lexical probabilities of the words."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen45-slide43/text.txt": [
        {
            "question": "How can we break the loop between estimating lexical probabilities from a parallel corpus and estimating alignments between the corpora?",
            "reference-answers": [
                "We can estimate the parameters in the generative model if we had the alignments, and if we had the parameters in the generative model, we can estimate the alignments. So the question is how to tear this loop apart."
            ]
        },
        {
            "question": "How do we obtain lexical probabilities from a parallel corpus?",
            "reference-answers": [
                "We would like to estimate these lexical probabilities from a parallel corpus."
            ]
        },
        {
            "question": "How do we obtain lexical probabilities from a parallel corpus?",
            "reference-answers": [
                "We would like to estimate these lexical probabilities from a parallel corpus."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen46-slide44/text.txt": [
        {
            "question": "What is the purpose of the EM algorithm in the context of estimating a model from incomplete data?",
            "reference-answers": [
                "The EM algorithm is exactly designed to fill in the gaps in the data when we have the model, allowing us to estimate the model parameters."
            ]
        },
        {
            "question": "What is the purpose of the EM algorithm in relation to having complete data and the model?",
            "reference-answers": [
                "The EM algorithm is exactly designed to fill in the gaps in the data when we have the model, allowing us to estimate the model parameters."
            ]
        },
        {
            "question": "What is the purpose of the EM algorithm in the context of incomplete data?",
            "reference-answers": [
                "The EM algorithm is exactly designed to fill in the gaps in the data when we have the model, allowing us to estimate the model parameters."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen47-slide45/text.txt": [
        {
            "question": "What can be linked with \"la\" equally likely as with \"maison\" at the beginning?",
            "reference-answers": [
                "house"
            ]
        },
        {
            "question": "What is the initial relationship between the words \"la\", \"maison\", \"house\", and \"fleur\" in the model's lexical probabilities?",
            "reference-answers": [
                "They are initialized uniformly, meaning they can be linked with each other equally likely."
            ]
        },
        {
            "question": "What happens to the lexical probabilities at the beginning of the process described in the text?",
            "reference-answers": [
                "They are initialized uniformly."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen48-slide46/text.txt": [
        {
            "question": "What happens to the alignment link between 'the' and 'la' after subsequent iterations of the model?",
            "reference-answers": [
                "The alignment link between 'the' and 'la' will get stronger after subsequent iterations of the model, as 'the' co-occurs more often with 'la' than with'meson'."
            ]
        },
        {
            "question": "What happens to the alignment link between \"the\" and \"la\" after multiple iterations of the model?",
            "reference-answers": [
                "The alignment link between \"the\" and \"la\" will get stronger."
            ]
        },
        {
            "question": "What happens to the alignment link between the and \"la\" after multiple iterations of the model?",
            "reference-answers": [
                "The alignment link between the and \"la\" will get stronger after multiple iterations of the model, as the model realizes that \"la\" co-occurs more often with \"the\" than with \"meson\"."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen49-slide28/text.txt": [
        {
            "question": "What is the guarantee provided by the full coverage of the words in the given context?",
            "reference-answers": [
                "It's guaranteed that the word \"flower\" will eventually get aligned to \"flare\"."
            ]
        },
        {
            "question": "What is the guarantee that the word \"flower\" will eventually get aligned to \"flare\"?",
            "reference-answers": [
                "The guarantee that the word \"flower\" will eventually get aligned to \"flare\" is the full coverage of the words, as stated by the pigeonhole principle."
            ]
        },
        {
            "question": "What is the outcome for words that are not covered in other sentences according to the alignment principle described in the text?",
            "reference-answers": [
                "They will get aligned to each other simply because the probability mass has to be distributed somewhere the la is already being occupied by the so the flower is likely to choose the flare."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen50-slide26/text.txt": [
        {
            "question": "What can be determined about the alignment of words when the algorithm converges and has a global optimum?",
            "reference-answers": [
                "When the algorithm converges and has a global optimum, we will know which words align to which words."
            ]
        },
        {
            "question": "What type of convergence is being referred to in the context of aligning words?",
            "reference-answers": [
                "Global optimum convergence."
            ]
        },
        {
            "question": "What type of convergence can be expected at the end of the process described in the text?",
            "reference-answers": [
                "Global optimum and it also converges quickly."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen51-slide26/text.txt": [
        {
            "question": "What is the method used to estimate conditional probability in the given context?",
            "reference-answers": [
                "Maximum likelihood estimate."
            ]
        },
        {
            "question": "What is the method used to estimate the conditional probability in the given scenario?",
            "reference-answers": [
                "Maximum likelihood estimate."
            ]
        },
        {
            "question": "What method is used to estimate the conditional probability of the LAW at the other end of the alignment?",
            "reference-answers": [
                "Maximum likelihood estimate."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen52-slide26/text.txt": [
        {
            "question": "What is the purpose of the \"modal\" in the expectation step of the expectation maximization algorithm?",
            "reference-answers": [
                "The modal is used to apply to the data in the expectation step, and it's the dictionary of word translations that defines the probability of the source sentence target sentence given the alignment."
            ]
        },
        {
            "question": "What is the purpose of the modal in the expectation step of the expectation maximization algorithm?",
            "reference-answers": [
                "The modal is used to apply to the data in the expectation step, and it's the dictionary of word translations that defines the probability of the source sentence target sentence given the alignment."
            ]
        },
        {
            "question": "What is the purpose of the modal in the expectation step of the expectation maximization algorithm?",
            "reference-answers": [
                "The modal is used to apply to the data in the expectation step, and it's the dictionary of word translations that defines the probability of the source sentence target sentence given the alignment."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen53-slide26/text.txt": [
        {
            "question": "What is the next step after mentioning \"So now the formulas\"?",
            "reference-answers": [
                "Let's see how detailed can we cover."
            ]
        },
        {
            "question": "What is the next step in the exam preparation process, according to the given text?",
            "reference-answers": [
                "Let's see how detailed can we cover."
            ]
        },
        {
            "question": "What is the next step after mentioning formulas in the text?",
            "reference-answers": [
                "Let's see how detailed can we cover."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen54-slide26/text.txt": [
        {
            "question": "What is the probability of the alignment given the source and target sentences in the IBM model one, after considering all possible alignments and normalizing them to sum to one?",
            "reference-answers": [
                "The probability of the alignment given the source and target sentences in the IBM model one, after considering all possible alignments and normalizing them to sum to one, is 0.82 for the alignment where the and la are aligned together, and the house and mezon are aligned together, and 0.052 for the alignment where the la is unaligned."
            ]
        },
        {
            "question": "What is the purpose of the normalization constant in the IBM model one, and how is it handled in the process of calculating the probability of the target sentence and alignment given the source sentence?",
            "reference-answers": [
                "The normalization constant is ignored in the calculation of the probability of the target sentence and alignment given the source sentence, as it is not necessary for the calculation of the conditional probability."
            ]
        },
        {
            "question": "What is the IBM model one, and how does it estimate the probability of a target sentence and alignment given a source sentence?",
            "reference-answers": [
                "The IBM model one is the probability of the conditional probability of the target sentence and the alignment given the source sentence. It is defined as the product of the word level probabilities and the lexical probabilities, and is calculated by multiplying the probabilities of each possible alignment. The model then normalizes these probabilities to obtain the probability of the alignment given the source and target sentences."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen55-slide26/text.txt": [
        {
            "question": "What is the numerator in the probability fraction that represents the likelihood of the alignment given the source and target sentences, according to the IBM model one alignment?",
            "reference-answers": [
                "The numerator is the alignment, which is the definition of the IBM model one of the target sentence and the alignment given the source."
            ]
        },
        {
            "question": "What is the numerator of the probability fraction used to estimate the fractional counts in the IBM model one alignment?",
            "reference-answers": [
                "The numerator is the alignment defined by the source sentence and the alignment given the target sentence."
            ]
        },
        {
            "question": "What is the numerator in the probability fraction that represents the likelihood of the alignment given the source and target sentences?",
            "reference-answers": [
                "The numerator is the alignment, which is the definition of the IBM model one of the target sentence and the alignment given the source."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen56-slide26/text.txt": [
        {
            "question": "What is the purpose of summing over all possible alignments in the given probability calculation?",
            "reference-answers": [
                "To sum over all possible alignments means to sum over all the possible dot filled matrices of which words corresponded to which, indicating which target word is connected to which source word."
            ]
        },
        {
            "question": "What is the purpose of the matrix of alignment points in the IBM Model 1, according to the provided explanation?",
            "reference-answers": [
                "The matrix of alignment points is used to indicate which target word is connected to which source word for each possible alignment."
            ]
        },
        {
            "question": "What does the IBM Model 1 say to normalize the lexical probabilities of the words?",
            "reference-answers": [
                "normalize it in some way."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen57-slide26/text.txt": [
        {
            "question": "What is the content of the given text?",
            "reference-answers": [
                "There is no text provided."
            ]
        },
        {
            "question": "What is the content of the text \"Yeah, so this on\"?",
            "reference-answers": [
                "There is no content provided in the given text."
            ]
        },
        {
            "question": "What is the first word of the given TEXT?",
            "reference-answers": [
                "Yeah"
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen58-slide26/text.txt": [
        {
            "question": "What is the title of the slide?",
            "reference-answers": [
                "This slide, so what..."
            ]
        },
        {
            "question": "What is the title of the slide?",
            "reference-answers": [
                "This slide, so what..."
            ]
        },
        {
            "question": "What is the subject of the sentence \"This slide\"?",
            "reference-answers": [
                "Slide"
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen59-slide26/text.txt": [
        {
            "question": "What is the name of the statistical model that relies on lexical translation probabilities and the full probability of the target given the source across all alignments?",
            "reference-answers": [
                "IBM model 1."
            ]
        },
        {
            "question": "What is the name of the probability model used by the IBM that relies on lexical translation probabilities and the full probability of the target given the source across all alignments?",
            "reference-answers": [
                "IBM model 1."
            ]
        },
        {
            "question": "What type of model is referred to as the \"IBM model 1\" based on the information provided?",
            "reference-answers": [
                "The IBM model 1, which relies on the lexical translation probabilities and also the full probability of the target given the source across all the alignments."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen60-slide26/text.txt": [
        {
            "question": "What is a problem with having a sum in the denominator of a mathematical expression?",
            "reference-answers": [
                "Having a sum in the denominator is difficult to work with."
            ]
        },
        {
            "question": "What is a problem with having a sum in the denominator of a mathematical expression?",
            "reference-answers": [
                "Having a sum in the denominator is difficult to work with."
            ]
        },
        {
            "question": "What type of mathematical expression is difficult to work with when it has a sum in the denominator?",
            "reference-answers": [
                "Having a sum in the denominator."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen61-slide26/text.txt": [
        {
            "question": "What is the formula mentioned in the text that allows for the swap of sum and product in calculations?",
            "reference-answers": [
                "Factoring out elements that appear in more than one place in the calculation."
            ]
        },
        {
            "question": "What is the purpose of the algebraic manipulation described in the text?",
            "reference-answers": [
                "The purpose of the algebraic manipulation described is to realize that the probability of the target sentence given the source can be estimated by multiplying over all the target positions the summation over all the source words that the target can be mapped to considering their lexical probabilities."
            ]
        },
        {
            "question": "What is the formula mentioned in the text as a way to estimate the probability of the target sentence given the source?",
            "reference-answers": [
                "The probability of the target sentence given the source can be estimated by multiplying over all the target positions the summation over all the source words that the target can be mapped to considering their lexical probabilities."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen62-slide26/text.txt": [
        {
            "question": "What is the trick mentioned in the given text?",
            "reference-answers": [
                "The trick is to go over the formula to realize how the sum and the product were swapped."
            ]
        },
        {
            "question": "What is the purpose of reviewing the formula mentioned in the text?",
            "reference-answers": [
                "To realize how the sum and the product were swapped."
            ]
        },
        {
            "question": "What is the trick mentioned in the text that involves swapping the sum and the product?",
            "reference-answers": [
                "Going over the formula is the trick."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen64-slide26/text.txt": [
        {
            "question": "What is the nature of the \"full graph\" mentioned in the text?",
            "reference-answers": [
                "The full graph is the sum of all pairs in one of the calculations, which includes all the elements, where each pair is a multiplication of the things that can be regrouped into a product of summations."
            ]
        },
        {
            "question": "What is the purpose of considering the sum of all pairs in a full graph?",
            "reference-answers": [
                "In one of the calculations you are considering the sum of all pairs, so all the full graph."
            ]
        },
        {
            "question": "What type of calculation is being considered that involves the sum of all pairs in a full graph?",
            "reference-answers": [
                "The calculation being considered is a sum of all pairs in a full graph, which can be regrouped into a product of summations."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen66-slide26/text.txt": [
        {
            "question": "What is the significance of the normalization in the computation of the IBM model 1 alignment between the source and target sentences?",
            "reference-answers": [
                "The normalization cancels out, making the computation tractable."
            ]
        },
        {
            "question": "What is the purpose of the probability of the alignment of the matrix of zeros and ones in the context of lexical translation probabilities?",
            "reference-answers": [
                "The probability of the alignment of the matrix of zeros and ones is used to collect an updated fractional counts, which in turn refines the lexical translation probabilities."
            ]
        },
        {
            "question": "What is the key factor that makes the computation of alignment probabilities in the IBM model 1 alignment tractable?",
            "reference-answers": [
                "The normalizations cancel out, which allows the product to be done after the division, making the computation tractable."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen67-slide26/text.txt": [
        {
            "question": "What is the purpose of using the estimated alignment between words in the source and target sentences to create fractional counts?",
            "reference-answers": [
                "We use this knowledge to create the fractional counts."
            ]
        },
        {
            "question": "What is the purpose of using the alignment between words in the source and target sentences in the fractional counts creation process?",
            "reference-answers": [
                "We use the alignment between words in the source and target sentences to create the fractional counts."
            ]
        },
        {
            "question": "What is the purpose of using the alignment information between source and target sentences to create fractional counts?",
            "reference-answers": [
                "We use this knowledge to create the fractional counts."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen68-slide26/text.txt": [
        {
            "question": "What is the method used to estimate the likelihood of a word in a given context, based on its co-occurrence with other words?",
            "reference-answers": [
                "The maximum likelihood estimate of a word's likelihood in a given context is calculated by dividing the fractional count of the target word by the sum of fractional counts of all other words."
            ]
        },
        {
            "question": "What is the method used to estimate the likelihood of a word given a set of observed word pairs?",
            "reference-answers": [
                "The maximum likelihood estimate."
            ]
        },
        {
            "question": "What is the maximum likelihood estimate calculated from the observed word frequencies?",
            "reference-answers": [
                "The maximum likelihood estimate is the fractional count that falls to the target word divided by the sum of fractional counts."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen69-slide26/text.txt": [
        {
            "question": "What programming language should be used to implement the pseudocode provided as homework?",
            "reference-answers": [
                "Your favorite language."
            ]
        },
        {
            "question": "What programming language should be used to implement the pseudocode provided as homework?",
            "reference-answers": [
                "Your favorite language."
            ]
        },
        {
            "question": "What programming language should be used to implement the pseudocode provided as homework?",
            "reference-answers": [
                "Your favorite language."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen71-slide26/text.txt": [
        {
            "question": "What is the initial probability distribution of the words in the model?",
            "reference-answers": [
                "We initialize the model with uniform probabilities."
            ]
        },
        {
            "question": "What is the initial probability distribution of the Czech word \"Bili\" given the corpus of sentence pairs?",
            "reference-answers": [
                "Bili was surely linked to something, and since Bili summed to one, it was either linked to White or to House, but we don't know which one."
            ]
        },
        {
            "question": "What is the initial state of the model when it is first initialized, according to the given explanation?",
            "reference-answers": [
                "We initialize the dictionary, we initialize the model with uniform probabilities."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen73-slide26/text.txt": [
        {
            "question": "What is the primary function of the IBM Model 3 in the context of lexical translation?",
            "reference-answers": [
                "The primary function of the IBM Model 3 is to translate a single word into multiple words."
            ]
        },
        {
            "question": "What is added by the IBM Model 2 compared to the IBM Model 1 in the lexical translation process?",
            "reference-answers": [
                "Absolute reordering models."
            ]
        },
        {
            "question": "What is the main difference between the IBM Model 2 and the IBM Model 1 in the context of lexical translation?",
            "reference-answers": [
                "The IBM Model 2 adds absolute reordering models to the IBM Model 1, considering the exact position of the word in the sentence."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen74-slide26/text.txt": [
        {
            "question": "What is the role of the lexical translation probability in the word alignment process described in the IBM Model 4 system?",
            "reference-answers": [
                "The lexical translation probability is used to determine the most likely translations for specific words in the source sentence, such as \"Mary\" being translated to \"Maria\", and is also used to suggest the order of words in the translation, as it provides the same entry for related words like \"slap\" (with different translations Daba, Una, Bofetada)."
            ]
        },
        {
            "question": "What is the purpose of the distortion model in the IBM Model 4 word alignment system?",
            "reference-answers": [
                "The distortion model allows the words to be further reordered, and the number of words in the reordered sequence is based on the same context, which can be considered a longer term."
            ]
        },
        {
            "question": "What is the purpose of the lexical translations in the IBM Model 4 word alignment process?",
            "reference-answers": [
                "The lexical translations in the IBM Model 4 word alignment process provide the most likely translations for words, such as \"Mary\" being translated to \"Maria\", and are used as a basis for further processing by the language model and distortion model."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen75-slide26/text.txt": [
        {
            "question": "What is the IBM Model 4 mentioned in the text?",
            "reference-answers": [
                "The IBM Model 4."
            ]
        },
        {
            "question": "What is the name of the second computer mentioned in the text?",
            "reference-answers": [
                "IBM Model 4 and the IBM Model 5"
            ]
        },
        {
            "question": "What is the IBM Model 4?",
            "reference-answers": [
                "So that's the IBM Model 4 and the..."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen76-slide26/text.txt": [
        {
            "question": "What is the difference between using intersection and union when aligning parallel texts to extract a reliable link?",
            "reference-answers": [
                "When extracting a reliable link, you rely on the intersection."
            ]
        },
        {
            "question": "What is the purpose of relying on the intersection of alignments when extracting a reliable dictionary for humans?",
            "reference-answers": [
                "When extracting a reliable dictionary for humans, you rely on the intersection of alignments to ensure a reliable link."
            ]
        },
        {
            "question": "What is the difference between using intersection and union when aligning parallel texts to extract reliable links for dictionary extraction?",
            "reference-answers": [
                "When extracting reliable links for dictionary extraction, you rely on the intersection for a one-to-one reliable link, but to extract phrase translations, you do something between the intersection and union, which is called \"grow dive final\"."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen77-slide26/text.txt": [
        {
            "question": "What is the Symmetrisation heuristic that includes only points in close vicinity from the intersection ones?",
            "reference-answers": [
                "The popular Symmetrisation heuristic is the Grodiag final where you include only points that are already in close vicinity from the intersection ones."
            ]
        },
        {
            "question": "What is the Symmetrisation heuristic, according to the given text?",
            "reference-answers": [
                "The Symmetrisation heuristic is the Grodiag final where you include only points that are already in close vicinity from the intersection ones."
            ]
        },
        {
            "question": "What is the Symmetrisation heuristics according to the provided text?",
            "reference-answers": [
                "The popular Symmetrisation heuristics is the Grodiag final where you include only points that are already in close vicinity from the intersection ones."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen78-slide26/text.txt": [
        {
            "question": "What is the general difficulty level for humans to align auxiliary words in word alignment tasks, based on the observations made in the study?",
            "reference-answers": [
                "The general difficulty level for humans to align auxiliary words in word alignment tasks is quite high, as seen in the observations that auxiliary words, especially those without a counterpart in the target language, were the hardest words to align for humans."
            ]
        },
        {
            "question": "What are some of the auxiliary words that humans found difficult to align when manually aligning words in different languages?",
            "reference-answers": [
                "In English, the auxiliary words that humans found difficult to align were \"to\", \"the\", \"of\", \"a\", and in Czech, the auxiliary words were \"comma\", \"sev\", \"na\", and so on."
            ]
        },
        {
            "question": "What type of words were found to be the hardest for humans to align during manual alignment tasks in both English and Czech?",
            "reference-answers": [
                "Auxiliary words."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen79-slide26/text.txt": [
        {
            "question": "What is the main message about improving automatic alignment when the task is ill-defined?",
            "reference-answers": [
                "There is no point in improving an algorithm if the task is ill-defined, as it will not lead to measurable improvement."
            ]
        },
        {
            "question": "What is the main message of the experiment conducted by Giza on two models, a baseline model and an improved model, regarding the alignment of tokens?",
            "reference-answers": [
                "The main message of the experiment conducted by Giza is that for tokens where humans have had no troubles in aligning words, an improved model indeed increased the number of tokens that were well aligned, but if the task is ill-defined, then there is no point in improving the algorithm."
            ]
        },
        {
            "question": "What is the main message about improving automatic alignment algorithms according to the findings of the study?",
            "reference-answers": [
                "If your task is ill-defined then there is no point in improving, in trying to improve your algorithm."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen80-slide26/text.txt": [
        {
            "question": "What are the two main types of alignments that have been observed between English and Chinese, and how do they differ in terms of their nature and implications?",
            "reference-answers": [
                "The two main types of alignments observed between English and Chinese are:\n\n1. Lexical equivalent pairs, where the alignment points are based on words with the same meaning.\n2. Role equivalent pairs, where the alignment points are based on words with the same function or role, but not necessarily the same meaning, such as a content word in Chinese and a passive marker."
            ]
        },
        {
            "question": "What are the two types of possible alignments between English and Chinese that have been observed, according to colleagues' research?",
            "reference-answers": [
                "The two types of possible alignments between English and Chinese that have been observed are: \n\n1. 96% of alignment points for English definition article, where there is no counterpart.\n2. Role equivalent pairs that are not lexical equivalent, where there is a content word in Chinese and a passive marker, but not a lexical translation of the word in English."
            ]
        },
        {
            "question": "What type of alignments between English and Chinese are essentially of two types according to other colleagues?",
            "reference-answers": [
                "There are essentially two types of alignments between English and Chinese: \n\n1. 96% of alignment points for the English definition article, \n2. Role equivalent pairs that are not lexical equivalent."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen81-slide26/text.txt": [
        {
            "question": "What is the result of two groups annotating the same data set independently, without knowing each other, when both groups have the same linguistic background?",
            "reference-answers": [
                "We ended up with a three-way annotation just because the linguistic of both these groups was the same."
            ]
        },
        {
            "question": "What is the outcome when two groups of annotators, working independently, use the same established theory and rules for annotating a dataset?",
            "reference-answers": [
                "When two groups of annotators, working independently, use the same established theory and rules for annotating a dataset, they will end up with a three-way annotation of the same data set."
            ]
        },
        {
            "question": "What type of annotation were the two groups working on independently, without knowing each other?",
            "reference-answers": [
                "They were working on annotating a test set."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen82-slide26/text.txt": [
        {
            "question": "What is the purpose of marking auxiliary words in the tectogrammatic representation of a sentence?",
            "reference-answers": [
                "The auxiliaries are marked in red here and they are hidden as node attributes only within these trees, making it easier to align the nodes in the trees because they correspond to each other."
            ]
        },
        {
            "question": "What is the purpose of marking auxiliary words in red in the tectogrammatic representation?",
            "reference-answers": [
                "The auxiliaries are marked in red here and they are hidden as node attributes only within these trees, making it easier to align the nodes in the trees because they correspond to each other."
            ]
        },
        {
            "question": "What is the purpose of marking auxiliary words in the tectogrammatic representation of a sentence?",
            "reference-answers": [
                "The auxiliaries are marked in red here and they are hidden as node attributes only within these trees, making it easier to align the nodes in the trees because they correspond to each other."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen83-slide26/text.txt": [
        {
            "question": "What was the main observation made when applying the texogrammatic approach to phrase-based machine translation systems?",
            "reference-answers": [
                "The main observation was that this is a better defined task."
            ]
        },
        {
            "question": "What was the outcome of the colleague's attempt to align texogrammonical nodes instead of words in machine translation?",
            "reference-answers": [
                "The outcome of the colleague's attempt to align texogrammonical nodes instead of words in machine translation was that it improved the alignment and human agreement on the task."
            ]
        },
        {
            "question": "What were the main observations regarding the application of a texogrammatic layer to machine translation systems?",
            "reference-answers": [
                "The main observation was that this is a better defined task, making it easier to automate, but there is a disadvantage: it becomes language dependent, requiring the definition of a texogrammatic layer for all languages and the use of complex tools for annotation."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen84-slide26/text.txt": [
        {
            "question": "What is the main idea behind the LEAF approach in the context of modal representation in linguistics?",
            "reference-answers": [
                "The main idea behind the LEAF approach is that you distinguish between content-bearing (headwords) and non-content-bearing (auxiliary) words in a modal, allowing it to link only headwords across languages, while attaching non-headwords within the given language."
            ]
        },
        {
            "question": "What is the main difference between the LEAF approach and the RIS approach in distinguishing between content-bearing and non-content-bearing words in a modal?",
            "reference-answers": [
                "The main difference between the LEAF approach and the RIS approach is that the LEAF approach distinguishes between content-bearing and non-content-bearing words in the modal explicitly, whereas the RIS approach makes this distinction implicitly."
            ]
        },
        {
            "question": "What is the main difference between the approach described in the text as LEAF and RIS?",
            "reference-answers": [
                "The main difference between the LEAF approach and RIS is that LEAF links only headwords across languages, while RIS links both headwords and non-headwords across languages."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen85-slide26/text.txt": [
        {
            "question": "What was the main limitation of using word alignments in phrase-based machine translation from a statistical point of view?",
            "reference-answers": [
                "The main limitation of using word alignments in phrase-based machine translation from a statistical point of view was that the probabilities were kind of ill-defined."
            ]
        },
        {
            "question": "What was the outcome of trying to move from word alignment to true phrase alignment based on the phrase-based model?",
            "reference-answers": [
                "It didn't bring enough improvement in translation quality."
            ]
        },
        {
            "question": "What was the main reason why word alignments were problematic from the statistical point of view?",
            "reference-answers": [
                "The probabilities were kind of ill-defined."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen86-slide26/text.txt": [
        {
            "question": "What is the translation of the phrase \"to get in shape for the 90s\" into Czech?",
            "reference-answers": [
                "Aby vztoupila do devadesátých let v conejší formě"
            ]
        },
        {
            "question": "What is the recommended translation for the phrase \"to get in shape for the 90s\" into Czech?",
            "reference-answers": [
                "Aby vztoupila do devadesátých let v conejší formě"
            ]
        },
        {
            "question": "What is the difference between the alignment of two phrases and the word level correspondence between them?",
            "reference-answers": [
                "The alignment of two phrases can become less reachable if a better translation is used, and there is no clear word level correspondence between the two phrases."
            ]
        }
    ],
    "nmt-class/lecture04-alignment/screen87-slide32/text.txt": [
        {
            "question": "How do the English and Czech translations of the sentence differ in terms of the interval range they convey?",
            "reference-answers": [
                "The English and Czech translations convey different interval ranges; the English says \"until January\", implying the actions start before January, whereas the Czech says \"only in January\", implying the actions start exactly on January."
            ]
        },
        {
            "question": "What is the difference in the way the English and Czech languages describe when a particular set of routes are expected to begin functioning?",
            "reference-answers": [
                "The English language describes the expected start date as \"until,\" while the Czech language describes it as \"until January,\" with the Czech language specifying the exact month."
            ]
        },
        {
            "question": "What is the difference in the way the English and Czech languages express the start of a function or operation?",
            "reference-answers": [
                "The English language expresses the start of a function or operation by saying \"to begin until,\" while the Czech language expresses it by saying \"they will start functioning only in January,\" indicating a more limited timeframe or expectation of when the function will begin."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen01-slide02/text.txt": [
        {
            "question": "What is the topic of the fifth lecture on machine translation?",
            "reference-answers": [
                "Phrase based machine translation."
            ]
        },
        {
            "question": "What is the topic of the fifth lecture on machine translation?",
            "reference-answers": [
                "Phrase based machine translation."
            ]
        },
        {
            "question": "What is the main topic of this lecture?",
            "reference-answers": [
                "Phrase based machine translation."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen02-slide03/text.txt": [
        {
            "question": "What is the main focus of the lecture on phrase-based machine translation, according to the overview provided?",
            "reference-answers": [
                "The main focus of the lecture on phrase-based machine translation is the decoding, so translation with the model, and the weight optimization, the minimum error rate training."
            ]
        },
        {
            "question": "What is the main focus of the lecture on phrase-based machine translation?",
            "reference-answers": [
                "The main focus of the lecture on phrase-based machine translation is the decoding, or translation, with the model, and the weight optimization, or minimum error rate training."
            ]
        },
        {
            "question": "What is the main focus of the lecture on phrase-based MT, according to the speaker?",
            "reference-answers": [
                "The main focus of the lecture on phrase-based MT will be devoted to the decoding, so translation with the model."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen03-slide04/text.txt": [
        {
            "question": "What is the primary difference between the linguistic knowledge in Phrasebase MT dictionaries and those used by humans?",
            "reference-answers": [
                "The primary difference is that Phrasebase MT dictionaries contain fully inflected words and multi-word expressions, whereas human translation dictionaries typically do not."
            ]
        },
        {
            "question": "What is the primary difference between the translation dictionary used in Phrasebase MT and the normal translation dictionary for humans?",
            "reference-answers": [
                "The primary difference between the translation dictionary used in Phrasebase MT and the normal translation dictionary for humans is that the Phrasebase MT dictionary contains many multi-word expressions and all words are fully inflected, whereas the normal translation dictionary for humans typically contains word-for-word correspondences."
            ]
        },
        {
            "question": "What is the main difference between the translation dictionary used in Phrasebase MT and a normal translation dictionary for humans?",
            "reference-answers": [
                "The main difference is that the Phrasebase MT dictionary contains many multi-word expressions and all the words are fully inflected, whereas a normal translation dictionary for humans does not."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen04-slide05/text.txt": [
        {
            "question": "What is the purpose of using the argmax when running the probability estimate in the log linear model?",
            "reference-answers": [
                "We are actually interested in the sentence itself and not its probability, so we only want to know which sentence will win in this competition."
            ]
        },
        {
            "question": "What is the purpose of the weighted sum in the log linear model when calculating the conditional probability of the target sentence given the source?",
            "reference-answers": [
                "The weighted sum gives you the individual scores for each of the candidates, and it's used to determine which sentence will win in the competition."
            ]
        },
        {
            "question": "What is the purpose of running the probability estimate within the argmax in the log linear model?",
            "reference-answers": [
                "We are actually interested in the sentence itself and not its probability, so we only want to know which sentence will win in this competition."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen05-slide06/text.txt": [
        {
            "question": "What is the key assumption of phrase-based machine translation, and how does it differ from other machine translation approaches?",
            "reference-answers": [
                "The key assumption of phrase-based machine translation is that sentences can be translated by translating short sequences of words independently of each other, and that each of these phrases is translated independently of the others. This differs from other machine translation approaches because it breaks down the input sentence into K phrases, translates each independently, and then concatenates them, allowing for reordering and segmentation."
            ]
        },
        {
            "question": "What is the key assumption of phrase-based Machine Translation Evaluation (MTE)?",
            "reference-answers": [
                "The key assumption of phrase-based Machine Translation Evaluation (MTE) is that sentences can be translated by translating short sequences of words independently of each other."
            ]
        },
        {
            "question": "What is the key assumption of phrase-based Machine Translation Evaluation (MTE) that allows for the translation of sentences by breaking down the input sentence into short sequences of words that can be translated independently of each other?",
            "reference-answers": [
                "The key assumption of phrase-based Machine Translation Evaluation (MTE) is that sentences can be translated by translating short sequences of words independently of each other."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen06-slide07/text.txt": [
        {
            "question": "What is the primary function of the phrase translation probability feature in phrase-based MT?",
            "reference-answers": [
                "The phrase translation probability feature scores phrases independently of each other and multiplies the probabilities of the phrase translation probability, decomposing it along the segmentation."
            ]
        },
        {
            "question": "What is the purpose of the phrase translation probability feature in phrase-based MT systems?",
            "reference-answers": [
                "The phrase translation probability feature in phrase-based MT systems scores phrases independently of each other and multiplies the probabilities of phrases given a fixed segmentation. This feature tells us how good each phrase is as a translation of the source phrase, regardless of the context."
            ]
        },
        {
            "question": "What is the effect of using a phrase count or phrase penalty as a feature function in phrase-based MT on the length of phrases used in the output?",
            "reference-answers": [
                "Using a phrase count or phrase penalty as a feature function in phrase-based MT controls whether the system prefers to use longer phrases or shorter phrases. If the training data matches the test data, the system tends to use longer phrases, but if the test data does not match the training data, the system tends to use shorter phrases to avoid introducing errors due to phrase boundary issues."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen07-slide08/text.txt": [
        {
            "question": "What are the steps involved in the training of a phrase-based machine translation system?",
            "reference-answers": [
                "The steps involved in the training of a phrase-based machine translation system are:\n\n1. Find parallel texts\n2. Align them at the level of documents and sentences\n3. Align them at the level of words\n4. Extract the translation units with their scores\n5. Estimate the importance of the parameters in the translation units\n6. Perform inference (actual translation) using the estimated parameters"
            ]
        },
        {
            "question": "What are the steps involved in finding parallel texts for a phrase-based machine translation system?",
            "reference-answers": [
                "First you had to find parallel texts."
            ]
        },
        {
            "question": "What are the steps involved in training a phrase-based machine translation system according to the phrase-based empty pipeline approach?",
            "reference-answers": [
                "The steps involved in training a phrase-based machine translation system according to the phrase-based empty pipeline approach are:\n\n1. Find parallel texts\n2. Align them at the level of documents and sentences and then at the level of words\n3. Extract the translation units with their scores\n4. Estimation of parameters to determine which are more important and which are less important\n5. Inference (actual translation) using the input sentence, breaking it into known units listed in the translation dictionary and phrase table."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen08-slide09/text.txt": [
        {
            "question": "What is the method used to estimate the probabilities of the most important feature in phrase-based machine translation, as described in the text?",
            "reference-answers": [
                "We use the maximum likelihood estimate to see how often the given source and phrases co-occurred together, normalizing that by the count of the antecedent and the count of the source phrase alone and the count of the target phrases alone."
            ]
        },
        {
            "question": "What is the method used to estimate the probabilities of the most important feature in phrase-based machine translation?",
            "reference-answers": [
                "We use the maximum likelihood estimate to see how often the given source and phrases co-occurred together, normalizing that by the count of the antecedent and the count of the source phrase alone and the count of the target phrases alone."
            ]
        },
        {
            "question": "What is the method used to estimate the probabilities of the most important feature in phrase-based machine translation?",
            "reference-answers": [
                "We use the maximum likelihood estimate to see how often the given source and phrases co-occurred together, normalizing that by the count of the antecedent and the count of the source phrase alone and the count of the target phrases alone."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen09-slide10/text.txt": [
        {
            "question": "What is the purpose of the consistency with word alignment in the phrase extraction process?",
            "reference-answers": [
                "The consistency with word alignment ensures that no word is forgotten and that all words corresponding to the meaning of a source word are included in the extracted phrase."
            ]
        },
        {
            "question": "What is the purpose of the consistency with word alignment in the phrase extraction process?",
            "reference-answers": [
                "The consistency with word alignment ensures that no word is forgotten and that all words corresponding to the meaning of a source word are included in the extracted phrase."
            ]
        },
        {
            "question": "What is the purpose of extracting phrases from the parallel corpus that are consistent with the word alignment in the phrase-based machine translation system?",
            "reference-answers": [
                "The purpose of extracting phrases from the parallel corpus that are consistent with the word alignment is to count how often the English phrase is paired with each word in the source language, such as \"nini\", \"tou\", and so on, to determine the conditional probabilities of the translations."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen10-slide09/text.txt": [
        {
            "question": "What is the meaning of the phrase \"Europa translated as in Europe\" in the context of the phrase table?",
            "reference-answers": [
                "The phrase \"Europa translated as in Europe\" means that the German phrase \"Europa\" is translated to the English phrase \"in Europe\"."
            ]
        },
        {
            "question": "What are the two types of scores mentioned in the phrase translation probabilities?",
            "reference-answers": [
                "The co-occurrence counts divided by either the count of the source phrase or the count of the target phrase."
            ]
        },
        {
            "question": "What type of scores are associated with each phrase in the phrase translation probabilities, and how are they calculated?",
            "reference-answers": [
                "The scores associated with each phrase in the phrase translation probabilities are the co-occurrence counts divided by either the count of the source phrase or the count of the target phrase."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen11-slide10/text.txt": [
        {
            "question": "What is the effect of lexical weighting on phrases when the components of the phrase are common and frequent enough?",
            "reference-answers": [
                "The lexical weighting will probably result in a high translation score for the phrase when the components are common and frequent enough."
            ]
        },
        {
            "question": "What is the purpose of the \"lexical weighting\" in phrase translation when considering multi-word expressions?",
            "reference-answers": [
                "The lexical weighting promotes the phrase because richly was very often seen with faster and full stop was very often seen with with the full stop so this is a kind of a smoothing."
            ]
        },
        {
            "question": "What type of phrase translation is promoted by lexical weighting when the components of a multi-word expression are frequent enough?",
            "reference-answers": [
                "Lexical weighting promotes the translation of multi-word expressions into phrases that are composed of smaller units, by smoothing out the translation based on the frequency of components such as \"richly\", \"faster\", and \"full stop\"."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen12-slide11/text.txt": [
        {
            "question": "What is the reason why lexically weighted scores are considered reliable even for long and infrequent phrases?",
            "reference-answers": [
                "The reason why lexically weighted scores are considered reliable even for long and infrequent phrases is that the number of observations of word pairs is much higher in the lexically weighted scores."
            ]
        },
        {
            "question": "What is the purpose of the phrase penalty in the standard decoder?",
            "reference-answers": [
                "The phrase penalty was removed in very late versions of the standard decoder."
            ]
        },
        {
            "question": "What is the effect of dividing low phrase counts by 1 in the maximum likelihood estimate?",
            "reference-answers": [
                "There is a high risk that some of these numbers will be very imprecise."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen13-slide12/text.txt": [
        {
            "question": "How does the phrase-based system determine the applicable phrases for a given sentence in the first phase of translation?",
            "reference-answers": [
                "You search your phrase table and consider which phrases are applicable for this sentence."
            ]
        },
        {
            "question": "How do you determine which phrases are applicable for a given sentence in the phrase-based translation system?",
            "reference-answers": [
                "You search your phrase table to determine which phrases are applicable for the given sentence."
            ]
        },
        {
            "question": "How does the phrase-based system search for applicable phrases in the first phase of translation?",
            "reference-answers": [
                "You search your phrase table and consider which phrases are applicable for this sentence."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen14-slide13/text.txt": [
        {
            "question": "What is the best choice for translating the input sentence \"Er get Janik na Hause\"?",
            "reference-answers": [
                "he does not go home."
            ]
        },
        {
            "question": "What is the best translation for the phrase \"Er get Janik na Hause\" according to the given phrase table?",
            "reference-answers": [
                "he does not go home."
            ]
        },
        {
            "question": "What is the best choice for translating the sentence \"Er get Janik na Hause\" according to the given phrase table?",
            "reference-answers": [
                "he does not go home."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen15-slide14/text.txt": [
        {
            "question": "What is the second stage of the translation process mentioned in the text?",
            "reference-answers": [
                "Main search comes and that's the second stage of the translation."
            ]
        },
        {
            "question": "What is the second stage of the translation process according to the given explanation?",
            "reference-answers": [
                "Main search comes and that's the second stage of the translation."
            ]
        },
        {
            "question": "What is the second stage of the translation process mentioned in the text?",
            "reference-answers": [
                "Main search comes and that's the second stage of the translation."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen16-slide15/text.txt": [
        {
            "question": "What is the status of the coverage vector after the empty hypothesis is applied?",
            "reference-answers": [
                "The coverage vector is still set to zero."
            ]
        },
        {
            "question": "What is the state of the coverage vector after no input words have been translated?",
            "reference-answers": [
                "The coverage vector is still set to zero."
            ]
        },
        {
            "question": "What is the state of the coverage vector after no input words have been translated?",
            "reference-answers": [
                "The coverage vector is still set to zero."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen17-slide16/text.txt": [
        {
            "question": "What is hypothesis expansion in the context of translating words from a given input?",
            "reference-answers": [
                "Hypothesis expansion is the process of expanding the initial hypothesis with the word that translates the second word in the input, as in translating the word \"get\" to \"r\"."
            ]
        },
        {
            "question": "What is hypothesis expansion in the context of translation?",
            "reference-answers": [
                "Hypothesis expansion is the process of expanding the initial hypothesis with the word that translates the second word in the input, as in translating the word \"get\" to \"r\"."
            ]
        },
        {
            "question": "What is the term for expanding the initial hypothesis with the word that translates the second word in the input?",
            "reference-answers": [
                "Hypothesis expansion."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen18-slide17/text.txt": [
        {
            "question": "How many hypotheses can be formed based on the initial hypothesis, considering different translations of the first word?",
            "reference-answers": [
                "Three"
            ]
        },
        {
            "question": "How many initial hypotheses can be formed based on the translation of the first word \"er\" and the second word?",
            "reference-answers": [
                "Three."
            ]
        },
        {
            "question": "How many hypotheses can cover different source words and produce different translations?",
            "reference-answers": [
                "Three"
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen19-slide18/text.txt": [
        {
            "question": "What is the result of backtracking the hypothesis that covers the whole output and the whole input?",
            "reference-answers": [
                "We arrive back at the starting point."
            ]
        },
        {
            "question": "What is the purpose of the expansion of the hypothesis in the given text?",
            "reference-answers": [
                "To further explore and refine the hypothesis based on the translation of words and possible orderings of phrases."
            ]
        },
        {
            "question": "What is the hypothesis that covers the whole output and the whole input after considering all possible orderings of phrases?",
            "reference-answers": [
                "The hypothesis that covers the whole output and the whole input is the one based on the current estimate of the weights."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen20-slide19/text.txt": [
        {
            "question": "What is the purpose of the path through the search graph in the given context?",
            "reference-answers": [
                "The path through the search graph determines the final full output text of the target sentence, which is the best scoring sentence."
            ]
        },
        {
            "question": "What is the purpose of the path through the search graph in generating the final output text of the target sentence?",
            "reference-answers": [
                "The path through the search graph back to the initial hypothesis is then the final full output text of the target sentence, the best scoring sentence."
            ]
        },
        {
            "question": "What is the final output text of the target sentence?",
            "reference-answers": [
                "The path through the search graph back to the initial hypothesis is then the final full output text of the target sentence, the best scoring sentence."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen21-slide18/text.txt": [
        {
            "question": "What is the significance of realizing something now, according to the text?",
            "reference-answers": [
                "It's now important."
            ]
        },
        {
            "question": "What is the significance of the current moment according to the speaker?",
            "reference-answers": [
                "It's now important."
            ]
        },
        {
            "question": "What is the significance of realizing that something is now important?",
            "reference-answers": [
                "It is now important."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen22-slide19/text.txt": [
        {
            "question": "How many hypotheses, partial hypotheses, should we consider in this search space?",
            "reference-answers": [
                "...consider in this search space."
            ]
        },
        {
            "question": "What is the number of hypotheses that the speaker believes they should consider in the search space?",
            "reference-answers": [
                "...partial hypotheses that we should consider in the search space."
            ]
        },
        {
            "question": "What is the scope of the search for possible hypotheses in this context?",
            "reference-answers": [
                "This search space, the search of possible hypotheses is pretty big. We have many translation options and we have many translation options for each particle span, but we have also many spans. So the number of hypotheses, the partial hypotheses that we should..."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen23-slide20/text.txt": [
        {
            "question": "What is the general idea behind the reduction of the Hamiltonian circuit problem to the machine translation problem, as described in the text?",
            "reference-answers": [
                "The general idea behind the reduction is to convert the Hamiltonian circuit problem into a machine translation problem by labeling each node with a word and licensing edges in the graph as bigrams in a bigram language model, and then finding the most likely bigram-based ordering of the words, which corresponds to a Hamiltonian circuit solution."
            ]
        },
        {
            "question": "What is the key assumption made when proving the NP-hardness of machine translation using a \"magical black box\" that solves a known NP-complete task in polynomial time?",
            "reference-answers": [
                "The key assumption made when proving the NP-hardness of machine translation using a \"magical black box\" is that this black box can solve machine translation in polynomial time."
            ]
        },
        {
            "question": "What is the assumption that needs to be made about the \"magical black box\" system in order to prove its NP-hardness in the context of machine translation?",
            "reference-answers": [
                "The assumption that needs to be made about the \"magical black box\" system is that it can manage the finding of the best word order in polynomial time."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen24-slide21/text.txt": [
        {
            "question": "What is the minimum set cover problem in the context of machine translation, and how does it relate to the complexity of machine translation systems?",
            "reference-answers": [
                "The minimum set cover problem in the context of machine translation is to find the minimum set of multiword phrases (or sets of source words) that can cover all the input nodes (or original nodes) in the source language, where the input nodes are denoted by words in the target language. This problem is used to relate the complexity of machine translation systems to the NP complexity, and if the problem is NP, it implies that machine translation is NP."
            ]
        },
        {
            "question": "What is the minimum set cover problem, and how is it related to the back optimization problem?",
            "reference-answers": [
                "The minimum set cover problem is a well-known NP complete task that involves selecting a subset of sets to cover all input nodes, and it is related to the back optimization problem."
            ]
        },
        {
            "question": "What is the minimum set cover task, and how is it related to the back optimization problem?",
            "reference-answers": [
                "The minimum set cover task is a well-known NP complete task that involves selecting a subset of sets to cover all input nodes, and it is related to the back optimization problem."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen25-slide22/text.txt": [
        {
            "question": "What are the three topics that will be discussed in relation to fighting complexity, according to the slides by Barry Heddo?",
            "reference-answers": [
                "Hypothesis recombination, stack-based pruning, and future cost estimation."
            ]
        },
        {
            "question": "What are some topics that will be discussed in relation to fighting complexity, according to the slides by Barry Heddo?",
            "reference-answers": [
                "Hypothesis recombination, stack-based pruning, and future cost estimation."
            ]
        },
        {
            "question": "What are the three topics to be discussed in relation to fighting complexity according to Barry Heddo's slides?",
            "reference-answers": [
                "Hypothesis recombination, stack-based pruning, and future cost estimation."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen26-slide23/text.txt": [
        {
            "question": "What is the purpose of the safe modification of the search space in the given context, and how does it affect the scores of future candidate hypotheses?",
            "reference-answers": [
                "The safe modification of the search space is to reduce the continuation of the search by a factor of two by recombining existing hypotheses, thereby avoiding the creation of duplicate hypotheses and only expanding the future once. This modification does not affect the scores of the future candidate hypotheses, as the future of these two candidate hypotheses is totally identical."
            ]
        },
        {
            "question": "What is the purpose of the recombination step in the search space reduction process described in the text?",
            "reference-answers": [
                "The system checks whether it already has a hypothesis which covers the same set of input words and produces the same output, and if so, combines these two hypotheses to reduce the search space by ignoring the creation of the second variant and joining them together."
            ]
        },
        {
            "question": "What type of modification is being referred to as \"safe modification of the search space\" in the context of reducing the search space by recombining existing hypotheses?",
            "reference-answers": [
                "reduction of the search space."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen27-slide24/text.txt": [
        {
            "question": "What is the condition under which two hypotheses with the same last two words can be combined using a trigram language model?",
            "reference-answers": [
                "Two hypotheses with the same last two words can be combined using a trigram language model if they have the same coverage vector and the history considered by all other features is identical."
            ]
        },
        {
            "question": "What is the outcome when two hypotheses have the same last two words and are scored using a trigram language model?",
            "reference-answers": [
                "The outcome is that the two hypotheses can be combined safely, as the scores in the future paths will be identical due to the trigram language model only considering the last two words."
            ]
        },
        {
            "question": "What type of language model is used to score hypotheses when the beginning of the history is different, according to the explanation provided?",
            "reference-answers": [
                "A trigram language model."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen28-slide25/text.txt": [
        {
            "question": "What is the condition imposed on the reordering model by the language model and the translation model?",
            "reference-answers": [
                "There is no condition imposed on the reordering model by the language model and the translation model."
            ]
        },
        {
            "question": "What is the condition imposed by the reordering model in the given context?",
            "reference-answers": [
                "The condition imposed by the reordering model comes from the language model and the translation model, and it does not impose any restrictions on it."
            ]
        },
        {
            "question": "What is the condition that comes from the language model regarding the reordering model?",
            "reference-answers": [
                "The condition coming from the language model regarding the reordering model is not explicitly stated in the provided text, however it is mentioned that the reordering model has to be considered and the language model imposes some restrictions on it."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen29-slide26/text.txt": [
        {
            "question": "What is the purpose of \"early pruning\" in the context of the search space?",
            "reference-answers": [
                "We have to drop less likely partial hypothesis before we are finished."
            ]
        },
        {
            "question": "What is the purpose of \"early pruning\" in the context of a search space?",
            "reference-answers": [
                "We have to drop less likely partial hypothesis before we are finished."
            ]
        },
        {
            "question": "What is the purpose of \"early pruning\" in the context of the search space?",
            "reference-answers": [
                "We have to drop less likely partial hypothesis before we are finished."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen30-slide25/text.txt": [
        {
            "question": "What is the purpose of organizing partial hypotheses in a sequence of stacks in phrase-based MT beam search?",
            "reference-answers": [
                "The purpose of organizing partial hypotheses in a sequence of stacks in phrase-based MT beam search is to ensure that the search proceeds linearly and not exponentially, by limiting the number of options to be explored at each step and ensuring fair competition among hypotheses within each stack."
            ]
        },
        {
            "question": "What is the purpose of the limitation on the number of candidate translations or partial hypotheses within a stack in the stack-based beam search approach?",
            "reference-answers": [
                "The limitation on the number of candidate translations or partial hypotheses within a stack is to prevent the system from storing too many options, thus reducing the search space to a linear bound, and preventing the search from becoming exponentially large."
            ]
        },
        {
            "question": "What is the purpose of organizing partial hypotheses in a sequence of stacks in phrase-based MT?",
            "reference-answers": [
                "The purpose of organizing partial hypotheses in a sequence of stacks in phrase-based MT is to ensure that the search is linear and not exponentially large, allowing for a fair comparison of competing hypotheses and limiting the exploration of options to a predetermined number."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen31-slide25/text.txt": [
        {
            "question": "What happens to the final stack at the end of the process?",
            "reference-answers": [
                "The final stack contains only hypotheses that cover all the words and is located at the top of the stack."
            ]
        },
        {
            "question": "What happens to a stack if it grows too big in the given algorithm?",
            "reference-answers": [
                "You can directly prune it."
            ]
        },
        {
            "question": "What happens to the stack if it has grown too big during the process of generating new hypotheses?",
            "reference-answers": [
                "You can directly prune it."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen32-slide25/text.txt": [
        {
            "question": "What are some pruning strategies that can be used for hypothesis in a stack, according to the text?",
            "reference-answers": [
                "You can want to keep at most K hypothesis in a stack or you can want to keep the best score and hypotheses which are not worse than 10 times the best score or one tenth of the best score."
            ]
        },
        {
            "question": "What are some possible pruning strategies for hypothesis stacks in terms of keeping the best score?",
            "reference-answers": [
                "You can want to keep the best score and hypotheses which are not worse than 10 times the best score or one tenth of the best score."
            ]
        },
        {
            "question": "What are the two pruning strategies mentioned for hypotheses in a stack?",
            "reference-answers": [
                "You can want to keep at most K hypothesis in a stack or you can want to keep the best score and hypotheses which are not worse than 10 times the best score or one tenth of the best score."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen33-slide25/text.txt": [
        {
            "question": "What is the complexity of the search when the reordering is limited to only options close to the currently translated one?",
            "reference-answers": [
                "The complexity of the search is linear."
            ]
        },
        {
            "question": "What is the complexity of the search when the reordering is limited to only options close to the currently translated one?",
            "reference-answers": [
                "The complexity of the search is linear."
            ]
        },
        {
            "question": "What happens to the search complexity if the reordering is limited to expanding only hypothesis close to the currently translated one?",
            "reference-answers": [
                "The search complexity reduces to linear complexity."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen34-slide25/text.txt": [
        {
            "question": "What is the purpose of considering a future cost estimate in the hypothesis evaluation process to ensure fairness in the allocation of partial hypotheses into stacks?",
            "reference-answers": [
                "The purpose of considering a future cost estimate is to ensure fairness in the allocation of partial hypotheses into stacks by preventing the pruning of hypotheses that will have a chance to recover their score by doing the easy part of the sentence later on."
            ]
        },
        {
            "question": "What is the purpose of the additional score component considered in the hypothesis allocation process?",
            "reference-answers": [
                "The additional score component is a function that estimates the future cost of reaching the final point, and it helps to make the comparison fair by taking into account the future cost estimate for the \"easy first\" and \"hard first\" hypotheses."
            ]
        },
        {
            "question": "What is the purpose of considering a future cost estimate in the evaluation of hypotheses for translation of a sentence?",
            "reference-answers": [
                "The future cost estimate is used to make the comparison fair between hypotheses that compete on the same stack, allowing for a more accurate evaluation of their scores."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen35-slide25/text.txt": [
        {
            "question": "What is the nature of the future cost estimate in the context of the A-star search algorithm?",
            "reference-answers": [
                "The future cost estimate is an optimistic estimate of the cost for each individual feature function as we proceed with the translation."
            ]
        },
        {
            "question": "What is the purpose of the estimated \"future cost\" in the context of the A star search algorithm?",
            "reference-answers": [
                "The estimated \"future cost\" is an optimistic estimate of how much will have to be paid for each of the individual feature functions as we proceed with the translation."
            ]
        },
        {
            "question": "What type of cost is the future cost estimated to be in the context of the A star search algorithm?",
            "reference-answers": [
                "The future cost is an optimistic estimate."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen36-slide25/text.txt": [
        {
            "question": "What is the approach used to estimate the future cost in the given text?",
            "reference-answers": [
                "The approach used to estimate the future cost is a dynamic programming style algorithm, filling up a diagonal or triangular table to determine the cheapest way of translating parts of the sentence."
            ]
        },
        {
            "question": "What type of algorithm is used to estimate the future cost of translating a sentence, according to the provided text?",
            "reference-answers": [
                "Dynamic programming algorithm."
            ]
        },
        {
            "question": "What type of algorithm is used to estimate the future cost in the given context?",
            "reference-answers": [
                "Dynamic programming algorithm."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen37-slide25/text.txt": [
        {
            "question": "What is the general rule about the cost of translating function words compared to content words?",
            "reference-answers": [
                "Function words are cheaper to translate than content words."
            ]
        },
        {
            "question": "What is an example of a function word in the given text?",
            "reference-answers": [
                "Function words."
            ]
        },
        {
            "question": "What is a general rule about the cost of translating function words versus content words?",
            "reference-answers": [
                "Function words are cheaper to translate than content words."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen38-slide25/text.txt": [
        {
            "question": "What is the total cost estimate when the hypothesis that translates the hard words first is chosen, compared to the total cost estimate when the hypothesis that translates the easy words first is chosen?",
            "reference-answers": [
                "The total cost estimate when the hypothesis that translates the hard words first is chosen (11.98) is less than the total cost estimate when the hypothesis that translates the easy words first is chosen (13.41)."
            ]
        },
        {
            "question": "What is the purpose of the future cost estimate in the system?",
            "reference-answers": [
                "The future cost estimate is there to avoid dead-end roads and to provide a smoother and easier path by paying first for the higher price of translating hard phrases."
            ]
        },
        {
            "question": "What is the effect of translating the hard words first compared to translating the easy words first in the context of the two hypotheses being compared?",
            "reference-answers": [
                "The total estimate of the full path once we finish is now better for the one that started with the hard words first, as it results in a lower total score and estimate."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen39-slide25/text.txt": [
        {
            "question": "What other decoding algorithms, besides A-star surges and greedy hill climbing, can be used for decoding?",
            "reference-answers": [
                "finite state transducers and other possible"
            ]
        },
        {
            "question": "What other decoding algorithms, aside from A-star surges and greedy hill climbing, may be used in the future lectures?",
            "reference-answers": [
                "finite state transducers."
            ]
        },
        {
            "question": "What other decoding algorithms, apart from A-star surges and greedy hill climbing, are mentioned as possible alternatives?",
            "reference-answers": [
                "finite state transducers."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen40-slide25/text.txt": [
        {
            "question": "What is a heuristic in the context of A-Star Search that guarantees the algorithm will find the best option?",
            "reference-answers": [
                "An admissible heuristic is the one which is optimistic, never overestimating the future cost."
            ]
        },
        {
            "question": "What is an admissible heuristic in the context of A-Star Search?",
            "reference-answers": [
                "An admissible heuristic is the one which is optimistic, never overestimating the future cost."
            ]
        },
        {
            "question": "What is a key characteristic of an admissible heuristic in the A-Star Search algorithm?",
            "reference-answers": [
                "An admissible heuristic is one which never overestimates the future cost."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen41-slide25/text.txt": [
        {
            "question": "What is the subject of the incomplete sentence \"Yep, so we can...\".",
            "reference-answers": [
                "Preparing for an exam."
            ]
        },
        {
            "question": "What is the next action the speaker will take?",
            "reference-answers": [
                "Prepare for the exam."
            ]
        },
        {
            "question": "What is the subject of the incomplete sentence \"Yep, so we can...\".",
            "reference-answers": [
                "Preparing for an exam."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen42-slide25/text.txt": [
        {
            "question": "What is the difference between local and non-local feature functions in phrase-based machine translation, and how do they contribute to the overall score of a hypothesis?",
            "reference-answers": [
                "Local feature functions, such as phrase translation probability, phrase penalty, and word penalty, are used to calculate the score of a phrase alone without any context. These features are associated with each phrase and are summed along the puzzle pieces to get the total score. Non-local feature functions, such as the language model, consider bigrams that span the boundaries of the puzzle pieces and cannot be evaluated independently of the context. The language model scores are used to mix the total language model feature into the total score of the recombination of partial hypotheses."
            ]
        },
        {
            "question": "What is the difference between the phrase penalty and the word penalty in the context of phrase-based machine translation?",
            "reference-answers": [
                "The phrase penalty increments by one with every new puzzle piece, whereas the word penalty increments by one with every new output word, meaning it should be two for a phrase that contains two output words."
            ]
        },
        {
            "question": "What is the difference between local and non-local feature functions in phrase-based machine translation?",
            "reference-answers": [
                "Local feature functions consider the output in a way that is in line with the segmentation, and are used to score the output within a particular span of the input sentence. Non-local feature functions, on the other hand, consider properties across boundaries of these spans, and are used to score the output in a way that takes into account the context of the surrounding hypothesis."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen43-slide25/text.txt": [
        {
            "question": "What is the main idea behind the minimum error rate training in machine learning, particularly in the context of phrase-based machine translation?",
            "reference-answers": [
                "The main idea behind the minimum error rate training in machine learning, particularly in the context of phrase-based machine translation, is to find the best balance of internal and external scores to optimize the model's performance, by adjusting the weights to ensure that the hypothesis preferred by the external score is also scored highly by the internal score, thereby achieving a better match between the two."
            ]
        },
        {
            "question": "What is the purpose of the algorithm proposed by Franz Josef Och in 2003 for optimizing the weights in phrase-based machine translation models?",
            "reference-answers": [
                "The algorithm by Franz Josef Och from 2003 finds the new weights in such a way that the external score will now better match the internal score, which is to say that the internal score will better match the external score."
            ]
        },
        {
            "question": "What is the main idea of the minimum error rate training in phrase-based machine translation?",
            "reference-answers": [
                "The main idea of the minimum error rate training in phrase-based machine translation is to find the best balance of internal and external scores to modify the model so that it ideally arrives at the solution that the user wants, by adjusting the weights of the internal parameters such as word translation and language model scores."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen44-slide25/text.txt": [
        {
            "question": "What is the effect of a high phrase penalty on the segmentation of the input sentence?",
            "reference-answers": [
                "Higher phrase penalty, which translates the input sentence into more segments."
            ]
        },
        {
            "question": "What is the purpose of the phrase penalty in the phrase table?",
            "reference-answers": [
                "The phrase penalty controls whether the system prefers many segments when segmenting the input sentence or few segments, with higher values resulting in more segments."
            ]
        },
        {
            "question": "What is the effect of a high phrase penalty on the system's output, according to the provided text?",
            "reference-answers": [
                "A high phrase penalty causes the system to chop sentences into more segments."
            ]
        }
    ],
    "nmt-class/lecture05-pbmt/screen45-slide25/text.txt": [
        {
            "question": "What is the primary limitation of the phrase-based MT system implemented with Moses decoder?",
            "reference-answers": [
                "The primary limitation of the phrase-based MT system implemented with Moses decoder is its built-in assumption of phrase independence, which is too strong for natural languages."
            ]
        },
        {
            "question": "What are some situations where the phrase-based translation system, specifically the Moses decoder, is still a useful tool?",
            "reference-answers": [
                "For various sequence mappings and in linguistic analysis, and for porting three bank annotation across languages, especially when a more literal translation is required."
            ]
        },
        {
            "question": "What type of machine translation systems are still useful and usable, especially for tasks like linguistic analysis and sequence transfer?",
            "reference-answers": [
                "Phrase-based machine translation systems, specifically the Moses decoder, are still useful and usable, especially for tasks like linguistic analysis and sequence transfer."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen01-slide01/text.txt": [
        {
            "question": "What is the topic of the next lecture?",
            "reference-answers": [
                "Machine translation."
            ]
        },
        {
            "question": "What topic will be discussed in today's lecture on machine translation?",
            "reference-answers": [
                "Morphology in machine translation."
            ]
        },
        {
            "question": "What is the topic of the lecture?",
            "reference-answers": [
                "Morphology in machine translation."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen02-slide02/text.txt": [
        {
            "question": "What is a major reason why the speaker is focused on morphology in Czech?",
            "reference-answers": [
                "The speaker is focused on morphology in Czech because Czech is a flective language."
            ]
        },
        {
            "question": "What are some of the problems caused by the rich morphology in Czech when translating into Czech?",
            "reference-answers": [
                "The problems caused by rich morphology in Czech when translating into Czech include the need to deal with the complex morphology of the language."
            ]
        },
        {
            "question": "What type of machine translation is particularly affected by the rich morphology of Czech?",
            "reference-answers": [
                "Phrase-based machine translation."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen03-slide03/text.txt": [
        {
            "question": "How many morphological tags are possible in Czech compared to English?",
            "reference-answers": [
                "More than 4,000."
            ]
        },
        {
            "question": "How does the word form variety in Czech compare to that in English in terms of the number of possible morphological tags?",
            "reference-answers": [
                "In Czech, there are more than 4,000 possible morphological tags, while in English, linguists are happy with just 50 tags."
            ]
        },
        {
            "question": "How many morphological tags are possible in Czech, compared to English?",
            "reference-answers": [
                "More than 4,000."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen04-slide04/text.txt": [
        {
            "question": "What is the term used to describe the large number of possible combinations of word endings in Czech translations, which can lead to a \"combinatorial explosion\"?",
            "reference-answers": [
                "combinatorial explosion"
            ]
        },
        {
            "question": "What is the term used to describe the large number of possible combinations when translating words in Czech, including the choice of word meaning, verb conjugation, and grammatical ending?",
            "reference-answers": [
                "combinatorial explosion"
            ]
        },
        {
            "question": "What is the combinatorial explosion in Czech translation that arises from the combination of word choice and ending?",
            "reference-answers": [
                "The combinatorial explosion in Czech translation arises from the combination of word choice and ending, resulting in many incorrect combinations, with only a few being correct."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen05-slide05/text.txt": [
        {
            "question": "What is the difference between agglutination and compounding in word formation?",
            "reference-answers": [
                "Agglutination and compounding are two different phenomena in word formation. The main difference is that in agglutination, the same word form is modified by adding many suffixes, prefixes, infixes, and other modifications, whereas in compounding, words are put together."
            ]
        },
        {
            "question": "What is the difference between agglutination and compounding in word formation?",
            "reference-answers": [
                "Agglutination and compounding are two different phenomena in word formation. The main difference is that in agglutination, the same word form is modified by adding many suffixes, prefixes, infixes, and other modifications, whereas in compounding, words are put together."
            ]
        },
        {
            "question": "What is the difference between compounding and agglutination in word formation?",
            "reference-answers": [
                "Compounding and agglutination are two different phenomena in word formation. Compounding is when words are put together, whereas agglutination involves using many suffixes, prefixes, infixes, and other modifications to express variations of meaning."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen06-slide06/text.txt": [
        {
            "question": "What is a major limitation of using the BLEU score for machine translation evaluation in morphologically rich languages?",
            "reference-answers": [
                "The major limitation of using the BLEU score for machine translation evaluation in morphologically rich languages is that it focuses only on word forms and penalizes errors in word endings, which can result in lower scores compared to English."
            ]
        },
        {
            "question": "What is a major limitation of using the BLEU score to evaluate machine translation in morphologically rich languages?",
            "reference-answers": [
                "The major limitation of using the BLEU score to evaluate machine translation in morphologically rich languages is that it focuses only on word forms and penalizes errors in word endings, which can result in lower scores compared to English."
            ]
        },
        {
            "question": "What is a limitation of using the BLEU score as a machine translation evaluation method for morphologically rich languages?",
            "reference-answers": [
                "The BLEU score only focuses on word forms and doesn't account for errors in morphology, which can lead to lower scores for morphologically rich languages."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen07-slide07/text.txt": [
        {
            "question": "How do we handle morphology in phrase-based machine translation?",
            "reference-answers": [
                "Morphology isn't mentioned in the provided text."
            ]
        },
        {
            "question": "How do you handle morphology in phrase-based machine translation?",
            "reference-answers": [
                "Morphology isn't mentioned in the provided text."
            ]
        },
        {
            "question": "How do you handle morphology in phrase-based machine translation?",
            "reference-answers": [
                "Morphology isn't mentioned in the provided text."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen08-slide08/text.txt": [
        {
            "question": "What are the two major components of phrase-based systems, according to the given explanation?",
            "reference-answers": [
                "The translation model and the language model."
            ]
        },
        {
            "question": "What are the two major components of phrase-based systems, according to the given text?",
            "reference-answers": [
                "The translation model and the language model."
            ]
        },
        {
            "question": "What are the two major components of phrase-based systems?",
            "reference-answers": [
                "The translation model and the language model."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen09-slide09/text.txt": [
        {
            "question": "What is a requirement for a language model to choose between the second and third examples in the provided text?",
            "reference-answers": [
                "You would have to have a corpus that talks about all colors and all types of striping of all animals."
            ]
        },
        {
            "question": "What type of word forms are used to translate \"two green striped cats\" in Czech, and why is the third example considered correct?",
            "reference-answers": [
                "The third example, \"zelené pruhovány kočky\", is considered correct because it is a fully inflected word form, disregarding the triagram language model's agreement."
            ]
        },
        {
            "question": "What type of word forms would be needed to correctly translate the phrase \"I saw two green striped cats\" into Czech?",
            "reference-answers": [
                "Fully inflected word forms, specifically all colors and all types of striping of all animals."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen10-slide10/text.txt": [
        {
            "question": "What is the difference in gender and case between the two translations of the phrase \"dva zelené pruhovány kočky\"?",
            "reference-answers": [
                "The first translation, dva zelené pruhovány kočky, can be interpreted as having a masculine nominative gender and a masculine case, while the second translation, dva zelené pruhovány kočky, is a perfect feminine noun phrase."
            ]
        },
        {
            "question": "What is the purpose of the morphological text in a speaker's presentation, according to the provided text?",
            "reference-answers": [
                "For a speaker to highlight the problem with the morphological text, so that the labels and morphological text are distinct for each word."
            ]
        },
        {
            "question": "What is the effect of morphological text on the understanding of noun phrases in the given examples?",
            "reference-answers": [
                "The morphological text makes it easier to understand noun phrases by having distinct labels for each word, but it also creates ambiguity, such as in the phrase \"dva zelené pruchované kočky\" where the case (nominative or accusative) cannot be determined."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen11-slide11/text.txt": [
        {
            "question": "What is the advantage of using a language model based on morphological text compared to one based on word forms, in terms of vocabulary size?",
            "reference-answers": [
                "The vocabulary size of a morphological text-based language model is much smaller (around 4,000) compared to a word form-based language model (around 2 million), allowing for the use of longer engrams and improved overall grammatical coherence in sentences."
            ]
        },
        {
            "question": "What is the advantage of using a morphological text in language models instead of word forms, and how does this impact the overall grammatical coherence of a sentence?",
            "reference-answers": [
                "Using a morphological text in language models instead of word forms allows for more reliable estimation of probabilities, as it observes many more instances of any noun and any adjective, resulting in a more reliable estimation of the probability of different word combinations. This leads to a smaller vocabulary size, enabling the use of longer engrams, which in turn provides the system with a greater power about the overall grammatical coherence in a sentence."
            ]
        },
        {
            "question": "What is the advantage of using a language model based on morphological text over one based on word forms in terms of vocabulary size?",
            "reference-answers": [
                "The vocabulary size of these morphological text is much smaller, with only 4,000 morphological text, whereas a language model based on word forms would have a vocabulary size of 2 million word forms."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen12-slide12/text.txt": [
        {
            "question": "What is the required amount of data needed to propose the translation \"Češky\" in Czech, equivalent to the English phrase \"kneecaps\"?",
            "reference-answers": [
                "50 million sentence pairs."
            ]
        },
        {
            "question": "What is the minimum data required to propose the translation \"Češky\" for the English word \"kneecaps\"?",
            "reference-answers": [
                "50 million sentence pairs."
            ]
        },
        {
            "question": "What type of data is required to propose the translation \"Češky\" for the English word phrase \"kneecaps\" in Czech?",
            "reference-answers": [
                "A corpus of 50 million sentence pairs is required to propose the translation \"Češky\" for the English word phrase \"kneecaps\" in Czech."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen13-slide13/text.txt": [
        {
            "question": "What is the benefit of using a morphological module in the factored phrase-based model, and how does it relate to training independently of parallel data?",
            "reference-answers": [
                "The benefit of using a morphological module in the factored phrase-based model is that it can be trained independently of parallel data, allowing for the extraction of morphological information from just monolingual corpus, which can produce more accurate results, such as translating \"kneecaps\" correctly."
            ]
        },
        {
            "question": "What is the benefit of the generation step in the factored phrase-based model that can be trained independently of parallel data?",
            "reference-answers": [
                "The benefit is that it can be trained independently of the parallel data, and it can be extracted from just the monolingual corpus."
            ]
        },
        {
            "question": "What is the main benefit of the factored phrase-based model in terms of training and data requirements?",
            "reference-answers": [
                "The main benefit of the factored phrase-based model is that the generation step can be trained independently of the parallel data, allowing for extraction of information from just the monolingual corpus."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen14-slide14/text.txt": [
        {
            "question": "What is the role of the generation steps in the factor phrase based machine translation model described in the text?",
            "reference-answers": [
                "The generation steps produce new factors from already known target side factors, ensuring vertical coherence in the schema by selecting words that are in line with the tag that came from the source and with the lemma created from the mapping steps from the source."
            ]
        },
        {
            "question": "What is the purpose of the generation steps in a factor phrase-based machine translation system?",
            "reference-answers": [
                "The generation steps produce new factors from already known target side factors, ensuring vertical coherence in the schema by selecting words that are in line with the tag and lemma created by the mapping steps from the source."
            ]
        },
        {
            "question": "What type of coherence is ensured by the generation steps in the morphological model, and what is the purpose of this coherence in the sequence of words?",
            "reference-answers": [
                "The generation steps ensure the vertical coherence in the simple schema, meaning they ensure that words are selected so that the form is in line with the tag that came from the source and with the lemma that was created with the mapping steps from the source. This coherence ensures that the words are selected so that they are in line with the morphological tags."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen15-slide15/text.txt": [
        {
            "question": "What is the general probabilistic relationship between the morphological tags in source and target languages, according to the system described in the text?",
            "reference-answers": [
                "In general, the probabilistic relationship between the morphological tags in source and target languages is that the tag is likely to be in relation."
            ]
        },
        {
            "question": "What is the purpose of the sequence of translation and generation steps in the system for translating words from the source language to the target language?",
            "reference-answers": [
                "The sequence of translation and generation steps is to arrive at the final thing, which includes translating the lemma into lemma, generating a word form based on the monolingual corpus, and then using the translation step to compare the source side morphological tag with the target side morphological tag, and finally generating the correct form of the word based on the morphological tag and lemma."
            ]
        },
        {
            "question": "What is the purpose of the generation step in the process of translating a word from the source language to the target language?",
            "reference-answers": [
                "The generation step is based on the monolingual corpus of the target side and searches for all possible morphological tags that can be produced for a given lemma."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen16-slide16/text.txt": [
        {
            "question": "What is the purpose of the extraction step in the factored phrase-based modal model, and how does it differ from the standard phrase extraction procedure?",
            "reference-answers": [
                "The extraction step in the factored phrase-based modal model simply observes the monolingual corpus and sees how often a particular word form was with a particle attack. This differs from the standard phrase extraction procedure, which is used for the mapping steps."
            ]
        },
        {
            "question": "What is the purpose of the extraction for generation steps in the factored phrase-based empty modal model?",
            "reference-answers": [
                "The extraction for generation steps simply observes the monolingual corpus and sees how often a particular word form was with a particle attack."
            ]
        },
        {
            "question": "What type of features can be used to score the final translation in the factored phrase-based empty modal system?",
            "reference-answers": [
                "The final translation can be scored using features such as engrams of the language modal, engrams of word forms, engrams of morphological tags, engrams of lemmas, and phrase translations, considering the lemma sequences and morphological tags of the source and target languages."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen17-slide17/text.txt": [
        {
            "question": "What is the basis of phrase-based machine translation?",
            "reference-answers": [
                "Phrase-based MT is based on word alignments and you extract phrases which are consistent with the word alignment."
            ]
        },
        {
            "question": "What is phrase-based MT based on according to the text?",
            "reference-answers": [
                "word alignments"
            ]
        },
        {
            "question": "What is the main purpose of extracting phrases in phrase-based machine translation?",
            "reference-answers": [
                "The main purpose of extracting phrases is to extract phrases which are consistent with the word alignment."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen18-slide18/text.txt": [
        {
            "question": "What is the translation of the phrase \"naturally John\" according to the sentence pair provided?",
            "reference-answers": [
                "naturally John can be translated as naturally John has."
            ]
        },
        {
            "question": "What is the meaning of the morphological text or part of speech text mentioned in the given passage?",
            "reference-answers": [
                "It is used to extend the translation of \"naturally John\" to \"naturally John has\"."
            ]
        },
        {
            "question": "What is the grammatical relationship between \"naturally\" and \"John\" in the sentence \"naturally John\"?",
            "reference-answers": [
                "naturally John can be translated as naturally John has, indicating that \"naturally\" functions as an adverb modifying \"John\"."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen19-slide19/text.txt": [
        {
            "question": "What is the general rule for the order of words in a sentence in German compared to English?",
            "reference-answers": [
                "In German, the verb goes second and then comes the subject, whereas in English, the subject is first and the verb is second."
            ]
        },
        {
            "question": "What are the syntactic patterns that this system uses, according to the text?",
            "reference-answers": [
                "Short distance syntactic patterns."
            ]
        },
        {
            "question": "What is the typical order of words in a sentence that starts with an adverb in German compared to English?",
            "reference-answers": [
                "In German, the verb goes second and then comes the subject, while in English, the subject is still the first and the verb is second."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen20-slide20/text.txt": [
        {
            "question": "What is the grammatical case used in the sentence \"Černé mu psovi\"?",
            "reference-answers": [
                "The sentence \"Černé mu psovi\" uses the dative case."
            ]
        },
        {
            "question": "What is the grammatical case used when referring to the \"black dog\" in the given sentence?",
            "reference-answers": [
                "The grammatical case used when referring to the \"black dog\" is the dative case."
            ]
        },
        {
            "question": "What is the grammatical case used for the noun'mu' in the sentence 'Černé mu psovi'?",
            "reference-answers": [
                "The noun'mu' is in the dative case."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen21-slide21/text.txt": [
        {
            "question": "What would you know how to translate if you break the phrase \"černému psobe\"?",
            "reference-answers": [
                "You would know how to translate \"černému psobe\" as \"black dog\"."
            ]
        },
        {
            "question": "What would you know how to translate if you break the phrase \"černému psobe\"?",
            "reference-answers": [
                "You would know how to translate \"černému psobe\" as \"black dog\"."
            ]
        },
        {
            "question": "What would happen if you break the phrase \"černému psobe\" in the database of fully inflected word forms?",
            "reference-answers": [
                "You would not know how to translate \"černému psobe\"."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen22-slide22/text.txt": [
        {
            "question": "What is the suggested approach for extracting phrases and creating separate tables in the given text?",
            "reference-answers": [
                "Extract separate phrases, separate tables. One will be for the lemmas and that will allow you to translate starý pán, whatever the form is, as old man and černý pás, whatever the form is, as black dog. And separately..."
            ]
        },
        {
            "question": "What are the two steps suggested by the teacher for extracting phrases and tables from the text?",
            "reference-answers": [
                "Extract separate phrases, separate tables. One will be for the lemmas and that will allow you to translate starý pán, whatever the form is, as old man and černý pás, whatever the form is, as black dog. And separately..."
            ]
        },
        {
            "question": "What type of information can be extracted from the phrases'starý pán' and 'černý pás' to translate them into English?",
            "reference-answers": [
                "Phrases'starý pán' and 'černý pás' can be used to extract separate lemmas and their corresponding translations, allowing for translations of'starý pán' as old man and 'černý pás' as black dog."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen23-slide23/text.txt": [
        {
            "question": "What is the benefit of translating accusative or dative to the sequence of an adjective and noun in English?",
            "reference-answers": [
                "You will be learning that you can translate either accusative or dative to the sequence of an adjective and noun in English. So the benefit..."
            ]
        },
        {
            "question": "What are the two forms (accusative or dative) that can be translated to the sequence of an adjective and noun in English?",
            "reference-answers": [
                "Accusative and dative."
            ]
        },
        {
            "question": "What is the benefit of translating accusative or dative to the sequence of an adjective and noun in English?",
            "reference-answers": [
                "You will be learning that you can translate either accusative or dative to the sequence of an adjective and noun in English. So the benefit..."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen24-slide24/text.txt": [
        {
            "question": "What is the increased robustness gained from using a combination of lemmas and morphological text from parallel data?",
            "reference-answers": [
                "Increased robustness that you have gained with this factorization is the ability to use a combination of lemmas and morphological text that was never seen together in the parallel data."
            ]
        },
        {
            "question": "What type of increased robustness can be gained by combining lemmas and morphological text from different phrases?",
            "reference-answers": [
                "Increased robustness that you have gained with this factorization is the ability to use a combination of lemmas and morphological text that was never seen together in the parallel data."
            ]
        },
        {
            "question": "What type of increased robustness have you gained by using a combination of lemmas and morphological text together?",
            "reference-answers": [
                "Increased robustness that you have gained with this factorization is the ability to use a combination of lemmas and morphological text that was never seen together in the parallel data."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen25-slide25/text.txt": [
        {
            "question": "Who presented the slides that are the basis for the exam material?",
            "reference-answers": [
                "Philip Kahn."
            ]
        },
        {
            "question": "What is the source of the slides being discussed?",
            "reference-answers": [
                "Philip Kahn presented them at MT Marathon more than 10 years ago."
            ]
        },
        {
            "question": "What type of presentation is the material from that is being reviewed, according to Philip Kahn?",
            "reference-answers": [
                "A presentation from MT Marathon more than 10 years ago."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen26-slide26/text.txt": [
        {
            "question": "What is the general process for translating a phrase sequence in phrase-based machine translation?",
            "reference-answers": [
                "You first consult your phrase tables to see what are all the possible translations of these phrases, and you consider the longer and the shorter ones."
            ]
        },
        {
            "question": "What is the purpose of consulting phrase tables in phrase-based machine translation?",
            "reference-answers": [
                "To see what all the possible translations of these phrases are."
            ]
        },
        {
            "question": "What is the process of translating a phrase sequence in phrase-based machine translation?",
            "reference-answers": [
                "You first consult your phrase tables to see what are all the possible translations of these phrases, and you consider the longer and the shorter ones."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen27-slide27/text.txt": [
        {
            "question": "What is the approach suggested for finding the best option?",
            "reference-answers": [
                "Selecting the best option."
            ]
        },
        {
            "question": "What is used when searching for something?",
            "reference-answers": [
                "that"
            ]
        },
        {
            "question": "What is the purpose of selecting the best options?",
            "reference-answers": [
                "So that's what you use, that's what you search for in the search."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen29-slide30/text.txt": [
        {
            "question": "What is the starting point for the process being described?",
            "reference-answers": [
                "So you are starting with the empty hypothesis and you are going further."
            ]
        },
        {
            "question": "What is the starting point for a hypothesis in this context?",
            "reference-answers": [
                "The empty hypothesis."
            ]
        },
        {
            "question": "What is the starting point for a hypothesis in the given context?",
            "reference-answers": [
                "The empty hypothesis."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen30-slide31/text.txt": [
        {
            "question": "What is the process of adding to the current hypothesis in the context described?",
            "reference-answers": [
                "Appending the current hypothesis with the words in the target."
            ]
        },
        {
            "question": "What is the process described in the given text?",
            "reference-answers": [
                "Covering words from the source and appending the current hypothesis with the words in the target."
            ]
        },
        {
            "question": "What is the process described in the given text?",
            "reference-answers": [
                "Covering words from the source and appending the current hypothesis with the words in the target."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen31-slide33/text.txt": [
        {
            "question": "What is the deciding factor in choosing the final path?",
            "reference-answers": [
                "The overall highest probability."
            ]
        },
        {
            "question": "What is the final choice that will cover everything and have the overall highest probability?",
            "reference-answers": [
                "The final choice will be the path which covers everything and has the overall highest probability."
            ]
        },
        {
            "question": "What is the final choice based on?",
            "reference-answers": [
                "The final choice will be the path which covers everything and has the overall highest probability."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen32-slide34/text.txt": [
        {
            "question": "What is the process of generating the surface form of the target site in factored decoding, according to the text?",
            "reference-answers": [
                "The process of generating the surface form of the target site in factored decoding is constructed in the sequence of mapping steps, where we can translate the lemma to lemma, the morphology to morphology and then generate the surface form of the target site using that."
            ]
        },
        {
            "question": "What is the process of constructing the surface form of the target site in factored decoding?",
            "reference-answers": [
                "The process of constructing the surface form of the target site in factored decoding is generated using the morphology to morphology and then generating the surface form of the target site using that."
            ]
        },
        {
            "question": "What is the process of creating the translation options for a source word like \"house\" in the context of factored decoding?",
            "reference-answers": [
                "The process of creating the translation options for a source word like \"house\" involves translating the lemma to lemma, morphology to morphology, and then generating the surface form of the target site using that, with the help of join operations of the SQL tables."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen33-slide35/text.txt": [
        {
            "question": "What is the difference in how translation options are constructed in the new system compared to the previous system?",
            "reference-answers": [
                "In the new system, translation options are constructed on the fly, whereas in the previous system, they were constructed pre-computed and stored."
            ]
        },
        {
            "question": "What is the main difference in how translation options are constructed in this system compared to a previous system?",
            "reference-answers": [
                "The main difference is that in this system, translation options are constructed on the fly, whereas in the previous system, they were pre-computed."
            ]
        },
        {
            "question": "What is the main difference between the construction of translation options in the original system and the new system?",
            "reference-answers": [
                "The main difference is that in the new system, translation options are constructed on the fly, resulting in many more options, whereas in the original system, translation options are pre-computed and more verbose."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen34-slide36/text.txt": [
        {
            "question": "What is the potential problem that can occur if the pruning limits are exceeded in the translation option generation process?",
            "reference-answers": [
                "You will be dropping possible translation options that will be necessary for the correct wording of the sentence."
            ]
        },
        {
            "question": "What are the potential consequences if the memory complexity of the pruning process grows too far beyond the limits?",
            "reference-answers": [
                "You will be dropping possible translation options that will be necessary for the correct wording of the sentence."
            ]
        },
        {
            "question": "What happens if the memory complexity of the pruning process grows too far beyond its limits?",
            "reference-answers": [
                "You will be dropping possible translation options that will be necessary for the correct wording of the sentence."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen35-slide38/text.txt": [
        {
            "question": "What is the main problem that phrase-based empty models have in understanding sentences?",
            "reference-answers": [
                "One of the main problems of phrase-based empty models is that they lack overall understanding of the sentence."
            ]
        },
        {
            "question": "What is the main problem of phrase-based empty taggers that this new approach aims to address?",
            "reference-answers": [
                "The main problem of phrase-based empty taggers is that they lack overall understanding of the sentence."
            ]
        },
        {
            "question": "What is the main problem of phrase-based empty taggers that the proposed setup is trying to address?",
            "reference-answers": [
                "The main problem of phrase-based empty taggers is that they lack overall understanding of the sentence."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen36-slide39/text.txt": [
        {
            "question": "How does the BLEU score change when sentences are tested on English-German or German-English?",
            "reference-answers": [
                "It increases the BLEU score a little because the overall fluency of the sentence is better."
            ]
        },
        {
            "question": "What is the primary reason the BLEU score may not be sensitive to improvements in sentence fluency?",
            "reference-answers": [
                "The BLEU score is limited to 4 grams only."
            ]
        },
        {
            "question": "What is the maximum number of grams that the BLEU score is limited to?",
            "reference-answers": [
                "4 grams."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen37-slide40/text.txt": [
        {
            "question": "What is a grammatically wrong sequence that a language model should avoid in its morphological analysis?",
            "reference-answers": [
                "A combination of a determiner in singular followed by a noun in plural."
            ]
        },
        {
            "question": "What is a grammatically wrong sequence according to the language model over the morphologicalales?",
            "reference-answers": [
                "A combination of a determiner in singular followed by a noun in plural."
            ]
        },
        {
            "question": "What type of grammatical sequence should a language model avoid in order to correctly handle morphological agreement?",
            "reference-answers": [
                "A combination of a determiner in singular followed by a noun in plural."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen38-slide41/text.txt": [
        {
            "question": "Is it suggested that translating lemmas to lemmas, such as \"kneecap\", may be a better approach than other methods?",
            "reference-answers": [
                "Yes, it is suggested that translating lemmas to lemmas, such as \"kneecap\", may be a better approach than other methods."
            ]
        },
        {
            "question": "What is the suggested approach for translating lemmas to lemmas?",
            "reference-answers": [
                "Translate lemmas to lemmas, like translating \"kneecap\" into any form in čeština, and then apply part of speech technology into morphology to generate the final word form."
            ]
        },
        {
            "question": "What type of translation is being suggested as a \"motivating example\" in the context of lemmas and word form generation?",
            "reference-answers": [
                "Translation of lemmas into lemmas."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen39-slide42/text.txt": [
        {
            "question": "What is the reason for the drop in translation quality in the new setup compared to the previous one?",
            "reference-answers": [
                "The reason for the drop in translation quality is that the new setup introduces additional independence assumptions, which bring about information loss and result in a decrease in translation quality."
            ]
        },
        {
            "question": "What is the likely reason for the decrease in translation quality when introducing independence assumptions in morphological generation models?",
            "reference-answers": [
                "The introduction of independence assumptions in morphological generation models leads to information loss, causing a decrease in translation quality."
            ]
        },
        {
            "question": "What is the effect of introducing independence assumptions in morphological generation models on translation quality?",
            "reference-answers": [
                "The introduction of independence assumptions in morphological generation models leads to a drop in translation quality, resulting in an information loss that affects the overall quality of the translations."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen40-slide43/text.txt": [
        {
            "question": "What is the name of the solution that combines two models to operate at once in machine translation?",
            "reference-answers": [
                "Alternative decoding paths."
            ]
        },
        {
            "question": "What is the name of the solution that combines two models to operate at once?",
            "reference-answers": [
                "Alternative decoding paths."
            ]
        },
        {
            "question": "What is the name of the solution that combines two models to operate at once?",
            "reference-answers": [
                "Alternative decoding paths."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen41-slide44/text.txt": [
        {
            "question": "What is the result of improving on both paths?",
            "reference-answers": [
                "You do get the improvement that you wanted, and you are improving over the baseline by far."
            ]
        },
        {
            "question": "If you follow both paths, what improvement can be expected?",
            "reference-answers": [
                "You can get the improvement that you wanted, and you are improving over the baseline by far."
            ]
        },
        {
            "question": "What improvement are you referring to in the TEXT?",
            "reference-answers": [
                "Improvement over the baseline."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen42-slide45/text.txt": [
        {
            "question": "What are some examples of information that need to be extracted or guessed during translation from certain language pairs?",
            "reference-answers": [
                "Information such as noun case, numbers for nouns, and the reference for pronouns need to be extracted or guessed during translation from certain language pairs, such as English to German or Czech, or Chinese to English."
            ]
        },
        {
            "question": "What are some examples of language pairs where information from the source side must be edited or extracted to complete the translation?",
            "reference-answers": [
                "When translating from English into German or English into Czech, and from Chinese to English, and when translating pronouns."
            ]
        },
        {
            "question": "What type of information can be extracted from the source side alone during language translation?",
            "reference-answers": [
                "Additional information such as case for noun phrases, number for nouns, and what pronouns refer to."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen43-slide46/text.txt": [
        {
            "question": "What is a good indication for whether a particle noun in a sentence should be translated as nominative or accusative in the target language?",
            "reference-answers": [
                "whether it serves as a subject or serves as the object in the sentence."
            ]
        },
        {
            "question": "What type of information from the word's function in the sentence (subject or object) can be used to determine whether it should be translated as nominative or accusative in the target language?",
            "reference-answers": [
                "The word's function in the sentence (subject or object) can be used to determine whether it should be translated as nominative or accusative in the target language."
            ]
        },
        {
            "question": "What type of mapping can be used to translate a particle noun in a sentence from English to Greek based on its role or function in the sentence?",
            "reference-answers": [
                "A mapping table from the role or function of the word in the sentence in English into the case in the target Greek, specifically mapping subject to nominative and object to accusative."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen44-slide47/text.txt": [
        {
            "question": "How can you determine whether a word sits in the subject position or the object position in a sentence based on its position in the tree?",
            "reference-answers": [
                "You determine whether a word sits in the subject position or the object position in a sentence based on its position in the tree by traversing the tree and knowing its position."
            ]
        },
        {
            "question": "How do you determine the case of a word based on its position in the tree?",
            "reference-answers": [
                "You determine the case of a word based on its position in the tree by traversing the tree and knowing whether it sits in the subject position or the object position."
            ]
        },
        {
            "question": "What is the implication of determining a word's position in the tree for its case?",
            "reference-answers": [
                "Determining a word's position in the tree implies its case, whether it's in the subject position or the object position."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen45-slide48/text.txt": [
        {
            "question": "What is the benefit of using explicitly available linguistic information on the source side in the translation process?",
            "reference-answers": [
                "It helps, and we can use it explicitly to improve the prediction."
            ]
        },
        {
            "question": "Does the use of explicitly available linguistic information on the source side improve the prediction?",
            "reference-answers": [
                "Indeed, it helps."
            ]
        },
        {
            "question": "What is a benefit of using explicitly available linguistic information on the source side for prediction?",
            "reference-answers": [
                "It helps."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen46-slide49/text.txt": [
        {
            "question": "What is the benefit of applying a second language model in the \"translate and Czech\" setup, where the system translates the form of English into the form of Czech and then uses generation to identify morphological tags?",
            "reference-answers": [
                "The benefit of applying a second language model in the \"translate and Czech\" setup is that you can apply the second language model twice, which allows you to check the coherence of the sequence of word forms, the coherence of the sequence of part of speech text or morphological text, and the coherence of the lemmas."
            ]
        },
        {
            "question": "What is the benefit of applying a second language model in the \"translate and Czech\" setup, where the system translates the form of English into the form of Czech and then uses generation as a tagger on the fly?",
            "reference-answers": [
                "The benefit of applying a second language model in the \"translate and Czech\" setup is that the system can check the coherence of the lemmas, in addition to the coherence of the sequence of word forms and the coherence of sequence of part of speech text or morphological text."
            ]
        },
        {
            "question": "What is the benefit of applying a second language model in the \"translate and Czech\" setup, where the system translates English form to Czech form and then identifies the morphological tag of each word?",
            "reference-answers": [
                "The benefit of applying a second language model in the \"translate and Czech\" setup is that you can apply the second language model there and check the coherence of the lemmas, and also the coherence of the sequence of part of speech text or morphological text, and you can also check the coherence of the lemmas."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen47-slide50/text.txt": [
        {
            "question": "What is the trade-off in the language model when it incorporates morphological tags into the tagging process on the fly?",
            "reference-answers": [
                "The trade-off is that incorporating morphological tags complicates the search, but it also gives the language model the power to select the good combination based on the more dense statistics of the morphological tags."
            ]
        },
        {
            "question": "What is the trade-off in the system when adding morphological tags to the tagging process?",
            "reference-answers": [
                "The trade-off is that adding morphological tags complicates the search, but also gives the system the power to select the good combination based on more dense statistics of the morphological tags."
            ]
        },
        {
            "question": "What is the effect of introducing morphological tags on the number of translation options in a language model?",
            "reference-answers": [
                "The number of translation options will increase immediately as soon as you add this explicit information."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen48-slide51/text.txt": [
        {
            "question": "What was the best setup for translation in 2009, according to the results, and what was the main reason for its success?",
            "reference-answers": [
                "The best result was actually achieved with the vanilla phrase-based system in 2009, and the main reason for its success was that the added complexity of the search space was not then compensated with sufficient gains from the language model, specifically the language model on word forms was good enough to make the decisions."
            ]
        },
        {
            "question": "What was the best translation result achieved in 2009, and what system was used to achieve it?",
            "reference-answers": [
                "The best result was achieved with the vanilla phrase-based system."
            ]
        },
        {
            "question": "What was the best setup for achieving translation quality in 2009, according to the results mentioned in the text?",
            "reference-answers": [
                "The vanilla phrase-based system."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen49-slide52/text.txt": [
        {
            "question": "What is the main reason why the model fails to produce accurate translation options due to the synchronous nature of the factored models?",
            "reference-answers": [
                "The main reason why the model fails to produce accurate translation options due to the synchronous nature of the factored models is that all translation options have to be fully instantiated and populated with all possible variations, which can lead to under-specified translation options and pruning limits being too strict, dropping some of the less likely individual noun forms and adjective forms."
            ]
        },
        {
            "question": "What is the purpose of pruning translation options in a factorized model before the main search?",
            "reference-answers": [
                "The purpose of pruning translation options in a factorized model before the main search is to prevent the model from being overwhelmed by too many possibilities, allowing it to focus on the most likely combinations of factors and avoid dropping less likely individual noun forms and combinations that the model would be searching for."
            ]
        },
        {
            "question": "What is the main reason why synchronous factored models fail in translation tasks?",
            "reference-answers": [
                "The main reason why synchronous factored models fail in translation tasks is that all the translation options have to be fully instantiated before entering the main search, and there is no room for under-specified translation options."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen50-slide53/text.txt": [
        {
            "question": "What is the optimal setup for using multiple language models in phrase-based machine translation, according to the author's experience?",
            "reference-answers": [
                "The optimal setup for using multiple language models in phrase-based machine translation is to use the \"big long and morph\" setup, which combines a seven-gram word form model, a four-gram model, and morphological tags, and then further improve it with 15-gram morphological tags."
            ]
        },
        {
            "question": "What is the best setup for using multiple language models in phrase-based MT systems, according to the author's experience?",
            "reference-answers": [
                "The best setup for using multiple language models in phrase-based MT systems is the \"big long and morph\" setup, which combines a 4-gram model trained on a large amount of data, a 7-gram model trained on full word forms, and morphological tags, and this setup gives the best improvement over the basic setup of using only the 7-gram model based on word forms."
            ]
        },
        {
            "question": "What is the optimal setup for using multiple language models in phrase-based machine translation, according to the author's experience?",
            "reference-answers": [
                "The optimal setup for using multiple language models in phrase-based machine translation is to use the \"big long and morph\" setup, which combines a seven-gram word form model, a four-gram model, and morphological tags, and then further improve it with 15-gram morphological tags."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen51-slide54/text.txt": [
        {
            "question": "What are the two techniques that try to handle the sparseness in unmodivation while avoiding the explosion?",
            "reference-answers": [
                "Two-step translation and reverse self-training."
            ]
        },
        {
            "question": "What are the two techniques mentioned that try to handle sparseness in search while avoiding the explosion of search errors?",
            "reference-answers": [
                "Two-step translation and reverse self-training."
            ]
        },
        {
            "question": "What are the two techniques called that try to handle sparseness in search without causing an explosion?",
            "reference-answers": [
                "Two-step translation and reverse self-training."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen52-slide55/text.txt": [
        {
            "question": "What is the primary goal of the first step in the proposed translation system for translating English into lemmatized Czech?",
            "reference-answers": [
                "The primary goal of the first step is to handle reorderings and changes in the number of words for various phrases."
            ]
        },
        {
            "question": "What is the primary goal of the proposed translation system in the given text, and what steps does it involve to achieve this goal?",
            "reference-answers": [
                "The primary goal of the proposed translation system is to translate English into lemmatized Czech, and it involves two main steps: \n\n1. Training a normal phrase-based system to translate from English into lemmatized Czech, which handles reorderings and changes in word number for various phrases, and \n2. Converting the simplified Czech to full Czech, trained on a large corpus of Czech, which is limited to word-for-word translation and phrase length of one."
            ]
        },
        {
            "question": "What is the main goal of the first step in the proposed translation system for translating English into lemmatized Czech?",
            "reference-answers": [
                "The main goal of the first step is to handle reorderings and changes in the number of words for various phrases."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen53-slide56/text.txt": [
        {
            "question": "What is the two-step setup referred to in the context of improving metrics such as BLEUCore and Semantic POS?",
            "reference-answers": [
                "The two-step setup refers to an improvement that was achieved by applying the setup on a small parallel and small monolingual corpus, which resulted in an improvement from vanilla to BLEUCore and Semantic POS metrics."
            ]
        },
        {
            "question": "What two metrics, BLEUCore and Semantic POS, improved after applying the two-step setup to a small parallel and small monolingual corpus?",
            "reference-answers": [
                "BLEUCore and Semantic POS."
            ]
        },
        {
            "question": "What is the name of the metric used to check whether content words are present, regardless of their forms, in addition to BLEUCore?",
            "reference-answers": [
                "Semantic POS."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen54-slide57/text.txt": [
        {
            "question": "What is the reason for the BLEU score to decrease despite the improvement in semantic words counting?",
            "reference-answers": [
                "The BLEU score is not very sensitive about words being dropped, which is why it decreases despite the improvement in semantic words counting."
            ]
        },
        {
            "question": "What is the BLEU score's sensitivity to dropped words, according to the provided information?",
            "reference-answers": [
                "The BLEU score is not very sensitive to dropped words."
            ]
        },
        {
            "question": "What is the effect of using a large monolingual corpus versus a small parallel corpus on the BLEU score?",
            "reference-answers": [
                "Using a large monolingual corpus versus a small parallel corpus makes the BLEU score less sensitive about dropped words."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen55-slide58/text.txt": [
        {
            "question": "What does making assumptions do to someone?",
            "reference-answers": [
                "You are shooting yourself in the foot when you are making these assumptions."
            ]
        },
        {
            "question": "What does making assumptions do to someone?",
            "reference-answers": [
                "You are shooting yourself in the foot when you are making these assumptions."
            ]
        },
        {
            "question": "What action is described as \"shooting yourself in the foot\" in the given text?",
            "reference-answers": [
                "Making assumptions."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen56-slide59/text.txt": [
        {
            "question": "Did the two annotators agree on the effectiveness of the two-step setup?",
            "reference-answers": [
                "No, they didn't agree on the effectiveness of the two-step setup."
            ]
        },
        {
            "question": "Was the two-step setup found to be worthwhile by the annotators?",
            "reference-answers": [
                "No, the two-step setup was not found to be worthwhile by the annotators, as they didn't agree on which sentences it was better."
            ]
        },
        {
            "question": "Was the two-step setup preferred by the annotators?",
            "reference-answers": [
                "Yes, the two-step setup was slightly preferred by each of the two annotators."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen57-slide60/text.txt": [
        {
            "question": "What is the purpose of using a small parallel corpus in the reverse self-training process for phrase-based machine translation?",
            "reference-answers": [
                "The purpose of using a small parallel corpus in the reverse self-training process for phrase-based machine translation is to illustrate how the word forms can be translated in different roles within a sentence, allowing the translation model to learn the correct word forms."
            ]
        },
        {
            "question": "What is the purpose of the reverse self-training technique in phrase-based machine translation?",
            "reference-answers": [
                "The purpose of the reverse self-training technique in phrase-based machine translation is to get the needed word forms in the parallel data, which is based on a translation model that proposes word forms to consider, allowing the selection of the right word forms."
            ]
        },
        {
            "question": "What is the purpose of using a small parallel corpus to help the reverse self-training process in phrase-based machine translation?",
            "reference-answers": [
                "The small parallel corpus is used to illustrate how the word forms can be translated in different sentences, showing the differences in Czech word forms due to different roles of the cat in the sentence, and to help the reverse self-training process by providing examples of word forms that can be produced with the existing system."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen58-slide61/text.txt": [
        {
            "question": "How would translating a phrase directly affect the usefulness of the resulting parallel data in a machine translation system?",
            "reference-answers": [
                "Translating a phrase directly would result in an unknown word, making the resulting parallel data of no use, as it would not provide any useful information for the machine translation system."
            ]
        },
        {
            "question": "How could we synthesize the source side and include this monolingual data in our parallel data collection?",
            "reference-answers": [
                "We would not learn anything useful."
            ]
        },
        {
            "question": "How would translating a phrase directly affect the usefulness of the resulting monolingual data?",
            "reference-answers": [
                "Translating a phrase directly would result in the inclusion of unknown words, making the resulting monolingual data of no use because it would not teach anything useful."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen59-slide63/text.txt": [
        {
            "question": "What is the difference in how the Czech language is treated in the reverse translation system compared to the English language?",
            "reference-answers": [
                "In the reverse translation system, Czech is treated differently than English in that Czech has a distinction of cases, whereas English does not, and therefore, the system will rely on lemmas to translate Czech forms, whereas it will not know how to translate English forms without the context of the lemmas."
            ]
        },
        {
            "question": "Will the Czech lemma kočka always be translated as \"cat\" in the reverse translation system?",
            "reference-answers": [
                "Yes, according to the text, the Czech lemma kočka will be translated as \"cat\" in all cases."
            ]
        },
        {
            "question": "What type of system will be trained for translation in English, as opposed to Czech?",
            "reference-answers": [
                "A reverse system that backs off or relies also on the lemmas."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen60-slide64/text.txt": [
        {
            "question": "What is the meaning of the sentence \"Chetlsem okočce\"?",
            "reference-answers": [
                "This sentence, Chetlsem okočce, as I read about a cat."
            ]
        },
        {
            "question": "What is the sentence Chetlsem okočce that is included in the parallel data?",
            "reference-answers": [
                "And now you include this in your parallel data and that's the sentence Chetlsem okočce, as I read about a cat."
            ]
        },
        {
            "question": "What is the original sentence about that has been included in the parallel data?",
            "reference-answers": [
                "A cat."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen61-slide65/text.txt": [
        {
            "question": "What is the benefit of learning a new phrase about a cat, specifically the word \"okotse\"?",
            "reference-answers": [
                "You get to extend the translation model to be able to offer the forms that the language model will then happily appreciate."
            ]
        },
        {
            "question": "What is the benefit of learning a new phrase about a cat called \"okotse\"?",
            "reference-answers": [
                "You get to extend the translation model to offer the forms that the language model will then happily appreciate."
            ]
        },
        {
            "question": "What type of word is being extended by the translation model in the given text?",
            "reference-answers": [
                "A new form of a noun word."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen62-slide66/text.txt": [
        {
            "question": "What approach would you use to create synthetic parallel data for the reverse translation step in a machine translation model, and how would this approach differ for languages with richer or poorer morphology?",
            "reference-answers": [
                "For the reverse translation step, you can create synthetic parallel data by translating only the form to the unknown, and then resorting to translating the Czech lemma (kočka) to the English form, essentially making up the English side. This approach would be more suitable for languages with poorer morphology, such as English."
            ]
        },
        {
            "question": "What type of linguistic expertise is required when translating from one language to another in the reverse translation step?",
            "reference-answers": [
                "For other languages, you would have to apply other linguistic expertise."
            ]
        },
        {
            "question": "What type of linguistic expertise would be required to train a model for translating Czech into another language, such as Turkish?",
            "reference-answers": [
                "For other languages you would have to apply other linguistic expertise."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen63-slide67/text.txt": [
        {
            "question": "What is the effect of using a large language model with a small amount of monolingual data on BLEU scores?",
            "reference-answers": [
                "BLEU scores will increase as the monolingual data grows, indicating that the large language model can estimate n-grams more reliably."
            ]
        },
        {
            "question": "What is the effect of using a large language model with a small amount of monolingual data on BLEU scores?",
            "reference-answers": [
                "BLEU scores will increase as the monolingual data grows, indicating that the large language model can estimate n-grams more reliably."
            ]
        },
        {
            "question": "What type of data is likely to result in higher BLEU scores as it grows?",
            "reference-answers": [
                "monolingual data"
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen64-slide68/text.txt": [
        {
            "question": "What is the benefit of including all word forms from monolingual data in a translation model?",
            "reference-answers": [
                "You get double the increase."
            ]
        },
        {
            "question": "What is the benefit of including all word forms from monolingual data in a translation model?",
            "reference-answers": [
                "You get double the increase."
            ]
        },
        {
            "question": "What is the benefit of including all word forms from monolingual data in a translation model?",
            "reference-answers": [
                "You get double the increase."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen65-slide69/text.txt": [
        {
            "question": "At what point does the approach of using reverse translation become less beneficial due to the large amount of parallel data?",
            "reference-answers": [
                "When you have two million parallel sentences."
            ]
        },
        {
            "question": "At what point does the reverse translation trick no longer provide a benefit in collecting parallel data?",
            "reference-answers": [
                "When you have two million parallel sentences."
            ]
        },
        {
            "question": "What is the point of using the reverse translation trick if the number of parallel sentences exceeds 2 million?",
            "reference-answers": [
                "There is no benefit from using the reverse translation trick if the number of parallel sentences exceeds 2 million."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen66-slide70/text.txt": [
        {
            "question": "What is the topic of the next section to be discussed in the text?",
            "reference-answers": [
                "Morphology in neural machine translation."
            ]
        },
        {
            "question": "What is the topic being discussed in the provided text?",
            "reference-answers": [
                "Morphology in neural machine translation."
            ]
        },
        {
            "question": "What is the topic of the discussion in the provided text?",
            "reference-answers": [
                "Morphology in neural machine translation."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen67-slide71/text.txt": [
        {
            "question": "What is the maximum number of different word forms that a neural machine translation can fit in its embedding tables?",
            "reference-answers": [
                "30 to 80 thousand different word forms."
            ]
        },
        {
            "question": "What is the maximum number of word forms that a neural machine translation system can typically fit in its embedding tables?",
            "reference-answers": [
                "30 to 80 thousand different word forms."
            ]
        },
        {
            "question": "What is the maximum number of different word forms that a neural machine translation with embedding tables can fit?",
            "reference-answers": [
                "30 to 80 thousand different word forms."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen68-slide72/text.txt": [
        {
            "question": "What is the method of constructing the dictionary that involves repeatedly identifying the most frequent character pairs and replacing them with new units?",
            "reference-answers": [
                "The method of constructing the dictionary involves repeatedly identifying the most frequent character pairs and replacing them with new units."
            ]
        },
        {
            "question": "What is the method used to construct the dictionary that breaks down words into units based on the most frequent character pairs?",
            "reference-answers": [
                "The method used to construct the dictionary is that you repeatedly identify which character pairs are often seen together, and then replace the most frequent character pair with a new unit."
            ]
        },
        {
            "question": "What is the method used to construct a fixed-size dictionary that contains frequent words as units and breaks longer words into smaller units?",
            "reference-answers": [
                "The method used to construct a fixed-size dictionary is to repeatedly identify which character pairs are often seen together, and replace the most frequent character pair with a new unit."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen69-slide73/text.txt": [
        {
            "question": "What is the purpose of repeating the merge operation in the context of a vocabulary list with word frequencies?",
            "reference-answers": [
                "The purpose of repeating the merge operation is to count each character pair depending on how often the word was seen, effectively creating a frequency list."
            ]
        },
        {
            "question": "What is the purpose of the merge operation in the context of a vocabulary list with word frequencies?",
            "reference-answers": [
                "The purpose of the merge operation is to count each character pair depending on how often the word was seen, in order to identify frequent character pairs."
            ]
        },
        {
            "question": "What type of data is being counted when a character pair is checked for frequency in the given vocabulary?",
            "reference-answers": [
                "Character pairs."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen70-slide74/text.txt": [
        {
            "question": "What is the new unit introduced to the vocabulary as a result of merging the most frequent character pair in the given example?",
            "reference-answers": [
                "the shape we"
            ]
        },
        {
            "question": "What is the new unit introduced to the vocabulary after merging the most frequent character pair in the given example?",
            "reference-answers": [
                "the shape we."
            ]
        },
        {
            "question": "What is the new unit introduced to the vocabulary in the example?",
            "reference-answers": [
                "the new unit introduced to the vocabulary is \"we\"."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen71-slide75/text.txt": [
        {
            "question": "What is the result of replacing a pair of characters in the original corpus with a single new letter?",
            "reference-answers": [
                "Your corpus now looks differently."
            ]
        },
        {
            "question": "What is the purpose of scanning for the most frequent pair of characters in the corpus after replacing a pair of characters with a single new letter?",
            "reference-answers": [
                "Your corpus now looks differently, so you have to scan for the most frequent pair of characters."
            ]
        },
        {
            "question": "What happens to the frequency of character pairs in a corpus when you replace a pair of characters with a single new letter?",
            "reference-answers": [
                "Your corpus now looks differently, and you have to scan for the most frequent pair of characters again."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen72-slide76/text.txt": [
        {
            "question": "What is the new merge operation introduced in the setup to aid in text compression?",
            "reference-answers": [
                "The new merge operation is a V followed by R, treating V, E, R as a single unit."
            ]
        },
        {
            "question": "What is the new merge operation that is introduced to compress the text during the setup, involving the letters V, E, and R?",
            "reference-answers": [
                "The new merge operation is the combination of V, E, and R as a single unit."
            ]
        },
        {
            "question": "What type of operation is introduced in the setup to treat 'V, E, R' as a single unit for text compression?",
            "reference-answers": [
                "A new merge operation that introduces 'V' followed by 'R'."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen73-slide77/text.txt": [
        {
            "question": "What is the speaker referring to when they say \"the next merge will be\"?",
            "reference-answers": [
                "The next merge will be a merge that is probably going to happen."
            ]
        },
        {
            "question": "What is the next merge likely to be?",
            "reference-answers": [
                "The next merge will be a merge."
            ]
        },
        {
            "question": "What is the expected outcome of the next merge?",
            "reference-answers": [
                "The next merge will be probably yes."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen74-slide78/text.txt": [
        {
            "question": "What is the single character that the given ST goes into?",
            "reference-answers": [
                "This"
            ]
        },
        {
            "question": "What is the relationship between the words \"This\", \"ST\", and \"single character\"?",
            "reference-answers": [
                "The word \"single character\" is describing the word \"ST\"."
            ]
        },
        {
            "question": "What type of punctuation is represented by the abbreviation \"ST\" in the given text?",
            "reference-answers": [
                "Single character ST."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen75-slide79/text.txt": [
        {
            "question": "What is the primary advantage of neural subword units over phrase-based subword units in machine translation systems?",
            "reference-answers": [
                "Neural subword units are conceptually simpler than phrase-based subword units as they don't require manual consideration of morphological richness, allowing the model to learn it automatically by observing sequences of subword units."
            ]
        },
        {
            "question": "What is the primary difference between phrase-based encoding and neural encoding in the context of machine translation?",
            "reference-answers": [
                "The primary difference between phrase-based encoding and neural encoding in the context of machine translation is that neural encoding learns the correct combination of subword units automatically, whereas phrase-based encoding requires manual specification of morphological richness, such as stems and endings."
            ]
        },
        {
            "question": "What is the main advantage of neural empty over phrase-based empty in machine translation systems?",
            "reference-answers": [
                "Neural empty is conceptually simpler than phrase-based empty because it learns the correct combination of subword units automatically and handles morphological richness without requiring explicit care."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen76-slide80/text.txt": [
        {
            "question": "What is the difference in how the sub-bord text encoder (STE) and Byte Pair Encoding (BPE) handle words with suffixes, and how does this affect the model's ability to generalize and understand word relationships?",
            "reference-answers": [
                "STE (sub-bord text encoder) adds an underscore at the end of the word, which allows it to separate words with empty suffixes, enabling the model to generalize and understand word relationships. In contrast, BPE (Byte Pair Encoding) in its default variation does not handle empty suffixes well, as it treats them as unfinished words and may break them into separate components, leading to a loss of word relationships and the model's ability to generalize."
            ]
        },
        {
            "question": "What is the effect of adding underscores to the end of words when processing a corpus with Byte Pair Encoding (BPE)?",
            "reference-answers": [
                "The addition of underscores to the end of words when processing a corpus with BPE allows the model to see the word as a single unit, even if the ending is empty or includes a single word, thereby enabling it to generalize the word's behavior."
            ]
        },
        {
            "question": "What is the effect of adding underscores to the end of words before processing with BPE, compared to processing without them?",
            "reference-answers": [
                "When adding underscores to the end of words before processing with BPE, it allows the model to separate empty suffixes and unfinished words, resulting in the same token being produced for words with or without an empty suffix, whereas without the underscores, empty suffixes are not separated and can lead to the broken identity of the word."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen77-slide81/text.txt": [
        {
            "question": "What was found to be the most effective technique for improving the BLEU score in German-to-Czech experiments using BPE?",
            "reference-answers": [
                "The sub-vortex encoder from tensor to tensor was found to be the most effective technique for improving the BLEU score in German-to-Czech experiments using BPE."
            ]
        },
        {
            "question": "What was the best technique found for improving the performance of BLEU scores in German-to-Czech experiments?",
            "reference-answers": [
                "The sub-vortex encoder from tensor to tensor was the best technique found for improving the performance of BLEU scores in German-to-Czech experiments."
            ]
        },
        {
            "question": "What technique did the authors find to be the most effective for improving the BLEU score in their German-to-Czech experiments?",
            "reference-answers": [
                "The sub-vortex encoder from tensor to tensor was the most effective technique for improving the BLEU score in their German-to-Czech experiments."
            ]
        }
    ],
    "nmt-class/lecture06-morphology/screen78-slide82/text.txt": [
        {
            "question": "What was found to be the best method for linguistically motivated segmentation of words in the German to Czech setups?",
            "reference-answers": [
                "The sub-tex encoder worked best."
            ]
        },
        {
            "question": "What was found to be the best approach for linguistic motivated segmentation of words in the German to Czech setups?",
            "reference-answers": [
                "The sub-tex encoder worked best."
            ]
        },
        {
            "question": "What type of linguistic separation methods were used in the German to Czech setups mentioned in the text?",
            "reference-answers": [
                "In the German to Czech setups, unsupervised and supervised linguistically motivated segmentation of words were used, including supervised segmentation based on a derivation dictionary of Czech word forms."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen01-slide01/text.txt": [
        {
            "question": "What type of machine translation approaches will be discussed in today's lecture?",
            "reference-answers": [
                "Pre-neural machine translation approaches."
            ]
        },
        {
            "question": "What type of machine translation approaches will be discussed in today's lecture?",
            "reference-answers": [
                "Pre-neural machine translation approaches."
            ]
        },
        {
            "question": "What type of machine translation approaches will be covered in today's lecture?",
            "reference-answers": [
                "Pre-neural machine translation approaches."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen02-slide02/text.txt": [
        {
            "question": "What is the \"tectorochromatic layer\" in the Pragueian approach to machine translation?",
            "reference-answers": [
                "The \"tectorochromatic layer\" is a deep syntactic tree in the Pragueian approach to machine translation."
            ]
        },
        {
            "question": "What is the name of the tectorochromatic layer approach that has been built for over a decade to aid in machine translation?",
            "reference-answers": [
                "The tectorochromatic layer approach is called the Pragueian approach."
            ]
        },
        {
            "question": "What is the Tectorochromatic layer in machine translation, and how does it relate to the Pragueian approach?",
            "reference-answers": [
                "The Tectorochromatic layer is a concept from the Pragueian approach to machine translation, specifically a deep syntactic tree approach that has been built over a decade and has helped machine translation in the past, but is currently dormant due to the lack of neural MT development to utilize it."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen03-slide03/text.txt": [
        {
            "question": "What were the main limitations of phrase-based machine translation systems before Neural MT, particularly in terms of grammatical coherence and sentence structure?",
            "reference-answers": [
                "The main limitations of phrase-based machine translation systems before Neural MT were that they didn't check for grammatical coherence and that sentences could easily go beyond a certain word limit, resulting in word-salad outputs that were hard to understand. Additionally, phrases did not allow for gaps, and reordering modules were weak, lacking explicit linguistic information to determine sentence structure."
            ]
        },
        {
            "question": "What was the primary problem with phrase-based machine translation systems, specifically in terms of grammatical coherence and sentence structure?",
            "reference-answers": [
                "The primary problem with phrase-based machine translation systems was that the phrases didn't check for grammatical coherence and didn't allow for gaps, which made it impossible to produce grammatically correct sentences with proper syntactic structure."
            ]
        },
        {
            "question": "What were the main limitations of phrase-based machine translation systems before Neural MT, specifically regarding grammatical coherence and sentence structure?",
            "reference-answers": [
                "The main limitations of phrase-based machine translation systems before Neural MT were that they didn't check for grammatical coherence and that sentences could easily go beyond a certain word limit, resulting in word-salad outputs that were hard to understand. Additionally, phrases did not allow for gaps, which are necessary for certain language constructions, and the reordering modules were weak, lacking explicit linguistic information to determine sentence structure."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen04-slide04/text.txt": [
        {
            "question": "What type of model was the hierarchical model that tried to solve some of the issues mentioned in the data?",
            "reference-answers": [
                "A hierarchical model."
            ]
        },
        {
            "question": "What type of model was the hierarchical model that tried to solve some of the issues mentioned in the text?",
            "reference-answers": [
                "A hierarchical model."
            ]
        },
        {
            "question": "What type of model was the hierarchical model that tried to solve some of the issues mentioned in the text?",
            "reference-answers": [
                "A hierarchical model."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen05-slide05/text.txt": [
        {
            "question": "What is a limitation of the 2005 model in terms of grammatical structure validation?",
            "reference-answers": [
                "The 2005 model does not check what fits into gaps in phrases, it only allows gaps in phrases, and it will not validate whether a sentence has a grammatical structure."
            ]
        },
        {
            "question": "What are the limitations of the grammatical model introduced by David Chang in 2005?",
            "reference-answers": [
                "The model does not check what fits into gaps, only allows gaps in phrases, and does not preserve grammatical structure for invalid inputs, resulting in nonsensical translations."
            ]
        },
        {
            "question": "What type of grammatical model is the 2005 system described as, which was introduced by David Chang?",
            "reference-answers": [
                "It is a hierarchical approach."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen06-slide06/text.txt": [
        {
            "question": "What is the difference between phrase-based machine translation and the hierarchical model in extracting phrases?",
            "reference-answers": [
                "In phrase-based machine translation, phrases are extracted as allowed by the data, whereas in the hierarchical model, smaller phrases can be subtracted from bigger phrases."
            ]
        },
        {
            "question": "What is the difference between phrase-based machine translation and the hierarchical model in terms of phrase extraction?",
            "reference-answers": [
                "In phrase-based machine translation, phrases are extracted as allowed by the data, whereas in the hierarchical model, smaller phrases can be subtracted from bigger phrases."
            ]
        },
        {
            "question": "What is the difference between phrase-based machine translation and the hierarchical model?",
            "reference-answers": [
                "In phrase-based machine translation, you start with a pair of sentences and word alignments, and extract phrases as allowed by the data. In contrast, the hierarchical model also allows you to subtract smaller phrases from the bigger phrase."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen07-slide07/text.txt": [
        {
            "question": "What is the role of the non-terminal 'x' in the hierarchical model described in the text?",
            "reference-answers": [
                "The non-terminal 'x' is the only non-terminal used in the hierarchical model, and it represents the unindexed non-terminal in both the source and target phrases."
            ]
        },
        {
            "question": "What is the purpose of the non-terminal 'x' in the hierarchical model described in the text?",
            "reference-answers": [
                "The non-terminal 'x' is used to represent the unch Alumni criminal numbered in the source size and target size."
            ]
        },
        {
            "question": "What is the only non-terminal used in this hierarchical model of sentence construction?",
            "reference-answers": [
                "The only non-terminal used in this hierarchical model of sentence construction is the non-terminal x."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen08-slide08/text.txt": [
        {
            "question": "What is the main issue with the current phrase-based extraction approach in the given problem, and what is the motivation to move to a proper syntactic model?",
            "reference-answers": [
                "The main issue with the current phrase-based extraction approach is that the number of extractable lures is too high due to the arbitrary limitations on the number of symbols and the extraction rules, resulting in a cluttered search space. The motivation to move to a proper syntactic model is that it would allow non-terminals to have linguistic meaning and impose restrictions on what can be plugged in, making the model more proper and reducing the search space."
            ]
        },
        {
            "question": "What limitations were imposed on the extraction of phrases in the phrase-based extraction approach?",
            "reference-answers": [
                "The limitations imposed on the extraction of phrases were that there had to be some evidence in the input, at least one terminal had to be aligned, and it was not allowed to extract more than two phrases from a longer phrase."
            ]
        },
        {
            "question": "What type of model is the language model described in the text, and why is it more difficult to integrate into this new type of search?",
            "reference-answers": [
                "The language model is a non-local feature, making it more difficult to integrate into this new type of search."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen09-slide10/text.txt": [
        {
            "question": "What is the difference between constituency trees and dependency trees in the formal description of sentence structure?",
            "reference-answers": [
                "Constituency trees reflect only how the sentence is divided into smaller parts, whereas dependency trees describe the relationships between words in a sentence."
            ]
        },
        {
            "question": "What is the main difference between constituency trees and dependency trees in describing the structure of a sentence?",
            "reference-answers": [
                "Constituency trees reflect only how the sentence is divided into smaller parts, whereas dependency trees describe the relationships between words in a sentence."
            ]
        },
        {
            "question": "What is the main difference between constituency trees and dependency trees in the formal descriptions of sentence structure?",
            "reference-answers": [
                "Constituency trees reflect only how the sentence is divided into smaller parts, whereas dependency trees reflect both how the sentence is divided into smaller parts and the relationships between the parts."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen10-slide11/text.txt": [
        {
            "question": "What is the most important part of a sentence that controls the structure beneath its constituents, based on the given explanation?",
            "reference-answers": [
                "The most important part of a sentence that controls the structure beneath its constituents is the predicate part, specifically the verb."
            ]
        },
        {
            "question": "What is the most important part of a VP that controls the structure of the sentence?",
            "reference-answers": [
                "The verb."
            ]
        },
        {
            "question": "What is the most important part of a sentence that governs the whole structure beneath, according to the information provided?",
            "reference-answers": [
                "The predicate part, the VP."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen11-slide12/text.txt": [
        {
            "question": "How can a dependency tree be represented in one of two ways?",
            "reference-answers": [
                "In one of these two ways."
            ]
        },
        {
            "question": "What is the purpose of the head word in a dependency tree?",
            "reference-answers": [
                "The head word in a dependency tree is to represent only the relation between the words, pulling up to the very root of the tree and indicating which words belong to which."
            ]
        },
        {
            "question": "What is the main characteristic of a dependency tree in terms of the labels on its nodes?",
            "reference-answers": [
                "There are only terminals in a dependency tree, and no non-terminal labels are on the head node."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen12-slide13/text.txt": [
        {
            "question": "What is the title of the machine translation talk recommended by the teacher?",
            "reference-answers": [
                "Machine translation talk number 10"
            ]
        },
        {
            "question": "What is the title of the machine translation talk that the speaker recommends as a complement to the lecture?",
            "reference-answers": [
                "Machine translation talk number 10"
            ]
        },
        {
            "question": "What is the title of the machine translation talk recommended by the speaker?",
            "reference-answers": [
                "Machine translation talk number 10"
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen13-slide14/text.txt": [
        {
            "question": "What is the maximum likelihood estimate for the probability of a VP being further expanded into V and having two objects, one direct and one indirect?",
            "reference-answers": [
                "Normalize the observed counts of VP being further expanded into V and divide it by the total number of observations of VPN."
            ]
        },
        {
            "question": "What is the purpose of assigning probabilities to each production in a context-free grammar?",
            "reference-answers": [
                "To discriminate among all the options and to indicate which productions are more common in the data, and to normalize the observed counts of VP being further expanded into V."
            ]
        },
        {
            "question": "What is the maximum likelihood estimate for the probability of a VP being further expanded into V and two objects, given a linguistically annotated tree bank?",
            "reference-answers": [
                "Normalize the observed counts of VP being further expanded into V and divide it by the total number of observations of VPN."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen14-slide15/text.txt": [
        {
            "question": "What is the purpose of the table of non-terminal spans in the CKY or CYK parsing algorithm?",
            "reference-answers": [
                "The table of non-terminal spans is used to fill in the items that represent the possible analysis of each cell, and it also contains cells that indicate how the non-terminals are constructed by combining other non-terminals and terminals, ultimately leading to the construction of the full syntactic tree for the sentence."
            ]
        },
        {
            "question": "What is the purpose of the table of non-terminal spans in the parsing process, and how does it relate to the construction of the syntactic tree?",
            "reference-answers": [
                "The table of non-terminal spans is used to fill in the set of states in the parsing process, where each cell corresponds to a particular span in the sentence and lists all the possible analyses of that span. This table helps to construct the syntactic tree by indicating the possible combinations of non-terminals and terminals that can be used to parse the sentence, and the back pointers allow for the construction of the full syntactic tree by traversing back from the final non-terminal S down to the full sentence."
            ]
        },
        {
            "question": "What is the purpose of the CKY or CYK algorithm in parsing a given sentence?",
            "reference-answers": [
                "The CKY or CYK algorithm is used to determine whether a given sentence is allowed by the grammar, by the set of rules or not, in cubic time."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen15-slide16/text.txt": [
        {
            "question": "What is the difference in the order of \"something being somewhere\" in Chinese compared to English, according to the provided context-free grammar rule?",
            "reference-answers": [
                "The order of \"something being somewhere\" is different in Chinese compared to English, and the rule indicates this difference by the coindexation of the non-terminals in the right-hand side of the rule, specifically by swapping the position of X0 and X1 in the left-hand side of the rule."
            ]
        },
        {
            "question": "What is the purpose of the coindexation of non-terminals in the right-hand side of a context-free grammar rule for machine translation?",
            "reference-answers": [
                "The coindexation of non-terminals in the right-hand side of a context-free grammar rule for machine translation indicates that the order of something being somewhere is different in the target language, and it is captured by swapping the position of non-terminals in the left-hand side position."
            ]
        },
        {
            "question": "What type of grammar is described in the example as capturing the double generation for machine translation between two languages?",
            "reference-answers": [
                "A synchronous context-free grammar."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen16-slide17/text.txt": [
        {
            "question": "What would be the outcome if the English tree representing the sentence \"John fell in love with Mary\" were mapped to a constituency tree representing the sentence \"Jan Miluje Marii\" in Czech?",
            "reference-answers": [
                "There would be no way to map these two trees together with the Synchronous context-free grammar, because the English tree is deeper."
            ]
        },
        {
            "question": "What would prevent a synchronous context-free grammar from mapping two constituency trees together if the English tree is deeper than the Czech tree?",
            "reference-answers": [
                "The difference in the number of productions or rule applications in the two trees would prevent a synchronous context-free grammar from mapping them together."
            ]
        },
        {
            "question": "What would be the result of trying to map two constituency trees, one for English and one for Czech, using a synchronous context-free grammar if the English tree is deeper?",
            "reference-answers": [
                "There would be no way to map these two trees together."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen17-slide18/text.txt": [
        {
            "question": "What is the difference between the productions in the Synchronous Tree Substitution Grammars and the way lexicalization is handled in the Czech constituency tree?",
            "reference-answers": [
                "In Synchronous Tree Substitution Grammars, productions are always full subtrees, whereas in the Czech constituency tree, lexicalization is handled by mapping specific slots (verb and object) to specific lexical elements (e.g., FEL to MILUJE, MARI to MARY), and the corresponding component in the Czech tree is a verb phrase, indicating no lexicalization."
            ]
        },
        {
            "question": "What is the purpose of the two slots in the red part of the Synchronous Tree Substitution Grammar for the VP within a full subtree?",
            "reference-answers": [
                "The two slots in the red part of the Synchronous Tree Substitution Grammar for the VP within a full subtree are for the verb and the second (or object), allowing them to be filled with the verb FEL and the verb MARI, respectively, which map to the verb MILUJE and MARY."
            ]
        },
        {
            "question": "What type of grammars are being referred to as Synchronous Tree Substitution Grammars in the provided text?",
            "reference-answers": [
                "Synchronous Tree Substitution Grammars."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen18-slide19/text.txt": [
        {
            "question": "What is the purpose of using a special non-terminal VP in synchronous tree substitution grammars to condense inner structure of subtrees?",
            "reference-answers": [
                "The special non-terminal VP can be used to condense the inner structure of subtrees and only increase the set of non-terminals used, allowing for the same power as synchronous context free grammars."
            ]
        },
        {
            "question": "What is the purpose of using a special non-terminal VP to condense the inner structure of subtrees in synchronous tree substitution grammars?",
            "reference-answers": [
                "The special non-terminal VP can be used to condense the inner structure of subtrees and includes terminals like PP, P, and N, allowing for a more compact representation of the inner structure and enabling the use of a single production to correspond to one-to-one."
            ]
        },
        {
            "question": "What type of generalization is being sought in the mapping between synchronous tree substitution grammars and constituency trees?",
            "reference-answers": [
                "A generalization that allows for mapping between two different trees without having to resort to a very large rule that digests the entire left-hand tree and produces the entire target language tree."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen19-slide20/text.txt": [
        {
            "question": "How does the language model in machine translation differ from the left-to-right processing in phrase-based MT, particularly in terms of input digestion and output production?",
            "reference-answers": [
                "The language model in machine translation differs from the left-to-right processing in phrase-based MT in that the input is digested bottom up and the output is produced in the exact parallel bottom up fashion, whereas in phrase-based MT the input is digested in any order and the output is produced left to right."
            ]
        },
        {
            "question": "What is the main difference in processing style between synchronous substitution grammars/context-free grammars and phrase-based machine translation?",
            "reference-answers": [
                "The main difference in processing style between synchronous substitution grammars/context-free grammars and phrase-based machine translation is that synchronous substitution grammars/context-free grammars process the input sentence bottom up, while phrase-based machine translation processes the input sentence left to right."
            ]
        },
        {
            "question": "What is the main difference between the processing style of synchronous substitution grammars/synchronous context-free grammars in machine translation and phrase-based machine translation?",
            "reference-answers": [
                "The main difference between the processing style of synchronous substitution grammars/synchronous context-free grammars in machine translation and phrase-based machine translation is that in synchronous substitution grammars/synchronous context-free grammars, the input is digested bottom up, and the output is produced in the exact parallel bottom up fashion, whereas in phrase-based machine translation, the input is digested left to right, and the output is produced left to right."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen20-slide21/text.txt": [
        {
            "question": "What is the purpose of the state splitting in the CKY parsing process, and how does it differ from the approach used in phrase-based MT?",
            "reference-answers": [
                "The state splitting is the idea that your search space, all the labels of the boxes that you have on your table are split to contain more information. Normally you would have only one label for x that of the box. So the state splitting is the idea that your search space is larger, your state labels are more fine-grained as is needed by the further processing in the system. This is actually a the problem with the history and the hypothesis recombination that we discussed in the phrase-based MT. Except in phrase-based MT, it was all left to right. Now it's all bottom up, so we have like two ends of history"
            ]
        },
        {
            "question": "What is the purpose of the state splitting in the CKY parsing algorithm for language model scoring?",
            "reference-answers": [
                "The state splitting is the idea that your search space, all the labels of the boxes that you have on your table are split to contain more information, so that the language model can ask what is the word between and what is the word after, in order to score the hypothesis more reliably."
            ]
        },
        {
            "question": "What is the purpose of splitting the state labels in the CKY parsing model to improve language model scoring?",
            "reference-answers": [
                "The state splitting is the idea that your search space, all the labels of the boxes that you have on your table are split to contain more information, so that the language model can ask what is the word between and what is the word after, in order to score the hypothesis more reliably."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen21-slide22/text.txt": [
        {
            "question": "What is the difference between the hierarchical model and the true syntactic trees used in machine translation?",
            "reference-answers": [
                "The hierarchical model is just a hierarchical model, whereas the true syntactic trees used in machine translation have labels assigned to them by linguists when drawing a tree bank."
            ]
        },
        {
            "question": "What type of parsing is used for machine translation according to the text?",
            "reference-answers": [
                "Bottom-up parsing."
            ]
        },
        {
            "question": "What type of parsing is used for machine translation, according to the provided text?",
            "reference-answers": [
                "Bottom-up parsing."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen22-slide23/text.txt": [
        {
            "question": "What is the general outcome of using the hierarchical model, the phrase-based model, and the syntactic model for phrase extraction in language pairs?",
            "reference-answers": [
                "The general outcome is that the hierarchical model was better in some cases, the phrase-based model was better in some cases, and the syntactic model was most often worse."
            ]
        },
        {
            "question": "What are the two reasons for the experimental results showing that the hierarchical model was better, the phrase-based model was better, and the syntactic model was most often worse for various language pairs?",
            "reference-answers": [
                "The two reasons for the experimental results are: \n1. The hierarchical model was better\n2. The phrase-based model was better"
            ]
        },
        {
            "question": "What are the two main factors that determine whether the hierarchical model, the phrase-based model, or the syntactic model is most often better for extraction of phrases in substitution grammars?",
            "reference-answers": [
                "The two main factors that determine whether the hierarchical model, the phrase-based model, or the syntactic model is most often better for extraction of phrases in substitution grammars are:\n\n1. The language pair.\n2. Experimental results showing that sometimes the hierarchical model was better, sometimes the phrase-based model was better, and the syntactic model was most often worse."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen23-slide24/text.txt": [
        {
            "question": "Why is the exam difficult?",
            "reference-answers": [
                "... reasons why that is difficult, why is the exam difficult,..."
            ]
        },
        {
            "question": "Why is it difficult to identify reasons why something is difficult?",
            "reference-answers": [
                "...the reasons why that is difficult, why is the difficulty in identifying reasons why something is difficult not explicitly stated."
            ]
        },
        {
            "question": "Why is the exam difficult?",
            "reference-answers": [
                "... reasons why that is difficult, why is the exam difficult,..."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen24-slide25/text.txt": [
        {
            "question": "What is the main drawback of using syntactic approaches in natural language processing compared to phrase-based and hierarchical approaches?",
            "reference-answers": [
                "Syntactic approaches suffer from too few rules in your extracted rule tables and too few license derivations."
            ]
        },
        {
            "question": "What are some limitations of syntactic approaches compared to phrase-based and hierarchical approaches?",
            "reference-answers": [
                "Syntactic approaches suffer from too few rules in your extracted rule tables and too few license derivations."
            ]
        },
        {
            "question": "What are the two main issues that syntactic approaches suffer from compared to phrase-based and hierarchical approaches?",
            "reference-answers": [
                "Syntactic approaches suffer from too few rules in your extracted rule tables and too few license derivations."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen25-slide26/text.txt": [
        {
            "question": "What is the problem with phrase-based MT that syntactic approach encounters when extracting word alignments?",
            "reference-answers": [
                "When extracting word alignments in phrase-based MT, the syntactic approach encounters the problem that the word alignment \"Green Witch\" is not a constituent in the syntactic tree, leading to a loss of information."
            ]
        },
        {
            "question": "What is the problem with phrase-based MT when extracting translations, according to the syntactic approach?",
            "reference-answers": [
                "When extracting translations in phrase-based MT using the syntactic approach, the problem is that the word alignment also includes syntactic information, which means that \"Green Witch\" is not a constituent in the syntactic tree, leading to a loss of accurate extraction."
            ]
        },
        {
            "question": "What is the problem that arises in phrase-based MT when syntactic information is also present, according to the detailed illustration of the two rules?",
            "reference-answers": [
                "Green Witch is not any constituent in the syntactic tree."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen26-slide27/text.txt": [
        {
            "question": "What is a potential problem with the system's ability to translate a sentence that consists of a noun phrase with a prepositional phrase?",
            "reference-answers": [
                "The system may not be able to translate the sentence as a whole due to the need to decompose it, which can easily introduce an error."
            ]
        },
        {
            "question": "What is a potential problem with the system's ability to translate a noun phrase like \"Taiwan surplus in trade between two shores\"?",
            "reference-answers": [
                "The system cannot translate the noun phrase as a whole, and it has to decompose it, which can easily introduce an error."
            ]
        },
        {
            "question": "What is a problem that can occur when a translation system attempts to translate a noun phrase that is already a single unit in the source language?",
            "reference-answers": [
                "The system may not be able to translate the noun phrase as a whole, and therefore may introduce an error, due to the need to decompose it."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen27-slide28/text.txt": [
        {
            "question": "What is the reason for the loss of coverage of the syntactic-based system in the two languages?",
            "reference-answers": [
                "The loss of coverage of the syntactic-based system in the two languages is due to the presence of a dangling verb phrase, which is a valid constituent in one language but not in the other."
            ]
        },
        {
            "question": "What is the reason for the loss of coverage of the syntactic-based system in the two languages?",
            "reference-answers": [
                "The loss of coverage of the syntactic-based system in the two languages is due to the presence of a dangling verb phrase, which is a valid constituent in one language but not in the other."
            ]
        },
        {
            "question": "What is a valid constituent in one language but not in another language according to the provided TEXT?",
            "reference-answers": [
                "A dangling verb phrase."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen28-slide29/text.txt": [
        {
            "question": "What is the motivation behind binarizing grammatical constructions into smaller binary productions in the syntactic system?",
            "reference-answers": [
                "Binarizing grammatical constructions into smaller binary productions allows the system to extract phrases that would otherwise be non-reachable, and enables the alignments to match with these subparts, thereby increasing the robustness of the machine translation system to handle partly wrong inputs."
            ]
        },
        {
            "question": "What is the purpose of binarizing grammatical constructions in the syntactic system, and how does it relate to extracting phrases from input sentences?",
            "reference-answers": [
                "Binarizing grammatical constructions makes them smaller and decomposes them into smaller bits, allowing them to be used more often and extracting smaller phrases that a phrase-based system would not."
            ]
        },
        {
            "question": "What type of grammatical constructions should be made smaller or decomposed into smaller bits in order to improve the machine translation system's robustness and ability to handle partly wrong inputs?",
            "reference-answers": [
                "Binarize grammatical constructions to convert productions with more elements than two into a sequence of binary productions."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen29-slide30/text.txt": [
        {
            "question": "What is the approach to machine translation described as \"syntax augmented machine translation\" by Ashish Venugopal and Andras Solman?",
            "reference-answers": [
                "The approach to machine translation described as \"syntax augmented machine translation\" by Ashish Venugopal and Andras Solman is constructing artificial phrases by putting pieces together regardless of whether there is any linguistically motivated component."
            ]
        },
        {
            "question": "What is the name of the approach that involves constructing artificial phrases by putting the pieces together without any linguistically motivated component?",
            "reference-answers": [
                "Syntax augmented machine translation by Ashish Venugopal and Andras Solman."
            ]
        },
        {
            "question": "What is the main advantage of the syntax augmented machine translation approach described by Ashish Venugopal and Andras Solman?",
            "reference-answers": [
                "The main advantage of the syntax augmented machine translation approach is that it allows us to process non-grammatical data."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen30-slide31/text.txt": [
        {
            "question": "What is the problem with using a synchronous tree substitution grammar when the input is a multi-word expression, such as \"more than 20 men\"?",
            "reference-answers": [
                "The problem is that the synchronous tree substitution grammar does not allow non-terminals to match when plugging things together, and the rules do not allow to plug a multi-word expression (like \"more than 20 men\") into a slot that expects a single word element (like \"men\")."
            ]
        },
        {
            "question": "What is the problem with the synchronous tree substitution grammar in handling phrases as noun phrases in the plural?",
            "reference-answers": [
                "The problem with the synchronous tree substitution grammar is that it does not allow non-terminals to match when plugging pieces together, which makes it impossible to handle phrases as noun phrases in the plural, as the rules do not allow the non-terminals to be substituted together to form a multi-word expression."
            ]
        },
        {
            "question": "What is the problem that arises when a synchronous tree substitution grammar is given a multi-word expression instead of a single word element, such as \"cats\" or \"men\"?",
            "reference-answers": [
                "The problem that arises is that the synchronous tree substitution grammar expects the non-terminals to match when plugging things together, but in this case, there is no way to plug a multi-word expression into a slot that expects a single word element, such as a noun in plural, because the rules do not allow it."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen31-slide32/text.txt": [
        {
            "question": "What type of substitution is allowed in the STSG model, as opposed to a higher-like model where all non-terminals are the same?",
            "reference-answers": [
                "In the STSG model, only matching substitutions are allowed, as opposed to a higher-like model where any substitution is allowed."
            ]
        },
        {
            "question": "What type of substitution is allowed in the STSG model to make it robust enough to handle real inputs?",
            "reference-answers": [
                "Matching substitutions."
            ]
        },
        {
            "question": "What type of substitutions are currently allowed in the STSG grammar, according to David Cheng's paper?",
            "reference-answers": [
                "Matching substitutions."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen32-slide33/text.txt": [
        {
            "question": "What is the main difference between the hierarchical model and the bottom-up parsing approach in machine translation?",
            "reference-answers": [
                "The hierarchical model uses only one non-terminal, whereas the bottom-up parsing approach needs to keep record of what is in the boxes and uses proper non-terminal labels in the syntactic trees to extract non-isomorphic trees and allow fuzzy matching."
            ]
        },
        {
            "question": "What is the purpose of keeping a record of what is in the boxes during bottom-up parsing in machine translation?",
            "reference-answers": [
                "So that when you are putting the smaller boxes together with the bigger boxes, your language model can run over all the words and score it."
            ]
        },
        {
            "question": "What type of parsing approach is used in machine translation, and what is the purpose of keeping a record of words in boxes during this process?",
            "reference-answers": [
                "The bottom-up approach is used in machine translation. Keeping a record of words in boxes during this process allows the language model to run over all the words and score them, enabling the proper construction of the target side and the use of tricks such as binarization to extract non-isomorphic trees."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen33-slide34/text.txt": [
        {
            "question": "What is the topic of the two empty talks mentioned in the text?",
            "reference-answers": [
                "The topic of the two empty talks mentioned in the text is constituency syntax and dependency syntax."
            ]
        },
        {
            "question": "What is the topic of the empty talk mentioned in the text?",
            "reference-answers": [
                "It is empty and related to constituency syntax and dependency syntax."
            ]
        },
        {
            "question": "What type of syntax is being discussed in the text?",
            "reference-answers": [
                "Constituency syntax."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen34-slide35/text.txt": [
        {
            "question": "What is the main difference between constituency trees and dependency trees in the representation of sentence structure?",
            "reference-answers": [
                "Constituency trees represent the bracketing and the history of how adjacent constituents are put together to make bigger units, whereas dependency trees talk about the sentence as it is written in the end and indicate which words depend on which, showing dependencies that happen along the edges."
            ]
        },
        {
            "question": "What is the main difference between constituency trees and dependency trees in representing the structure of a sentence?",
            "reference-answers": [
                "Constituency trees represent the bracketing and the history of how adjacent constituents are put together to make bigger units, whereas dependency trees talk about the sentence as it is written in the end and indicate which words depend on which, showing dependencies that happen along the edges."
            ]
        },
        {
            "question": "What is the main difference between constituency trees and dependency trees in representing sentence structure?",
            "reference-answers": [
                "Constituency trees represent the bracketing and the history of how adjacent constituents are put together to make bigger units, whereas dependency trees talk about the sentence as it is written in the end and indicate which words depend on which, showing dependencies that happen along the edges."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen35-slide36/text.txt": [
        {
            "question": "What is the difference in the case that the verb \"should be cut\" in a Czech translation, compared to the case when the verb \"should cut\" in the same translation?",
            "reference-answers": [
                "In the Czech translation, the case for the trava (grass) has to be decided based on whether the sentence is passive (\"the grass should be cut\") or active (\"you should cut the grass around your house\"). In the passive sentence, the trava serves as the subject and needs to be in the nominative case, whereas in the active sentence, the trava serves as the object and needs to be in the accusative case."
            ]
        },
        {
            "question": "What is the case that the word \"trava\" needs to be in the Czech translation of the sentence \"The grass around your house should be cut\"?",
            "reference-answers": [
                "The word \"trava\" needs to be in the nominative case in the Czech translation of the sentence \"The grass around your house should be cut\", when the sentence is passive, like \"the grass should be cut\"."
            ]
        },
        {
            "question": "What is the main difference in the way the verb 'cut' is translated into Czech, depending on whether the sentence is in active or passive voice?",
            "reference-answers": [
                "The main difference in the way the verb 'cut' is translated into Czech, depending on whether the sentence is in active or passive voice, is the case of the word \"trava\" (grass). In the active voice, \"trava\" serves as the object and needs to take the accusative case, whereas in the passive voice, \"trava\" serves as the subject and needs to take the nominative case."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen36-slide37/text.txt": [
        {
            "question": "What is the main advantage of using a dependency tree over n-grams in predicting lexical choices and grammatical categories in a phrase-based translation system?",
            "reference-answers": [
                "The main advantage of using a dependency tree over n-grams in predicting lexical choices and grammatical categories in a phrase-based translation system is that the context in the dependency tree is better at predicting the lexical choices and the choice of the grammatical categories."
            ]
        },
        {
            "question": "What is the main difference between adjacency and dependency trees in predicting lexical choices and grammatical categories?",
            "reference-answers": [
                "In adjacency trees, the words are far away from each other, whereas in dependency trees, the dependent words are very often close or next to each other."
            ]
        },
        {
            "question": "What is a key advantage of the dependency approach over phrase-based translation in predicting lexical choices and grammatical categories?",
            "reference-answers": [
                "The context in the dependency tree is better at predicting the lexical choices and the choice of the grammatical categories than n-grams."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen37-slide38/text.txt": [
        {
            "question": "What is the purpose of using hierarchical phrases with gaps in a sentence?",
            "reference-answers": [
                "The purpose of using hierarchical phrases with gaps is to cover long distance dependencies in a sentence."
            ]
        },
        {
            "question": "What is an example of a hierarchical phrase with a gap that can cover long distance dependency?",
            "reference-answers": [
                "We can create a gap phrase with \"that should be cut soon\" and use this gap to cover all the words that are pumped in between, such as \"grass around your house\"."
            ]
        },
        {
            "question": "What type of dependency can a hierarchical phrase with gaps cover?",
            "reference-answers": [
                "One long distance dependency."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen38-slide39/text.txt": [
        {
            "question": "What is the phenomenon of \"crossing brackets\" in the context of linguistics, and how is it handled in dependency trees?",
            "reference-answers": [
                "The phenomenon of \"crossing brackets\" in linguistics refers to the movement of a word outside of its normal position in a sentence, resulting in a non-projective structure. This is handled in dependency trees by introducing traces, which are co-indexed variables that represent the moved word. The moved word is then indicated as being \"crossed out\" or \"torn away\" from its original position, and its trace is shown in the tree, indicating that it still depends on the verb and other elements in the sentence."
            ]
        },
        {
            "question": "What is the phenomenon of \"crossing brackets\" in linguistics, according to the explanation provided?",
            "reference-answers": [
                "The phenomenon of \"crossing brackets\" in linguistics refers to the movement of a word outside of its normal position in a sentence, resulting in a reordering of the word order that cannot be accounted for by the hierarchical assumption of constituency trees. This movement is represented by the introduction of \"traces\" or \"co-indexed variables\" that indicate the word's original position in the sentence."
            ]
        },
        {
            "question": "What is the phenomenon of \"crossing brackets\" in the context of linguistics, and how is it handled in grammar rules?",
            "reference-answers": [
                "The phenomenon of \"crossing brackets\" in linguistics refers to the movement of a word outside of its normal position in a sentence, resulting in a non-projective structure. This is handled in grammar rules by introducing \"traces\", which are co-indexed variables that represent the moved word. These traces are used to indicate that the word has been moved out of its normal position, allowing the grammar to correctly analyze the sentence."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen39-slide40/text.txt": [
        {
            "question": "What is the difference between a projective tree and a non-projective tree in the context of dependency trees?",
            "reference-answers": [
                "A projective tree is a dependency tree that can be represented by a constituency-free grammar, and it has no gaps. A non-projective tree, on the other hand, has gaps and cannot be represented by a constituency-free grammar, but it can be handled by a modelly context-sensitive grammar."
            ]
        },
        {
            "question": "What is the difference between a projective tree and a non-projective tree in the context of dependency trees?",
            "reference-answers": [
                "A projective tree is a dependency tree that can be represented by a constituency-free grammar, and it has no gaps. A non-projective tree, on the other hand, has gaps and cannot be represented by a constituency-free grammar, but it can be handled by a modelly context-sensitive grammar."
            ]
        },
        {
            "question": "What is the difference between a projective tree and a non-projective tree in terms of their representation and the grammatical systems that can handle them?",
            "reference-answers": [
                "A projective tree can be represented by a constituency-free grammar, whereas a non-projective tree cannot, and requires a more complex grammatical system, such as a context-sensitive grammar, to handle its gaps."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen40-slide41/text.txt": [
        {
            "question": "What is the word order required in Dutch to indicate that John Grass saw something being cut?",
            "reference-answers": [
                "In Dutch, you would have to use the word order that I just said: Thing in Dutch that John Grass saw being cut."
            ]
        },
        {
            "question": "What is the word order required in Dutch to express the sentence \"Thing in Dutch that John Grass saw being cut\"?",
            "reference-answers": [
                "In Dutch, you would have to use the word order that I just said: Thing in Dutch that John Grass saw being cut."
            ]
        },
        {
            "question": "What is the word order required in Dutch to express the same meaning as \"Thing in Dutch that John Grass saw being cut\"?",
            "reference-answers": [
                "In Dutch, you would have to use the word order that I just said: Thing in Dutch that John Grass saw being cut."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen41-slide42/text.txt": [
        {
            "question": "What is the consequence of applying two dependency rules at the same time in the parse tree for the given Czech sentence?",
            "reference-answers": [
                "Either you use this tree first and for that you already have to have the the saw being digested and packed in a box. And then the other element, this John sits outside and there is no way to unbox the packed thing already."
            ]
        },
        {
            "question": "What is the consequence of trying to apply two dependencies in a single derivation in the context of Czech grammar translation?",
            "reference-answers": [
                "There is a big risk that the system will then make the bad choice."
            ]
        },
        {
            "question": "What is the consequence of attempting to apply two rules simultaneously in the hierarchical approach to translation into Czech?",
            "reference-answers": [
                "There is no way to apply these two rules in a single derivation."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen42-slide43/text.txt": [
        {
            "question": "What percentage of Czech sentences contain non-projectivity, with many gaps?",
            "reference-answers": [
                "Almost a quarter of Czech sentences contain non-projectivity."
            ]
        },
        {
            "question": "What percentage of Czech sentences contain non-projectivity, with the remaining sentences being well-nested with at most one gap?",
            "reference-answers": [
                "Almost a quarter of Czech sentences contain non-projectivity, while 99.5% of Czech sentences are actually well-nested with at most one gap."
            ]
        },
        {
            "question": "What percentage of Czech sentences contain non-projectivity, with many gaps?",
            "reference-answers": [
                "Almost a quarter of Czech sentences contain non-projectivity."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen43-slide44/text.txt": [
        {
            "question": "What is a key advantage of dependency trees over constituency trees in the analysis of Czech language?",
            "reference-answers": [
                "They are more appropriate for Czech than constituency trees because we have frequent non-projectivity."
            ]
        },
        {
            "question": "What type of tree is more appropriate for Czech than constituency trees due to frequent non-projectivity?",
            "reference-answers": [
                "Dependency trees."
            ]
        },
        {
            "question": "What type of tree is more appropriate for analyzing Czech language due to frequent non-projectivity?",
            "reference-answers": [
                "Dependency trees."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen44-slide45/text.txt": [
        {
            "question": "What is the difference between the observed pair of trees in machine translation and the dependency trees described?",
            "reference-answers": [
                "The observed pair of trees in machine translation and the dependency trees described are the same, as the observed pair of trees are now dependency trees."
            ]
        },
        {
            "question": "What is the purpose of the dependency trees in machine translation, according to the provided text?",
            "reference-answers": [
                "The trees are now dependency trees, so there is no non-terminals."
            ]
        },
        {
            "question": "What is the main difference between the original \"pair of trees\" and the \"dependency trees\" mentioned in the context of machine translation?",
            "reference-answers": [
                "There is no non-terminals in dependency trees."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen46-slide47/text.txt": [
        {
            "question": "What is the purpose of decomposing trees into smaller treelets in the context of a substitution grammar?",
            "reference-answers": [
                "You will have a dictionary of treelets that can be used to synchronously use these treelets on both the source and target sides to cover the source sentence and build the target sentence."
            ]
        },
        {
            "question": "What is the purpose of decomposing trees into smaller treelets in the context of synchronously using them for source and target sentence generation?",
            "reference-answers": [
                "You will have a dictionary of treelets that can be used to synchronously use these treelets on both the source side and target side to cover the source sentence and build the target sentence."
            ]
        },
        {
            "question": "What is the purpose of decomposing trees into smaller treelets in the context of synchronously using them on both the source and target sides?",
            "reference-answers": [
                "You will have a dictionary of treelets that can be used to synchronously use these treelets on both the source and target sides to cover the source sentence and build the target sentence."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen47-slide52/text.txt": [
        {
            "question": "What approach did you initially aim to use for translation, and what layers of description did you intend to apply it to?",
            "reference-answers": [
                "The synchronous tree substitution grammar approach was initially aimed to be used for translation, and it was intended to be applied at both the surface syntactic level and the deep syntactic level."
            ]
        },
        {
            "question": "What was the goal of the author's thesis several years ago?",
            "reference-answers": [
                "To transfer translation with the syntactic trees using the synchronous tree substitution grammar approach at both the surface and deep syntactic levels, and to be applicable at any of these layers of description."
            ]
        },
        {
            "question": "What approach did the author's thesis aim to transfer, specifically in relation to translation of syntactic trees?",
            "reference-answers": [
                "The synchronous tree substitution grammar approach."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen48-slide49/text.txt": [
        {
            "question": "What is the topic of the talk mentioned in the given text?",
            "reference-answers": [
                "Deep syntax."
            ]
        },
        {
            "question": "What is the topic of the discussion in the provided text?",
            "reference-answers": [
                "Deep syntax."
            ]
        },
        {
            "question": "What is the purpose of a dedicated empty talk mentioned in the context of deep syntax?",
            "reference-answers": [
                "The purpose of a dedicated empty talk mentioned in the context of deep syntax is not explicitly stated in the provided text."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen49-slide50/text.txt": [
        {
            "question": "What is the name of the more successful machine translation system that the author compares to the STSG approach?",
            "reference-answers": [
                "The tecto-empty machine translation system."
            ]
        },
        {
            "question": "What is the name of the more successful machine translation system that was developed, and what assumption did it not make that contributed to its success?",
            "reference-answers": [
                "The more successful machine translation system is called the \"tecto-empty machine translation system\" and it did not make the assumptions that the author made in the original system, which contributed to its success."
            ]
        },
        {
            "question": "What approach did the author find to be more successful than the STSG approach in machine translation?",
            "reference-answers": [
                "The tecto-empty machine translation system."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen50-slide51/text.txt": [
        {
            "question": "When did the formal formulation of the textogrammatic layer theory start in the Prague linguistic circle?",
            "reference-answers": [
                "The Prague linguistic circle in the mid-war era."
            ]
        },
        {
            "question": "When did the formal formulation of the textogrammatic layer theory start in the Prague linguistic circle?",
            "reference-answers": [
                "The Prague linguistic circle in the mid-war era."
            ]
        },
        {
            "question": "When did the textogrammatic layer theory formally start to be formulated?",
            "reference-answers": [
                "In the mid-war era, the textogrammatic layer theory formally started to be formulated."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen51-slide52/text.txt": [
        {
            "question": "What is the Prague Dependency 3 Bank, and how is it used in the process of analyzing a sentence?",
            "reference-answers": [
                "The Prague Dependency 3 Bank is the source of the input sentence, and it is used as the starting point for analyzing a sentence, with its sequence of space-delimited tokens being the initial step in the process."
            ]
        },
        {
            "question": "What is an example of a node that was added in the Prague Dependency 3 Bank to represent a subject that is not pronounced in a Czech sentence?",
            "reference-answers": [
                "An actor for the subject, which was later prod-dropped."
            ]
        },
        {
            "question": "What type of language is Czech, according to the provided information?",
            "reference-answers": [
                "A prodrop language."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen52-slide52/text.txt": [
        {
            "question": "What is the difference in representation between the auxiliary words in the analytical and tectogrammatical levels of representation in a sentence?",
            "reference-answers": [
                "When moving from the analytical to the tectogrammatical level, auxiliary words are hidden and their information is stored in attributes, and the active and passive voice, as well as coreference, are resolved."
            ]
        },
        {
            "question": "What is the role of auxiliary words in the transition from the analytical to the tectogrammatical level of representation in linguistic annotation?",
            "reference-answers": [
                "When moving from the analytical to the tectogrammatical level of representation, auxiliary words need to be hidden, and their information is stored in attributes."
            ]
        },
        {
            "question": "What is the main difference between the auxiliary words in Czech and their counterparts in English?",
            "reference-answers": [
                "There is not a big correspondence between the Czech auxiliaries and the English auxiliaries."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen53-slide52/text.txt": [
        {
            "question": "What is the difference in the number and matching of auxiliaries between Czech and English sentences at the surface syntactic level?",
            "reference-answers": [
                "In Czech sentences, there are more auxiliaries than in English sentences, and the auxiliaries do not match with each other well."
            ]
        },
        {
            "question": "What is the difference in the number and matching of auxiliaries in the Czech and English sentences at the surface syntactic level?",
            "reference-answers": [
                "In the Czech sentence, there are more auxiliaries than in the English sentence, and the auxiliaries do not match with each other well."
            ]
        },
        {
            "question": "What is the difference in the number and matching of auxiliaries between Czech and English sentences at the surface syntactic level?",
            "reference-answers": [
                "In Czech sentences, there are more auxiliaries than in English sentences, and the auxiliaries do not match with each other well."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen54-slide52/text.txt": [
        {
            "question": "What is the term used to describe the relationship between the changing entity, the one who should change, and the pronoun referring to what should be changed?",
            "reference-answers": [
                "predicate argument structure"
            ]
        },
        {
            "question": "What is the term used to describe the structurally identical tectogrammatical trees that also share the same isomorphic properties?",
            "reference-answers": [
                "Structurally identical and isomorphic."
            ]
        },
        {
            "question": "What is the predicate argument structure of the sentence referred to in the TEXT?",
            "reference-answers": [
                "There is this event of changing, there is this someone who should be changing things, and there is this something, the pronoun, that refers to what should be changed."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen55-slide56/text.txt": [
        {
            "question": "What is the main advantage of using the tectogrammatic layer in the proposed translation system compared to direct translation?",
            "reference-answers": [
                "The main advantage of using the tectogrammatic layer is that the transfer at this layer is easier than direct translation because the structures are smaller, and long distance dependencies are not relevant."
            ]
        },
        {
            "question": "What is the expected benefit of using a tectogrammatic layer in the translation system compared to direct translation?",
            "reference-answers": [
                "The expected benefit of using a tectogrammatic layer is that the transfer at the tectogrammatic layer should be easier than direct translation, because the structures are smaller and long distance dependencies are not relevant."
            ]
        },
        {
            "question": "What is the main advantage of the tectogrammatic layer in the proposed system for English and Czech translation?",
            "reference-answers": [
                "The main advantage of the tectogrammatic layer is that the transfer at the tectogrammatic layer is easier than direct translation because the structures are smaller."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen56-slide57/text.txt": [
        {
            "question": "What is the approach the author had in replacing the red subtree with a smaller English subtree in synchronous tree substitution grammars?",
            "reference-answers": [
                "The author would replace the red subtree with a smaller English subtree in synchronous tree substitution grammars by decomposing the input into tree leds, replacing tree leds with their translations, and then joining these tree leds to create the full tree."
            ]
        },
        {
            "question": "What is the purpose of decomposing the input into tree leds in the given approach?",
            "reference-answers": [
                "The input would be decomposed into tree leds to create the full tree."
            ]
        },
        {
            "question": "What type of tree substitution grammars is the author proposing to replace the red subtree with a smaller English subtree?",
            "reference-answers": [
                "Synchronous tree substitution grammars."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen57-slide58/text.txt": [
        {
            "question": "What is the purpose of the additional labels and attributes in the notes for the STSG approach?",
            "reference-answers": [
                "The additional labels and attributes in the notes serve to preserve the information about modality and tense, which were reflected by morphological variation or auxiliaries in the input sentence, and are not stored in the tree structure."
            ]
        },
        {
            "question": "What is the purpose of the additional labels and attributes in the notes in the STSG approach?",
            "reference-answers": [
                "The additional labels and attributes in the notes in the STSG approach are used to preserve the information about modality or tense, which were reflected by morphological variation or some auxiliaries in the input sentence, and to prevent this information from being lost."
            ]
        },
        {
            "question": "What is the purpose of additional labels or attributes in the real text-organic notes that is not reflected in the tree structure?",
            "reference-answers": [
                "The additional labels or attributes in the real text-organic notes are for the things like modality or tense, which were reflected by either the morphological variation or some auxiliaries in the input sentence."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen58-slide59/text.txt": [
        {
            "question": "What is the approach of STSG that factorizes along the structure of the tree, and what is the approach of T-layer that factorizes along the attributes?",
            "reference-answers": [
                "STSG factorizes along the structure of the tree, and T-layer factorizes along the attributes."
            ]
        },
        {
            "question": "What is the approach that the author tried to take in order to resolve the clash between the structure and the attributes in the context of factorization, but ultimately found to be difficult?",
            "reference-answers": [
                "The author tried to resolve the clash between the structure and the attributes by introducing independence assumptions and factorizing along both the structure of the tree (STSG) and the attributes (T-layer), but ultimately found it difficult to ensure that all these layers of trees match in structure."
            ]
        },
        {
            "question": "What is the main challenge in STSG factorization, according to the text?",
            "reference-answers": [
                "The main challenge in STSG factorization is ensuring that the layers of trees match in structure."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen59-slide60/text.txt": [
        {
            "question": "What approach emerged as the best approach in the empirical evaluation of the system, according to the author?",
            "reference-answers": [
                "The view which uses just the phrases and does not reorder them emerged as the best approach in the empirical evaluation of the system."
            ]
        },
        {
            "question": "What approach, according to the empirical evaluation, comes out as the best for sentence analysis?",
            "reference-answers": [
                "The view which uses just the phrases and does not reorder them, empirically comes out as the best approach."
            ]
        },
        {
            "question": "What approach to modeling sentence structure empirically came out as the best in the evaluation of the given systems?",
            "reference-answers": [
                "The view which uses just the phrases and does not reorder them empirically came out as the best approach."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen60-slide61/text.txt": [
        {
            "question": "What is a major problem in the tectogrammatical approach due to the search being over a big space?",
            "reference-answers": [
                "The combinatorial explosion of defected output that struck me in the tectogrammatical approach, where the search is over too big space and the NBEST list varies in unimportant attributes."
            ]
        },
        {
            "question": "What are some of the problems that arise when dealing with complex systems in the context of the tectogrammatical approach?",
            "reference-answers": [
                "The combinatorial explosion of defected output, the search being over too big a space, and the NBEST list varying in unimportant attributes are some of the problems that arise when dealing with complex systems in the context of the tectogrammatical approach."
            ]
        },
        {
            "question": "What is a major issue with the pipeline that leads to a huge data loss due to incompatibility of structures?",
            "reference-answers": [
                "The major issue with the pipeline is that whenever any of the tools makes an error, these errors will propagate, leading to a huge data loss due to the incompatibility of structures."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen61-slide62/text.txt": [
        {
            "question": "What is the name of the approach that uses the tectogrammatic layer and worked reasonably well according to the text?",
            "reference-answers": [
                "The tecto-empty approach."
            ]
        },
        {
            "question": "What is the name of the approach that uses a tectogrammatic layer and works reasonably well according to the text?",
            "reference-answers": [
                "The tecto-empty approach."
            ]
        },
        {
            "question": "What is the name of the approach that uses the tectogrammatic layer and worked reasonably well according to the text?",
            "reference-answers": [
                "The tecto-empty approach."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen62-slide63/text.txt": [
        {
            "question": "Who is credited with finishing the approach that makes the output sentence grammatical?",
            "reference-answers": [
                "Martin Popel."
            ]
        },
        {
            "question": "Who are the individuals responsible for developing this approach?",
            "reference-answers": [
                "Zdeněk Žavokrtsky and Martin Popel."
            ]
        },
        {
            "question": "Who started this approach and who finished it to make it work the best?",
            "reference-answers": [
                "Zdeněk Žavokrtsky started it, and Martin Popel finished it to make it work the best."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen63-slide64/text.txt": [
        {
            "question": "What type of model is referred to as the \"transfer stack\" in the provided text?",
            "reference-answers": [
                "Hidden Markov-3 model."
            ]
        },
        {
            "question": "What type of model is the focus of the last-mentioned slide on the exam?",
            "reference-answers": [
                "Hidden Markov-3 model."
            ]
        },
        {
            "question": "What type of model is illustrated as the \"transfer stack\" in the final slide of Martin Popel's slides?",
            "reference-answers": [
                "Hidden Markov-3 model."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen64-slide65/text.txt": [
        {
            "question": "What is the role of the \"should\" in the tree structure described in the text?",
            "reference-answers": [
                "The \"should\" is the root of the tree."
            ]
        },
        {
            "question": "What is the purpose of the morphological layer in the machine translation process?",
            "reference-answers": [
                "The morphological layer is part of the input for machine translation, where each word has a node."
            ]
        },
        {
            "question": "What is the purpose of the morphological layer in the machine translation process?",
            "reference-answers": [
                "The morphological layer is part of the input for machine translation, where each word has a node."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen65-slide66/text.txt": [
        {
            "question": "What are referred to as \"auxiliaries\" in the context of identifying functional words?",
            "reference-answers": [
                "auxiliaries."
            ]
        },
        {
            "question": "What are referred to as \"auxiliaries\" in the context of identifying functional words?",
            "reference-answers": [
                "auxiliaries."
            ]
        },
        {
            "question": "What type of words are referred to as \"auxiliaries\" in the context of identifying functional words?",
            "reference-answers": [
                "auxiliaries."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen66-slide67/text.txt": [
        {
            "question": "Where will auxiliaries belong to in relation to your mark edges?",
            "reference-answers": [
                "You will contract your mark edges like where these auxiliaries will belong to."
            ]
        },
        {
            "question": "Where will the auxiliaries belong to, according to the instruction?",
            "reference-answers": [
                "Your mark edges."
            ]
        },
        {
            "question": "Where will the auxiliaries belong to?",
            "reference-answers": [
                "on the mark edges"
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen67-slide68/text.txt": [
        {
            "question": "What is the purpose of contracting the X-series in the tectogram article 3?",
            "reference-answers": [
                "They have been hidden, have been contracted."
            ]
        },
        {
            "question": "What is the purpose of contracting the X-series in the tectogram article 3?",
            "reference-answers": [
                "They have been hidden, have been contracted."
            ]
        },
        {
            "question": "What type of content can be found in article 3 of the tectogram?",
            "reference-answers": [
                "Content bearing words."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen68-slide69/text.txt": [
        {
            "question": "What grammatical category did the machine fill in as in the given sentence?",
            "reference-answers": [
                "The machine was a noun."
            ]
        },
        {
            "question": "What grammatical category does the word \"this machine\" serve in the given sentence?",
            "reference-answers": [
                "The word \"this machine\" serves as a noun, and it functions as the subject to the verb, and as an attribute to the translation, and also serves as the complement to the verb."
            ]
        },
        {
            "question": "What grammatical category does the word \"this machine\" serve as in the sentence \"This machine was a noun\"?",
            "reference-answers": [
                "The word \"this machine\" serves as a noun in the sentence."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen69-slide70/text.txt": [
        {
            "question": "What type of verb is related to the grammar teams mentioned in the text?",
            "reference-answers": [
                "Morphology."
            ]
        },
        {
            "question": "What type of grammar is related to the morphology mentioned in the phrase \"fill in the grammar teams\"?",
            "reference-answers": [
                "The grammar related to the morphology mentioned in the phrase \"fill in the grammar teams\" is the morphology itself, and specifically, it is related to the verb."
            ]
        },
        {
            "question": "What type of grammar is related to the verb \"You fill in the grammar teams\"?",
            "reference-answers": [
                "Morphology."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen70-slide71/text.txt": [
        {
            "question": "What is the assumption made when starting to transform the source tree into the target tree in the process described?",
            "reference-answers": [
                "The assumption made when starting to transform the source tree into the target tree is that the trees are isomorphic."
            ]
        },
        {
            "question": "What is the assumption made when moving from the source tree to the target tree in the morphological information process?",
            "reference-answers": [
                "The trees are assumed to be isomorphic."
            ]
        },
        {
            "question": "What is the assumption made about the trees in the process of moving from the source to the target side of the morphological tree?",
            "reference-answers": [
                "The trees are assumed to be isomorphic."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen71-slide72/text.txt": [
        {
            "question": "How many choices do you have for translating the lexical labels in the given example?",
            "reference-answers": [
                "You have many choices for translating the lexical labels."
            ]
        },
        {
            "question": "What are some possible translations for the word \"machine\" in a lexical translation?",
            "reference-answers": [
                "počítač, stroj, strojový"
            ]
        },
        {
            "question": "What are some possible translations for the word \"subject\" in the given text?",
            "reference-answers": [
                "subject can be translated usually as in nominative"
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen72-slide73/text.txt": [
        {
            "question": "What model will be used to select the best combination of those in the talk?",
            "reference-answers": [
                "Markov 3 model."
            ]
        },
        {
            "question": "What is mentioned as the topic for the last slide of the talk?",
            "reference-answers": [
                "Markov 3 model to select the best combination of those and we'll see that in the last slide of this talk today."
            ]
        },
        {
            "question": "What is the purpose of selecting the best combination of factors according to Markov 3 model?",
            "reference-answers": [
                "To see that in the last slide of this talk today."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen73-slide74/text.txt": [
        {
            "question": "What is the first step in producing the final surface syntactic tree, according to the provided text?",
            "reference-answers": [
                "You use this best combination to produce the final surface syntactic tree."
            ]
        },
        {
            "question": "What is the first step in producing the final surface syntactic tree?",
            "reference-answers": [
                "You use this best combination to produce the final surface syntactic tree."
            ]
        },
        {
            "question": "What is the first step in producing the final surface syntactic tree according to the provided text?",
            "reference-answers": [
                "You use this best combination to produce the final surface syntactic tree."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen74-slide75/text.txt": [
        {
            "question": "What is known about the form of the word \"Snudny\" in the given translation?",
            "reference-answers": [
                "It is known that Snudny was in positive form."
            ]
        },
        {
            "question": "What is known about the form of the word \"Snudny\" in the translation?",
            "reference-answers": [
                "It is known that Snudny was in positive form."
            ]
        },
        {
            "question": "What is the grammatical form of the translation \"Snudny\" in the given text?",
            "reference-answers": [
                "The grammatical form of the translation \"Snudny\" is positive."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen75-slide76/text.txt": [
        {
            "question": "What is the role of explicit representation in ensuring the grammatical correctness of output sentences?",
            "reference-answers": [
                "The explicit representation enables the application of linguistic knowledge to ensure the grammatical correctness of output sentences."
            ]
        },
        {
            "question": "What is the purpose of the explicit representation in ensuring grammatical correctness in the system?",
            "reference-answers": [
                "The explicit representation is applied because it allows the system to ensure that the output sentence will be grammatically correct, inheriting cases and numbers from nouns to the dependent words such as adjectives."
            ]
        },
        {
            "question": "What type of information is applied to ensure that the output sentence is grammatically correct?",
            "reference-answers": [
                "Linguistic knowledge."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen76-slide77/text.txt": [
        {
            "question": "What is the purpose of adding functional words to a sentence?",
            "reference-answers": [
                "Then you need to add functional words and..."
            ]
        },
        {
            "question": "What are functional words that need to be added to a sentence?",
            "reference-answers": [
                "functional words and..."
            ]
        },
        {
            "question": "What is the purpose of adding functional words to a sentence?",
            "reference-answers": [
                "Then you need to add functional words and..."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen77-slide78/text.txt": [
        {
            "question": "What is a potential drawback of reordering sentences as part of the reordering process?",
            "reference-answers": [
                "This reordering can, by the way, introduce non-projectivities."
            ]
        },
        {
            "question": "What is a potential drawback of reordering a sentence in a projective manner?",
            "reference-answers": [
                "This reordering can, by the way, introduce non-projectivities."
            ]
        },
        {
            "question": "What is a potential drawback of reordering sentences as part of the reordering process?",
            "reference-answers": [
                "This reordering can, by the way, introduce non-projectivities."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen78-slide79/text.txt": [
        {
            "question": "What is the result of generating word forms based on demorphology?",
            "reference-answers": [
                "The word forms."
            ]
        },
        {
            "question": "What is the purpose of generating word forms based on demorphology?",
            "reference-answers": [
                "And you finally generate the word forms based on demorphology."
            ]
        },
        {
            "question": "What is the process of generating word forms based on demorphology?",
            "reference-answers": [
                "And you finally generate the word forms based on demorphology."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen79-slide80/text.txt": [
        {
            "question": "What is the translation of \"Stravi\" in the given sentence?",
            "reference-answers": [
                "Stravi seems to be a proper noun or a name, as it is the first word of the sentence."
            ]
        },
        {
            "question": "What is the expected difficulty level of the translation of \" Překlad by měl bít snadný\"?",
            "reference-answers": [
                "The expected difficulty level of the translation of \"Překlad by měl bít snadný\" is likely to be challenging, given that the sentence \"Stravi, Překlad by měl bít snadný\" is already in a form that suggests a more complex translation, as indicated by the phrase \"by měl bít snadný\", which may require a nuanced understanding of the original text."
            ]
        },
        {
            "question": "What is the expected form of the translation of \"by měl bít snadný\"?",
            "reference-answers": [
                "by měl bít snadný should be Stravi, Překlad by měl být snadný"
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen80-slide81/text.txt": [
        {
            "question": "What is the goal of the Hidden Markov model in the context of target site tectogrammetical trees?",
            "reference-answers": [
                "The goal of the Hidden Markov model is to find the best selection of the labels for each of the target site nodes, given the source nodes, in combination."
            ]
        },
        {
            "question": "What are the two possible translations for a noun in the nominative case, according to the given options?",
            "reference-answers": [
                "According to the given options, the two possible translations for a noun in the nominative case are:\n\n1. Překlad\n2. Převod"
            ]
        },
        {
            "question": "What are the two options for translating a noun in the nominative case in the Hidden Markov 3 model?",
            "reference-answers": [
                "The two options for translating a noun in the nominative case in the Hidden Markov 3 model are: Překlad and Převod."
            ]
        }
    ],
    "nmt-class/lecture07-syntax-in-smt/screen81-slide82/text.txt": [
        {
            "question": "What is the difference between the two components of the HMM model in the context of machine translation, namely the translation model and the language model view?",
            "reference-answers": [
                "The translation model and the language model view are two components of the HMM model in the context of machine translation. The translation model corresponds to the emission probabilities in the HMM model, representing the probabilities that link together the source words and target words and how often they co-occurred in a parallel tree bank. On the other hand, the language model view corresponds to the transition probabilities in the HMM model, representing the probabilities of co-occurrences within the target language."
            ]
        },
        {
            "question": "What is the main difference between the translation model and the language model in the context of the hidden Markov model?",
            "reference-answers": [
                "The translation model and the language model are two components of the hidden Markov model, and the main difference between them is that the translation model links together the source words and target words based on their co-occurrence probabilities, while the language model considers the probabilities of co-occurrences within the target language."
            ]
        },
        {
            "question": "What is the main difference between the translation model and the language model in the context of the hidden Markov model?",
            "reference-answers": [
                "The translation model and the language model are two components of the hidden Markov model, and the main difference between them is that the translation model links together the source words and target words based on their co-occurrence probabilities, while the language model considers the probabilities of co-occurrences within the target language."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen01-slide02/text.txt": [
        {
            "question": "What is the name of the standard model being discussed in the lecture?",
            "reference-answers": [
                "The transform model."
            ]
        },
        {
            "question": "What is the name of the standard model of statistical machine translation being discussed in the lecture?",
            "reference-answers": [
                "The transform model."
            ]
        },
        {
            "question": "What is the name of the standard model of statistical machine translation being discussed in the lecture?",
            "reference-answers": [
                "The transform model."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen02-slide03/text.txt": [
        {
            "question": "What is the current state of syntax in neural machine translation, according to the speaker, and what impact does it have on the effectiveness of the transformer network?",
            "reference-answers": [
                "The current state of syntax in neural machine translation is diverse and there is currently no single way to incorporate it into the model, depending on factors such as training data size, languages, and linguistic annotation quality. However, the results suggest that transformer networks can learn many of these things on their own without explicit information."
            ]
        },
        {
            "question": "What is the current approach to incorporating syntax information into neural machine translation models, according to the results of the talk mentioned in the text?",
            "reference-answers": [
                "There is currently no single way to incorporate syntax information into neural machine translation models, and the approach depends on factors such as training data size, languages in question, and quality of explicit linguistic annotation, with the results suggesting that transformer networks can learn many things on their own without explicit information."
            ]
        },
        {
            "question": "What is the current state of incorporating explicit syntax information into transformer networks for neural machine translation?",
            "reference-answers": [
                "There is currently no single way to incorporate explicit syntax information into transformer networks for neural machine translation, and the effectiveness of such approaches depends on factors such as training data size, languages in question, and quality of explicit linguistic annotation, but transformer networks can learn some of these things on their own without any explicit information."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen03-slide04/text.txt": [
        {
            "question": "What is the role of the attention mechanism in a sequence-to-sequence system with attention, and how does it affect the decoding process?",
            "reference-answers": [
                "The attention mechanism is trained on the fly and decides what weight should be given to each of the input positions at a particular decoding step. This controls the word order and the general flow of the translation."
            ]
        },
        {
            "question": "What is the purpose of the attention mechanism in a sequence-to-sequence system with attention?",
            "reference-answers": [
                "The attention mechanism is controlling the word order and the general flow of the translation by deciding what weight should be given to each of the input positions at a particular decoding step."
            ]
        },
        {
            "question": "What is the purpose of the attention mechanism in a sequence-to-sequence system with attention?",
            "reference-answers": [
                "The attention mechanism is controlling the word order and the general flow of the translation by deciding what weight should be given to each of the input positions at a particular decoding step."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen04-slide05/text.txt": [
        {
            "question": "What is the purpose of the attention energies in the bidirectional recurrent networks?",
            "reference-answers": [
                "The attention energies decide how important each of the state is and you normalize it with the softmax."
            ]
        },
        {
            "question": "What is the purpose of the attention energies in a bidirectional recurrent network?",
            "reference-answers": [
                "The attention energies decide how important each of the state is and you normalize it with the softmax."
            ]
        },
        {
            "question": "What is the purpose of the attention energies in a bidirectional recurrent network?",
            "reference-answers": [
                "The attention energies decide how important each of the state is and you normalize it with the softmax."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen05-slide07/text.txt": [
        {
            "question": "What is the process the decoder uses to decide the next word in the sequence?",
            "reference-answers": [
                "The decoder consults its previous state, the context vector, the last word produced and it decides what should be the next word."
            ]
        },
        {
            "question": "What is the process the decoder uses to decide on the next word in the sequence?",
            "reference-answers": [
                "The decoder consults its previous state, the context vector, the last word produced and it decides what should be the next word."
            ]
        },
        {
            "question": "What is the process that the decoder uses to decide on the next word in the output sequence?",
            "reference-answers": [
                "The decoder consults its previous state, the context vector, the last word produced and it decides what should be the next word."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen06-slide07/text.txt": [
        {
            "question": "What model is the subject of the next sentence in the provided text?",
            "reference-answers": [
                "transformer model"
            ]
        },
        {
            "question": "What is the topic of the text that the teacher is preparing for?",
            "reference-answers": [
                "The transformer model and the transformer."
            ]
        },
        {
            "question": "What is the subject of the next sentence after \"Yeah, so let's move to the transformer model\"?",
            "reference-answers": [
                "...and the transformer..."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen07-slide08/text.txt": [
        {
            "question": "When was the Transformer model (MODEL) introduced?",
            "reference-answers": [
                "The Transformer model (MODEL) was introduced in 2017 in a paper called Attention is all you need."
            ]
        },
        {
            "question": "When was the transformer MODEL first introduced?",
            "reference-answers": [
                "The transformer MODEL was introduced in 2017."
            ]
        },
        {
            "question": "When was the Transformer model introduced in a paper titled \"Attention is all you need\"?",
            "reference-answers": [
                "The Transformer model was introduced in 2017 in a paper titled \"Attention is all you need\"."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen08-slide09/text.txt": [
        {
            "question": "What is the alternative way to view the Transformer Illustrated blog post, besides the clear and simple description?",
            "reference-answers": [
                "The alternative way to view the Transformer Illustrated blog post, besides the clear and simple description, is by reading the paper annotated in PyTorch code, which allows you to see how the paper maps directly."
            ]
        },
        {
            "question": "What is an alternative way to view the Transformer Illustrated blog post, in addition to its description?",
            "reference-answers": [
                "The view from equations."
            ]
        },
        {
            "question": "What type of view can be accessed by reading the paper annotated in PyTorch code?",
            "reference-answers": [
                "The view from equations."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen09-slide10/text.txt": [
        {
            "question": "How many layers of encoders and decoders are typically used in a transformer model, according to the original paper?",
            "reference-answers": [
                "Six."
            ]
        },
        {
            "question": "What is the typical number of layers of encoders and decoders in a transformer model, according to the original paper?",
            "reference-answers": [
                "Six."
            ]
        },
        {
            "question": "What is the optimal number of layers for a transformer network, according to the original paper?",
            "reference-answers": [
                "Six."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen10-slide11/text.txt": [
        {
            "question": "How many sublayers does the transformer model have in its encoder?",
            "reference-answers": [
                "The encoder has two sublayers."
            ]
        },
        {
            "question": "How many sublayers does the transformer model have in its encoder?",
            "reference-answers": [
                "The encoder has two sublayers."
            ]
        },
        {
            "question": "How many sublayers does the encoder have in the transformer model?",
            "reference-answers": [
                "The encoder has two sublayers."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen11-slide12/text.txt": [
        {
            "question": "What is the role of the embedding layer in the processing of input sequences in the given context?",
            "reference-answers": [
                "The embedding layer converts each sparse one-hot representation of the words to dense vectors."
            ]
        },
        {
            "question": "What is the purpose of the residual connections in the network described in the text?",
            "reference-answers": [
                "The residual connections highlight that the position one remains to reflect information from the word number one, but this is not needed, as the network is free to move the information anywhere."
            ]
        },
        {
            "question": "What is the purpose of the residual connections in the self-attention mechanism?",
            "reference-answers": [
                "The residual connections highlight that the position one remains to reflect information from the word number one, but this is not needed, as the network is free to move the information anywhere."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen12-slide13/text.txt": [
        {
            "question": "What is the nature of the transformation performed on the tokens in the encoder layer of a word network?",
            "reference-answers": [
                "The same transformation is performed on every token."
            ]
        },
        {
            "question": "What is the primary difference in how information is processed in word networks compared to the previous method described?",
            "reference-answers": [
                "The primary difference is that word networks are token-based, meaning the transformation is done on each token individually, rather than all words talking to each other."
            ]
        },
        {
            "question": "What is the process of obtaining the final result of the encoder layer one in a word network model?",
            "reference-answers": [
                "The process of obtaining the final result of the encoder layer one in a word network model is performed by doing the same transformation at every of these tokens, and then passing these tokens, these representations to the next layer of the encoder."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen13-slide14/text.txt": [
        {
            "question": "What is the purpose of the positional encoding vectors in the transformer model, and how are they constructed?",
            "reference-answers": [
                "The positional encoding vectors are used to store information about the positions of words in the sentence, allowing the network to distinguish between words at different positions, and the network can identify whether a word is at the beginning, middle, or end of the sentence. The positional encoding vectors are constructed as vectors that change with every single token and with the index of the token, and they are added to the word level embeddings."
            ]
        },
        {
            "question": "What is the purpose of the positional encoding vectors in the transformer model, and how are they constructed?",
            "reference-answers": [
                "The positional encoding vectors are used to store information about the positions of words in the sentence, allowing the network to distinguish between words at different positions, and the network can identify whether a word is at the beginning, middle, or end of the sentence. The positional encoding vectors are constructed as vectors that change with every single token and with the index of the token, and they are added to the word level embeddings."
            ]
        },
        {
            "question": "What type of information processing is used to construct the positional encoding vectors in the transformer model, according to the provided explanation?",
            "reference-answers": [
                "The Fourier transform style of information processing."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen14-slide15/text.txt": [
        {
            "question": "What is the core element of the transformer network mentioned in the text?",
            "reference-answers": [
                "self-attention."
            ]
        },
        {
            "question": "What is the core element of the transformer network mentioned in the text?",
            "reference-answers": [
                "self-attention."
            ]
        },
        {
            "question": "What is the core element of the transformer network mentioned in the text?",
            "reference-answers": [
                "self-attention."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen15-slide16/text.txt": [
        {
            "question": "What is the main advantage of using convolutional neural networks over traditional sequence-to-sequence architectures for processing long sequences?",
            "reference-answers": [
                "The main advantage of using convolutional neural networks over traditional sequence-to-sequence architectures for processing long sequences is that they allow for constant-time processing, where the receptive field covers the whole sentence, enabling the processing of whole sentences in constant time, not dependent on the number of positions in the sentence."
            ]
        },
        {
            "question": "What are the two constants that specify the breadth in which a convolutional neural network explores the input elements?",
            "reference-answers": [
                "The kernel size and the depth of the network."
            ]
        },
        {
            "question": "What are the two constants that specify how a convolutional neural network processes input sequences or subsequences at a time?",
            "reference-answers": [
                "The depth of the network and the kernel size."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen16-slide17/text.txt": [
        {
            "question": "What is the cost associated with the increased memory needed in computing a self-attentive network?",
            "reference-answers": [
                "The memory needed in computing a self-attentive network is dependent on the square of the length of the sequences."
            ]
        },
        {
            "question": "What is the memory complexity of self-attention networks in computing?",
            "reference-answers": [
                "The memory needed in computing the self-attentive network is dependent on the square of the length of the sequences."
            ]
        },
        {
            "question": "What is the cost of using a self-attention network in terms of the number of intermediate numbers needed?",
            "reference-answers": [
                "The memory needed in computing a self-attentive network is dependent on the square of the length of the sequences."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen17-slide18/text.txt": [
        {
            "question": "How does self-attention enable the network to aggregate information from an arbitrarily long input into a fixed-size vector?",
            "reference-answers": [
                "We want to aggregate the information from an input which is arbitrarily long into a fixed size vector and we want this to be in a trainable way so that the network itself can decide what is important and what is not."
            ]
        },
        {
            "question": "How does self-attention enable a network to aggregate information from an arbitrarily long input into a fixed-size vector?",
            "reference-answers": [
                "We want to aggregate the information from an input which is arbitrarily long into a fixed size vector and we want this to be in a trainable way so that the network itself can decide what is important and what is not."
            ]
        },
        {
            "question": "How does the self-attention mechanism aggregate information from an input of arbitrary length into a fixed-size vector?",
            "reference-answers": [
                "We want to aggregate the information from an input which is arbitrarily long into a fixed size vector and we want this to be in a trainable way so that the network itself can decide what is important and what is not."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen18-slide19/text.txt": [
        {
            "question": "What is the purpose of using projection matrices to transform input word embeddings into keys, queries, and values in a self-attention mechanism?",
            "reference-answers": [
                "It's up to the network to decide what is important, and using projection matrices allows the network to transform input word embeddings into keys, queries, and values in a way that enables this decision-making process."
            ]
        },
        {
            "question": "What is the purpose of the projection matrices in the self-attention mechanism, and what determines whether they are used to generate keys, queries, or values?",
            "reference-answers": [
                "The projection matrices are used to generate keys, queries, and values. The purpose of these matrices is to specify how the queries are generated from the input tokens (for queries), how the keys are generated (for keys), and how the values are computed (for values). If the matrices are identical, the whole vector of the word can be used, and it's up to the network to decide what is important."
            ]
        },
        {
            "question": "What type of matrices are used to project input word embeddings to generate keys, queries, and values in a self-attention mechanism?",
            "reference-answers": [
                "Projection matrices."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen19-slide20/text.txt": [
        {
            "question": "What is the purpose of calculating the dot product between the query vector and the key vector in the given context?",
            "reference-answers": [
                "The dot product is used to compare the query vector with the key vector, to determine the similarity or importance of the word at a given position, and to identify the core or salient feature of the word."
            ]
        },
        {
            "question": "What is the purpose of the dot product calculation between the query vector and the key vector in the given context?",
            "reference-answers": [
                "The dot product calculation is used to compare every position with every position in the sentence, and to determine the importance or salience of a word, its core, and how it matches with other words in the sentence."
            ]
        },
        {
            "question": "What is the purpose of the dot product calculation between the query vector, query matrix, key vector, and key matrix in the described matching process?",
            "reference-answers": [
                "The dot product calculation is used to compare every position with every position in the sentence, and to determine the importance or salience of a word, its core, and how it matches with other words in the sentence."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen20-slide21/text.txt": [
        {
            "question": "What type of normalization is applied after normalizing the scores in a vector representation to account for its dimensionality?",
            "reference-answers": [
                "Softmax normalization."
            ]
        },
        {
            "question": "What type of normalization is applied to the scores after accounting for the dimensionality of the vector representation?",
            "reference-answers": [
                "Softmax normalization."
            ]
        },
        {
            "question": "What type of normalization is applied to the scores after accounting for the dimensionality of the vector representation?",
            "reference-answers": [
                "Softmax normalization."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen21-slide22/text.txt": [
        {
            "question": "What is the effect of the self-attention mechanism on the representation of each word in the sentence after the transformation at a given layer?",
            "reference-answers": [
                "The self-attention mechanism aggregates the information from the whole sentence at every token position to a new representation, but it heavily focuses on the current position itself, considering only a little bit of information from surrounding positions."
            ]
        },
        {
            "question": "What is the effect of the self-attention mechanism on the number of positions in a sentence after it has been transformed?",
            "reference-answers": [
                "After the self-attention mechanism, you have the same number of positions."
            ]
        },
        {
            "question": "What happens to the number of positions in a sentence after the self-attention mechanism is applied?",
            "reference-answers": [
                "The same number of positions."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen22-slide23/text.txt": [
        {
            "question": "What is the time complexity of the process described for generating the intermediate representation using self-attention?",
            "reference-answers": [
                "The process described can be done in constant time."
            ]
        },
        {
            "question": "What is the time complexity of the self-attention mechanism described in the text?",
            "reference-answers": [
                "The time complexity is constant, as all operations can be done in constant time."
            ]
        },
        {
            "question": "What is the operation that is done to the weights after matching the keys and queries, and what is the purpose of this operation?",
            "reference-answers": [
                "Soft mach normalization."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen23-slide22/text.txt": [
        {
            "question": "What is the location of the attention being referred to in the text?",
            "reference-answers": [
                "on the GPU."
            ]
        },
        {
            "question": "What is the location of the attention of one head mentioned in the text?",
            "reference-answers": [
                "on the GPU."
            ]
        },
        {
            "question": "What is the location of the attention being referred to in the text?",
            "reference-answers": [
                "on the GPU."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen24-slide23/text.txt": [
        {
            "question": "What is referred to as a \"hat\" in the context of the transformer model?",
            "reference-answers": [
                "Each of these views or considerations of the input sequence is called a hat."
            ]
        },
        {
            "question": "What are referred to as \"hats\" in the transformer model?",
            "reference-answers": [
                "views or considerations of the input sequence that are processed in parallel."
            ]
        },
        {
            "question": "What is a \"hat\" in the context of the transformer model?",
            "reference-answers": [
                "Each of these views or considerations of the input sequence is called a hat."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen25-slide24/text.txt": [
        {
            "question": "How many heads are in the standard transform model?",
            "reference-answers": [
                "Eight."
            ]
        },
        {
            "question": "How many heads are there in the standard transform model, and how do the matrices for each head specify the keys, queries, and values?",
            "reference-answers": [
                "In the standard transform model, there are eight heads. Each head is defined by matrices that specify what are the keys, what are the queries, and what are the values."
            ]
        },
        {
            "question": "How many heads are typically used in the standard transform model, but people may experiment with different numbers of?",
            "reference-answers": [
                "Eight."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen26-slide25/text.txt": [
        {
            "question": "How would you handle the eight different possible outputs when processing the independent heads in a constant time?",
            "reference-answers": [
                "You would just concatenate them and project them to the size that you wanted."
            ]
        },
        {
            "question": "How do you handle the eight possible outputs when you concatenate and project them to the desired size?",
            "reference-answers": [
                "You would just concatenate them and project them to the size that you wanted."
            ]
        },
        {
            "question": "How would you handle an eight times longer output than expected in this scenario?",
            "reference-answers": [
                "You would just concatenate them and project them to the size that you wanted."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen27-slide26/text.txt": [
        {
            "question": "What is the purpose of the trainable projection matrix in the self-attention mechanism?",
            "reference-answers": [
                "The trainable projection matrix is used to squash the final output of the self-attention mechanism back to the original dimension of the representation."
            ]
        },
        {
            "question": "What is the purpose of the 'query' weight matrix in the self-attention mechanism?",
            "reference-answers": [
                "The 'query' weight matrix is used to compare with the 'keys' to obtain the weights that are applied to the 'values'."
            ]
        },
        {
            "question": "What is the purpose of the projection matrix in the self-attention mechanism?",
            "reference-answers": [
                "The projection matrix squashes the concatenated output to the original dimension of the representation."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen28-slide27/text.txt": [
        {
            "question": "What is the purpose of masking in the decoder self-attention mechanism in the Transformer model?",
            "reference-answers": [
                "The decoder self-attention mechanism uses masking to prevent looking into the future, by forcing all positions from the current position onwards to be set to zeros."
            ]
        },
        {
            "question": "What is the purpose of masking in the decoder self-attention mechanism in the Transformer model?",
            "reference-answers": [
                "The decoder self-attention mechanism uses masking to prevent looking into the future, by forcing all positions from the current position onwards to be set to zeros."
            ]
        },
        {
            "question": "What is the purpose of masking in the decoder self-attention mechanism of the Transformer?",
            "reference-answers": [
                "The decoder self-attention mechanism uses masking to prevent looking into the future, by forcing all positions from the current position onwards to be set to zeros."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen29-slide28/text.txt": [
        {
            "question": "What can be done using the attention weights in a similar way to the attention in a sequence-to-sequence algorithm to understand where a network is looking?",
            "reference-answers": [
                "You can use the attention weights to see where the network is looking, specifically to look at what the head is looking at, and what positions it is assigning to when producing a representation."
            ]
        },
        {
            "question": "What information does the network use when producing the next layer representation of a pronoun, according to the trained weights in the head of the layer 5 encoder?",
            "reference-answers": [
                "The network uses the information which is available in the antecedent of the pronoun when producing the next layer representation of a pronoun."
            ]
        },
        {
            "question": "What type of information can be used to identify the antecedent of a pronoun in a sentence, based on the attention weights in a neural network?",
            "reference-answers": [
                "The trained weights managed to identify the antecedent of the pronoun, using the information available in the antecedent of the pronoun itself."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen30-slide29/text.txt": [
        {
            "question": "What is the primary focus of the second head in processing a clause?",
            "reference-answers": [
                "The second head puts most attention to the verb parts of this clause."
            ]
        },
        {
            "question": "What is the primary focus of the second head in analyzing a clause?",
            "reference-answers": [
                "The second head puts most attention to the verb parts of this clause."
            ]
        },
        {
            "question": "What is the main focus of the second head in understanding the syntax of a clause?",
            "reference-answers": [
                "The second head puts most attention to the verb parts of this clause."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen31-slide30/text.txt": [
        {
            "question": "What is the purpose of pruning weights in a neural network after training?",
            "reference-answers": [
                "To save computation time."
            ]
        },
        {
            "question": "What is the purpose of pruning weights in a neural network after training?",
            "reference-answers": [
                "To save computation time."
            ]
        },
        {
            "question": "What happens to the weights of a network after training if they do not contribute too much to the final result?",
            "reference-answers": [
                "Many of the weights after the training can be actually pruned because they do not contribute too much to the final result."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen32-slide31/text.txt": [
        {
            "question": "What is the reason for the presence of explicit information in early papers on neural machine translation that pre-date the transformer model?",
            "reference-answers": [
                "The reason for the presence of explicit information in early papers on neural machine translation that pre-date the transformer model is that they are actually pre-transformer."
            ]
        },
        {
            "question": "What is the significance of the presence of explicit information in early papers on neural machine translation?",
            "reference-answers": [
                "The presence of explicit information in early papers on neural machine translation is because those papers are actually pre-transformer, and that's why the explicit information was there."
            ]
        },
        {
            "question": "What type of information is referred to as \"explicit information\" in neural machine translation?",
            "reference-answers": [
                "Explicit information in neural machine translation."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen33-slide33/text.txt": [
        {
            "question": "How can linguistic information be incorporated into a neural machine translation system in a way that mimics the syntactic structure of the input sentences?",
            "reference-answers": [
                "One way to incorporate linguistic information into a neural machine translation system is to construct the network to mimic the syntactic structure of the sentence, essentially following the linguistic structure of the sentence."
            ]
        },
        {
            "question": "How do you add linguistic information to a neural machine translation system, and what are some ways to incorporate this information into the NMT system?",
            "reference-answers": [
                "You can add linguistic information to a neural machine translation system by using tools outside of the NMT system to pre-process input and target sentences with parsers, taggers, and then incorporating this information into the NMT system. This can be done by constructing the network to mimic the sentence structure, using graph conversion networks, or by adding explicit information to every token, including syntactic, morphological, or other factors, and relying on the multitasking mechanism to train the network to produce sequences of words and additional information."
            ]
        },
        {
            "question": "How do you add linguistic information to a neural machine translation system, and what are some strategies for incorporating explicit syntactic or morphological information into the system?",
            "reference-answers": [
                "You can add linguistic information to a neural machine translation system by using tools outside of the system, such as parsers and taggers to pre-process input and training sentences. One strategy is to follow the linguistic structure of the sentence and construct the network to mimic that structure, which can be achieved by using recurrent neural networks and introducing three LSTMs. Another strategy is to put explicit syntactic, morphological, or other information to every token, and train the network to produce sequences of words and additional information using a multitasking mechanism. This strategy can be combined with the attention mechanism, which can be equipped with explicit linguistic information."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen34-slide33/text.txt": [
        {
            "question": "How is approach related to the exam?",
            "reference-answers": [
                "The approach seems to be related to the exam as it is mentioned in the phrase \"So how to...\""
            ]
        },
        {
            "question": "How do I approach the exam?",
            "reference-answers": [
                "Approach is there. So how to... approach the exam?"
            ]
        },
        {
            "question": "How do I approach something if the approach is already there?",
            "reference-answers": [
                "So how do you approach something if the approach is already there?"
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen35-slide34/text.txt": [
        {
            "question": "What is the main difference between the three LSTMs and the plain LSTM/GRU in terms of how they consider previous token information in a sequence?",
            "reference-answers": [
                "The main difference between the three LSTMs and the plain LSTM/GRU is that the three LSTMs consider previous token information from a dependence in the tree, rather than just the previous token in the linear order, allowing them to notice dependencies between words that are far away from each other."
            ]
        },
        {
            "question": "What is the main difference between the mathematical approximation of dependency trees and the properties of constituency trees used to design tree LSTMs?",
            "reference-answers": [
                "The main difference is that the mathematical approximation of dependency trees disregards the order of children and allows for any number of children, whereas the properties of constituency trees are designed so that there is often a fixed number of children."
            ]
        },
        {
            "question": "What is the main difference between the way information is considered in plain LSTMs and the modified LSTMs designed for dependency trees?",
            "reference-answers": [
                "The main difference is that in plain LSTMs, the previous state information comes from the predecessor in the linear order, whereas in modified LSTMs designed for dependency trees, the previous state information comes from the dependence in the tree, disregarding the order of the children."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen36-slide35/text.txt": [
        {
            "question": "What is the main difference between this approach and the three LSTMs in the sequence to sequence approach?",
            "reference-answers": [
                "The main difference between this approach and the three LSTMs in the sequence to sequence approach is that this approach has a linear backbone and exploits explicit knowledge, whereas the three LSTMs rely on a more rigid structure."
            ]
        },
        {
            "question": "What is the key difference between the second approach and the three LSTMs in sequence to sequence models?",
            "reference-answers": [
                "The key difference between the second approach and the three LSTMs in sequence to sequence models is that the second approach has a linear backbone, whereas the three LSTMs do not."
            ]
        },
        {
            "question": "What type of backbone is the structure that mimics the syntactic structure of the sentence made of?",
            "reference-answers": [
                "The structure that mimics the syntactic structure of the sentence is made of a linear backbone."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen37-slide36/text.txt": [
        {
            "question": "What is the primary goal of the network structure refinement in the paper, and how does it improve Chinese to English translation?",
            "reference-answers": [
                "The primary goal of the network structure refinement is to allow information to flow both from bottom up (from words to syntactic parts of the tree) and backwards (from top to bottom, and from one node to its predecessors and successors). This refinement improves Chinese to English translation by enabling every node to consider all its predecessors and successors, as well as its governors, and bring information from the governors back to the node, resulting in some improvements."
            ]
        },
        {
            "question": "What is the primary goal of the network structure refinement in the paper, as described in the context of Chinese to English translation?",
            "reference-answers": [
                "The primary goal of the network structure refinement is to allow the information to flow not only from bottom up from the words to the top of the syntactic parts of the tree but also backwards, enabling bidirectional encoding and consideration of predecessors, successors, and governors."
            ]
        },
        {
            "question": "What type of information flow is allowed in the network structure after the refinement mentioned in the paper?",
            "reference-answers": [
                "Both bottom-up and top-down information flow are allowed in the network structure, from every position running a long thread up to the whole tree and then down back to the same node."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen38-slide37/text.txt": [
        {
            "question": "What is the purpose of using a weight matrix in the graph convolution network described in the text?",
            "reference-answers": [
                "The weight matrix tells the node how to make use of the information from the governor."
            ]
        },
        {
            "question": "What is the purpose of the two weight matrices in the graph convolution network structure for processing dependency parses?",
            "reference-answers": [
                "The two weight matrices are used to tell a node how to make use of the information from its governor and how to make use of information from its arbitrary number of children."
            ]
        },
        {
            "question": "What type of network structure is being described as combining the idea of convolution with the idea of network structure along the dependency parse?",
            "reference-answers": [
                "Graph convolution networks."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen39-slide38/text.txt": [
        {
            "question": "What type of approaches are being discussed in the exam, and what are some of their main characteristics?",
            "reference-answers": [
                "The exam is discussing approaches that are conceptually simpler, mainly sticking to standard sequence-to-sequence or transformer-style processing."
            ]
        },
        {
            "question": "What type of processing approaches will be mainly discussed in the exam?",
            "reference-answers": [
                "They will mainly stick to the standard sequence to sequence or also transformer style processing."
            ]
        },
        {
            "question": "What type of processing approaches will the discussion focus on?",
            "reference-answers": [
                "The discussion will mainly focus on standard sequence to sequence or transformer style processing."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen40-slide39/text.txt": [
        {
            "question": "What is the main idea behind the use of \"super tags\" in encoding syntactic information at each token in a sentence?",
            "reference-answers": [
                "The main idea behind the use of \"super tags\" is to encode syntactic information at each token in a sentence by labeling tokens with something that indicates how that word fits into the rest of the sentence, making explicit the natural property of morphology-rich languages to indicate relations between words."
            ]
        },
        {
            "question": "What is the purpose of the super tags in syntactic encoding at each token, according to the idea described in the text?",
            "reference-answers": [
                "The super tags are used to encode syntactic information at each token, and their purpose is to make explicit the natural way in which morphology rich languages indicate the relations between words, by providing a formal label that reflects how a word fits into the rest of the sentence."
            ]
        },
        {
            "question": "What is the main idea behind the use of \"super tags\" in encoding syntactic information at each token in a sentence?",
            "reference-answers": [
                "The main idea behind the use of \"super tags\" is to encode syntactic information at each token in a sentence by labeling tokens with something that indicates how that word fits into the rest of the sentence, making explicit the natural property of morphology-rich languages to indicate relations between words."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen41-slide39/text.txt": [
        {
            "question": "What is the purpose of using slashes in the CCG text to specify the requirements for a valid verb?",
            "reference-answers": [
                "The slashes in the CCG text are used to specify that the text is a requirement for a valid verb, to make it complemented by a noun phrase from the right hand side and a propositional phrase from the left hand side, thus making it a fully saturated element in the sentence."
            ]
        },
        {
            "question": "What type of elements does the CCG text specify must be added to the sentence to make it fully saturated?",
            "reference-answers": [
                "A propositional phrase from the left hand side and a noun phrase from the right hand side."
            ]
        },
        {
            "question": "What type of elements does the CCG text require to be fully saturated in a sentence?",
            "reference-answers": [
                "A propositional phrase from the left hand side and a noun phrase from the right hand side."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen42-slide39/text.txt": [
        {
            "question": "What is the subject of the sentence \"Yeah, so, there was...\"?",
            "reference-answers": [
                "Something is about to be mentioned."
            ]
        },
        {
            "question": "What happened, according to the speaker?",
            "reference-answers": [
                "There is no previous text provided."
            ]
        },
        {
            "question": "What happened according to the speaker at the beginning of the conversation?",
            "reference-answers": [
                "There was something."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen43-slide40/text.txt": [
        {
            "question": "How can we put syntactic information at each token?",
            "reference-answers": [
                "We have a discussion about how to put syntactic information at each token."
            ]
        },
        {
            "question": "How do you put syntactic information at each token?",
            "reference-answers": [
                "We have a discussion about how to put syntactic information at each token."
            ]
        },
        {
            "question": "How do we put syntactic information at each token?",
            "reference-answers": [
                "We have a discussion about how to put syntactic information at each token."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen44-slide41/text.txt": [
        {
            "question": "What is the approach of interleaving multiple target sequences in a sequence-to-sequence network, and how does it improve translation performance?",
            "reference-answers": [
                "The approach of interleaving multiple target sequences in a sequence-to-sequence network involves interweaving these sequences, especially if they correspond to each other position-wise. This allows the network to consider multiple target sequences simultaneously and enables it to learn how to interleave these sequences. As a result, the network can produce translations that take into account both the morphological and syntactic information, leading to improved translation performance."
            ]
        },
        {
            "question": "What is the benefit of using morphological information in statistical machine translation systems, according to the provided text?",
            "reference-answers": [
                "The network, by thinking about the syntax or thinking about the morphological categories, has a bigger chance of producing the sentence correctly."
            ]
        },
        {
            "question": "What type of additional information can be used as source factors in statistical machine translation systems to improve the translation of morphologically rich languages like Czech?",
            "reference-answers": [
                "Morphological tags or sequence of super tags for CCG, word form, dependency information, and vocabulary of lemmas can be used as additional information as source factors in statistical machine translation systems to improve the translation of morphologically rich languages like Czech."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen45-slide42/text.txt": [
        {
            "question": "What was the title of the published paper that the author mentioned in the Prague Building of Mathematical Linguistics?",
            "reference-answers": [
                "Replacing Linguists with Dummies."
            ]
        },
        {
            "question": "What was the title of the paper published in the Prague Building of Mathematical Linguistics, which introduced a method for replacing linguists with dummy tags in a sequence-to-sequence model?",
            "reference-answers": [
                "Replacing Linguists with Dummies."
            ]
        },
        {
            "question": "What type of secondary decoder was used to predict the target syntax in the experiment described in the paper \"Replacing Linguists with Dummies\"?",
            "reference-answers": [
                "A secondary decoder was used to predict the target syntax, and it was a secondary decoder that allowed sequences of length to differ or to be interleaved, making the output sentences double the length."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen46-slide43/text.txt": [
        {
            "question": "What is the reason why the network performs better in the interleaving setup compared to the multi-decoder setup?",
            "reference-answers": [
                "The network performs better in the interleaving setup because it has an additional step to deliberate about the next word, allowing it to produce more accurate results."
            ]
        },
        {
            "question": "What is the outcome when the same tag is used in the interleaved tag setup with a vocabulary size of one for the sequence-to-sequence model?",
            "reference-answers": [
                "The network does not learn anything useful."
            ]
        },
        {
            "question": "What is the effect of using the same tag with a vocabulary size set to one for the interleaved tag on the performance of the recurrent neural network?",
            "reference-answers": [
                "The network does not learn anything useful."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen47-slide44/text.txt": [
        {
            "question": "What is the outcome when a network is given a task that is too easy in a multitask setting?",
            "reference-answers": [
                "The network will not learn the interesting task at all, and will optimize for the easy part."
            ]
        },
        {
            "question": "What is the outcome when a network is given a too easy task in a multitask setting?",
            "reference-answers": [
                "The network will not learn the interesting task at all, and will optimize for the easy part."
            ]
        },
        {
            "question": "What happens to a network when given a task that is too easy, in a multitask setting?",
            "reference-answers": [
                "The network will not learn the interesting task at all, and will optimize for the easy part, not learning anything."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen48-slide45/text.txt": [
        {
            "question": "What is the benefit of increasing the depth of a neural network in the context of linguistics and machine learning?",
            "reference-answers": [
                "The benefit actually comes from the increased depth of the network."
            ]
        },
        {
            "question": "What is the benefit of increasing the depth of a neural network in this context, according to the provided text?",
            "reference-answers": [
                "The benefit actually comes from the increased depth of the network."
            ]
        },
        {
            "question": "What is the benefit of increasing the depth of a neural network in the context of linguistic information and network power?",
            "reference-answers": [
                "The benefit actually comes from the increased depth of the network."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen49-slide46/text.txt": [
        {
            "question": "What is the topic of the last part mentioned in the provided text?",
            "reference-answers": [
                "Making use of linguistic information in the attention."
            ]
        },
        {
            "question": "What is the topic of the last part discussed in the text?",
            "reference-answers": [
                "Making use of linguistic information in the attention."
            ]
        },
        {
            "question": "What is the last part of the process being discussed in the text?",
            "reference-answers": [
                "Making use of linguistic information in the attention."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen50-slide47/text.txt": [
        {
            "question": "What is the purpose of restricting the way attention is calculated in the context of English Chinese translation?",
            "reference-answers": [
                "Restricting the way attention is calculated helps avoid repeating words in the output."
            ]
        },
        {
            "question": "What is one way that the attention mechanism can be restricted or modified in the context of source syntax to avoid repeating words in the output?",
            "reference-answers": [
                "One way to restrict or modify the attention mechanism is to \"constrain or changing or specifying the network structure in the attention part based on the source syntax.\""
            ]
        },
        {
            "question": "What type of restrictions can be placed on the calculation of attention in a network based on source syntax?",
            "reference-answers": [
                "Constraining, changing, or specifying the network structure in the attention part based on the source syntax."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen51-slide48/text.txt": [
        {
            "question": "What is the approach used to constrain the transformer encoder to produce a dependency representation of the source sentence, rather than strictly following its syntactic structure?",
            "reference-answers": [
                "Instead of forcing the calculation to follow the syntactic structure of the sentence, we say, do you find whatever way of combining the numbers you like, but make sure to realize what was the structure of the sentence."
            ]
        },
        {
            "question": "What is the purpose of constraining the training of the transformer encoder to produce a dependency representation of the source sentence in addition to matching the output sentence?",
            "reference-answers": [
                "The purpose of constraining the training of the transformer encoder is to enable the network to produce a dependency representation of the source sentence in addition to matching the output sentence, effectively forcing the network to realize the syntactic structure of the sentence, but in a soft way, allowing it to combine numbers in any way while adhering to the sentence's structure."
            ]
        },
        {
            "question": "What type of constraint is being used to force the transformer encoder to produce a dependency parse of the source sentence?",
            "reference-answers": [
                "A soft way of constraining what the network does, by requiring the network to realize the structure of the sentence."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen52-slide49/text.txt": [
        {
            "question": "What is the optimal layer at which the transformer model should be trained to predict the parse in order to produce better translations?",
            "reference-answers": [
                "The optimal layer at which the transformer model should be trained to predict the parse in order to produce better translations is the fifth or second to last layer."
            ]
        },
        {
            "question": "What is the best position for the transformer to predict the parse in order to produce better translations?",
            "reference-answers": [
                "The best position for the transformer to predict the parse in order to produce better translations is the second to last layer."
            ]
        },
        {
            "question": "What type of information is found to be beneficial for a neural network when training a dependency parser, according to the experiment described in the text?",
            "reference-answers": [
                "The type of information found to be beneficial for a neural network when training a dependency parser is the parse that the network produces at the layer one, and also the parse that the network produces at the layer four or five."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen53-slide50/text.txt": [
        {
            "question": "What is the representation of a simple dependency tree in the matrix form used to train the transformer model?",
            "reference-answers": [
                "The first word depends on the root, the second word depends on the first word."
            ]
        },
        {
            "question": "What is the purpose of the transformer model in this context, given that it is being trained to produce a diagonal instead of a dependency tree?",
            "reference-answers": [
                "The transformer model is being trained to produce a diagonal in the matrix form, which means that every word depends on its predecessor, and it is not producing a true dependency tree."
            ]
        },
        {
            "question": "What type of dependency tree is represented by a linear sequence in the given dummy parse?",
            "reference-answers": [
                "A linear sequence represents a linear parse."
            ]
        }
    ],
    "nmt-class/lecture08-transformer-and-syntax-in-nmt/screen54-slide51/text.txt": [
        {
            "question": "What is the effect of using a diagonal parse in the transformer model on translation quality, and how does it compare to using a true parse?",
            "reference-answers": [
                "The effect of using a diagonal parse in the transformer model is that it improves the translation quality, and it is even better than using a true parse in some cases."
            ]
        },
        {
            "question": "What is the effect of using a diagonal parse on the translation quality when training a transformer model?",
            "reference-answers": [
                "The effect of using a diagonal parse on the translation quality when training a transformer model is that it improves the translation and yields a precision close to 100%, and the effect is the same or even better than using a true parse."
            ]
        },
        {
            "question": "What is the effect of using a diagonal matrix in the self-attention matrices of the transformer on the translation quality of the model?",
            "reference-answers": [
                "The effect of using a diagonal matrix in the self-attention matrices of the transformer on the translation quality of the model is that it improves the translation quality, and the gain is the same whether the information is learned towards the true parse or towards a diagonal parse, with the translation quality being even better with the diagonal parse."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen01-slide01/text.txt": [
        {
            "question": "What is the topic of the lecture that will be discussed today?",
            "reference-answers": [
                "Whether current empty systems understand what they are translating or not."
            ]
        },
        {
            "question": "What is the title of the lecture?",
            "reference-answers": [
                "Whether current empty systems understand what they are translating or not"
            ]
        },
        {
            "question": "What type of discussion will be held in today's lecture on machine translation?",
            "reference-answers": [
                "We'll be discussing word and sentence representations."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen02-slide02/text.txt": [
        {
            "question": "What does it mean to mean something?",
            "reference-answers": [
                "We'll be discussing what it means to mean something, and what we expect from sentence meaning."
            ]
        },
        {
            "question": "What do we expect from sentence meaning?",
            "reference-answers": [
                "We'll conclude with discussing what do we expect from sentence meaning."
            ]
        },
        {
            "question": "What does it mean to mean something?",
            "reference-answers": [
                "We'll be discussing what it means to mean something, and what we expect from sentence meaning."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen03-slide03/text.txt": [
        {
            "question": "What is the difference between the triangle mentioned in the text and the WOKUA triangle?",
            "reference-answers": [
                "The WOKUA triangle is the one that appears early in the series of lectures, whereas the triangle mentioned in the text is a different one, not the WOKUA triangle."
            ]
        },
        {
            "question": "What is the triangle referred to in machine translation that is different from the one seen in the early series of lectures?",
            "reference-answers": [
                "The triangle referred to in machine translation is the WOKUA triangle."
            ]
        },
        {
            "question": "What type of triangle is referred to at the beginning of machine translation, according to the provided text?",
            "reference-answers": [
                "The triangle referred to at the beginning of machine translation is the WOKUA triangle."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen04-slide04/text.txt": [
        {
            "question": "What is represented by the lower corner of the semiotics triangle according to Richards and Ogden?",
            "reference-answers": [
                "The source or the lower corner of the triangle corresponds to the symbol, to something that you hear or see, the message."
            ]
        },
        {
            "question": "What is the lower corner of the semiotics triangle corresponding to?",
            "reference-answers": [
                "The source or the lower corner of the triangle corresponds to the symbol, to something that you hear or see, the message."
            ]
        },
        {
            "question": "What corresponds to the lower corner of the semiotics triangle according to Richards and Ogden?",
            "reference-answers": [
                "The source or the lower corner of the triangle corresponds to the symbol, to something that you hear or see, the message."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen05-slide05/text.txt": [
        {
            "question": "What is the meaning of the symbol represented by the sentence \"Danny approached the chair with a yellow bag\"?",
            "reference-answers": [
                "The symbol is meant to stand for some situation, to correspond to some situation."
            ]
        },
        {
            "question": "What is the purpose of the symbol in the given text?",
            "reference-answers": [
                "It is meant to stand for some situation, to correspond to some situation."
            ]
        },
        {
            "question": "What is the purpose of the symbol in the sentence?",
            "reference-answers": [
                "The symbol is meant to stand for some situation, to correspond to some situation."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen06-slide06/text.txt": [
        {
            "question": "What is the meaning representation of the particle symbol in the two different situations described in the sentence?",
            "reference-answers": [
                "The last corner of the triangle is the thought or reference."
            ]
        },
        {
            "question": "What is the ambiguity of the given sentence, and how does it relate to the meaning representation of a particle symbol?",
            "reference-answers": [
                "The ambiguity of the sentence lies in its ability to refer to two different situations: Danny holding the bag and approaching the chair, or Danny approaching the chair with the bag already on it. The ambiguity relates to the meaning representation of the particle symbol, as the last corner of the triangle (the thought or reference) determines the meaning, allowing the same symbol to refer to two different situations."
            ]
        },
        {
            "question": "What is the meaning representation of the particle symbol referred to in the sentence?",
            "reference-answers": [
                "The last corner of the triangle is the thought or reference."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen07-slide07/text.txt": [
        {
            "question": "How will the meaning of \"the yellow back\" differ in the tree if it is in two different positions?",
            "reference-answers": [
                "The meaning of \"the yellow back\" will be essentially different in the tree if it is in two different positions."
            ]
        },
        {
            "question": "What is the position of the 'yellow back' in the constituency tree in the two different situations?",
            "reference-answers": [
                "The 'yellow back' will be essentially hanging elsewhere in two different positions in the tree."
            ]
        },
        {
            "question": "What type of information can be encoded in a constituency tree to represent different meanings or situations?",
            "reference-answers": [
                "The positions in the tree."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen08-slide08/text.txt": [
        {
            "question": "What is the difference between the two representations in the given formal semantics scenario?",
            "reference-answers": [
                "The difference between the two representations lies in how the bag is connected to the person and the chair, whether it was held by the person or was already sitting on the chair."
            ]
        },
        {
            "question": "What is the difference between the two systems or representations in the given scenario?",
            "reference-answers": [
                "The difference between the two systems or representations is the link between the bag and the person or the chair, where either the bag was connected to the person because he was holding it or the bag was connected to the chair because the bag was already sitting on the chair."
            ]
        },
        {
            "question": "What type of differences can occur between two systems or representations when describing the meaning of a sentence using formal semantics?",
            "reference-answers": [
                "Differences in the meaning of a sentence can occur between two systems or representations in terms of the relationships between entities, such as whether an entity (e.g. bag) is connected to a person or to another entity (e.g. chair)."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen09-slide09/text.txt": [
        {
            "question": "How will artificial neural networks perceive the differences between different situations when processing video representations?",
            "reference-answers": [
                "When processing video representations, artificial neural networks will have a chance to perceive the differences between different situations due to the different representations, or activations in the neural networks."
            ]
        },
        {
            "question": "How do artificial neural networks perceive differences between situations?",
            "reference-answers": [
                "When an artificial neural network is processing the videos of these situations, then the representations, the activations in the neural networks, artificial or natural, will be different. So somehow the networks will have a chance to perceive the difference."
            ]
        },
        {
            "question": "How will artificial neural networks perceive differences between situations when processing video representations?",
            "reference-answers": [
                "When processing video representations, artificial neural networks will have a chance to perceive the difference because the representations, the activations in the neural networks, will be different."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen10-slide10/text.txt": [
        {
            "question": "How do human translators handle ambiguous terms in machine translation or when the original author is no longer available to provide clarification?",
            "reference-answers": [
                "Human translators may preserve the ambiguity, making it as close ambiguous as possible in the target language, or they may warn the reader about unclear terms, and in cases where the original text is unclear, they may mention that the original text was not clear, and the author should provide their own explanation."
            ]
        },
        {
            "question": "What is the purpose of a translator's comment in a book when the author is no longer available to resolve ambiguities in the original text?",
            "reference-answers": [
                "When the author is no longer available to resolve ambiguities in the original text, translators may resort to mentioning that the original text was not clear, and then providing a translator's comment to clarify the meaning or warn the reader about the ambiguity."
            ]
        },
        {
            "question": "What is the approach that human translators may take when they encounter ambiguous information in a translation that cannot be resolved?",
            "reference-answers": [
                "Human translators may preserve the ambiguity, making it as close ambiguous as possible in the target language, or they may warn the reader about the unclear term."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen11-slide11/text.txt": [
        {
            "question": "What were some notable achievements of machine translation systems in the WMT competition in 2018 and 2019?",
            "reference-answers": [
                "In English to Czech, a machine translation system significantly surpassed professional translation at the segment level in 2018, and in English to German, a system surpassed humans at the document level in 2019."
            ]
        },
        {
            "question": "What evaluation procedures were used in the WMT competitions in 2018 and 2019 to assess the performance of machine translation systems?",
            "reference-answers": [
                "Document level evaluation and segment level evaluation were used in the WMT competitions in 2018 (English to Czech) and 2019 (English to German)."
            ]
        },
        {
            "question": "What systems significantly surpassed professional translation in the WMT competition in 2018 and 2019?",
            "reference-answers": [
                "In English to Czech it was at the segment level in 2018 and in English to German in 2019."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen12-slide12/text.txt": [
        {
            "question": "How many years would it take to read the training text for the 2018 English to Czech machine translation system?",
            "reference-answers": [
                "50 years."
            ]
        },
        {
            "question": "What is the name of the machine translation system that was trained on a large amount of text to translate English to Czech, according to the 2018 Charles University Transformer setup?",
            "reference-answers": [
                "Charles University Transformer setup."
            ]
        },
        {
            "question": "What is the approximate amount of text that the 2018 Charles University Transformer setup for English-Czech machine translation was trained on?",
            "reference-answers": [
                "You would need 50 years to read it if you were reading eight hours a day, and only 40% of this amount of text was actually parallel."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen13-slide13/text.txt": [
        {
            "question": "How would Google translate the Czech sentence \"ma, ma, mele, maso\" into English?",
            "reference-answers": [
                "ma, mis, min, sink, meat"
            ]
        },
        {
            "question": "What is the translation of the sentence \"ma, ma, mele, maso\" provided by Google?",
            "reference-answers": [
                "ma, mis, min, sink, meat"
            ]
        },
        {
            "question": "What is the translation that Google provides for the sentence \"ma, ma, mele, maso\"?",
            "reference-answers": [
                "ma, mis, min, sink, meat"
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen14-slide14/text.txt": [
        {
            "question": "What is a characteristic of a free word order language, and how does this impact the interpretation of questions in machine translation?",
            "reference-answers": [
                "A characteristic of a free word order language is that the word order in the question actually specifies what you are checking, what you are validating with your question."
            ]
        },
        {
            "question": "Does the word order in a question in a free word order language specify what the question is checking and validating?",
            "reference-answers": [
                "No, the word order in a question in a free word order language does not necessarily specify what the question is checking and validating."
            ]
        },
        {
            "question": "What type of language is the language being discussed, and how does its word order relate to the questions being asked about it?",
            "reference-answers": [
                "The language being discussed is a free word order language, and its word order in the question specifies what is being checked or validated."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen15-slide15/text.txt": [
        {
            "question": "What is the result of Microsoft Bing translator's attempt to translate the sentence \"Mama mele maso, maso mele mama, maso mama mele\" into English?",
            "reference-answers": [
                "Moms eating meat, already the first sentence is wrong."
            ]
        },
        {
            "question": "What is the primary reason why Microsoft Bing translator produced an incorrect translation of the sentence \"Mama mele maso, maso mele mama, maso mama mele\"?",
            "reference-answers": [
                "The primary reason why Microsoft Bing translator produced an incorrect translation of the sentence is that Bing was trained on other types of text and there was not much data about mincing meat in the training data, resulting in the loss of the verb \"grinds\" in the translation."
            ]
        },
        {
            "question": "What type of text was likely used for training Microsoft Bing translator?",
            "reference-answers": [
                "Other types of text."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen16-slide16/text.txt": [
        {
            "question": "What is the topic of the Czech sentence being discussed in the provided text?",
            "reference-answers": [
                "The topic of the Czech sentence is the word order used to highlight topic-focused articulation."
            ]
        },
        {
            "question": "What is the author's reasoning for using the word order in the Czech sentence?",
            "reference-answers": [
                "The author is using the word order to highlight the topic focused articulation in the Czech sentence, as they believe this is the most appropriate word order."
            ]
        },
        {
            "question": "What is the word order in the Czech sentence that highlights the topic focused articulation?",
            "reference-answers": [
                "The word order in the Czech sentence that highlights the topic focused articulation is: So now the superhuman system, same inputs, mom grinds meat, does mom grind meat, that is perfect, and meat moms grinding."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen17-slide17/text.txt": [
        {
            "question": "What is the system's output when the question is reordered as \"does mom have meat\"?",
            "reference-answers": [
                "The system output is not acceptable."
            ]
        },
        {
            "question": "What is the purpose of the superhuman system's output in this scenario?",
            "reference-answers": [
                "The system output is not acceptable."
            ]
        },
        {
            "question": "What is the acceptable output of the superhuman system?",
            "reference-answers": [
                "The system output is not acceptable."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen18-slide19/text.txt": [
        {
            "question": "What is the significance of a cut through a neural network in terms of understanding its representation of inputs?",
            "reference-answers": [
                "Every cut of the network is a place where you can observe what the network is doing, how the network is representing."
            ]
        },
        {
            "question": "What is the purpose of a cut through a neural network, according to the explanation provided?",
            "reference-answers": [
                "Every cut of the network is a place where you can observe what the network is doing, how the network is representing."
            ]
        },
        {
            "question": "What is a \"cut\" in the context of a neural network, according to the explanation provided?",
            "reference-answers": [
                "A \"cut\" in the context of a neural network is a set of neurons such that every path through the network must cross this cut."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen19-slide20/text.txt": [
        {
            "question": "How many neurons were in the hidden layer of the network in the given example?",
            "reference-answers": [
                "There were three neurons in the hidden layer of the network in the given example."
            ]
        },
        {
            "question": "How does the introduction of a third coordinate, representing the distance from each of the three lines, make it easier to separate inner points from the circumference in a 2D space?",
            "reference-answers": [
                "The introduction of a third coordinate makes it easier to separate inner points from the circumference because, in this new space, points can be classified based on how far they are from and on which side they are from each of the three lines, allowing for a more precise separation of inner points from the circumference."
            ]
        },
        {
            "question": "What type of space is created when a 2D space is transformed into a new space based on the distances from three lines?",
            "reference-answers": [
                "A 3D space, referred to as the ABC space, is created where the new coordinates represent the distances from three lines."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen20-slide21/text.txt": [
        {
            "question": "Is the representation learned by the network in the hidden space good for something else than separating the classes that we are trying to separate?",
            "reference-answers": [
                "The representation learned by the network in the hidden space may be good for something else than separating the classes that we are trying to separate."
            ]
        },
        {
            "question": "Is the representation learned by the network good for something else than separating the classes that we are trying to separate?",
            "reference-answers": [
                "The representation learned by the network is designed or trained to best separate the classes that we are trying to separate."
            ]
        },
        {
            "question": "Is the representation learned by the network useful for separating classes beyond its original purpose?",
            "reference-answers": [
                "The representation learned by the network is designed or trained to best separate the classes that we are trying to separate, so it is likely useful for separating classes beyond its original purpose."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen21-slide22/text.txt": [
        {
            "question": "What is the purpose of the hand-drawn examples provided in the text?",
            "reference-answers": [
                "The purpose of the hand-drawn examples provided is to illustrate the transformation of the input picture and its representation in the new space."
            ]
        },
        {
            "question": "What is the purpose of the hand-drawn examples provided in the text?",
            "reference-answers": [
                "The purpose of the hand-drawn examples provided is to illustrate the transformation of the input picture and its representation in the new space."
            ]
        },
        {
            "question": "What type of task is being referred to as \"the main task\" in the provided text?",
            "reference-answers": [
                "Hand drawing."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen22-slide23/text.txt": [
        {
            "question": "What is the benefit of using the ABC representation in the context of a picture?",
            "reference-answers": [
                "It allows to separate the border from the face in the picture."
            ]
        },
        {
            "question": "What is the purpose of the ABC representation mentioned in the text?",
            "reference-answers": [
                "It allows to separate the border from the face in the picture."
            ]
        },
        {
            "question": "What is the benefit of using the ABC representation in the picture?",
            "reference-answers": [
                "It allows to separate the border from the face in the picture."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen23-slide24/text.txt": [
        {
            "question": "What can happen if your input is very complicated and the network learns to process it?",
            "reference-answers": [
                "...something which you did not originally expect."
            ]
        },
        {
            "question": "What happens if your input is something very complicated and the network learns to process this complicated thing into something else?",
            "reference-answers": [
                "...something which other things can also happen."
            ]
        },
        {
            "question": "What happens if your input is something very complicated and the network learns to process this complicated thing into something else?",
            "reference-answers": [
                "...something which other things can also happen."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen24-slide25/text.txt": [
        {
            "question": "What is a good hidden representation in the context of understanding and recognizing patterns?",
            "reference-answers": [
                "A good hidden representation is one that resembles something we are happy to see, making sense in some way."
            ]
        },
        {
            "question": "What are the conditions under which we would say that a hidden representation is good?",
            "reference-answers": [
                "We would say that a hidden representation is good when we like it, when we understand it, and it resembles something that we are happy to see there."
            ]
        },
        {
            "question": "What is a good hidden representation in the context of understanding and recognizing patterns?",
            "reference-answers": [
                "A good hidden representation is one that resembles something we are happy to see, making sense in some way."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen25-slide26/text.txt": [
        {
            "question": "What is a good representation in the context of a neural network, and how does it relate to the tasks it is trained for?",
            "reference-answers": [
                "A good representation in the context of a neural network is one that allows the network to solve its main task, and it is designed to be good for the center of the circumference or for translating, and also serves well on task interfaces, making sense in some way, which is visible when observing the representations on a given test set."
            ]
        },
        {
            "question": "What are some secondary tasks that can be used to evaluate the learned representations in a network?",
            "reference-answers": [
                "Sentiment classification, or whatever."
            ]
        },
        {
            "question": "What type of data is needed for training a speech recognition system versus a translation system?",
            "reference-answers": [
                "For speech recognition, you need the audio and the transcription. For translation, you need a parallel corpus."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen26-slide28/text.txt": [
        {
            "question": "What is the primary purpose of word embeddings, such as Word2Vec and GloVe, according to the text?",
            "reference-answers": [
                "Word embeddings are continuous representations of words that have much less dimensions, trained for various tasks."
            ]
        },
        {
            "question": "What are some of the best known word embeddings mentioned in the text?",
            "reference-answers": [
                "Word2Vec and GloVe."
            ]
        },
        {
            "question": "What are the two main language modeling tasks that lead to the creation of word embeddings?",
            "reference-answers": [
                "The two main language modeling tasks that lead to the creation of word embeddings are predicting the word in a corpus from its four neighbors and predicting the likely neighbors of a given word."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen27-slide29/text.txt": [
        {
            "question": "What type of relation was observed between country names and capital names in the highly dimensional space of word embeddings?",
            "reference-answers": [
                "A similar relation to the one observed between country names and capital names was observed in the highly dimensional space."
            ]
        },
        {
            "question": "What type of relation was observed between country names and capital names in the highly dimensional space?",
            "reference-answers": [
                "A similar relation to that between country names and capital names was observed."
            ]
        },
        {
            "question": "What type of relation was observed between country names and capital names in the highly dimensional space of word embeddings?",
            "reference-answers": [
                "A similar relation to the one observed between country names and capital names was observed in the highly dimensional space."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen28-slide30/text.txt": [
        {
            "question": "What type of questions were there in the test set associated with Word2Egg?",
            "reference-answers": [
                "There were two types of questions in the test set associated with Word2Egg: semantic questions and syntactic/morphosyntactic questions."
            ]
        },
        {
            "question": "What type of questions did the test set associated with Word2Egg typically consist of?",
            "reference-answers": [
                "The test set associated with Word2Egg typically consisted of semantic and syntactic/morphosyntactic questions."
            ]
        },
        {
            "question": "What type of questions were there in the test set associated with Word2Egg?",
            "reference-answers": [
                "There were two types of questions in the test set associated with Word2Egg: semantic questions and syntactic/morphosyntactic questions."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen29-slide31/text.txt": [
        {
            "question": "What is the estimated accuracy of the Tomáš Mikolov test set for semantic and syntactic questions?",
            "reference-answers": [
                "The Tomáš Mikolov test set reached an accuracy of about 60% for syntactic or morphosyntactic questions, but no accuracy estimate was provided for the semantic questions."
            ]
        },
        {
            "question": "What is the estimated accuracy of the model when it learned the space without knowing anything about the gender of nouns, existence of gender, or existence of countries?",
            "reference-answers": [
                "The accuracy of the model when it learned the space without knowing anything about the gender of nouns, existence of gender, or existence of countries is about 60%."
            ]
        },
        {
            "question": "What type of questions were found to be only three types in the test set used to evaluate the semantic learning model?",
            "reference-answers": [
                "The semantic questions were only of three types: country and city, country and currency, and country and masculine family member going to feminine family member."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen30-slide32/text.txt": [
        {
            "question": "What was the accuracy of the system when tested on its own test set, using the origin V2VAC model?",
            "reference-answers": [
                "The accuracy of the system when tested on its own test set, using the origin V2VAC model, was 43."
            ]
        },
        {
            "question": "What was the accuracy of the model on the test set when it was not trained for the specific relations being evaluated?",
            "reference-answers": [
                "The accuracy on the test set was 43."
            ]
        },
        {
            "question": "What was the accuracy of the model on the test set when using the origin V2VAC model?",
            "reference-answers": [
                "The accuracy on the test set was 43."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen31-slide33/text.txt": [
        {
            "question": "What was the performance of the subgram model on the original test set compared to the word2vec model?",
            "reference-answers": [
                "The performance of the subgram model on the original test set was 42, which was a little bit lower than the word2vec model performance."
            ]
        },
        {
            "question": "What was the performance of the subgram model on the original test set compared to the word2vec model?",
            "reference-answers": [
                "The performance of the subgram model on the original test set was 42, which was a little bit lower than the word2vec model performance."
            ]
        },
        {
            "question": "What was the performance of the model that included subword units or substrings of characters on the original test set?",
            "reference-answers": [
                "The performance of the model that included subword units or substrings of characters on the original test set was 42."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen32-slide34/text.txt": [
        {
            "question": "What is the primary advantage of writing nine rules for regular patterns in analyzing morphological behavior, according to the text?",
            "reference-answers": [
                "Writing nine rules for regular patterns will surpass the performance of both systems in both datasets significantly, illustrating that regular patterns can achieve good results without deep learning."
            ]
        },
        {
            "question": "What is the author's advice when it comes to analyzing morphological behavior in text?",
            "reference-answers": [
                "If you want some morphology analyzer, write the nine rules and don't bother with word embeddings."
            ]
        },
        {
            "question": "What type of analysis is more effective for understanding morphological behavior, according to the text?",
            "reference-answers": [
                "Writing nine rules for the regular patterns."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen33-slide35/text.txt": [
        {
            "question": "When did the paper submitted by the author and their subword word embeddings appear in the conference Text, Speech and Dialogue?",
            "reference-answers": [
                "The paper submitted by the author and their subword word embeddings appeared in the conference Text, Speech and Dialogue in September 2016."
            ]
        },
        {
            "question": "When did the follow-up paper by Tomáš Mikolov, which used the same idea of word embedding as the authors, get published?",
            "reference-answers": [
                "The follow-up paper by Tomáš Mikolov, which used the same idea of word embedding as the authors, was submitted to archive in July of the same year as the authors' paper."
            ]
        },
        {
            "question": "What conference did the authors submit their paper to in March 2016?",
            "reference-answers": [
                "Text, speech and dialogue."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen34-slide36/text.txt": [
        {
            "question": "What is the main difference between the two papers mentioned in the text?",
            "reference-answers": [
                "The main difference between the two papers is that our paper did not release the code, whereas the FastEx paper released a fast and good code."
            ]
        },
        {
            "question": "What is the key difference between the two papers mentioned in the text?",
            "reference-answers": [
                "The key difference between the two papers is that one released the code and implemented a fast code, while the other did not."
            ]
        },
        {
            "question": "What is the key factor needed for an idea to spread, according to the author of the FastEx paper?",
            "reference-answers": [
                "complementing it with a fast and good code"
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen35-slide37/text.txt": [
        {
            "question": "What are the two types of similarities that humans may evaluate when annotating words, and how do these similarities differ?",
            "reference-answers": [
                "The two types of similarities that humans may evaluate when annotating words are relatedness and similarity. Relatedness refers to the words appearing in similar contexts, such as \"teacher is related to student\" and \"coffee is related to cup\". Similarity, on the other hand, refers to the conceptual connection between words, such as \"teacher is similar to professor\" and \"car is similar to train\"."
            ]
        },
        {
            "question": "What are the two types of similarities that can be reflected in human annotation when evaluating word representations?",
            "reference-answers": [
                "The two types of similarities that can be reflected in human annotation when evaluating word representations are non-specific relatedness and conceptual similarity."
            ]
        },
        {
            "question": "What are the two types of similarities that can be observed in human annotation of words?",
            "reference-answers": [
                "The two types of similarities that can be observed in human annotation of words are non-specific relatedness and conceptual similarity."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen36-slide38/text.txt": [
        {
            "question": "What is the topic of the next section to be discussed in the exam?",
            "reference-answers": [
                "Sentence representations."
            ]
        },
        {
            "question": "What is the topic of the next section to be covered in the exam?",
            "reference-answers": [
                "Sentence representations."
            ]
        },
        {
            "question": "What is the next topic to be covered in the exam?",
            "reference-answers": [
                "Sentence representations."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen37-slide39/text.txt": [
        {
            "question": "What is the purpose of the \"cut\" in the encoder-decoder architecture that contains the whole representation of the input sentence?",
            "reference-answers": [
                "The \"cut\" in the encoder-decoder architecture contains the whole representation of the input sentence, which is stored in a fixed length vector by the encoder."
            ]
        },
        {
            "question": "What is the purpose of the cut through the network in the encoder-decoder architecture?",
            "reference-answers": [
                "The cut through the network, which is right before the decoder, has the whole representation of the sentence."
            ]
        },
        {
            "question": "What is the purpose of the cut through the network that separates the encoder and the decoder?",
            "reference-answers": [
                "The cut through the network separates the encoder and the decoder and contains the whole representation of the sentence."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen38-slide40/text.txt": [
        {
            "question": "What is the primary difference between the sentences in the upper and lower parts of the screen?",
            "reference-answers": [
                "The primary difference between the sentences in the upper and lower parts of the screen is that the upper part sentences are about receiving a card, while the lower part sentences are about giving a card."
            ]
        },
        {
            "question": "What is the key difference between the sentences in the upper and lower parts of the screen?",
            "reference-answers": [
                "The key difference between the sentences in the upper and lower parts of the screen is that the upper part sentences are about receiving a card, while the lower part sentences are about giving a card."
            ]
        },
        {
            "question": "What is the key factor that determines the similarity of the sentences in the plot from Satzkever's paper?",
            "reference-answers": [
                "The key factor that determines the similarity of the sentences in the plot from Satzkever's paper is the message of the sentence, specifically who is receiving the card."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen39-slide41/text.txt": [
        {
            "question": "Can attention-based systems handle the limitation of fixed-size vectors in processing sentences?",
            "reference-answers": [
                "Yes, attention-based systems can handle the limitation of fixed-size vectors in processing sentences because they attend to all the words in the source sentence as they go."
            ]
        },
        {
            "question": "Can attention-based systems truly perform better than other systems because they are not limited by a fixed-size vector for processing sentence meaning?",
            "reference-answers": [
                "Yes, because they attend to all the words in the source sentence as they go, and this is exactly the bottleneck that they are not suffering from."
            ]
        },
        {
            "question": "Can attention-based systems effectively handle the limitations of representing sentence meaning in a single fixed-size vector?",
            "reference-answers": [
                "Yes, attention-based systems can effectively handle the limitations of representing sentence meaning in a single fixed-size vector, as they attend to all the words in the source sentence as they go."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen40-slide42/text.txt": [
        {
            "question": "What do we expect in terms of meaning?",
            "reference-answers": [
                "Aspects of meaning, so that we know what to expect."
            ]
        },
        {
            "question": "What do we expect from the aspects of meaning?",
            "reference-answers": [
                "So that we know what do we expect."
            ]
        },
        {
            "question": "What do we expect to know about aspects of meaning?",
            "reference-answers": [
                "Aspects of meaning, so that we know what we expect."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen41-slide43/text.txt": [
        {
            "question": "What is the semantic representation of pictures according to the given explanation?",
            "reference-answers": [
                "They label each pixel in the picture with some class label."
            ]
        },
        {
            "question": "What is the purpose of labeling each pixel in a picture with a class label?",
            "reference-answers": [
                "They label each pixel in the picture with some class label."
            ]
        },
        {
            "question": "What is the semantic representation of pictures according to the text?",
            "reference-answers": [
                "They label each pixel in the picture with some class label."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen42-slide44/text.txt": [
        {
            "question": "Can you determine the expected output of a computer program, and is it decidable whether the program will stop at all?",
            "reference-answers": [
                "It is not decidable whether the program will stop at all, but you can determine the expected output of a computer program."
            ]
        },
        {
            "question": "Can you determine whether a computer program will stop at all, given its semantics?",
            "reference-answers": [
                "No, it is not decidable whether the program will stop at all or not."
            ]
        },
        {
            "question": "Is the meaning of sentences always decidable?",
            "reference-answers": [
                "No, the meaning of sentences is not always decidable."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen43-slide45/text.txt": [
        {
            "question": "What is the main idea of the structuralist approach to the meaning of a sentence, according to the Textogramalical Theory?",
            "reference-answers": [
                "The main idea of the structuralist approach to the meaning of a sentence is that units of the lower layers of representation are put together to form units in the higher levels of representation, and the linguistic meaning is defined at each level separately by the relation to the surrounding layer."
            ]
        },
        {
            "question": "What is the main difference between the structuralist approach to the meaning of a sentence and the linguistic meaning itself?",
            "reference-answers": [
                "The main difference between the structuralist approach to the meaning of a sentence and the linguistic meaning itself is that the structuralist approach captures the structure of expressions, whereas the linguistic meaning refers to the structure of expressions at each level of linguistic description (morphology, syntax, semantics)."
            ]
        },
        {
            "question": "What is the main idea of the structuralist approach to the meaning of a sentence according to the Textogramalical Theory by Petrus Gall?",
            "reference-answers": [
                "The main idea of the structuralist approach to the meaning of a sentence according to the Textogramalical Theory by Petrus Gall is that units of the lower layers of representation are put together to form units in the higher levels of representation, and the linguistic meaning is defined at each level separately by the relation to the surrounding layer."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen44-slide46/text.txt": [
        {
            "question": "What is the benefit of continuous representations that is not present in symbolic theories, according to the author?",
            "reference-answers": [
                "The great benefit of continuous representations is that they are learnable, they emerge as a side effect of learning to do some tasks, and they are good at capturing the meanings as vague, applicable in many possible situations, and the ambiguity of expressions."
            ]
        },
        {
            "question": "What is the benefit of continuous representations that is not easily captured in symbolic theories?",
            "reference-answers": [
                "The great benefit of continuous representations is that they are learnable, and as a side effect, we get these representations, and they can easily capture that the meanings are vague, and that the meanings are never specified enough to fit to a single situation."
            ]
        },
        {
            "question": "What is the benefit of continuous representations that is not necessarily present in symbolic theories?",
            "reference-answers": [
                "The great benefit of continuous representations is that they are learnable, they emerge as a side effect of learning to do some tasks, and they are good at capturing the meanings as vague, the ambiguity of expressions, and the statefulness of expressions."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen45-slide47/text.txt": [
        {
            "question": "What is the central idea behind Chris Manning's concept of compositionality of meaning?",
            "reference-answers": [
                "The central idea behind Chris Manning's concept of compositionality of meaning is that understanding complex sentences relies on being able to compose, or construct the meaning of the whole from new elements."
            ]
        },
        {
            "question": "What is the central idea of Chris Manning's concept of compositionality in relation to understanding complex sentences?",
            "reference-answers": [
                "The central idea of Chris Manning's concept of compositionality is that understanding complex sentences relies on the compositionality, and that composing the meaning of the whole sentence from its elements is crucial."
            ]
        },
        {
            "question": "What is the key concept, as described by Chris Manning, that is crucial for understanding complex sentences?",
            "reference-answers": [
                "The compositionality of meaning."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen46-slide48/text.txt": [
        {
            "question": "What is the approach used by Carverne and Canavra to represent hierarchical structure in vectors of real numbers?",
            "reference-answers": [
                "Carverne and Canavra illustrate that you can represent hierarchical structure or whatever you like that you have put together by having some operations and being able to reverse some of these operations."
            ]
        },
        {
            "question": "What is an example of a compositional structure that can be represented using the method illustrated by Carverne and Canavra?",
            "reference-answers": [
                "A hierarchical structure, or a structure that you have put together, such as a list in programming languages like Lisp, can be represented using the method illustrated by Carverne and Canavra."
            ]
        },
        {
            "question": "What type of operation can be used to query a vector and recover the value of a specific variable, disregarding the other variables?",
            "reference-answers": [
                "Multiplication."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen47-slide49/text.txt": [
        {
            "question": "How can sentence level embeddings, created by deterministic encoders, encode ambiguity in a sentence, and what would be an ideal representation of an expression in a semantic space?",
            "reference-answers": [
                "It's difficult to model ambiguity in sentence level embeddings, but one possible approach is to create a distribution over the points in the semantic space, where the embedding for a sentence should represent a distribution over the meanings of its words, rather than a single point. For example, the embedding for \"Apple\" should be a distribution peaked around the area of fruits, with another peak around the area of companies, to reflect its dual meaning."
            ]
        },
        {
            "question": "How do sentence level embeddings created by deterministic encoders encode the ambiguity of an expression?",
            "reference-answers": [
                "It's difficult to say how these embeddings encode the ambiguity, but it might be some average of the meanings, and they don't seem to work well for expressions with multiple meanings."
            ]
        },
        {
            "question": "How do sentence-level embeddings created by deterministic encoders encode the ambiguity of an ambiguous sentence?",
            "reference-answers": [
                "It's difficult to say how these embeddings encode the ambiguity, but it might be some average of the meanings, and they don't seem to work well for ambiguous words like \"apple\"."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen48-slide50/text.txt": [
        {
            "question": "What is the main problem with the stateless meaning in modeling, according to the given text?",
            "reference-answers": [
                "The main problem with the stateless meaning in modeling is that it suffers from the ambiguity."
            ]
        },
        {
            "question": "What is the primary problem with stateless meaning representation in language processing tasks, according to the provided text?",
            "reference-answers": [
                "The primary problem with stateless meaning representation is the ambiguity."
            ]
        },
        {
            "question": "What is the main issue with the stateless meaning of the model, according to the provided text?",
            "reference-answers": [
                "The main issue with the stateless meaning of the model is that it suffers from the problems with the ambiguity."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen49-slide51/text.txt": [
        {
            "question": "Is the space of linguistic meanings continuous?",
            "reference-answers": [
                "The space of linguistic meanings is not explicitly stated as continuous or discontinuous in the text, but it is noted that the space of linguistic expressions is \"just huge\" and that the experiment of Markus Dreyer and Daniel Marku resulted in \"dozens of thousands of possible translations\", suggesting that the space of linguistic meanings may not be continuous."
            ]
        },
        {
            "question": "Is the linguistic space of meanings continuous?",
            "reference-answers": [
                "The answer to the question \"Is the linguistic space of meanings continuous?\" is not explicitly stated in the provided text."
            ]
        },
        {
            "question": "Is the linguistic space of meanings continuous?",
            "reference-answers": [
                "The answer to the question \"Is the linguistic space of meanings continuous?\" is not explicitly stated in the provided text."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen50-slide52/text.txt": [
        {
            "question": "Will the Czech counterparts of two different English sentences live in the same area in the sentence embedding space, considering the manifold of each sentence?",
            "reference-answers": [
                "It is unclear whether the Czech counterparts of two different English sentences will live in the same area in the sentence embedding space, as the TEXT does not provide a conclusive answer to this question."
            ]
        },
        {
            "question": "Will the Czech counterparts of two different English sentences live in the same area in the sentence embedding space?",
            "reference-answers": [
                "It is unclear whether the Czech counterparts of two different English sentences will live in the same area in the sentence embedding space, as the TEXT states that \"the question is whether... they will live in the same area in the sentence embedding space.\""
            ]
        },
        {
            "question": "Will the Czech counterparts of different English sentences live in the same area in the sentence embedding space?",
            "reference-answers": [
                "It is unclear whether the Czech counterparts of different English sentences will live in the same area in the sentence embedding space."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen51-slide53/text.txt": [
        {
            "question": "What is the purpose of asking human annotators to provide sentences in between examples of a particle direction?",
            "reference-answers": [
                "To validate the relation and create a partial ordered set of sentences."
            ]
        },
        {
            "question": "What is the purpose of asking human annotators to provide sentences between two examples of a particular direction of exploration?",
            "reference-answers": [
                "To validate the relation and create a partial ordered set of sentences."
            ]
        },
        {
            "question": "What type of sentences are being explored and validated in this research?",
            "reference-answers": [
                "Sentences in a continuous space of sentences, specifically in the context of particle directions and extrapolation."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen52-slide52/text.txt": [
        {
            "question": "What is the purpose of having sentences with similar meaning in the same input sentence?",
            "reference-answers": [
                "The sentences come from the same input sentence."
            ]
        },
        {
            "question": "What is the purpose of the sentences in the provided text?",
            "reference-answers": [
                "The sentences in the provided text are all variations of the same idea, coming from the same input sentence, and they aim to convey a similar meaning."
            ]
        },
        {
            "question": "What type of sentences are being referred to in the given TEXT?",
            "reference-answers": [
                "Identical sentences."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen53-slide53/text.txt": [
        {
            "question": "What is the purpose of organizing the sentences into a partial ordered set in the context of the given text?",
            "reference-answers": [
                "We are organizing the sentences to this partial ordered set so that we can relate it to the manifold of some embeddings."
            ]
        },
        {
            "question": "What is the purpose of organizing sentences into a partial ordered set?",
            "reference-answers": [
                "We are organizing the sentences to this partial ordered set in order to relate this partial ordered set to the manifold of some embeddings."
            ]
        },
        {
            "question": "What type of mathematical structure is being referred to as a \"partial ordered set\" in the given text?",
            "reference-answers": [
                "A set with a partial order relation."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen54-slide54/text.txt": [
        {
            "question": "What are some examples of modification in sentences that can be asked in an exam?",
            "reference-answers": [
                "We could ask about different variants of politeness, make the sentence more in the future or more in the past, express how much the speaker believes the meaning of the sentence, and how much the speaker is willing or able to do the action expressed in the sentence."
            ]
        },
        {
            "question": "What are some types of modification that can be applied to sentences?",
            "reference-answers": [
                "We could ask people to make the sentence more in the future or more in the past, express how much the speaker believes the meaning of the sentence, and we could also ask them to express how much the speaker is willing or able to do the action expressed in the sentence."
            ]
        },
        {
            "question": "What are some examples of modification that can be made to a sentence?",
            "reference-answers": [
                "We could ask people to make the sentence more in the future or more in the past, express how much the speaker believes the meaning of the sentence, and we could ask them to make the sentence more in terms of the generality, whether it is cold, chilly, or freezing."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen55-slide55/text.txt": [
        {
            "question": "What is the general idea behind the three versions of the sentence in the given text?",
            "reference-answers": [
                "The general idea behind the three versions of the sentence is that they all convey the idea of doing something to a wall, with varying degrees of specificity and vagueness."
            ]
        },
        {
            "question": "What is the purpose of the expression \"do the thingy there\" in the context of the given text?",
            "reference-answers": [
                "The expression \"do the thingy there\" is used when the speaker is out of words and can't think of a specific way to phrase something, resulting in a vague or generic instruction that can still be understood by the human in the context."
            ]
        },
        {
            "question": "What is the effect of using different versions of a sentence in the same context?",
            "reference-answers": [
                "The different versions of the sentence can still be understandable by the human in the same context, as the last version of the sentence is still understandable based on the context."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen56-slide56/text.txt": [
        {
            "question": "What is the difference in tone between the polite and impolite pairs of sentences in the provided text?",
            "reference-answers": [
                "The polite pairs of sentences are characterized by phrases such as \"Can you please give me a minute?\", \"May I talk to Mary?\", and \"Is Mary here?\", which convey a sense of respect and consideration for the listener's time and feelings. \n\nThe impolite pairs of sentences, on the other hand, are marked by phrases such as \"Close the damn door man\", \"You never answer your phone\", which convey a sense of annoyance, frustration, and disrespect towards the listener."
            ]
        },
        {
            "question": "What is the difference in tone between the polite and impolite pairs of sentences in the given examples?",
            "reference-answers": [
                "The polite pairs of sentences have a polite tone, while the impolite pairs have a rude tone."
            ]
        },
        {
            "question": "What is the difference between polite and impolite pairs of sentences as illustrated in the provided examples?",
            "reference-answers": [
                "The difference between polite and impolite pairs of sentences is the level of politeness and rudeness expressed, with polite pairs using phrases like \"Can you please\" and \"May I,\" and impolite pairs using phrases like \"Close the damn door man\" and \"You never answer your phone.\""
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen57-slide57/text.txt": [
        {
            "question": "What is the purpose of asking annotators to create sentences that are in between two extremes, specifically in the politeness and rudeness dimension?",
            "reference-answers": [
                "To create a range of sentences that convey the same message in different ways, illustrating various formulations for expressing politeness and rudeness."
            ]
        },
        {
            "question": "What is the purpose of the sentences that annotators will be asked to create?",
            "reference-answers": [
                "The annotators will be asked to create sentences that are in between two extremes (one being \"you aren't made of glass\" and the other being a polite request like \"please move\"), which will illustrate various ways to formulate the same message, specifically in the politeness and rudeness dimension."
            ]
        },
        {
            "question": "What type of sentences are annotators asked to create in the politeness and rudeness dimension?",
            "reference-answers": [
                "Sentences which are in between politeness and rudeness, such as \"hey can you move or please move or could you move a little bit, you're blocking the screen.\""
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen58-slide58/text.txt": [
        {
            "question": "What is the purpose of asking a third set of annotators to put different wordings on the scale?",
            "reference-answers": [
                "To organize them."
            ]
        },
        {
            "question": "What is the purpose of asking a third set of annotators to put different wordings on a scale?",
            "reference-answers": [
                "To organize them."
            ]
        },
        {
            "question": "What is the purpose of asking a third set of annotators to put different wordings on a scale?",
            "reference-answers": [
                "To organize them."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen59-slide59/text.txt": [
        {
            "question": "Will you be able to find similar relations in the partially ordered set of sentences that are incomparable in terms of politeness?",
            "reference-answers": [
                "The question is whether we will be able to find similar relations in the partially ordered set of sentences that are incomparable in terms of politeness."
            ]
        },
        {
            "question": "Will you be able to find similar relations in a partially ordered set where some sentences are totally incomparable?",
            "reference-answers": [
                "The question is whether we will be able to find similar relations in a partially ordered set where some sentences are totally incomparable."
            ]
        },
        {
            "question": "What type of relations can be found in a partially ordered set of sentences that are incomparable in terms of politeness or rudeness?",
            "reference-answers": [
                "Similar relations."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen60-slide60/text.txt": [
        {
            "question": "What is the purpose of unfolding or unrolling the manifold in the highly dimensional space?",
            "reference-answers": [
                "So you will be hoping that in the highly dimensional space you will have a similar structure."
            ]
        },
        {
            "question": "What is the purpose of unfolding or unrolling a manifold in a highly dimensional space?",
            "reference-answers": [
                "So you will be hoping that in the highly dimensional space you will have a similar structure."
            ]
        },
        {
            "question": "What happens when you unfold or unroll a manifold in the highly dimensional space?",
            "reference-answers": [
                "...you will have a similar structure."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen61-slide61/text.txt": [
        {
            "question": "What type of representation is being referred to as having a better match with the manually collected data?",
            "reference-answers": [
                "A semantic representation."
            ]
        },
        {
            "question": "What type of representation would have a better match with the manually collected data, according to the given text?",
            "reference-answers": [
                "A very semantic representation."
            ]
        },
        {
            "question": "What type of representation is being referred to as having a better match with the manually collected data?",
            "reference-answers": [
                "A semantic representation."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen62-slide62/text.txt": [
        {
            "question": "What is the topic of the given text?",
            "reference-answers": [
                "Evaluating sentence representation."
            ]
        },
        {
            "question": "What is the topic of the discussion in the provided text?",
            "reference-answers": [
                "Evaluating sentence representation."
            ]
        },
        {
            "question": "What is the main topic of the provided text?",
            "reference-answers": [
                "Evaluating sentence representation."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen63-slide63/text.txt": [
        {
            "question": "What is SenteVal, and how does it relate to evaluating sentence representations?",
            "reference-answers": [
                "SenteVal is a repository or toolset for scoring sentence representations in many ways, and it evaluates sentence representations by providing a reference for a given sentence."
            ]
        },
        {
            "question": "What is SenteVal, and what is its purpose in evaluating sentence representations?",
            "reference-answers": [
                "SenteVal is a repository or toolset for scoring sentence representations in many ways, and its purpose is to evaluate sentence representations by converting them to vectors and assessing their performance in various tasks."
            ]
        },
        {
            "question": "What is SenteVal, and how does it work in the context of evaluating sentence representations?",
            "reference-answers": [
                "SenteVal is a repository or toolset for scoring sentence representations in many ways. It evaluates a sentence representation by a reference, and the vector cannot be evaluated alone, so it needs to be processed by a large number of sentences and then evaluated in various tasks."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen64-slide64/text.txt": [
        {
            "question": "What is the focus of the experiment from 2018 that the author is going to show?",
            "reference-answers": [
                "The focus of the experiment from 2018 is to identify how much semantic the representations learned by the attention model in a sequence-to-sequence architecture are."
            ]
        },
        {
            "question": "What was the year of the experiment that the speaker is referring to in their presentation?",
            "reference-answers": [
                "2018"
            ]
        },
        {
            "question": "What was the main focus of the experiment presented in 2018, in terms of the attention model and sequence-to-sequence architecture?",
            "reference-answers": [
                "The main focus of the experiment presented in 2018 was to identify how much semantic the representations learned by the attention model, in relation to the equality of translation and BLEU score."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen65-slide65/text.txt": [
        {
            "question": "What is the purpose of using a neural network to convert the input sentence to a hidden representation before passing it to the Senteval tool?",
            "reference-answers": [
                "The purpose of using a neural network to convert the input sentence to a hidden representation before passing it to the Senteval tool is to give these representations to the Senteval tool, allowing it to learn to process the representations and predict the score."
            ]
        },
        {
            "question": "What type of neural network representations can be used to convert input sentences to hidden representations for the Senteval evaluation task?",
            "reference-answers": [
                "Neural network representations."
            ]
        },
        {
            "question": "What type of neural network representations are used to convert the input sentence to a hidden representation for the Senteval evaluation task?",
            "reference-answers": [
                "Neural network representations."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen66-slide66/text.txt": [
        {
            "question": "If your representation would not highlight the important things in the reference, what would be the likely outcome in the classification task?",
            "reference-answers": [
                "You would get a low score in the classification task."
            ]
        },
        {
            "question": "If your representation would not highlight the important things in the reference, what would be the likely outcome in the classification task?",
            "reference-answers": [
                "You would get a low score in the classification task."
            ]
        },
        {
            "question": "What type of task would be negatively affected by a poor representation of a particle task?",
            "reference-answers": [
                "The classification task."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen67-slide67/text.txt": [
        {
            "question": "What is the purpose of the individual sentence representations mentioned in the task?",
            "reference-answers": [
                "They serve in the task alone."
            ]
        },
        {
            "question": "What are the SOLOTAR classification tasks?",
            "reference-answers": [
                "Movie sentiment, product review polarity, whether someone is assessing the product or not, or the question type, whether someone is asking for a number or for location."
            ]
        },
        {
            "question": "What type of classification tasks are represented by the SOLOTAR?",
            "reference-answers": [
                "Movie sentiment, product review polarity, whether someone is assessing the product or not, or the question type, whether someone is asking for a number or for location."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen68-slide68/text.txt": [
        {
            "question": "What is an example of an entailment relation between two sentences according to the natural language inference task?",
            "reference-answers": [
                "A square full of people and life, and the square is busy."
            ]
        },
        {
            "question": "What are the three classes of classification for the natural language inference task?",
            "reference-answers": [
                "One sentence is entailed in the other, whether they are neutral to each other, so they are about different things or whether they are in conflict with each other."
            ]
        },
        {
            "question": "What is the evaluation metric for the classification of pairs of sentence embeddings in the natural language inference task?",
            "reference-answers": [
                "The extent to which you classify these pairs of sentence embeddings."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen69-slide69/text.txt": [
        {
            "question": "What is the alternative method for evaluating sentence embeddings when there is no regression training data available?",
            "reference-answers": [
                "Measuring the similarity between the embeddings."
            ]
        },
        {
            "question": "What is an alternative approach to evaluating sentence embeddings if regression training data is not available?",
            "reference-answers": [
                "You can simply measure the similarity between the embeddings and predict the similarity by the similarity of the embeddings."
            ]
        },
        {
            "question": "What method can be used to evaluate sentence embeddings if there is no regression training data available?",
            "reference-answers": [
                "Measure the similarity between the embeddings and predict the similarity by the similarity of the embeddings."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen70-slide70/text.txt": [
        {
            "question": "What are the two sources of data mentioned in the text as part of the evaluation process?",
            "reference-answers": [
                "Two sources of data mentioned in the text as part of the evaluation process are: \n1. The Chinese sentence\n2. Its many translations."
            ]
        },
        {
            "question": "What are the two sources of data mentioned in the text as being used for evaluation?",
            "reference-answers": [
                "Two sources of data mentioned in the text as being used for evaluation are: \n1. The Chinese sentence \n2. Its many translations."
            ]
        },
        {
            "question": "What are the two sources of data being referred to in the text?",
            "reference-answers": [
                "Two sources of data: \n1. The Chinese sentence \n2. Its many translations."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen71-slide71/text.txt": [
        {
            "question": "How many captions are associated with a single image in the Coco data set?",
            "reference-answers": [
                "Five captions."
            ]
        },
        {
            "question": "What is the typical structure of the Coco data set?",
            "reference-answers": [
                "The Coco data set contains a single image with five captions."
            ]
        },
        {
            "question": "What type of data is the Coco dataset?",
            "reference-answers": [
                "The Coco dataset is images."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen72-slide72/text.txt": [
        {
            "question": "What measures are available to evaluate the quality of the clusters formed from the original Chinese sentence or the picture?",
            "reference-answers": [
                "A few measures to evaluate how good these clusters are."
            ]
        },
        {
            "question": "What are the measures used to evaluate the quality of the clusters?",
            "reference-answers": [
                "A few measures to evaluate how good these clusters are."
            ]
        },
        {
            "question": "What are the measures used to evaluate how good the clusters are?",
            "reference-answers": [
                "The measures used to evaluate how good the clusters are are not explicitly stated in the TEXT, however, it is mentioned that \"we have a few measures\" to evaluate the quality of the clusters."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen73-slide73/text.txt": [
        {
            "question": "What is the purpose of the Davis Bulldin Index in the context of clustering?",
            "reference-answers": [
                "The Davis Bulldin Index checks how well the cluster is separated from the other clusters, meaning it measures how clearly separated the clusters of individual sentences or pictures are."
            ]
        },
        {
            "question": "What is the purpose of the Davis Bulldin Index in the context of clustering?",
            "reference-answers": [
                "The Davis Bulldin Index checks how well the cluster is separated from the other clusters, meaning it measures how clearly separated the clusters of individual sentences or pictures are."
            ]
        },
        {
            "question": "What is the purpose of the Davis Bulldin Index?",
            "reference-answers": [
                "The Davis Bulldin Index checks how well the cluster is separated from the other clusters, meaning it measures how clearly separated individual sentences or pictures are from each other."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen74-slide74/text.txt": [
        {
            "question": "What is another way of measuring the goodness of a clustering in the given method?",
            "reference-answers": [
                "You retrieve the nearest neighbor for each element and you will check whether this nearest neighbor is in the same cluster."
            ]
        },
        {
            "question": "What is another way of measuring the goodness of a clustering, besides checking if the clusters are compact?",
            "reference-answers": [
                "Retrieving the nearest neighbor for each element and checking whether this nearest neighbor is in the same cluster."
            ]
        },
        {
            "question": "What is another way of measuring the goodness of a clustering besides checking if the clusters are compact?",
            "reference-answers": [
                "Retrieving the nearest neighbor for each element and checking whether this nearest neighbor is in the same cluster."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen75-slide75/text.txt": [
        {
            "question": "What is the purpose of using a test set in a classification task?",
            "reference-answers": [
                "To check whether the classifier is predicting the correct class or not."
            ]
        },
        {
            "question": "What is the purpose of using a test set in a classification task?",
            "reference-answers": [
                "To check whether the classifier is predicting the correct class or not."
            ]
        },
        {
            "question": "What is the purpose of removing points from a dataset to train a classifier?",
            "reference-answers": [
                "To check whether the classifier is predicting the correct class or not, using the removed points as a test set."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen76-slide76/text.txt": [
        {
            "question": "What is the problem with using the attention mechanism in sequence-to-sequence models to generate a single vector representation of an input sentence?",
            "reference-answers": [
                "The attention mechanism produces a different vector at every step of the decoding process, resulting in no single vector representation of the input sentence."
            ]
        },
        {
            "question": "What is the problem with using a sequence-to-sequence model with annotation features, a bidirectional encoder, and an attention mechanism for sentence representation, especially when dealing with varying sentence lengths?",
            "reference-answers": [
                "The problem is that the attention mechanism generates a different vector at every step of the decoding process, resulting in no single vector representation of the input sentence, and concatenating these vectors is not possible due to varying sentence lengths."
            ]
        },
        {
            "question": "What is the problem with using a sequence-to-sequence model with annotation features, a bidirectional encoder, and an attention mechanism to obtain a single vector representation of an input sentence?",
            "reference-answers": [
                "The attention mechanism produces a different vector at every step of the decoding process, resulting in no single vector representation of the input sentence."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen77-slide77/text.txt": [
        {
            "question": "How can we create fixed-size representations in a model while still preserving the information attached to the model, without using attention?",
            "reference-answers": [
                "One option is to well don't use attention."
            ]
        },
        {
            "question": "How do we create fixed-size representations in a model while preserving the attached information?",
            "reference-answers": [
                "One option is to well don't use attention."
            ]
        },
        {
            "question": "How do we create fixed-size representations in a model while still preserving the information attached to the model?",
            "reference-answers": [
                "One option is to well don't use attention."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen78-slide78/text.txt": [
        {
            "question": "What was the early practice of NullMT in terms of encoding?",
            "reference-answers": [
                "You can use just the final state of each of these directions of encoding."
            ]
        },
        {
            "question": "What was the early practice of NullMT in encoding?",
            "reference-answers": [
                "You can use just the final state of each of these directions of encoding."
            ]
        },
        {
            "question": "What was the early practice of NullMT in encoding?",
            "reference-answers": [
                "You can use just the final state of each of these directions of encoding."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen79-slide79/text.txt": [
        {
            "question": "What is the purpose of summing over all the vectors in the process of creating a sentence representation?",
            "reference-answers": [
                "To ensure the resulting vector for the sentence representation is always of the same size regardless of the sentence length."
            ]
        },
        {
            "question": "What is the purpose of summing over all vectors in the process of creating a sentence representation?",
            "reference-answers": [
                "To ensure the resulting vector for the sentence representation is always of the same size regardless of the sentence length."
            ]
        },
        {
            "question": "What type of pooling is recommended to ensure that the resulting vector for a sentence representation is always of the same size regardless of the sentence length?",
            "reference-answers": [
                "Max pooling or average pooling over all the states."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen80-slide80/text.txt": [
        {
            "question": "What is the purpose of using multiple heads in the inner attention mechanism in the transformer architecture?",
            "reference-answers": [
                "The purpose of using multiple heads in the inner attention mechanism in the transformer architecture is to give the system flexibility to look at various inputs and various parts of the input sentence."
            ]
        },
        {
            "question": "What is the purpose of using multiple heads in the inner attention mechanism in the transformer architecture?",
            "reference-answers": [
                "The purpose of using multiple heads in the inner attention mechanism in the transformer architecture is to give the system flexibility to look at various inputs and various parts of the input sentence."
            ]
        },
        {
            "question": "What is the purpose of using multiple heads in the inner attention mechanism in the transformer architecture?",
            "reference-answers": [
                "The purpose of using multiple heads in the inner attention mechanism in the transformer architecture is to give the system flexibility to look at various inputs and various parts of the input sentence."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen81-slide81/text.txt": [
        {
            "question": "What is the term used to describe the process of the decoder attending to various parts of the sentence, as well as a summary of attention?",
            "reference-answers": [
                "Attention-attention or compound attention."
            ]
        },
        {
            "question": "What is the term used to describe the process where the decoder operates on the entire embedding of the sentence, as well as attending to a summary of attention?",
            "reference-answers": [
                "Attention-attention."
            ]
        },
        {
            "question": "What type of attention mechanism is described in the text as allowing the decoder to attend to various parts of the sentence?",
            "reference-answers": [
                "Attention-attention or compound attention."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen82-slide82/text.txt": [
        {
            "question": "What type of network or model is assumed to have a fixed number of words in the output sentence?",
            "reference-answers": [
                "The recurrent network and the transformer style encoder and transformer style decoder are assumed to have a fixed number of words in the output sentence."
            ]
        },
        {
            "question": "What type of encoder and decoder can be used to generate a sentence with a fixed number of words?",
            "reference-answers": [
                "The transformer style encoder and transformer style decoder."
            ]
        },
        {
            "question": "What type of encoder and decoder can be used to process output sentences of a fixed number of words?",
            "reference-answers": [
                "The transformer style encoder and transformer style decoder."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen83-slide83/text.txt": [
        {
            "question": "What difference did the use of different data sets (English to Czech vs. English to German) make in the evaluation of the sentence embeddings?",
            "reference-answers": [
                "The use of different data sets (English to Czech vs. English to German) made the results affected by the size of the training data and the domain variables."
            ]
        },
        {
            "question": "What effect did the size of the training data have on the results of the English sentence embeddings?",
            "reference-answers": [
                "The size of the training data had an effect on the results of the English sentence embeddings, as the results differed between the English to Czech systems (using a large corpus of diverse domains) and the English to German systems (using only the Multi-30k dataset, which is limited to image captions)."
            ]
        },
        {
            "question": "What type of data sets were used for training systems to translate English into Czech and German?",
            "reference-answers": [
                "For English to Czech, a large corpus of very diverse domains was used. For English to German, the Multi-30k dataset which is on image captions was used."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen84-slide84/text.txt": [
        {
            "question": "What is the best-performing model in terms of BLEU score according to the results of the probes?",
            "reference-answers": [
                "The standard normal attention model."
            ]
        },
        {
            "question": "What is the best performance in terms of BLEU score among the models tested?",
            "reference-answers": [
                "The standard normal attention model."
            ]
        },
        {
            "question": "What is the best performance in terms of BLEU score achieved by the models used in the probes?",
            "reference-answers": [
                "The standard normal attention model."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen85-slide85/text.txt": [
        {
            "question": "What is the reason for trusting the BLEU scores in the English evaluation?",
            "reference-answers": [
                "We can trust BLEU scores on the English evaluation because the BLEU scores were consistent with human evaluation."
            ]
        },
        {
            "question": "Why did the authors choose to double-check the BLEU scores with human evaluation?",
            "reference-answers": [
                "Because we want to rely on the BLEU scores as a measure of the translation quality."
            ]
        },
        {
            "question": "What measure of translation quality were the researchers relying on to trust the BLEU scores?",
            "reference-answers": [
                "BLEU scores."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen86-slide86/text.txt": [
        {
            "question": "What type of attention mechanisms are observed to perform better in setups?",
            "reference-answers": [
                "Inner attention and compound attention."
            ]
        },
        {
            "question": "What type of attention performs better in setups used in certain applications?",
            "reference-answers": [
                "Inner attention and compound attention perform better in setups used in certain applications."
            ]
        },
        {
            "question": "What type of attention setups perform better according to the observations made?",
            "reference-answers": [
                "The setups which use the inner attention or the compound attention perform better."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen87-slide87/text.txt": [
        {
            "question": "What is the relationship between the number of heads in attention and the score?",
            "reference-answers": [
                "The more heads in attention, the better the score will be."
            ]
        },
        {
            "question": "What is the relationship between the number of heads in attention and the score?",
            "reference-answers": [
                "The more heads in attention, the better the score will be."
            ]
        },
        {
            "question": "What is the relationship between the number of heads in attention and the score?",
            "reference-answers": [
                "The more heads in attention, the better the score will be."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen88-slide88/text.txt": [
        {
            "question": "What is the significance of the semantic evaluation of the representations learned by the English to Czech machine translation system?",
            "reference-answers": [
                "The significance of the semantic evaluation of the representations learned by the English to Czech machine translation system is that it is important."
            ]
        },
        {
            "question": "What is the purpose of the semantic evaluation mentioned in the provided text?",
            "reference-answers": [
                "The purpose of the semantic evaluation is to assess the representations learned by the English to Czech machine translation system."
            ]
        },
        {
            "question": "What is the significance of the semantic evaluation of the English to Czech machine translation system?",
            "reference-answers": [
                "The significance of the semantic evaluation of the English to Czech machine translation system is that it is important."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen89-slide89/text.txt": [
        {
            "question": "What is the significance of glove embeddings in the measures mentioned in the text?",
            "reference-answers": [
                "The baselines such as bag of words using glove embeddings are very good in these measures."
            ]
        },
        {
            "question": "What are the two methods for representing sentences that are mentioned as being very good in the measures provided?",
            "reference-answers": [
                "The two methods for representing sentences mentioned as being very good in the measures provided are glove embeddings and bag of words."
            ]
        },
        {
            "question": "What type of evaluation measures are used to assess the performance of the neural network systems and glove embeddings in the provided dataset?",
            "reference-answers": [
                "The centival evaluation measures used to assess the performance of the neural network systems and glove embeddings include: \n1. Average accuracy for the classification task\n2. Average similarity for the similarity-based task\n3. COCO dataset using the Davis-Bulden index\n4. Clustering and neural networks"
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen90-slide90/text.txt": [
        {
            "question": "What is the recommended approach for using attention in models to improve performance across multiple evaluation tasks?",
            "reference-answers": [
                "It is better to use just the final state of the encoder and decoder."
            ]
        },
        {
            "question": "Does using the final state of the encoder and decoder in a system improve its performance across multiple evaluation tasks?",
            "reference-answers": [
                "Yes, using the final state of the encoder and decoder is better for performance across multiple evaluation tasks."
            ]
        },
        {
            "question": "What is the effect of using attention in a model when evaluating its performance across multiple tasks?",
            "reference-answers": [
                "Using attention in a model actually harms its performance when evaluating it across multiple tasks, and using just the final state of the encoder and decoder would serve better."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen91-slide91/text.txt": [
        {
            "question": "How does the number of heads in a setup affect performance in semantics tasks?",
            "reference-answers": [
                "The more heads we have in the same setup, the worse the performance in the semantics tasks."
            ]
        },
        {
            "question": "What is the effect of having more heads in a setup on performance in semantics tasks?",
            "reference-answers": [
                "The more heads we have in the same setup, the worse the performance in the semantics tasks."
            ]
        },
        {
            "question": "What happens to the performance in semantics tasks when there are more heads in the same setup?",
            "reference-answers": [
                "The performance in the semantics tasks worsens when there are more heads in the same setup."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen92-slide92/text.txt": [
        {
            "question": "What is the primary limitation of the sequence-to-sequence model in natural language processing, as illustrated by the system's ability to produce good translations without understanding the sentence meaning?",
            "reference-answers": [
                "The primary limitation of the sequence-to-sequence model in natural language processing is that it operates at a shallow level, where it stores the words in the sentence rather than the meaning, and it is not necessary to process the message of the sentence to produce good translations."
            ]
        },
        {
            "question": "What type of representation do sequence-to-sequence models use, according to the text, to translate sentences?",
            "reference-answers": [
                "The sequence-to-sequence models use superficial information, specifically the words in the sentence, rather than the meaning of the sentence, to translate sentences."
            ]
        },
        {
            "question": "What type of representation does a sequence-to-sequence model store, according to the provided text?",
            "reference-answers": [
                "The sequence-to-sequence model stores the words that are there in the sentence, not the meaning of the sentence."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen93-slide93/text.txt": [
        {
            "question": "What is the effect of removing the transformer setup in the English to German evaluation on the correlation between different metrics?",
            "reference-answers": [
                "The BLE is more negatively correlated and the other metrics are more positively correlated with each other when removing the transformer setup."
            ]
        },
        {
            "question": "What type of neural network is suggested to be re-evaluated in the text, given that the standard Bahdanau shallow recurrent neural network is found to be only processing rather than generating representations for semantic scoring?",
            "reference-answers": [
                "Deep recurrent neural networks."
            ]
        },
        {
            "question": "What type of neural network is the model that is being considered for re-evaluation, and what is the primary concern with the current implementation of this model?",
            "reference-answers": [
                "The model being considered for re-evaluation is a recurrent neural network. The primary concern with the current implementation of this model is that it is shallow (i.e., it uses the standard Bahdanau shallow recurrent neural network), which may not lead to representations that perform well in semantic scoring."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen94-slide94/text.txt": [
        {
            "question": "What is the attention-attention model described in the text?",
            "reference-answers": [
                "The attention-attention model described in the text is a compound attention model with eight heads, where the network learns inner attention and the heads look at specific output words when the sentence produces a particular output word."
            ]
        },
        {
            "question": "What is the name of the attention model described in the text that combines inner and compound attention?",
            "reference-answers": [
                "Attention-attention model."
            ]
        },
        {
            "question": "What type of attention mechanism is being referred to in the \"attention-attention model\"?",
            "reference-answers": [
                "Compound attention."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen95-slide95/text.txt": [
        {
            "question": "What impression did you have when you observed the pattern of the yellow and red hats in multiple sentences?",
            "reference-answers": [
                "We had the impression that like the yellow hat is always used at the beginning of the sentence and then the red hat is the second one used."
            ]
        },
        {
            "question": "What pattern did the researchers observe when using the yellow and red hats in multiple sentences?",
            "reference-answers": [
                "The researchers observed that the yellow hat is always used at the beginning of the sentence, and the red hat is used as the second one."
            ]
        },
        {
            "question": "What impression did the researchers have after observing the pattern of hat usage in multiple sentences?",
            "reference-answers": [
                "We had the impression that like the yellow hat is always used at the beginning of the sentence and then the red hat is the second one used."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen96-slide96/text.txt": [
        {
            "question": "Where on average across all the sentences do the heads look in a translation model?",
            "reference-answers": [
                "The heads look on average across all the sentences at the midpoint, dividing the sentence into two equal parts, the first eighth and the second eighth."
            ]
        },
        {
            "question": "Where on average across all the sentences do the heads look, specifically in relation to the structure of the sentence?",
            "reference-answers": [
                "The heads look on average at the first and second eighth of the sentence."
            ]
        },
        {
            "question": "What type of heads does a recurrent neural model learn to divide the sentence into, equidistant from the beginning and end?",
            "reference-answers": [
                "The heads a recurrent neural model learns to divide the sentence into are for the first and second eighth of the sentence."
            ]
        }
    ],
    "nmt-class/lecture09-word-and-sent-reprs/screen97-slide97/text.txt": [
        {
            "question": "How does the system process a sentence with multiple heads, and what are the implications for tasks that require searching for specific information within the sentence?",
            "reference-answers": [
                "The system processes a sentence with multiple heads by having one head looking at the beginning, the second head looking at the second part, and so on, until the last head looks at the final part of the sentence. This superficial processing makes it harder to search for specific information within the sentence, especially for tasks like polarity check, as the information may be scattered across multiple heads, requiring the model to search across them to find the relevant information."
            ]
        },
        {
            "question": "How does the number of heads in the system affect its performance in tasks like polarity check?",
            "reference-answers": [
                "The more heads you have, the worse it will perform in tasks like polarity check because the system is processing the sentence in a shallow way, dividing information across heads, making it harder to search for specific information like the quality of the movie."
            ]
        },
        {
            "question": "How does the performance of a model with multiple heads compare to one with fewer heads or no attention mechanism in tasks that require searching for specific information within a sentence?",
            "reference-answers": [
                "The performance of a model with multiple heads is worse in tasks that require searching for specific information within a sentence, as the heads only divide the information and make it harder to search for specific details, whereas models with fewer heads or no attention mechanism have all the information available at the same level, making it easier to search for specific details."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen01-slide01/text.txt": [
        {
            "question": "Why would multilingual machine translation be helpful, considering that machine translation already involves at least two languages?",
            "reference-answers": [
                "The text does not explicitly state why multilingual machine translation would be helpful, but it implies that it may be because machine translation already involves at least two languages, and the question is why more than two languages would be beneficial, suggesting that multilingual machine translation could be helpful for more complex or nuanced language relationships."
            ]
        },
        {
            "question": "Why would multilingual machine translation be helpful, given that machine translation already involves at least two languages?",
            "reference-answers": [
                "The text doesn't explicitly state why multilingual machine translation would be helpful, but it implies that it may be because machine translation already involves at least two languages, and the question is why more than two languages would be beneficial, suggesting that multilingual machine translation could be helpful for more complex or nuanced language relationships."
            ]
        },
        {
            "question": "Why would multilingual machine translation be helpful?",
            "reference-answers": [
                "Machine translation by itself already involves at least two languages, so the question is why more than two languages would be helpful."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen02-slide02/text.txt": [
        {
            "question": "What is the main difference between transfer learning and truly multilingual setups in language processing systems?",
            "reference-answers": [
                "The main difference between transfer learning and truly multilingual setups in language processing systems is that transfer learning uses auxiliary languages to focus on one language pair, whereas truly multilingual setups aim to preserve the translation quality of multiple languages involved simultaneously."
            ]
        },
        {
            "question": "What are the three different setups for using multiple languages in a system as discussed in the lecture?",
            "reference-answers": [
                "The three different setups for using multiple languages in a system are:\n\n1. Transfer setup\n2. Truly multilingual setup\n3. Massively multilingual setup"
            ]
        },
        {
            "question": "What is the main difference between transfer learning and truly multilingual systems in the context of language setup?",
            "reference-answers": [
                "The main difference between transfer learning and truly multilingual systems is that transfer learning involves using auxiliary data from multiple languages to improve a single language pair, whereas truly multilingual systems aim to preserve the translation quality of all languages involved and perform well on multiple languages simultaneously."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen03-slide03/text.txt": [
        {
            "question": "What is the approximate number of languages on Earth for which there is sufficient resources for training a good performing machine translation system?",
            "reference-answers": [
                "Only a handful of languages have sufficient resources for training a good performing machine translation system."
            ]
        },
        {
            "question": "What is the approximate number of languages on earth that have sufficient resources for training a good performing machine translation system?",
            "reference-answers": [
                "Only a handful of languages have sufficient resources for training a good performing machine translation system."
            ]
        },
        {
            "question": "What is the motivation behind developing multilingual machine translation systems, especially for low-resource languages?",
            "reference-answers": [
                "The motivation behind developing multilingual machine translation systems, especially for low-resource languages, is that as you learn more languages, you can further learn related languages due to similarities in word stems, grammatical constructions, and vocabulary size, ultimately improving translation quality, especially when working with texts available in multiple languages and needing to translate into additional languages."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen04-slide04/text.txt": [
        {
            "question": "What is the primary goal of transfer learning in the context of machine translation?",
            "reference-answers": [
                "The primary goal of transfer learning in the context of machine translation is to improve the translation quality in one target or \"child\" language pair."
            ]
        },
        {
            "question": "What is the primary goal of using transfer learning in machine translation?",
            "reference-answers": [
                "The primary goal of using transfer learning in machine translation is to improve the translation quality in one target or \"child\" language pair."
            ]
        },
        {
            "question": "What is the primary goal of transfer learning in machine translation?",
            "reference-answers": [
                "The primary goal of transfer learning in machine translation is to improve the translation quality in one target or \"child\" language pair, and to reuse data for other languages."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen05-slide05/text.txt": [
        {
            "question": "What is typically observed in the performance of neural machine translation systems during training?",
            "reference-answers": [
                "The performance on the development set grows and then stays stable."
            ]
        },
        {
            "question": "What is the typical trading curve for neural machine translation systems during training?",
            "reference-answers": [
                "The performance on the development set grows and then stays stable."
            ]
        },
        {
            "question": "What is the typical performance curve for neural machine translation systems that exhibit no overfitting?",
            "reference-answers": [
                "The performance on the development set grows and then stays stable."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen06-slide06/text.txt": [
        {
            "question": "What would be the expected outcome if additional data from another task and language was incorporated into the model?",
            "reference-answers": [
                "We would hope for a better curve, specifically the curve with transfer learning."
            ]
        },
        {
            "question": "If adding additional data from another task and language improves the learning curve, what would be the expected outcome of this approach?",
            "reference-answers": [
                "We would hope for a better curve, the curve with transfer learning."
            ]
        },
        {
            "question": "What type of curve would be hoped for if additional data from another task and language were incorporated into the model?",
            "reference-answers": [
                "A better curve, specifically a curve with transfer learning."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen07-slide07/text.txt": [
        {
            "question": "What are the three main areas where improvements can be made in the performance of a neural machine translation system?",
            "reference-answers": [
                "The initial performance, the learning speed, and the final performance should be improved."
            ]
        },
        {
            "question": "What are the three key areas where improvements can be made to a neural machine translation system?",
            "reference-answers": [
                "The initial performance, the learning speed, and the final performance of the system should be improved."
            ]
        },
        {
            "question": "What are the three key areas where improvements can be made in the performance of a neural machine translation system, according to the experiment described in the text?",
            "reference-answers": [
                "The initial performance, the learning speed, and the final performance should be improved."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen08-slide08/text.txt": [
        {
            "question": "What is the simplest technique for achieving transfer learning in language pair models?",
            "reference-answers": [
                "Train your system on the parent corpus, parent power corpus, parent language pair, until convergence, and then use that trained system for the language pair of interest."
            ]
        },
        {
            "question": "What is the simplest technique for achieving transfer learning?",
            "reference-answers": [
                "Train your system on a parent corpus, parent power corpus, parent language pair, until convergence."
            ]
        },
        {
            "question": "What is the simplest technique for achieving transfer learning in language processing?",
            "reference-answers": [
                "Train your system on a parent corpus, parent power corpus, parent language pair, until convergence, and then use that trained system for the language pair of interest."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen09-slide09/text.txt": [
        {
            "question": "What would happen to the child model's performance if it is initialized with the weights of the parent language pair instead of being trained randomly?",
            "reference-answers": [
                "You can get rid of the degradation due to the overfitting and you get the better performance."
            ]
        },
        {
            "question": "What would happen to the performance of a child model if it is not initialized with random weights, but instead continued training on the same data as the parent language pair?",
            "reference-answers": [
                "You can get rid of the degradation due to the overfitting and you get the better performance."
            ]
        },
        {
            "question": "What happens when a model is trained on a small dataset and then tested on a larger, unseen dataset, leading to poor performance?",
            "reference-answers": [
                "The model learns to memorize the data and doesn't generalize well, resulting in poor performance on the held out set due to overfitting."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen10-slide10/text.txt": [
        {
            "question": "What is the term used to describe the phenomenon where neural networks forget previously learned knowledge when the training data changes?",
            "reference-answers": [
                "The phenomenon where neural networks forget previously learned knowledge when the training data changes is called catastrophic forgetting."
            ]
        },
        {
            "question": "What is the phenomenon referred to as when a neural network adapts too quickly to new training data and forgets previously learned information?",
            "reference-answers": [
                "The phenomenon referred to as when a neural network adapts too quickly to new training data and forgets previously learned information is called \"catastrophic forgetting\"."
            ]
        },
        {
            "question": "What is the term for the phenomenon where neural networks forget previously learned information when trained on new data?",
            "reference-answers": [
                "The phenomenon is called catastrophic forgetting."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen11-slide11/text.txt": [
        {
            "question": "What is a suitable approach to training a neural network to avoid failing to learn from non-random data?",
            "reference-answers": [
                "Randomizing the data is a suitable approach to training a neural network to avoid failing to learn from non-random data."
            ]
        },
        {
            "question": "What is a better approach to training a network than sorting the corpus by sentence length?",
            "reference-answers": [
                "Randomizing the data is a better approach to training a network than sorting the corpus by sentence length."
            ]
        },
        {
            "question": "What type of data is recommended for training a neural network to avoid failing to learn in the final task?",
            "reference-answers": [
                "Randomized data."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen12-slide12/text.txt": [
        {
            "question": "What type of sentence length did the model learn from in the first batch, and what was the maximum sentence length in that batch?",
            "reference-answers": [
                "The model learned from batches of very short sentences up to five words, and the maximum sentence length in that batch was five words."
            ]
        },
        {
            "question": "What was the outcome of the model when it was exposed to sentences of all lengths in the final training stage?",
            "reference-answers": [
                "The model was slightly skewed to the longer sentences."
            ]
        },
        {
            "question": "What type of sentence length did the model learn first, and then what lengths were it exposed to afterwards?",
            "reference-answers": [
                "The model was first exposed to sentences of length up to five words, and then to sentences of length up to ten, followed by sentences of length up to fifteen, and finally all lengths."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen13-slide13/text.txt": [
        {
            "question": "What is the term used to describe the phenomenon where a model unlearns to produce long sentences after being trained on a dataset with varying sentence lengths?",
            "reference-answers": [
                "Catastrophic forgetting."
            ]
        },
        {
            "question": "What is the phenomenon where a model forgets to produce long sentences after being trained on a task that involves truncating sentences?",
            "reference-answers": [
                "Catastrophic forgetting, where the model unlearns to produce long sentences after being trained on a task that involves truncating sentences."
            ]
        },
        {
            "question": "What type of model is observed to unlearn producing long sentences as it is trained to limit sentence lengths?",
            "reference-answers": [
                "The recurrent sequence to sequence model."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen14-slide14/text.txt": [
        {
            "question": "What was the approach in early transfer learning experiments when the languages were related?",
            "reference-answers": [
                "The early works focused on the setup where we have one language in common and that was usually the English, and the languages were always related in the early experiments."
            ]
        },
        {
            "question": "What was the typical setup for early transfer learning experiments in language pairs?",
            "reference-answers": [
                "The early works focused on the setup where we have one language in common and that was usually the English, and the languages were always related in the early experiments."
            ]
        },
        {
            "question": "What type of language pairs were used in the early experiments on transfer learning?",
            "reference-answers": [
                "The early experiments used language pairs where the languages were always related, and this included English as the common language."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen15-slide15/text.txt": [
        {
            "question": "What is a potential issue with extracting a subword dictionary from a parent corpus and a child corpus together?",
            "reference-answers": [
                "The subword dictionary would be heavily overfitted to the parent corpus."
            ]
        },
        {
            "question": "What is a potential problem if you extract the subword dictionary from a parent corpus and a child corpus together, given that the parent corpus is typically big and the child corpus is typically small?",
            "reference-answers": [
                "The subword dictionary would be heavily overfitted to the parent corpus."
            ]
        },
        {
            "question": "What happens to the subword dictionary when it is extracted from a large parent corpus and a small child corpus?",
            "reference-answers": [
                "The subword dictionary would be heavily overfitted to the parent corpus."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen16-slide16/text.txt": [
        {
            "question": "What approach did the researchers take to balance the vocabulary in their corpora?",
            "reference-answers": [
                "They subsampled from the parent corpus to have the corpora of the same sizes and then extracted."
            ]
        },
        {
            "question": "What method did the researchers use to balance the vocabulary in the corpora?",
            "reference-answers": [
                "They subsampled from the parent corpus to have the corpora of the same sizes."
            ]
        },
        {
            "question": "What method did the researchers use to balance the vocabulary in the corpora?",
            "reference-answers": [
                "They subsampled from the parent corpus to have the corpora of the same sizes."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen17-slide17/text.txt": [
        {
            "question": "Was Czech equally represented in the parent and child languages in the experiment?",
            "reference-answers": [
                "No, Czech was not equally represented in the parent and child languages in the experiment, as it was equally represented in the child language but not in the parent language."
            ]
        },
        {
            "question": "Was Czech equally represented in the parent and child language in the subword vocabulary?",
            "reference-answers": [
                "No, Czech was not equally represented in the parent and child language in the subword vocabulary, as it was equally represented in the child language, but its representation in the parent language is not mentioned."
            ]
        },
        {
            "question": "Was Czech equally represented in the child language as it was in the parent language?",
            "reference-answers": [
                "No, Czech was not equally represented in the child language as it was in the parent language, because Estonian, which was the child language, was equally represented in the child language, but Czech was not."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen18-slide18/text.txt": [
        {
            "question": "What is the translation direction that the parent model is based on, given that it is paired with both English-Slovak and Slovak-English translations?",
            "reference-answers": [
                "The parent model is based on the English-Czech translation direction, given that it is paired with both English-Slovak and Slovak-English translations, and it is also mentioned that the corpus size difference is ninefold between Czech-English and English-Slovak."
            ]
        },
        {
            "question": "What is the corpus size difference between the Czech-English model and the English-Slovak model?",
            "reference-answers": [
                "The Czech-English model had nine times more data than the English-Slovak model."
            ]
        },
        {
            "question": "What is the corpus size difference between the Czech-English and English-Slovak translation directions?",
            "reference-answers": [
                "We had nine times more data for Czech-English than we had for English-Slovak."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen19-slide19/text.txt": [
        {
            "question": "What is the reason for the bigger improvement in translation quality when translating from English compared to translating into English?",
            "reference-answers": [
                "The reason for the bigger improvement in translation quality when translating from English compared to translating into English is that the additional English data directly helps the language model of the child, benefiting the decoder directly from the parent training data."
            ]
        },
        {
            "question": "What is the reason for the greater improvement in translation accuracy when translating into English compared to translating from English?",
            "reference-answers": [
                "The additional English data directly helps the language model of the child, so the decoder really benefits directly from the parent training data, which leads to a greater improvement in translation accuracy when translating into English."
            ]
        },
        {
            "question": "What is the reason for the bigger improvement in translation accuracy when translating into English compared to translating from English?",
            "reference-answers": [
                "The reason for the bigger improvement in translation accuracy when translating into English compared to translating from English is that the additional English data directly helps the language model of the child, benefiting the decoder directly from the parent training data."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen20-slide20/text.txt": [
        {
            "question": "What is the relationship between Finnish and Estonian?",
            "reference-answers": [
                "Finnish and Estonian are closely related languages."
            ]
        },
        {
            "question": "What is the relationship between Finnish and Estonian?",
            "reference-answers": [
                "Finnish and Estonian are closely related languages."
            ]
        },
        {
            "question": "What is the relationship between Finnish and Estonian languages?",
            "reference-answers": [
                "Finnish and Estonian languages are closely related."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen21-slide21/text.txt": [
        {
            "question": "What is the setup for the improvement in scores when going from English?",
            "reference-answers": [
                "We get the improvement when we are going from English."
            ]
        },
        {
            "question": "What is the setup for the improvement in scores?",
            "reference-answers": [
                "We get the scores from the related language we get some improvement from Russian which is larger we get a bigger improvement and we get the biggest improvement from Czech which is totally unrelated and actually we get the improvement when we are going from English so that's the setup."
            ]
        },
        {
            "question": "What is the language from which we get the biggest improvement in scores?",
            "reference-answers": [
                "Czech."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen22-slide22/text.txt": [
        {
            "question": "What is the conclusion of the experiment based on the training data?",
            "reference-answers": [
                "The conclusion from this experiment is that it's not too important how related the parent and child language is."
            ]
        },
        {
            "question": "Does the script in which Russian is written play a significant role in the improvement observed in the experiment?",
            "reference-answers": [
                "No, the script in which Russian is written does not play a significant role in the improvement observed in the experiment."
            ]
        },
        {
            "question": "What is the conclusion of the experiment mentioned in the text?",
            "reference-answers": [
                "The conclusion from this experiment is that it's not too important how related the parent and child language is."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen23-slide23/text.txt": [
        {
            "question": "What languages were the Finnish and English language pairs of interest in the child where the pre-training was moved to?",
            "reference-answers": [
                "Finnish and English."
            ]
        },
        {
            "question": "What languages were the child and parent using when testing the transfer of knowledge?",
            "reference-answers": [
                "The child and parent were using Finnish and English when testing the transfer of knowledge."
            ]
        },
        {
            "question": "What languages are the child and the low-resource parent being pre-trained on?",
            "reference-answers": [
                "Estonian, Estonian English"
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen24-slide24/text.txt": [
        {
            "question": "What is the most important aspect that affects the performance of the child in the language translation experiments?",
            "reference-answers": [
                "The parent size and the size of the training data for the parent is the most important aspect."
            ]
        },
        {
            "question": "What is the most important aspect that affects the performance of the child in the language model, according to the experiments conducted?",
            "reference-answers": [
                "The parent size and the size of the training data for the parent is the most important aspect."
            ]
        },
        {
            "question": "What is the most important aspect that affects the performance of the child model in machine translation experiments?",
            "reference-answers": [
                "The parent size and the size of the training data for the parent are the most important aspects, but specifically, the size of the training data for the parent is the most important aspect."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen25-slide25/text.txt": [
        {
            "question": "What improvements were observed in the experiment where the parent model was trained on English into Finnish and the child model was trained on Estonian into English?",
            "reference-answers": [
                "We still get an improvement over the baseline even when the parent model has English on the wrong side."
            ]
        },
        {
            "question": "What is the outcome when the parent model has English on the correct side compared to when the parent model has English on the wrong side?",
            "reference-answers": [
                "The improvements were bigger when the parent had the English on the correct side."
            ]
        },
        {
            "question": "What type of improvements were observed in the experiment where the parent model was English into Finnish and the child model was Estonian into English?",
            "reference-answers": [
                "Improvements were observed in the experiment."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen26-slide26/text.txt": [
        {
            "question": "What is the size of the corpora used for training the child for Estonian-English translation, compared to the intended child?",
            "reference-answers": [
                "The corpora used for training the child are 12 times bigger than the intended child."
            ]
        },
        {
            "question": "What is the outcome when training a model to translate Estonian into English with no shared vocabulary from other languages?",
            "reference-answers": [
                "There is some improvement."
            ]
        },
        {
            "question": "What is the effect of training a model to translate Estonian into English on a corpus that includes multiple languages, such as Arabic, Russian, or Spanish, without any common language between the target and source languages?",
            "reference-answers": [
                "There is some improvement in translating Estonian into English, even without any common language between the target and source languages."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen27-slide27/text.txt": [
        {
            "question": "What improvements were significant in the experiment, and what was the non-significant improvement?",
            "reference-answers": [
                "We got the half-blah, so that's the non-significant improvement and all the others are significant."
            ]
        },
        {
            "question": "What type of improvement was seen from pre-training on a language pair that does not share the script?",
            "reference-answers": [
                "A non-significant improvement."
            ]
        },
        {
            "question": "What type of improvements were observed in the language pairs being tested?",
            "reference-answers": [
                "We got a non-significant improvement from pre-training on a language pair which doesn't share the script at all."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen28-slide28/text.txt": [
        {
            "question": "What is the condition for achieving the best performance when training a child from a parent?",
            "reference-answers": [
                "When the parent is fully converged."
            ]
        },
        {
            "question": "What is the importance of the parent's overall performance in the training process?",
            "reference-answers": [
                "The parent's overall performance is also important, as starting the child from the parent when the parent is fully converged will result in the best performance, and stopping the parent prematurely and switching to the child too soon will not be as effective."
            ]
        },
        {
            "question": "What happens to the performance of the child model if the parent model is not fully converged before switching to the child model?",
            "reference-answers": [
                "If you stop training the parent prematurely and switch to the child too soon, you will get the worst performance."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen29-slide29/text.txt": [
        {
            "question": "What is the effect of using transfer learning with a very small parent model and a large parent model on the performance of a machine learning model?",
            "reference-answers": [
                "Using a very small parent model with a large parent model can result in a 10-point increase in performance, illustrating that transfer learning is very useful in bridging the gap between the difference in training data sizes between the child and parent models."
            ]
        },
        {
            "question": "What is the expected performance of a baseline model when training on a very small setup with 10,000 sensors and sentence pairs?",
            "reference-answers": [
                "The blue score is just close to two points."
            ]
        },
        {
            "question": "What is the effect of using transfer learning with a very small parent model on the performance of the baseline model?",
            "reference-answers": [
                "Using transfer learning with a very small parent model results in a 10-point increase in the performance of the baseline model."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen30-slide30/text.txt": [
        {
            "question": "What percentage of tokens in the child's output were found to be new words that the parent language did not have?",
            "reference-answers": [
                "10%"
            ]
        },
        {
            "question": "What percentage of the child's output tokens were Estonian words that did not come from the parent language?",
            "reference-answers": [
                "10%"
            ]
        },
        {
            "question": "What percentage of the child's output consisted of new Estonian words that the parent did not have?",
            "reference-answers": [
                "10%"
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen31-slide31/text.txt": [
        {
            "question": "What is the reason there are no words or subword units in the child model due to the difference in script between Estonian and Russian?",
            "reference-answers": [
                "Because Russian is written in Cyrillic and Estonian is written in Latin, there is actually no words, no subword units that would come to the child model."
            ]
        },
        {
            "question": "What is the reason why there are no words or subword units that would come to the child model due to the script differences between Estonian and Russian?",
            "reference-answers": [
                "Because Russian is written in Cyrillic and Estonian is written in Latin, there is actually no words, no subword units that would come to the child model."
            ]
        },
        {
            "question": "What type of vocabulary overlap is present between English, Russian, and Estonian due to the difference in their scripts?",
            "reference-answers": [
                "There is no vocabulary overlap between the three languages due to the difference in their scripts, as Russian is written in Cyrillic and Estonian is written in Latin."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen32-slide32/text.txt": [
        {
            "question": "What is the effect of training a neural machine translation system on sentences of varying lengths on the BLEU score?",
            "reference-answers": [
                "Training a neural machine translation system on sentences of varying lengths results in a lower BLEU score, especially when training on short sentences (BLEU score will be very low) and long sentences (BLEU score decreases due to the precision of n-grams)."
            ]
        },
        {
            "question": "What is the effect of training a neural machine translation system on sentences of only a certain range of word lengths on its performance?",
            "reference-answers": [
                "When training a neural machine translation system on sentences of only a certain range of word lengths, its performance suffers. Specifically, training on short sentences (less than 10 words) results in very low BLEU scores and outputs that are also very short, while training on longer sentences (20-40 words) results in low BLEU scores and outputs that are much longer than necessary, with many unconfirmed words."
            ]
        },
        {
            "question": "What happens to the BLEU score when the neural machine translation system is trained on sentences of a certain length, resulting in outputs that are either too short or too long?",
            "reference-answers": [
                "The BLEU score decreases when the neural machine translation system is trained on sentences of a certain length, resulting in outputs that are either too short (penalized on brevity penalty) or too long (penalized on precision of n-grams)."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen33-slide33/text.txt": [
        {
            "question": "What is the average BLEU score achieved by the model when using unconstrained parents, and what is the improvement or baseline performance in this case?",
            "reference-answers": [
                "The average BLEU score is not mentioned, but the baseline performance is 19, and the improvement or transfer learning is also 19."
            ]
        },
        {
            "question": "What is the BLEU score when using the unconstrained parent model for the child setup?",
            "reference-answers": [
                "The BLEU score does not benefit that, as it does not see that much benefit in the in the BLEU score from this."
            ]
        },
        {
            "question": "What is the average BLEU score for the child model when using unconstrained parents?",
            "reference-answers": [
                "The BLEU score does not benefit that, so you don't see that much benefit in the BLEU score."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen34-slide34/text.txt": [
        {
            "question": "What is the purpose of the transfer mentioned in the text?",
            "reference-answers": [
                "To highlight the baseline transfer, the trivial transfer that we have discussed."
            ]
        },
        {
            "question": "What type of transfer is being referred to in the statement?",
            "reference-answers": [
                "baseline transfer"
            ]
        },
        {
            "question": "What type of transfer is being referred to as the \"baseline transfer\" in the provided text?",
            "reference-answers": [
                "trivial transfer"
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen35-slide35/text.txt": [
        {
            "question": "What is the topic of the next section after the previous section in the given TEXT?",
            "reference-answers": [
                "Machine translation."
            ]
        },
        {
            "question": "What is the topic of the next section after \"So far\"?",
            "reference-answers": [
                "Multilingual machine translation."
            ]
        },
        {
            "question": "What is the next topic to be discussed after \"So far\"?",
            "reference-answers": [
                "Now let's move to the multilingual machine translation."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen36-slide36/text.txt": [
        {
            "question": "What is the term used to describe a machine translation system that can translate a pair of languages that it never saw as a pair in the training data?",
            "reference-answers": [
                "Zero-shot training."
            ]
        },
        {
            "question": "What is the term used to describe a system that can translate a pair of languages that it never saw as a pair in the training data?",
            "reference-answers": [
                "Zero-shot training."
            ]
        },
        {
            "question": "What is the term used to describe a system that can translate into a language it hasn't seen at all, beyond zero-shot training?",
            "reference-answers": [
                "Beyond zero-shot training, a system that can translate into a language it hasn't seen at all or from a language that it hasn't seen at all is not explicitly described in the text, however it is mentioned that the text refers to this as \"beyond zero-shot\"."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen37-slide37/text.txt": [
        {
            "question": "How many target languages can you put into a model so that you don't decrease the performance too much?",
            "reference-answers": [
                "Unfortunately, the text does not provide a specific answer to the question. However, it mentions that the goal is to run just one system and emit in parallel on GPU all these target languages at once, suggesting that the number of target languages is not a major concern, but rather the efficiency of the system."
            ]
        },
        {
            "question": "How many target languages can you put into a model so that you don't decrease the performance too much?",
            "reference-answers": [
                "Unfortunately, the text does not provide a specific answer to the question. However, it mentions that the goal is to run just one system and emit in parallel on GPU all these target languages at once, suggesting that the number of target languages is not a major concern, but rather the efficiency of the system."
            ]
        },
        {
            "question": "How many target languages can you put into a model so that you don't decrease the performance too much?",
            "reference-answers": [
                "Unfortunately, the text does not provide a specific answer to the question. However, it mentions that the goal is to run just one system and emit in parallel on GPU all these target languages at once, suggesting that the number of target languages is not a major concern, but rather the efficiency of the system."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen38-slide38/text.txt": [
        {
            "question": "What is the ideal setup for a machine translation system according to the given description?",
            "reference-answers": [
                "A flexible multilingual machine translation system where you could ask for many target languages at once and provide one or many possible sources, translating from whatever set of inputs into whatever set of outputs you like."
            ]
        },
        {
            "question": "What type of system would the ideal machine translation system be, according to the provided description?",
            "reference-answers": [
                "A flexible multilingual machine translation system."
            ]
        },
        {
            "question": "What type of system is described as the ideal setup for machine translation?",
            "reference-answers": [
                "A flexible multilingual machine translation system."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen39-slide39/text.txt": [
        {
            "question": "When did the idea of multisource translation originate?",
            "reference-answers": [
                "The idea of multisource translation is actually pretty old, it's already with word-based and phrase-based system, it was tested."
            ]
        },
        {
            "question": "When did the idea of multisource translation originate?",
            "reference-answers": [
                "The idea of multisource translation is actually pretty old, it's already with word-based and phrase-based system, it was tested."
            ]
        },
        {
            "question": "What type of translation systems have been tested using the concept of multisource translation?",
            "reference-answers": [
                "word-based and phrase-based systems."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen40-slide40/text.txt": [
        {
            "question": "What is the underlying principle of neural machine translation systems?",
            "reference-answers": [
                "The neural machine translation system is a conditioned language model, conditioned on the source sentence as a whole."
            ]
        },
        {
            "question": "What is the underlying principle of neural machine translation systems?",
            "reference-answers": [
                "The neural machine translation system is a conditioned language model, conditioned on the source sentence as a whole."
            ]
        },
        {
            "question": "What is the underlying principle of neural machine translation systems?",
            "reference-answers": [
                "The neural machine translation system is a conditioned language model, conditioned on the source sentence as a whole."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen41-slide41/text.txt": [
        {
            "question": "What is the main drawback of the setup described in the text regarding producing English from French and German sources?",
            "reference-answers": [
                "The main drawback of the setup is that you really need a multiparl corpus."
            ]
        },
        {
            "question": "What type of neural network was used in the setup described by Zoffa and Knight to produce English from French and German sources?",
            "reference-answers": [
                "A deep recurrent neural network."
            ]
        },
        {
            "question": "What type of neural network was used in the setup described in the text to produce English from French and German sources?",
            "reference-answers": [
                "A deep recurrent neural network."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen42-slide42/text.txt": [
        {
            "question": "What was the main question that Orhan Ferrat was trying to answer in his 2016 experiment with bilingual corpora?",
            "reference-answers": [
                "What to do with attention in bilingual corpora that are not multi-parallel but only bilingual and bilingual across many pairs."
            ]
        },
        {
            "question": "What was the main question Orhan Ferrat was trying to answer in his 2016 experiment with bilingual corpora?",
            "reference-answers": [
                "What to do with attention in bilingual corpora that are not multi-parallel but only bilingual and bilingual across many pairs."
            ]
        },
        {
            "question": "What was the main question Orhan Ferrat was trying to answer in his 2016 experiment with bilingual corpora?",
            "reference-answers": [
                "What to do with attention in bilingual corpora that are not multi-parallel but only bilingual and bilingual across many pairs."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen43-slide43/text.txt": [
        {
            "question": "Where does the attention walk across when producing the target output?",
            "reference-answers": [
                "across the positions in the source language"
            ]
        },
        {
            "question": "What happens to the attention as you produce the target output one word at a time?",
            "reference-answers": [
                "The attention walks across the positions in the source language."
            ]
        },
        {
            "question": "What happens to the attention when you are producing a single word at a time?",
            "reference-answers": [
                "The attention walks across the positions in the source language."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen44-slide44/text.txt": [
        {
            "question": "What is the role of the attention mechanism in the training process of encoders and decoders for different language pairs?",
            "reference-answers": [
                "The attention mechanism remains the same across all encoders and decoders, and is shared, depending on the language pair."
            ]
        },
        {
            "question": "What is the role of the attention mechanism in a multi-encoder and decoder setup?",
            "reference-answers": [
                "The attention mechanism is just the same, and it will be shared across all encoders and decoders."
            ]
        },
        {
            "question": "What happens to the attention mechanism during training of different language pairs?",
            "reference-answers": [
                "You will keep training the same attention mechanism across the language."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen45-slide45/text.txt": [
        {
            "question": "What improvements were observed in the system when the training data was small, compared to a baseline?",
            "reference-answers": [
                "There were improvements compared to the baseline, especially if the training data is rather small."
            ]
        },
        {
            "question": "What improvements were observed in the system when the training data was rather small, compared to the baseline?",
            "reference-answers": [
                "There were improvements compared to the baseline, especially if the training data is rather small."
            ]
        },
        {
            "question": "What were the improvements in the system when the training data was rather small?",
            "reference-answers": [
                "There were improvements compared to the baseline, especially if the training data is rather small."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen46-slide46/text.txt": [
        {
            "question": "What is the purpose of the teacher preparing for an exam?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        },
        {
            "question": "What is the purpose of the teacher preparing for an exam?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        },
        {
            "question": "What is the purpose of the teacher preparing for an exam?",
            "reference-answers": [
                "Preparing for an exam."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen47-slide45/text.txt": [
        {
            "question": "What type of experiments were generally conducted in the referenced research?",
            "reference-answers": [
                "experiments"
            ]
        },
        {
            "question": "What type of experiments are generally referred to in the text?",
            "reference-answers": [
                "Scientific experiments."
            ]
        },
        {
            "question": "What type of experiments were generally conducted?",
            "reference-answers": [
                "experiments that went generally into..."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen48-slide46/text.txt": [
        {
            "question": "When translating from English into a language other than English, what type of model performs better?",
            "reference-answers": [
                "When translating from English into a language other than English, a single paired model performs better."
            ]
        },
        {
            "question": "What is the benefit of using a multilingual model when translating into English, compared to using a single paired model when translating from English into another language?",
            "reference-answers": [
                "When translating into English, using a multilingual model is better than using a single paired model when translating from English into another language."
            ]
        },
        {
            "question": "What type of models is better suited for translating into English, as opposed to translating from English into other languages?",
            "reference-answers": [
                "The multilingual model is better suited for translating into English."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen49-slide48/text.txt": [
        {
            "question": "Is English considered more important than another subject?",
            "reference-answers": [
                "English is considered more important than another subject."
            ]
        },
        {
            "question": "What is the second word in the given text?",
            "reference-answers": [
                "than"
            ]
        },
        {
            "question": "What is the comparison being made in the given text?",
            "reference-answers": [
                "Something is being compared to English, but the specific thing is not mentioned in the given text."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen50-slide47/text.txt": [
        {
            "question": "What is the approach for processing a sentence with multiple languages when training on pairs of sentences, and how do the encoders and decoders contribute to this process?",
            "reference-answers": [
                "When processing a sentence with multiple languages, you can use the two encoders at once and combine the context vectors. The result after applying attention can be combined and the decoder processes this joint knowledge. The combined context vector can be averaged, processed independently, or used to modify the decoder's state."
            ]
        },
        {
            "question": "What is the approach used to process a sentence with multiple languages when using encoders and decoders that have been trained on pairs of sentences?",
            "reference-answers": [
                "You can use two encoders at once and combine the context vectors, then apply attention and process the joint knowledge with the decoder."
            ]
        },
        {
            "question": "What is the approach for processing a sentence that is already available in multiple languages when using multi-source multi-language setup?",
            "reference-answers": [
                "You can simply use two encoders at once and combine the context vectors after applying attention, and then use the combined context vector to generate output words, or process the combined context vector separately by the decoder to help it modify its state, or predict the best word later."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen51-slide49/text.txt": [
        {
            "question": "How do models trained on multi-language data perform when translating from Spanish into English compared to those trained on single-language data?",
            "reference-answers": [
                "Models trained on multi-language data perform better when translating into English, especially when the multi-language model also sees the encoders and decoders from other languages in the collection."
            ]
        },
        {
            "question": "What is the performance of the model when translating from Spanish into English versus when translating from French into English?",
            "reference-answers": [
                "The model performs better when translating into English, as seen in both the Spanish-English system and the baseline system."
            ]
        },
        {
            "question": "What is the effect of training a model on Spanish-English data on its performance when translating into French?",
            "reference-answers": [
                "The model trained on Spanish-English data does not show an improvement in performance when translating into French, as the other language data is not helping performance in this direction."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen52-slide50/text.txt": [
        {
            "question": "What is the baseline performance in the setup with two input sentences, one in Spanish and one in French, for translating into English?",
            "reference-answers": [
                "The baseline performance is 32."
            ]
        },
        {
            "question": "What is the baseline performance for a single input sentence in the translation task?",
            "reference-answers": [
                "The baseline performance for a single input sentence in the translation task is 32."
            ]
        },
        {
            "question": "What is the baseline performance when translating from a source language to English using only one input sentence?",
            "reference-answers": [
                "The baseline performance when translating from a source language to English using only one input sentence is 32."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen53-slide52/text.txt": [
        {
            "question": "What was the original idea of trying to improve translation into a particle language pair?",
            "reference-answers": [
                "improve translation into a particle language pair by including additional languages."
            ]
        },
        {
            "question": "What was the purpose of the experiment that involved including additional languages in a particle language pair?",
            "reference-answers": [
                "Trying to improve translation into a particle language pair by including additional languages."
            ]
        },
        {
            "question": "What was the original idea of the translation into a particle language pair?",
            "reference-answers": [
                "Trying to improve translation into a particle language pair by including additional languages."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen54-slide50/text.txt": [
        {
            "question": "What is the general approach to achieving good performance on multiple language pairs in transfer learning?",
            "reference-answers": [
                "The general approach to achieving good performance on multiple language pairs in transfer learning is to focus on the target language, the child language pair, and fine-tune or continue training on the parent language, with the goal of maintaining performance on other languages."
            ]
        },
        {
            "question": "What is the main complication in achieving gains from transfer learning when developing multilingual systems?",
            "reference-answers": [
                "Maintaining the performance on the other languages complicates the possible gains from transfer learning when developing multilingual systems."
            ]
        },
        {
            "question": "What is the main complication in achieving gains with multilingual systems, according to the provided setup?",
            "reference-answers": [
                "Maintaining the performance on the other languages complicates the possible gains."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen55-slide52/text.txt": [
        {
            "question": "What is the difference between a pivot translation and a Zero-shot translation in the context of machine translation?",
            "reference-answers": [
                "A pivot translation involves using a third language as an intermediary for translation, whereas a Zero-shot translation involves directly translating between two languages without using an intermediary language."
            ]
        },
        {
            "question": "What is the main difference between using a pivot translation system and a multi-way encoder-decoder system for zero-shot translation?",
            "reference-answers": [
                "The main difference is that a pivot translation system requires training and running the system twice, while a multi-way encoder-decoder system can be used for zero-shot translation by directly feeding the system with a multilingual input and obtaining the output."
            ]
        },
        {
            "question": "What is the main difference between the Zero-shot translation approach and the traditional pivot translation method?",
            "reference-answers": [
                "The main difference between the Zero-shot translation approach and the traditional pivot translation method is that the Zero-shot method directly translates from Spanish to French without going through English, whereas the traditional pivot method involves translating from Spanish to English and then from English to French, which takes twice the time and introduces more ambiguity and uncertainty."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen56-slide53/text.txt": [
        {
            "question": "What is the result of using the attention mechanism in a way that is not its intended use, according to the text?",
            "reference-answers": [
                "It doesn't work at all."
            ]
        },
        {
            "question": "What type of performance can be achieved when the attention mechanism is used in a way that is consistent with the network's training structure, but not when it is used in a novel way?",
            "reference-answers": [
                "Horrible performance on the DEF and test sets can be achieved when the attention mechanism is used in a novel way, but reasonable performance can be achieved when it is used consistently with the network's training structure."
            ]
        },
        {
            "question": "What type of performance can be obtained by a neural network that does not use explicit pivoting in the given task?",
            "reference-answers": [
                "Horrible performance on the DEF and test sets."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen57-slide54/text.txt": [
        {
            "question": "Where would you get the data to fine-tune the network by adding missing links between Spanish and French?",
            "reference-answers": [
                "Obviously, the data would come from parallel data between Spanish and French."
            ]
        },
        {
            "question": "Where would you get the small amount of parallel data between Spanish and French for fine-tuning the missing part of the network?",
            "reference-answers": [
                "The data would be obtained by fine-tuning on a small amount of parallel data between Spanish and French."
            ]
        },
        {
            "question": "Where would it be possible to obtain the parallel data between Spanish and French for fine-tuning the network?",
            "reference-answers": [
                "The data would be obtained by fine-tuning the network on a small amount of parallel data between Spanish and French."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen58-slide55/text.txt": [
        {
            "question": "What other corpora have been used to train the paths in the multi-way system?",
            "reference-answers": [
                "Spanish-English and English-French corpus."
            ]
        },
        {
            "question": "What type of corpora have been used to train the paths in the multi-way system?",
            "reference-answers": [
                "The original parallel corpora used to train the paths in the multi-way system are Spanish-English and English-French."
            ]
        },
        {
            "question": "What corpora have been used to train the paths in the multi-way system?",
            "reference-answers": [
                "The Spanish-English and English-French corpora have been used to train the paths in the multi-way system."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen59-slide56/text.txt": [
        {
            "question": "What is the purpose of using a French corpus in conjunction with a Spanish-English system to produce synthetic Spanish?",
            "reference-answers": [
                "And this is already something which can be... produced."
            ]
        },
        {
            "question": "What is an application of the French corpus and Spanish-English system mentioned in the text?",
            "reference-answers": [
                "producing some synthetic Spanish."
            ]
        },
        {
            "question": "What is the purpose of using a French corpus in conjunction with a Spanish-English system to produce synthetic Spanish?",
            "reference-answers": [
                "And this is already something which can be... produced."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen60-slide57/text.txt": [
        {
            "question": "What is the purpose of fine-tuning the network with the new data that goes across the language pairs?",
            "reference-answers": [
                "To continue training the network with the new data that goes across the language pairs, allowing the model to learn from both directions of translation."
            ]
        },
        {
            "question": "What type of training will the network undergo after being fine-tuned with the new data that go across the language pairs?",
            "reference-answers": [
                "They will continue training."
            ]
        },
        {
            "question": "What type of data will be used for fine-tuning the network during the continuation of training?",
            "reference-answers": [
                "Data that go from Spanish into French."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen61-slide58/text.txt": [
        {
            "question": "What is the BLEU score when using pivoting with no fine-tuning compared to the synthetic parallel corpus?",
            "reference-answers": [
                "The BLEU score is around 20 when using pivoting with no fine-tuning."
            ]
        },
        {
            "question": "What is the BLEU score achieved when using the synthetic parallel corpus, compared to pivoting with no fine-tuning?",
            "reference-answers": [
                "When using the synthetic parallel corpus, the BLEU score can go up to 17, which is worse than the pivoting with no fine-tuning (around 20)."
            ]
        },
        {
            "question": "What is the BLEU score range for the proposed method when using the synthetic parallel corpus and the pseudo-parallel corpus?",
            "reference-answers": [
                "The BLEU score can go up to 17 when using the synthetic parallel corpus, and up to 17 when using the pseudo-parallel corpus."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen62-slide59/text.txt": [
        {
            "question": "What is the performance of the baseline models with one million pairs, compared to using a true parallel corpus?",
            "reference-answers": [
                "We will get a better performance even with the sampling, indicating that using one million pairs is better than using a true parallel corpus."
            ]
        },
        {
            "question": "What is the outcome when using a true parallel corpus in the explicit pivoting setup, compared to using single pair baseline models?",
            "reference-answers": [
                "We get towards the performance of the explicit pivoting setup, or slightly below that, but not much."
            ]
        },
        {
            "question": "What is the effect of using a true parallel corpus on the performance of explicit pivoting setup in the given experiment?",
            "reference-answers": [
                "If we use a true parallel corpus, we get towards the performance of the explicit pivoting setup, but slightly below that, not much."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen63-slide60/text.txt": [
        {
            "question": "What is the main result of using a fixed set of parameters in the model to fit more languages at once, in terms of hardware savings?",
            "reference-answers": [
                "You are getting the hardware savings right away without any any loss hopefully."
            ]
        },
        {
            "question": "What are the main differences between multitask training and transfer learning when using a fixed set of parameters to train a multilingual model?",
            "reference-answers": [
                "The main difference between multitask training and transfer learning when using a fixed set of parameters to train a multilingual model is that multitask training refreshes the knowledge of all languages within every batch, whereas transfer learning trains on one language pair at a time."
            ]
        },
        {
            "question": "What is the main result of using a fixed set of parameters in the model to train for multiple languages at once?",
            "reference-answers": [
                "You are getting the hardware savings right away without any any loss hopefully."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen64-slide61/text.txt": [
        {
            "question": "What type of system did the researchers develop that includes many languages and can translate from different languages into English?",
            "reference-answers": [
                "A multilingual system from a Google experiment in 2016 that includes many languages and translates from different languages into English."
            ]
        },
        {
            "question": "What type of Google experiment is described in the text as being from 2016?",
            "reference-answers": [
                "A Google experiment."
            ]
        },
        {
            "question": "What type of system is being referred to as \"this multilingual system\" in the context of the Google experiment from 2016?",
            "reference-answers": [
                "A Google experiment from 2016 that includes many languages at once or maybe just two, and translation goes from different languages into English."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen65-slide62/text.txt": [
        {
            "question": "What are some potential drawbacks to using multilingual training data in machine translation systems?",
            "reference-answers": [
                "Using multilingual training data in machine translation systems can sometimes significantly decrease performance, particularly when the training data is imbalanced or when the target languages are not well-represented."
            ]
        },
        {
            "question": "What are some potential issues that can arise when creating a multilingual system for non-English languages?",
            "reference-answers": [
                "When creating a multilingual system for non-English languages, potential issues can arise, including: \n\n1. Learning a target language's words and producing them in another language, which is a bad idea.\n2. Oversampling and sizes of the corpora, particularly when corpora have different sizes and the original distribution is not preserved, leading to a loss in one of the languages."
            ]
        },
        {
            "question": "What are some potential issues with creating a multilingual system that involves translating non-English languages, as opposed to translating English languages?",
            "reference-answers": [
                "When trying to create a multilingual system that involves translating non-English languages, potential issues include:\n\n1. Learning and producing words from one language in another language, resulting in incorrect translations.\n2. Oversampling and unequal sizes of corpora, potentially skewing the distribution and leading to performance loss in one of the languages.\n3. Inability to preserve the original distribution of words between languages, leading to performance loss in one of the languages."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen66-slide61/text.txt": [
        {
            "question": "Can you feed multiple source languages into the same model if the target language remains the same?",
            "reference-answers": [
                "Yes, you can feed multiple source languages into the same model as long as the target is the same, you are not losing translation quality."
            ]
        },
        {
            "question": "Can you translate multiple source languages into the same target language without losing translation quality?",
            "reference-answers": [
                "Yes, you can feed multiple source languages in the same model as long as the target is the same, you are not losing translation quality."
            ]
        },
        {
            "question": "What happens to translation quality when multiple source languages are fed into the same model for the same target language?",
            "reference-answers": [
                "You are not losing translation quality."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen67-slide62/text.txt": [
        {
            "question": "What is the significance of the first token of the input sentence in a language model when feeding language pairs with different targets into the same model?",
            "reference-answers": [
                "The first token of the input sentence indicates which language we want to translate into."
            ]
        },
        {
            "question": "What is the purpose of the first token in the input sentence when feeding language pairs with different targets into the same model?",
            "reference-answers": [
                "The first token of the input sentence indicates which language we want to translate into."
            ]
        },
        {
            "question": "What happens to the loss when language pairs with different targets are fed into the same model?",
            "reference-answers": [
                "In some of these targets, you are probably getting a loss, but the first token of the input sentence still indicates which language to translate into."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen68-slide63/text.txt": [
        {
            "question": "Who trained a recurrent neural network system to translate the Bible in close to 1000 languages?",
            "reference-answers": [
                "Jörg Tiedemann trained a recurrent neural network system to translate the Bible in close to 1000 languages."
            ]
        },
        {
            "question": "What type of neural network system was used by Jörg Tiedemann in 2018 to translate the Bible into close to 1000 languages?",
            "reference-answers": [
                "A recurrent neural network system."
            ]
        },
        {
            "question": "What type of dataset was used to train Jörg Tiedemann's recurrent neural network system for translating the Bible into close to 1000 languages?",
            "reference-answers": [
                "The dataset used to train Jörg Tiedemann's recurrent neural network system consisted of combinations of each of the 900 languages with English, based on many different English translations of the Bible."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen69-slide64/text.txt": [
        {
            "question": "What is the general pattern of language families that emerges from the T-SNE projection in the two-dimensional vector space?",
            "reference-answers": [
                "The general pattern of language families that emerges from the T-SNE projection in the two-dimensional vector space is: Indo-European languages form a cluster, Niger-Congo languages are close to them, Austronesian languages are across the board, and Afro-Zero-Quechua and Creole languages are similar to the Indo-Europeans, with Quechua languages forming a distinct cluster."
            ]
        },
        {
            "question": "What is the position of the Afro-Zero-Quechua and Creole languages in relation to the Indo-European languages according to the T-SNE projection?",
            "reference-answers": [
                "They are similar to the Indo-European languages."
            ]
        },
        {
            "question": "What type of language families are empirically identified in the multilingual system, according to the T-SNE projection?",
            "reference-answers": [
                "The Indo-European languages, Niger-Congo languages, Austronesian languages, Afro-Zero-Quechua and Creole languages, and Quechua languages are empirically identified language families."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen70-slide63/text.txt": [
        {
            "question": "Does the method described in the text require human supervision to cluster languages?",
            "reference-answers": [
                "No, the method described in the text does not require human supervision to cluster languages."
            ]
        },
        {
            "question": "Does the text describe a supervised or unsupervised language clustering method?",
            "reference-answers": [
                "Unsupervised."
            ]
        },
        {
            "question": "Does the text describe a method that can cluster languages with or without human supervision?",
            "reference-answers": [
                "It can cluster languages in an unsupervised way."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen71-slide64/text.txt": [
        {
            "question": "How do linguists study language similarities?",
            "reference-answers": [
                "In a similar way that linguists study language similarities, they also study language differences."
            ]
        },
        {
            "question": "How do linguists approach the study of language in a manner similar to the context implied by the phrase \"In a similar way that linguists...\"?",
            "reference-answers": [
                "study language in a manner similar to that implied by the phrase, linguists approach language study by comparing it to other disciplines, such as anthropology, sociology, and psychology."
            ]
        },
        {
            "question": "How do linguists study language similarities?",
            "reference-answers": [
                "In a similar way that linguists study language similarities, they also study language differences."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen72-slide65/text.txt": [
        {
            "question": "What is the main goal of the recent research done by Google regarding multilingual systems?",
            "reference-answers": [
                "To really make multilingual systems work and make them work for many languages at once."
            ]
        },
        {
            "question": "What is the main goal of the research mentioned in the text?",
            "reference-answers": [
                "To make multilingual systems work for many languages at once."
            ]
        },
        {
            "question": "What type of systems is Google trying to make work for many languages at once?",
            "reference-answers": [
                "Multilingual systems."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen73-slide66/text.txt": [
        {
            "question": "How many languages do Orhan Ferrat and his colleagues have parallel corpora for?",
            "reference-answers": [
                "102 languages."
            ]
        },
        {
            "question": "How many languages do Orhan Ferrat from Google and colleagues have parallel corpora for?",
            "reference-answers": [
                "102 languages."
            ]
        },
        {
            "question": "How many languages do Orhan Ferrat and his colleagues have parallel corpora for?",
            "reference-answers": [
                "102 languages."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen74-slide67/text.txt": [
        {
            "question": "What is the general trend in translation quality according to the provided text?",
            "reference-answers": [
                "The general trend in translation quality is that it is better for the high resource language than for the low resource languages."
            ]
        },
        {
            "question": "What is the likely reason for the observed difference in translation quality between high resource and low resource languages?",
            "reference-answers": [
                "The likely reason for the observed difference in translation quality between high resource and low resource languages is that human judgments are likely involved, as BLEU scores are not comparable across languages."
            ]
        },
        {
            "question": "What is a likely explanation for the difference in translation quality between high resource languages and low resource languages?",
            "reference-answers": [
                "The natural thing to expect and the natural thing that we really see is that the translation quality is better for the high resource language than for the low resource languages."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen75-slide68/text.txt": [
        {
            "question": "What is the typical structure of the transformer setup for both the encoder and the decoder in a sequence-to-sequence system?",
            "reference-answers": [
                "The typical structure of the transformer setup for both the encoder and the decoder in a sequence-to-sequence system consists of multiple layers, with each layer having two sub-layers: a self-attention component and a feedforward network. The encoder consists of N layers, with six layers being normal, and each layer has two sub-layers. The decoder also consists of multiple layers, with the same structure as the encoder."
            ]
        },
        {
            "question": "What is the typical structure of the transformer setup for an encoder-decoder sequence-to-sequence system?",
            "reference-answers": [
                "The transformer setup for an encoder-decoder sequence-to-sequence system typically consists of an encoder with N layers, where normally there are six of these encoder layers, each having two sub-layers, including multihead attention and feedforward networks, and a decoder with the same structure as the encoder."
            ]
        },
        {
            "question": "What is the typical structure of the transformer setup, and how does it differ from recurrent neural networks?",
            "reference-answers": [
                "The typical structure of the transformer setup consists of an encoder-decoder sequence-to-sequence system where the encoder consists of N layers, and each of these layers has two sub-layers, including multihead attention and a feedforward network. The decoder also has the same structure, with multihead attention and a feedforward network. This setup differs from recurrent neural networks in that it uses self-attention instead of recurrent connections to consider all source sentence positions."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen76-slide69/text.txt": [
        {
            "question": "What is the difference in the number of parameters between the default transformer setup and the deep setup?",
            "reference-answers": [
                "The default transformer setup has 400 million parameters, while the deep setup has 1.3 billion parameters."
            ]
        },
        {
            "question": "What is the number of parameters in the deep transformer network setup that uses 12 layers in the encoder, 12 in the decoder, a doubled feedforward network dimension, and doubled heads?",
            "reference-answers": [
                "1.3 billion parameters."
            ]
        },
        {
            "question": "What is the effect of increasing the depth of the transformer setup from 12 layers to 24 layers, and doubling the size of the feedforward network and the number of heads, on the number of parameters to be trained?",
            "reference-answers": [
                "When you increase the depth of the transformer setup from 12 layers to 24 layers, and doubling the size of the feedforward network and the number of heads, the number of parameters to be trained will be 1.3 billion."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen77-slide70/text.txt": [
        {
            "question": "When is it better to use a separate pairwise model compared to a multilingual model, and what is the point at which languages become low resource compared to the average?",
            "reference-answers": [
                "One would have to carefully think about when to use separate pairwise models compared to multilingual models, specifically up until when a language becomes low resource compared to the average."
            ]
        },
        {
            "question": "At what point do the languages become low resource compared to the average when considering the use of multilingual models versus pairwise models?",
            "reference-answers": [
                "Because at some point the languages become low resource compared to the average."
            ]
        },
        {
            "question": "What is the optimal approach for model training when dealing with high and low resource languages?",
            "reference-answers": [
                "It is unclear when it is better to use the separate pairwise models versus the multilingual models, as the languages become low resource compared to the average."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen78-slide71/text.txt": [
        {
            "question": "What is the standard number of parameters for the massively multilingual model?",
            "reference-answers": [
                "400 million parameters."
            ]
        },
        {
            "question": "What is the standard number of parameters for the massively multilingual model?",
            "reference-answers": [
                "400 million parameters."
            ]
        },
        {
            "question": "What is the effect of increasing the number of parameters in the transformer setup on performance for high-resource language pairs?",
            "reference-answers": [
                "Increasing the number of parameters in the transformer setup from 400 million to 50 billion can lead to up to five black points on high-resource language pairs."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen79-slide72/text.txt": [
        {
            "question": "What is the purpose of the gating network in the proposed mixture of experts architecture?",
            "reference-answers": [
                "The gating network will observe the current input and decide which of the experts should be used, which are most relevant for this input, and then these experts would operate on this input to get the output."
            ]
        },
        {
            "question": "What is the purpose of the gating network in the proposed mixture of experts architecture?",
            "reference-answers": [
                "The gating network will observe the current input and decide which of the experts should be used, which are most relevant for this input, and then these experts would operate on this input to get the output."
            ]
        },
        {
            "question": "What is the main bottleneck in achieving significant improvements in language models when using a large number of target languages?",
            "reference-answers": [
                "The main bottleneck is still the fact that if you try to put too many target languages into one model without increasing the model capacity, it will lose performance."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen80-slide73/text.txt": [
        {
            "question": "What is the main idea behind the use of \"a few experts\" in the proposed network architecture?",
            "reference-answers": [
                "The main idea behind the use of \"a few experts\" in the proposed network architecture is to introduce a tunable sublayer that allows for supervised training of small adapter layers for specific language pairs, enabling the model to translate into the most relevant language pair at runtime."
            ]
        },
        {
            "question": "What is the main idea behind using a tunable sublayer in this approach to reduce the size of the network?",
            "reference-answers": [
                "The main idea behind using a tunable sublayer is to introduce a tunable sublayer to the network, allowing most of the network to be pre-trained on a big mixed corpus of main languages, while the sublayer is fine-tuned for a specific particle language pair in a supervised way."
            ]
        },
        {
            "question": "What type of sublayer are introduced by Orhan Ferden and colleagues to improve translation efficiency?",
            "reference-answers": [
                "A tunable sublayer."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen81-slide74/text.txt": [
        {
            "question": "What is the performance of the multilingual system compared to the bilingual baselines in this experiment?",
            "reference-answers": [
                "The multilingual system is underperforming the bilingual baselines."
            ]
        },
        {
            "question": "What is the outcome when using adapters on the transformer setup for multilingual systems?",
            "reference-answers": [
                "The loss is reduced and the performance on the low-resource languages is retained."
            ]
        },
        {
            "question": "What is the effect of using adapters on the performance of the multilingual system compared to the baseline size of the transformer setup?",
            "reference-answers": [
                "The loss is reduced and the performance on the low-resource languages is retained."
            ]
        }
    ],
    "nmt-class/lecture10-multilingual-mt/screen82-slide75/text.txt": [
        {
            "question": "What is the significance of adapters when translating out of English?",
            "reference-answers": [
                "The adapters are more prominent in translating out of English, indicating their increased importance in this context."
            ]
        },
        {
            "question": "What is the purpose of adapters when translating out of English, according to the provided text?",
            "reference-answers": [
                "The adapters are more prominent in translating out of English to highlight their importance."
            ]
        },
        {
            "question": "What is the main purpose of adapters when translating out of English?",
            "reference-answers": [
                "The adapters are more prominent because they are important when translating out of English."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen01-slide01/text.txt": [
        {
            "question": "What aspects of translation are going to be included in the lecture on multimodal machine translation?",
            "reference-answers": [
                "Speech and vision will be included as additional aspects of translation in the lecture on multimodal machine translation."
            ]
        },
        {
            "question": "What are the two additional aspects of translation that will be included in this lecture on multimodal machine translation?",
            "reference-answers": [
                "Speech and vision."
            ]
        },
        {
            "question": "What type of translation will be included in this semester's final lecture?",
            "reference-answers": [
                "Statistical machine translation of speech and vision."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen02-slide02/text.txt": [
        {
            "question": "What is the approach of the recent survey on multimodal approaches to machine translation by Sulubacic and colleagues, and how does it differ from the approach being discussed in the lecture?",
            "reference-answers": [
                "The recent survey on multimodal approaches to machine translation by Sulubacic and colleagues models the whole task of going from the source language speech to the target language text in one step with some deep neural network, which is an end-to-end approach. This differs from the approach being discussed in the lecture, which combines speech recognition with machine translation in order to translate what people are saying instead of what has been written in the text."
            ]
        },
        {
            "question": "What is the main difference between the approach of combining speech recognition with machine translation and the recent end-to-end approaches that model the task of going from source language speech to target language text in one step?",
            "reference-answers": [
                "The main difference is that the combined approach involves two independent systems, whereas the recent end-to-end approaches model the task in one step with a deep neural network."
            ]
        },
        {
            "question": "What type of approaches to machine translation are being discussed in the second part of the lecture?",
            "reference-answers": [
                "End-to-end approaches."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen03-slide03/text.txt": [
        {
            "question": "What approach have you been using to translate text from the source language to the target language so far?",
            "reference-answers": [
                "We have always had the text in the source language and we were using machine translation to get to the text in the target language."
            ]
        },
        {
            "question": "What approach have you always used to get the text in the target language?",
            "reference-answers": [
                "We have always used machine translation to get to the text in the target language."
            ]
        },
        {
            "question": "What method have you been using to get the text from the source language to the target language?",
            "reference-answers": [
                "We have been using machine translation."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen04-slide04/text.txt": [
        {
            "question": "What technology is required to convert speech into text for the machine translation system?",
            "reference-answers": [
                "We need some technology to convert the speech into the text that the machine translation system is..."
            ]
        },
        {
            "question": "What technology is needed to convert speech into text for the machine translation system?",
            "reference-answers": [
                "We need some technology to convert the speech into the text that the machine translation system is..."
            ]
        },
        {
            "question": "What type of technology is needed to convert speech into text for the machine translation system?",
            "reference-answers": [
                "We need some technology to convert the speech into the text that the machine translation system is..."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen05-slide05/text.txt": [
        {
            "question": "What is the third step in the cascade of speech translation systems described in the text?",
            "reference-answers": [
                "...cascade of three, where the first is speech-to-speech translation, the second is speech-to-text, and the third is text-to-speech."
            ]
        },
        {
            "question": "What is the next step in the process after converting text to speech?",
            "reference-answers": [
                "Converting the text back into speech, which is a speech-to-speech translation."
            ]
        },
        {
            "question": "What is the next step after text-to-speech translation in the proposed system?",
            "reference-answers": [
                "Further to convert the text back into speech, so that would be a speech-to-speech translation."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen06-slide06/text.txt": [
        {
            "question": "What is one approach to machine translation that does not require explicit transcription in the middle step?",
            "reference-answers": [
                "Spoken language translation."
            ]
        },
        {
            "question": "What is one of the methods referred to as a direct attempt at achieving the goal of information transfer between languages, without using explicit transcription?",
            "reference-answers": [
                "Spoken language translation."
            ]
        },
        {
            "question": "What is one approach to direct attempts at machine translation that does not use explicit transcription in the middle step?",
            "reference-answers": [
                "Spoken language translation."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen07-slide07/text.txt": [
        {
            "question": "What type of system is described as going directly to the speech in the target language?",
            "reference-answers": [
                "A speech-to-speech system."
            ]
        },
        {
            "question": "What type of system is being referred to when it directly translates speech in the target language?",
            "reference-answers": [
                "A speech-to-speech system."
            ]
        },
        {
            "question": "What type of system is being contrasted with the combination of ASR and MT in the given text?",
            "reference-answers": [
                "A speech-to-speech system."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen08-slide08/text.txt": [
        {
            "question": "What is the difference between using an image in image captioning and image-guided translation?",
            "reference-answers": [
                "The difference between using an image in image captioning and image-guided translation is that the former is a monolingual task (describing what is in the image with text in the source language), while the latter involves using the image in a translation task (using the image to aid in translation)."
            ]
        },
        {
            "question": "What is an example of a task that can be performed using an image in image captioning?",
            "reference-answers": [
                "describing, automatically describing what is in the image with text in the source language."
            ]
        },
        {
            "question": "What type of task can an image used in the illustration also be used for, in addition to image captioning?",
            "reference-answers": [
                "image guided translation."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen09-slide09/text.txt": [
        {
            "question": "What is the potential development timeline for visual guided translation technology?",
            "reference-answers": [
                "The visual guided translation technology is \"only first attempts so far\" and is going to be developed in the coming years."
            ]
        },
        {
            "question": "What is an emerging technology related to translation that involves visual guidance or video guidance?",
            "reference-answers": [
                "Visual guided translation."
            ]
        },
        {
            "question": "What is the current state of development for visual guided translation technology?",
            "reference-answers": [
                "The current state of development for visual guided translation technology is that it is still in its first attempts, and it is expected to be developed further in the coming years."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen10-slide11/text.txt": [
        {
            "question": "What is typically used as input for machine translation in this context?",
            "reference-answers": [
                "Grammatically correct individual sentences."
            ]
        },
        {
            "question": "What is typically used as the input for machine translation in this context?",
            "reference-answers": [
                "Grammatically correct individual sentences."
            ]
        },
        {
            "question": "What type of input is typically used for machine translation, according to the lecturer?",
            "reference-answers": [
                "Grammatically correct individual sentences."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen11-slide12/text.txt": [
        {
            "question": "What is the main aim of incremental machine translation?",
            "reference-answers": [
                "The main aim of incremental machine translation is to provide the stability of the output."
            ]
        },
        {
            "question": "What is the main aim of incremental machine translation?",
            "reference-answers": [
                "The main aim of incremental machine translation is to provide the stability of the output."
            ]
        },
        {
            "question": "What is the main aim of incremental machine translation?",
            "reference-answers": [
                "The main aim of incremental machine translation is to provide the stability of the output."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen12-slide13/text.txt": [
        {
            "question": "What is the primary goal of the deep neural network model proposed in the speech-to-speech translation system?",
            "reference-answers": [
                "The primary goal of the deep neural network model proposed in the speech-to-speech translation system is to directly model speech-to-speech translation, allowing it to process time frames in the source language and produce time frames in the target language, thereby handling all differences and commonalities between languages."
            ]
        },
        {
            "question": "What are the benefits of direct speech-to-speech translation over text-based translation?",
            "reference-answers": [
                "The benefits of direct speech-to-speech translation over text-based translation are clear, and they include handling all differences and commonalities between languages, preserving the voice, tone, and prosthetics, and also synthesizing the target voice to reflect what was expressed in the original speech."
            ]
        },
        {
            "question": "What is the main goal of the deep neural network model proposed in the context of speech-to-speech translation?",
            "reference-answers": [
                "The main goal of the deep neural network model is to directly model speech-to-speech translation, processing time frames in the source language and producing time frames in the target language, thereby handling differences and commonalities between languages and preserving voice, tone, and prosthetics."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen13-slide14/text.txt": [
        {
            "question": "What are the two components that would be connected together in the cascading machine spoken language translation process?",
            "reference-answers": [
                "The speech recognition and the machine translation."
            ]
        },
        {
            "question": "What are the two components that need to be connected in the cascading machine spoken language translation process?",
            "reference-answers": [
                "The speech recognition and the machine translation."
            ]
        },
        {
            "question": "What are the two components that need to be connected together in the cascading machine spoken language translation process?",
            "reference-answers": [
                "The speech recognition and the machine translation."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen14-slide15/text.txt": [
        {
            "question": "What is the standard measure used to evaluate the performance of speech recognition systems?",
            "reference-answers": [
                "Word error rate."
            ]
        },
        {
            "question": "What is the standard measure used to evaluate the performance of speech recognition systems?",
            "reference-answers": [
                "Word error rate."
            ]
        },
        {
            "question": "What is the standard measure used to evaluate the performance of speech recognition systems?",
            "reference-answers": [
                "Word error rate."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen15-slide16/text.txt": [
        {
            "question": "What is the significance of machine translation in relation to human capabilities, according to the previous discussion?",
            "reference-answers": [
                "Machine translation is getting on par with humans in some settings and in some evaluation ways."
            ]
        },
        {
            "question": "What is the author's point about machine translation?",
            "reference-answers": [
                "Machine translation is getting on par with humans in some settings and in some evaluation ways."
            ]
        },
        {
            "question": "What is the KVS on the evaluation of machine translation in relation to human performance?",
            "reference-answers": [
                "We have discussed in the past, bear in mind the KVS on the evaluation, that machine translation is also getting on par with humans in some settings and in some evaluation ways."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen16-slide17/text.txt": [
        {
            "question": "What is the proposed process for speech translation using ASR and machine translation?",
            "reference-answers": [
                "The proposed process for speech translation using ASR and machine translation is to run ASR on the sound that you want to translate and then run the machine translation to obtain a superhuman interpretation of what has been said."
            ]
        },
        {
            "question": "What is the purpose of running machine translation after ASR in a speech translation system?",
            "reference-answers": [
                "The purpose of running machine translation after ASR in a speech translation system is to get the superhuman interpretation of what has been said."
            ]
        },
        {
            "question": "What is the proposed sequence of steps for a speech translation system?",
            "reference-answers": [
                "Run ASR on the sound that you want to translate and then run the machine translation and that the superhuman interpretation of what has been said."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen17-slide18/text.txt": [
        {
            "question": "What is a significant challenge in developing ASR systems that can produce clear and correct sentences?",
            "reference-answers": [
                "The first problem is that ASR systems are trained and evaluated to produce lowercase words, and machine translation has focused on translating individual sentences, making it challenging to get from a sequence of words to clear and correct sentences."
            ]
        },
        {
            "question": "What are some challenges associated with using ASR systems for sentence translation?",
            "reference-answers": [
                "The challenges associated with using ASR systems for sentence translation include that they are trained and evaluated to produce lowercase words and are focused on translating individual sentences, making it difficult to get from a sequence of words to clear sentences."
            ]
        },
        {
            "question": "What are the main challenges in developing ASR systems and machine translation that need to be addressed?",
            "reference-answers": [
                "The main challenges in developing ASR systems and machine translation are that ASR systems are focused on producing lowercase words and machine translation is translating individual sentences, making it difficult to get from word sequences to clear sentences."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen18-slide19/text.txt": [
        {
            "question": "What is the term for dividing the flow of words into parts?",
            "reference-answers": [
                "segmenting"
            ]
        },
        {
            "question": "What do you have to segment the flow of words into?",
            "reference-answers": [
                "phrases"
            ]
        },
        {
            "question": "What do you have to segment the flow of words into?",
            "reference-answers": [
                "phrases"
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen19-slide20/text.txt": [
        {
            "question": "What would happen to the machine translation if the ASR emits uncertain outputs, and a NBEST list is not used in between the two components?",
            "reference-answers": [
                "The machine translation will take the uncertain output as the ground truth and translate it into the target language, potentially resulting in a completely confusing message."
            ]
        },
        {
            "question": "What would happen to the machine translation if the ASR emitted only one output instead of multiple candidates?",
            "reference-answers": [
                "The machine translation will take that candidate, for example, the delicious summer thing, as the ground truth, and it will translate it into the target language."
            ]
        },
        {
            "question": "What happens if the ASR is unsure about the meaning of a word, such as \"ice cream\"?",
            "reference-answers": [
                "The system will guess the correct output without access to further context, and the machine translation will take that candidate as the ground truth."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen20-slide21/text.txt": [
        {
            "question": "What is a potential problem in the pipeline that can occur at the very beginning of the system deployment?",
            "reference-answers": [
                "Acquiring the sound and presenting the output to the user can have a delicate interplay with the underlying algorithms, and you don't want to overload the user."
            ]
        },
        {
            "question": "What is one problem at the beginning of the pipeline that requires consideration when deploying the system?",
            "reference-answers": [
                "Acquiring the sound and presenting the output to the user."
            ]
        },
        {
            "question": "What is a key consideration when presenting output to the user in the system pipeline?",
            "reference-answers": [
                "You don't want to overload the user with all possible candidates, you want some stable and correct output as soon as possible."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen21-slide22/text.txt": [
        {
            "question": "What is the potential issue with integrating independent systems for speech recognition, ASR, and sentence segmentation?",
            "reference-answers": [
                "The potential issue with integrating independent systems for speech recognition, ASR, and sentence segmentation is that it can introduce further errors, which can be hard to handle."
            ]
        },
        {
            "question": "What are some of the potential errors that can be introduced when integrating independent systems for automatic speech recognition and machine translation in the ELITER project?",
            "reference-answers": [
                "Integration of independent systems for automatic speech recognition and machine translation can introduce further errors, such as acquiring the sound, shipping it to the ASR system, then to the sentence segmenter, and then to the translation system, which can lead to ambiguity of the input and uncertainty in the output."
            ]
        },
        {
            "question": "What type of system is being integrated in the European project ELITER, according to the speaker?",
            "reference-answers": [
                "Independent systems."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen22-slide23/text.txt": [
        {
            "question": "What challenges does the online aspect of subtitle sessions pose in this context?",
            "reference-answers": [
                "It poses difficulty in a certain way."
            ]
        },
        {
            "question": "What challenges does the online aspect of the session present in subtitle creation?",
            "reference-answers": [
                "The online aspect presents difficulty in subtitle creation due to the fact that it is done in real time, and it is also done in another language, which adds to the challenge."
            ]
        },
        {
            "question": "What challenges does the online aspect of subtitle creation pose?",
            "reference-answers": [
                "The online aspect makes it again difficult in a certain way."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen23-slide24/text.txt": [
        {
            "question": "What is the role of the mediator in the proposed system's architecture?",
            "reference-answers": [
                "The mediator serves as a hub for all the different workers, or independent systems developed at the participating universities and institutes."
            ]
        },
        {
            "question": "What is the function of the mediator in the proposed architecture?",
            "reference-answers": [
                "The mediator serves as a hub for all the different workers, connecting them together and shipping packets with sound data to various components of the processing pipeline, such as ASR and machine translation engines."
            ]
        },
        {
            "question": "What type of errors is the proposed architecture resilient to, but not to?",
            "reference-answers": [
                "The proposed architecture is resilient to some types of errors, but not to all types of errors."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen24-slide25/text.txt": [
        {
            "question": "What are some of the actual issues that you have encountered in your tests, according to the speaker?",
            "reference-answers": [
                "We have ran into these actual issues that we have in our tests."
            ]
        },
        {
            "question": "What are some of the actual issues that the author has encountered in their tests?",
            "reference-answers": [
                "The possible issues that the author has encountered in their tests are the issues that they have actually ran into, which are referred to as \"true issues\"."
            ]
        },
        {
            "question": "What issues have been encountered in tests according to the speaker?",
            "reference-answers": [
                "Possible issues that we have actually encountered in our tests."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen25-slide26/text.txt": [
        {
            "question": "What is one of the challenges faced by the ASR pipeline in terms of diagnosis and debugging due to its complexity and non-deterministic nature?",
            "reference-answers": [
                "It is pretty hard to diagnose and debug this multi-party system, especially if it's non-deterministic, due to the many components involved and their distributed nature."
            ]
        },
        {
            "question": "What type of architecture is the subtitling system, and how does it make debugging and diagnosing issues more difficult?",
            "reference-answers": [
                "The subtitling system is complex and multi-party, making it non-deterministic and distributed across many components, which makes it difficult to diagnose and debug issues."
            ]
        },
        {
            "question": "What type of system is difficult to diagnose due to its complexity and non-deterministic nature?",
            "reference-answers": [
                "A multi-party system, especially one that is complex and distributed in space, is difficult to diagnose due to its non-deterministic nature."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen26-slide27/text.txt": [
        {
            "question": "What happens to the sound quality if the first cable is badly plugged in?",
            "reference-answers": [
                "The sound quality is bad."
            ]
        },
        {
            "question": "What happens to the sound quality if the first cable is badly plugged in?",
            "reference-answers": [
                "The sound quality is bad."
            ]
        },
        {
            "question": "What happens to the sound quality if the first cable is badly plugged in?",
            "reference-answers": [
                "The sound quality is bad."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen27-slide28/text.txt": [
        {
            "question": "What are some potential issues that can occur in the presentation pipeline that may lead to unacceptable delays for end-users?",
            "reference-answers": [
                "Delays between or communication bottlenecks between the presentation worker and the web, and end user devices getting overloaded with data, which can lead to unacceptable delays for subtitles on web browsers."
            ]
        },
        {
            "question": "What are some potential issues that can cause unacceptable delays in the presentation of subtitles to end users?",
            "reference-answers": [
                "Delays between or communication bottlenecks between the presentation worker and the web, and end user devices getting overloaded with data."
            ]
        },
        {
            "question": "What are some potential issues that can cause delays in the presentation of subtitles to end-users, according to the final problem at the presentation?",
            "reference-answers": [
                "Delays between or communication bottleneck between the presentation worker and the web, and overflown data on end-user devices."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen28-slide29/text.txt": [
        {
            "question": "What type of models were compiled on the particle machine to be used in the ASR system?",
            "reference-answers": [
                "The models compiled on the particle machine were the ones used in the ASR system."
            ]
        },
        {
            "question": "What type of machine was the ASR system started locally on?",
            "reference-answers": [
                "The particle machine."
            ]
        },
        {
            "question": "What type of models were compiled only on the particle machine in the ASR system?",
            "reference-answers": [
                "The models compiled only on the particle machine were the ASR models."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen29-slide31/text.txt": [
        {
            "question": "What is likely to happen to the sound volume and clarity when a presenter is positioned with the chest mic on one side of their body and speaking to the other side?",
            "reference-answers": [
                "The sound volume and the clarity of the sound will decrease."
            ]
        },
        {
            "question": "What effect did a colleague's positioning of the chest mic have on the sound volume and clarity during a test session?",
            "reference-answers": [
                "The colleague's positioning of the chest mic had decreased the sound volume and the clarity of the sound."
            ]
        },
        {
            "question": "What effect did a colleague's placement of the chest mic have on the sound volume and clarity during a presentation?",
            "reference-answers": [
                "The placement of the chest mic had decreased the sound volume and the clarity of the sound."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen30-slide32/text.txt": [
        {
            "question": "What type of microphone provided a clear benefit in the experiment?",
            "reference-answers": [
                "The headset microphone."
            ]
        },
        {
            "question": "What type of microphone showed a clear benefit in this experiment?",
            "reference-answers": [
                "The headset microphone."
            ]
        },
        {
            "question": "What type of microphone was found to have a clear benefit in the experiment?",
            "reference-answers": [
                "The headset microphone."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen31-slide33/text.txt": [
        {
            "question": "What are some common problems people may experience when using handheld microphones?",
            "reference-answers": [
                "People could cover the microphone with..."
            ]
        },
        {
            "question": "What are some common problems that can occur when people use handheld microphones?",
            "reference-answers": [
                "People could cover the microphone with..."
            ]
        },
        {
            "question": "What are some common problems people face when using handheld microphones?",
            "reference-answers": [
                "People could cover the microphone with..."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen32-slide35/text.txt": [
        {
            "question": "Where should they not place the object in relation to their hand?",
            "reference-answers": [
                "Too far from their mouth or too far below their hand."
            ]
        },
        {
            "question": "What are three possible locations for placing an object?",
            "reference-answers": [
                "1. Too close to their mouth\n2. Too far from their mouth\n3. Too far below their hand"
            ]
        },
        {
            "question": "What are three possible locations where someone could place an object in relation to their mouth or hand?",
            "reference-answers": [
                "They could put it too close to their mouth, they could put it too far from their mouth, or they could put it too far below their hand."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen33-slide36/text.txt": [
        {
            "question": "What would happen to the ASR quality if the microphone picked up both the speaker's voice and the sound of the loudspeakers?",
            "reference-answers": [
                "The ASR quality could be already damaging because it is not trained on this double sound wave."
            ]
        },
        {
            "question": "What could be the effect on the ASR quality when a double sound wave is received by the microphone?",
            "reference-answers": [
                "The double sound wave could be already damaging the ASR quality, because obviously it is not trained on like"
            ]
        },
        {
            "question": "What would happen to the ASR quality if a microphone and loudspeaker were both playing the same sound with a little delay?",
            "reference-answers": [
                "The ASR quality could be already damaging because it is not trained on this double sound wave."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen34-slide37/text.txt": [
        {
            "question": "What is the potential problem if the output of an intermediate component in the pipeline is too loud?",
            "reference-answers": [
                "The components further down the pipeline will fight against that."
            ]
        },
        {
            "question": "What happens if the output is too loud in a pipeline?",
            "reference-answers": [
                "The components further down the pipeline will fight against that."
            ]
        },
        {
            "question": "What happens if the output of an intermediate component is too loud in a pipeline?",
            "reference-answers": [
                "The components further down the pipeline will fight against that."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen35-slide38/text.txt": [
        {
            "question": "What was the topic of the speaker's lecture at the beginning?",
            "reference-answers": [
                "ASR (Automated Speech Recognition) technology."
            ]
        },
        {
            "question": "What was the topic of the speaker's lecture at the beginning that related to speech recognition?",
            "reference-answers": [
                "The superhuman quality of speech recognition."
            ]
        },
        {
            "question": "What did the ASR fail to work after the speaker started talking?",
            "reference-answers": [
                "And suddenly the ASR will not work either."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen36-slide39/text.txt": [
        {
            "question": "What would be the ideal output of an ASR system in the given example?",
            "reference-answers": [
                "You have a bottle and then České Budějovice."
            ]
        },
        {
            "question": "What would an ASR system recognize if the noise in the recording was cancelled or reduced?",
            "reference-answers": [
                "Something like, you have somebody too instead of the bottle."
            ]
        },
        {
            "question": "What would be the ideal output of the ASR system in the given example?",
            "reference-answers": [
                "You have a bottle and then České Budějovice."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen37-slide40/text.txt": [
        {
            "question": "What is the word error rate of the system being discussed, according to the speaker?",
            "reference-answers": [
                "The word error rate of the system being discussed is 100%."
            ]
        },
        {
            "question": "What is the word error rate of the system being evaluated, according to the speaker?",
            "reference-answers": [
                "The word error rate of the system being evaluated is 100%."
            ]
        },
        {
            "question": "What is the word error rate of the systems compared to human recognition quality?",
            "reference-answers": [
                "The word error rate of the systems is 40% (10 times worse than the human level of recognition quality of 4%)."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen38-slide41/text.txt": [
        {
            "question": "What is the main limitation of speech recognition systems when faced with noisy input and poor recording environments?",
            "reference-answers": [
                "The main limitation of speech recognition systems when faced with noisy input and poor recording environments is that they fail almost completely."
            ]
        },
        {
            "question": "What are some common challenges faced by speech recognition systems in real-world settings?",
            "reference-answers": [
                "Noisy input and poor control of the recording environment, and the speaker's grammatical and pronunciation errors are some common challenges faced by speech recognition systems in real-world settings."
            ]
        },
        {
            "question": "What is the main issue with speech recognition systems in noisy input environments?",
            "reference-answers": [
                "The main issue with speech recognition systems in noisy input environments is that they fail almost completely, as seen in the 90-second speeches tested, and are also prone to grammatical and pronunciation errors, which can lead to the system choosing wrong wordings."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen39-slide42/text.txt": [
        {
            "question": "What is the significance of the non-native person's speech recognition in the context of machine translation?",
            "reference-answers": [
                "The non-native person's speech recognition served as a reality check for machine translation, indicating that the machine translation system needs improvement, particularly in handling non-native speech."
            ]
        },
        {
            "question": "What was the purpose of the non-native person's speech recognition and machine translation test?",
            "reference-answers": [
                "The non-native person's speech recognition and machine translation test served as a reality check, specifically for achieving \"superhuman\" capabilities in these areas."
            ]
        },
        {
            "question": "What was the effect of the non-native person's speech on the machine translation system?",
            "reference-answers": [
                "It served as a reality check for the machine translation system."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen40-slide43/text.txt": [
        {
            "question": "What is the standard ambiguity of words that is demonstrated in the provided text example?",
            "reference-answers": [
                "The standard ambiguity of words demonstrated is that the word \"if\" is mistranslated and its meaning is confused with \"op\", which corresponds to the English word \"weather\", leading to a misunderstanding of the sentence's intended meaning."
            ]
        },
        {
            "question": "What is the standard translation error that occurs when translating the German word \"op\" in the given text?",
            "reference-answers": [
                "The standard translation error is that the German word \"op\" is mistranslated as \"if\", which corresponds to the English weather, resulting in a misunderstanding of the intended meaning."
            ]
        },
        {
            "question": "What is the standard translation error that occurs when the German word \"op\" is used instead of the English word \"if\"?",
            "reference-answers": [
                "The standard translation error is that the German word \"op\" is mistranslated as the English weather, leading to a misunderstanding that it is difficult to ask whether you understand or do not understand, rather than the actual meaning that it is difficult to ask in the case when you do not understand."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen41-slide44/text.txt": [
        {
            "question": "What is the main difference between errors in machine translation alone and errors in speech recognition alone, according to the text?",
            "reference-answers": [
                "The main difference between errors in machine translation alone and errors in speech recognition alone is that errors in machine translation alone are less severe than errors in speech recognition alone."
            ]
        },
        {
            "question": "What are some of the severe errors that can occur in speech translation systems compared to errors in machine translation alone?",
            "reference-answers": [
                "Severe errors that can occur in speech translation systems include the combination of isolated sentences with negative or conflicting messages, such as \"let's forget it or you were an idiot and I don't want to work with you\", which can lead to loss of confidence in the overall message."
            ]
        },
        {
            "question": "What is the main difference between errors in machine translation alone and errors in machine translation combined with speech recognition systems?",
            "reference-answers": [
                "Errors in machine translation combined with speech recognition systems are more severe than errors in machine translation alone, because they lack the context needed to provide a full message."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen42-slide46/text.txt": [
        {
            "question": "What is the primary limitation of current end-to-end spoken language translation systems?",
            "reference-answers": [
                "They are limited to the level of utterances and cannot handle the segmentation of isolated words or sentences."
            ]
        },
        {
            "question": "What is the primary limitation of end-to-end spoken language translation systems when it comes to handling segmentation of sentences?",
            "reference-answers": [
                "The primary limitation of end-to-end spoken language translation systems when it comes to handling segmentation of sentences is that they are trained and tested on datasets which already come in isolated utterances, meaning they do not handle the segmentation of individual sentences."
            ]
        },
        {
            "question": "What is the main challenge in developing end-to-end spoken language translation systems?",
            "reference-answers": [
                "The main challenge in developing end-to-end spoken language translation systems is identifying the correct segmentation of individual sentences from sequences of words without punctuation and in lowercase."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen43-slide47/text.txt": [
        {
            "question": "How do sequence labeling algorithms handle the use of sound information in the input sequence of words, and what are the implications for different architectures?",
            "reference-answers": [
                "In sequence labeling algorithms, the handling of sound information depends on the architecture. Sometimes it may be easier to feed in the original sound, while in other cases, it would be difficult. The sound information can indicate the end of the sentence, especially if the intonation changes, and other aspects of prosody play a role, but this information is not directly correlated with the end of the sentence."
            ]
        },
        {
            "question": "How do early models approach the task of inserting punctuations into a sequence of words?",
            "reference-answers": [
                "Early models approach the task of inserting punctuations into a sequence of words by using language model scoring, considering a window of a few words and checking whether the probability of this sequence of words is higher or lower with or without punctuation symbols."
            ]
        },
        {
            "question": "What approaches can be used to insert punctuation into a sequence of words, and how do these approaches differ in terms of incorporating sound information?",
            "reference-answers": [
                "The approaches to insert punctuation into a sequence of words include:\n\n1. Language model scoring: Considering a window of a few words and checking the probability of the sequence with or without punctuation.\n2. Sequence labeling algorithms: Adding a tag to each word indicating the punctuation to be used after it, such as a full stop, comma, question mark, or capitalization.\n3. Machine translation: Translating a sequence of English words without punctuation to a sequence of English words with punctuation, which can be done using a separate machine translation system.\n\nThese approaches differ in terms of incorporating sound information:\n\n- Language model scoring and sequence labeling algorithms can be"
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen44-slide48/text.txt": [
        {
            "question": "What is the potential consequence of a random shift in punctuation marks in machine translation systems?",
            "reference-answers": [
                "A random shift of the punctuation marks can terribly damage the final output."
            ]
        },
        {
            "question": "What are the potential consequences of a random shift in punctuation marks during machine translation?",
            "reference-answers": [
                "A random shift of the punctuation mark can terribly damage the final output, and the machine translation system may use surrounding words that don't belong to the sentence, shuffle them, and place them in prominent positions in the sentence."
            ]
        },
        {
            "question": "What type of errors can occur in machine translation if a random shift of the punctuation mark is made?",
            "reference-answers": [
                "Severe errors can occur in machine translation if a random shift of the punctuation mark is made, including using surrounding words that may not belong to the sentence, shuffling them, and placing them in prominent positions in the sentence."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen45-slide49/text.txt": [
        {
            "question": "What is a potential advantage of end-to-end spoken language translation?",
            "reference-answers": [
                "It should not have these problems."
            ]
        },
        {
            "question": "What type of problems are mentioned as being avoided by end-to-end spoken language translation?",
            "reference-answers": [
                "Problems."
            ]
        },
        {
            "question": "What type of problems are associated with end-to-end spoken language translation, according to the speaker?",
            "reference-answers": [
                "These problems."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen47-slide49/text.txt": [
        {
            "question": "How are the systems trained and tested in the provided context?",
            "reference-answers": [
                "They are trained and tested on corpora which are utterance segmented by themselves."
            ]
        },
        {
            "question": "How are the systems trained and tested?",
            "reference-answers": [
                "They are trained and tested on corpora which are utterance segmented by themselves."
            ]
        },
        {
            "question": "How are the systems trained and tested?",
            "reference-answers": [
                "They are trained and tested on corpora which are utterance segmented by themselves."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen48-slide50/text.txt": [
        {
            "question": "What is a major drawback in speech recognition and spoken language translation due to insufficient training data?",
            "reference-answers": [
                "One major drawback is that the input sequences are much longer, requiring timeframes of sound instead of subword units, which is computationally challenging."
            ]
        },
        {
            "question": "What is one major drawback of using speech recognition for direct spoken language translation, according to the text?",
            "reference-answers": [
                "One major drawback of using speech recognition for direct spoken language translation is the insufficient training data, specifically the lack of speech in the source language and text in the target language in sufficient amounts."
            ]
        },
        {
            "question": "What is a significant drawback of training a spoken language translation model, according to the text?",
            "reference-answers": [
                "The main drawback is the insufficient training data, specifically the lack of speech in the source language and text in the target language in sufficient amounts."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen49-slide51/text.txt": [
        {
            "question": "What is the main limitation of the standard training approach for speech-to-text and speech-to-speech translation systems, according to the text?",
            "reference-answers": [
                "The main limitation of the standard training approach for speech-to-text and speech-to-speech translation systems is insufficient training data."
            ]
        },
        {
            "question": "What is the primary problem with standard training of speech encoder and text decoder on the speech-to-text speech corpus?",
            "reference-answers": [
                "The primary problem with standard training of speech encoder and text decoder on the speech-to-text speech corpus is insufficient training data."
            ]
        },
        {
            "question": "What is the main issue with standard training of speech encoder and text decoder on the speech-to-text speech corpus?",
            "reference-answers": [
                "The main issue with standard training of speech encoder and text decoder on the speech-to-text speech corpus is insufficient training data."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen50-slide52/text.txt": [
        {
            "question": "What type of neural network architecture was used by Berard and colleagues in their 2016 proof of concept for end-to-end spoken language translation?",
            "reference-answers": [
                "A deep LSTM encoder, then the standard attention and the deep LSTM decoder."
            ]
        },
        {
            "question": "What type of neural network was used in the end-to-end spoken language translation system trained on the synthetic corpus?",
            "reference-answers": [
                "A deep LSTM encoder, then the standard attention and the deep LSTM decoder."
            ]
        },
        {
            "question": "What type of neural network architecture was used by Berard and colleagues for end-to-end spoken language translation in their 2016 proof of concept?",
            "reference-answers": [
                "A deep LSTM encoder, then the standard attention and the deep LSTM decoder."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen51-slide53/text.txt": [
        {
            "question": "What type of recurrent neural networks were used in the 2018 experiments, and how do they condense the time dimension of the input?",
            "reference-answers": [
                "Paramiddle recurrent neural networks, which are like standard deep recurrent networks except that the deeper layers are not run at every time step but they are run only every three steps or every five steps, and this deep recurrent networks then condense the time dimension of the input."
            ]
        },
        {
            "question": "What type of neural network is used in the 2018 experiments to condense the time dimension of the input?",
            "reference-answers": [
                "Paramiddle recurrent neural networks."
            ]
        },
        {
            "question": "What type of recurrent neural network is used in the 2018 experiments mentioned in the text, which condenses the time dimension of the input?",
            "reference-answers": [
                "paramiddle recurrent neural networks."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen52-slide54/text.txt": [
        {
            "question": "What is the purpose of pre-training a neural network in the context of speech recognition and machine translation?",
            "reference-answers": [
                "They pre-train the neural network components on independent and easier to obtain datasets before fine-tuning them for specific tasks such as speech recognition and machine translation."
            ]
        },
        {
            "question": "What is the purpose of the pre-training approach for speech recognition and machine translation?",
            "reference-answers": [
                "They first pre-train it in the monolingual task and then they add the source language."
            ]
        },
        {
            "question": "What is the purpose of pre-training a neural network for speech recognition and machine translation?",
            "reference-answers": [
                "They pre-train the neural network components on independent and easier to obtain datasets to improve the system's performance in speech recognition and machine translation."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen53-slide55/text.txt": [
        {
            "question": "What is the number of parameters used in the ensembling system compared to the individual components, specifically the ASR and translation components?",
            "reference-answers": [
                "The ensembling system uses 9 million parameters, while the ASR only uses 6.3 million parameters."
            ]
        },
        {
            "question": "What is the number of parameters used in the ensembling system compared to the ASR only system?",
            "reference-answers": [
                "6.3 million parameters."
            ]
        },
        {
            "question": "What is the performance of the multitask training system compared to the other approaches mentioned in the text?",
            "reference-answers": [
                "The multitask training system performs best among the mentioned approaches."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen54-slide56/text.txt": [
        {
            "question": "What is still not clear in the results of the survey regarding the best architecture for the cascaded system?",
            "reference-answers": [
                "Which architecture would be the best so some people use convolution networks networks and LSTM some use convolution networks and transformers some use paramidal recurrent neural networks some use the knowledge distillation so teacher student approach some use pre-training some use multi-task setup"
            ]
        },
        {
            "question": "What architecture is currently being used to try and achieve a cascaded system in the field of neural networks?",
            "reference-answers": [
                "Convolution networks, LSTM, convolution networks and transformers, paramidal recurrent neural networks, knowledge distillation (teacher student approach), pre-training, and multi-task setup."
            ]
        },
        {
            "question": "What is the current state of the cascaded system being compared to in the survey results?",
            "reference-answers": [
                "We are really getting on par or very close to the cascaded system."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen55-slide57/text.txt": [
        {
            "question": "What is the difference between the two approaches modified by the Italian FBK team in their 2019 paper, and how do they compare to the standard transformer approach?",
            "reference-answers": [
                "The two approaches modified by the Italian FBK team in their 2019 paper differ in how they use the input data. The baseline approach adds linear transformations to the input, followed by two layers of transformation, and then reduces the size of the input using convolutional networks, before applying standard encoder layers of the transformer. In contrast, the S-transformer uses similar compression of the input, but applies convolutional networks and some attention over that, and adds positional encoding only right before entering the self-attention phase."
            ]
        },
        {
            "question": "What are the two main ways in which the Italian FBK team modified the standard transformer architecture in their approach?",
            "reference-answers": [
                "The Italian FBK team modified the standard transformer architecture in two ways: \n\n1. Adding linear transformations, two layers of transformation on the same combined input, and the positional encoding.\n2. Using two levels of convolutional networks to reduce the size of the input, and then applying the standard encoder layers of the transformer."
            ]
        },
        {
            "question": "What modifications did the Italian FBK team make to the standard transformer architecture in their 2019 paper?",
            "reference-answers": [
                "The Italian FBK team modified the standard transformer architecture in two ways: \n\n1. They added two layers of linear transformations to the combined input, which included the frequencies of the particular timeframe and the positional encoding.\n\n2. They used two levels of convolutional networks to reduce the size of the input.\n\nAnd then they put the standard encoder layers of the transformer on top of that."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen56-slide58/text.txt": [
        {
            "question": "What is the name of the system developed by Google that directly translates speech-to-speech and preserves speaker characteristics?",
            "reference-answers": [
                "The system developed by Google that directly translates speech-to-speech and preserves speaker characteristics is called Translator-Tran."
            ]
        },
        {
            "question": "What is the name of the system developed by Google that uses spectrograms, vocoder, and speaker characteristics to preserve voice characteristics in speech translation?",
            "reference-answers": [
                "The system developed by Google is called Translator-Tran."
            ]
        },
        {
            "question": "What is the name of the system developed by Google for speech-to-speech translation that preserves speaker characteristics?",
            "reference-answers": [
                "The system developed by Google for speech-to-speech translation that preserves speaker characteristics is called Translator-Tran."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen57-slide59/text.txt": [
        {
            "question": "What is the main topic of the speech that the speaker is referring to in the given text?",
            "reference-answers": [
                "The presentation."
            ]
        },
        {
            "question": "What is the purpose of the speaker glossing over the presentation?",
            "reference-answers": [
                "The speaker glosses over the presentation to \"talk a little\" about it, implying they will only briefly discuss it."
            ]
        },
        {
            "question": "What is the main focus of the speaker in the given speech?",
            "reference-answers": [
                "The speaker is glossing over the presentation, indicating that the main focus is not on the presentation itself, but rather on something else."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen58-slide60/text.txt": [
        {
            "question": "What is a critical factor in ensuring that subtitles are readable and effective in conveying a message?",
            "reference-answers": [
                "Updating your translation candidates and significant reordering in the updates can kill the whole show because people will not get the message even if your translations were perfect."
            ]
        },
        {
            "question": "What are some usability factors that need to be considered when deploying a system with subtitles?",
            "reference-answers": [
                "usability things that you have to consider are showing outputs too quickly, updating translation candidates, significant reordering in updates, and ensuring subtitles are large enough to read with perfect timing."
            ]
        },
        {
            "question": "What type of setting is necessary for a system deploying subtitles to ensure its usability?",
            "reference-answers": [
                "A good setting."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen59-slide61/text.txt": [
        {
            "question": "What is a potential issue with producing subtitles in multiple languages at once due to limited space for each language?",
            "reference-answers": [
                "It is often difficult to squeeze in the information and to keep it stable."
            ]
        },
        {
            "question": "What is a potential issue with producing subtitles in many languages at once?",
            "reference-answers": [
                "Limited space for each language, making it difficult to squeeze in the information and keep it stable."
            ]
        },
        {
            "question": "What is a challenge in producing subtitles for multiple languages with limited space?",
            "reference-answers": [
                "It is often difficult to squeeze in the information and to keep it stable."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen60-slide62/text.txt": [
        {
            "question": "What is the purpose of using paragraphs in a text to indicate the status of sentences?",
            "reference-answers": [
                "To show paragraphs where people can read back and to easily indicate the status of sentences, such as completed, being updated, and incoming."
            ]
        },
        {
            "question": "What is the purpose of the paragraphs in the provided text?",
            "reference-answers": [
                "The paragraphs are to show where people can read back, indicating completed, updated, and incoming sentences."
            ]
        },
        {
            "question": "What type of output can be mixed together to allow users to select what they would like to read?",
            "reference-answers": [
                "Paragraphs."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen61-slide63/text.txt": [
        {
            "question": "What is the purpose of the \"subtitler\" component in the subtitle generation process?",
            "reference-answers": [
                "The subtitler component decides when to move the subtitles one more line to prevent flickering and ensure the user sees the subtitles smoothly, preventing confusion due to frequent updates."
            ]
        },
        {
            "question": "What is the purpose of the subtitler component in the system described in the text?",
            "reference-answers": [
                "The subtitler component decides when to move the subtitles one more line to prevent flickering and maintain a clear view for the user."
            ]
        },
        {
            "question": "What is the main issue with the current system for displaying subtitles in a limited space?",
            "reference-answers": [
                "The main issue with the current system for displaying subtitles in a limited space is that the subtitles flicker as the segmenter and machine translation systems make changes, potentially showing previously displayed text that is then updated, which can be confusing for the user."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen62-slide64/text.txt": [
        {
            "question": "What type of output do users who do not speak the source language prefer, and what are they willing to wait for?",
            "reference-answers": [
                "Users who do not speak the source language prefer stability and precision over the immediateness of the translation, and they are willing to wait for seconds of delay."
            ]
        },
        {
            "question": "What type of output do users who do not speak the source language prefer, and what are they willing to wait for in order to achieve it?",
            "reference-answers": [
                "Users who do not speak the source language prefer stability and precision over the immediateness of the translation, and they are willing to wait for seconds of delay to achieve it."
            ]
        },
        {
            "question": "What type of output would a user who does not speak the source language prefer, and what would they be willing to wait for?",
            "reference-answers": [
                "A user who does not speak the source language would prefer stability and precision over the immediateness of the translation and would be willing to wait for seconds of delay."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen63-slide65/text.txt": [
        {
            "question": "Will the evaluation of spoken language translation take place?",
            "reference-answers": [
                "No, the evaluation of spoken language translation will be skipped."
            ]
        },
        {
            "question": "Will the evaluation of spoken language translation take place?",
            "reference-answers": [
                "No, the evaluation of spoken language translation will be skipped."
            ]
        },
        {
            "question": "Will the evaluation of spoken language translation be included in the exam?",
            "reference-answers": [
                "Yeah."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen64-slide66/text.txt": [
        {
            "question": "What are some additional aspects to consider when comparing the outputs of a machine translation system in spoken language, beyond just the quality of the translation?",
            "reference-answers": [
                "How much are you behind what has been just uttered in the online setup and some flicker."
            ]
        },
        {
            "question": "What are some additional factors to consider when comparing the outputs of a machine translation system in spoken language translation?",
            "reference-answers": [
                "In addition to the quality of the translation, when comparing the outputs of a machine translation system in spoken language translation, you also want to know how much you are behind what has been just uttered, and some flicker."
            ]
        },
        {
            "question": "What are some additional aspects to consider when comparing the outputs of a machine translation system in spoken language translation?",
            "reference-answers": [
                "In addition to the quality of the translation, when comparing the outputs of a machine translation system in spoken language translation, you also want to know how much you are behind what has been just uttered, and some flicker."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen65-slide67/text.txt": [
        {
            "question": "What is the potential issue with the evaluation process when there is a mismatch between the system's segmentation of the input sound and the golden segmentation used in the evaluation?",
            "reference-answers": [
                "The potential issue with the evaluation process is that the system's segmentation of the input sound may decide to segment the input sound differently than the golden segmentation used in the evaluation."
            ]
        },
        {
            "question": "What is the potential issue with evaluating speech recognition systems when there is a mismatch between the system's segmentation of the input sound and the golden segmentation used in the evaluation?",
            "reference-answers": [
                "The potential issue with evaluating speech recognition systems is the problem with segmentation, where the system may decide to segment the input sound differently than the golden segmentation used in the evaluation."
            ]
        },
        {
            "question": "What is the problem that arises during the evaluation of speech recognition systems due to differences in segmentation of input sound?",
            "reference-answers": [
                "The problem that arises during the evaluation of speech recognition systems due to differences in segmentation of input sound is the mismatch between the golden segmentation into sentences and how the systems decide to segment the input sound differently."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen66-slide69/text.txt": [
        {
            "question": "What is the nature of the presentation that is to follow the discussion on visual information?",
            "reference-answers": [
                "It will be a much shorter presentation."
            ]
        },
        {
            "question": "What is the expected duration of the presentation on visual information?",
            "reference-answers": [
                "This will be much shorter presentation."
            ]
        },
        {
            "question": "What type of presentation can be expected for visual information in the remaining part of the lecture?",
            "reference-answers": [
                "A much shorter presentation."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen67-slide70/text.txt": [
        {
            "question": "What would be the correct translation of the English sentence \"a tennis player is getting ready\" into Spanish?",
            "reference-answers": [
                "tenista se prepara."
            ]
        },
        {
            "question": "What would be the output for the English sentence \"the teacher is getting ready\"?",
            "reference-answers": [
                "tenedor se prepara"
            ]
        },
        {
            "question": "What would be the output of the sentence \"a tennis player is getting ready\" in Spanish?",
            "reference-answers": [
                "tenista se prepara"
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen68-slide71/text.txt": [
        {
            "question": "What is the grammatical gender of the first sentence in the provided text?",
            "reference-answers": [
                "male"
            ]
        },
        {
            "question": "What is the grammatical gender of the second sentence in the given text?",
            "reference-answers": [
                "The second sentence is in the female or feminine gender."
            ]
        },
        {
            "question": "What type of information is not available in the English source that you are likely to make a random guess about?",
            "reference-answers": [
                "Language or grammatical gender information."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen69-slide72/text.txt": [
        {
            "question": "If you have the queue, what else can you easily determine?",
            "reference-answers": [
                "...the image."
            ]
        },
        {
            "question": "If you have the queue, can you easily find an image next to that sentence?",
            "reference-answers": [
                "No, because the sentence \"And if you have the queue\" does not have an image next to it."
            ]
        },
        {
            "question": "What is the next step if you have the queue and an image is present?",
            "reference-answers": [
                "...easily understand the text."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen70-slide73/text.txt": [
        {
            "question": "What is the purpose of using the rectangular information from images in the Visual Genome database to improve translation?",
            "reference-answers": [
                "The idea is to use the rectangular information or the whole to improve the translation."
            ]
        },
        {
            "question": "What is the purpose of using the rectangular information from images in the Visual Genome database to improve translation?",
            "reference-answers": [
                "The idea is to use the rectangular information or the whole to improve the translation."
            ]
        },
        {
            "question": "What type of information can be used to improve the translation in the Visual Genome database?",
            "reference-answers": [
                "The rectangular information or the whole image in the Visual Genome database can be used to improve the translation."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen71-slide74/text.txt": [
        {
            "question": "How many ambiguous words were manually selected from the challenge test set after searching the whole Visual Genome?",
            "reference-answers": [
                "19 words."
            ]
        },
        {
            "question": "How many ambiguous words were found in the dedicated test set focused on ambiguous words?",
            "reference-answers": [
                "19 words."
            ]
        },
        {
            "question": "How many ambiguous words were selected from the challenge test set after manual subselection?",
            "reference-answers": [
                "19 words."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen72-slide75/text.txt": [
        {
            "question": "What is a more reliable indicator of the meaning of the word \"penalty\" than the word itself?",
            "reference-answers": [
                "The surrounding words can be very informative."
            ]
        },
        {
            "question": "What is a more reliable indicator of the meaning of the word \"penalty\" than the surrounding words in a given context?",
            "reference-answers": [
                "The images."
            ]
        },
        {
            "question": "What type of information can the surrounding words in an image provide, according to the provided text?",
            "reference-answers": [
                "The surrounding words in an image can be very informative."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen73-slide76/text.txt": [
        {
            "question": "What is the role of the attention mechanism in the processing of the input sentence in the described system?",
            "reference-answers": [
                "The attention mechanism focuses on different parts of the input sentence as the system proceeds to produce the output, allowing it to selectively attend to relevant states corresponding to different words in the sentence."
            ]
        },
        {
            "question": "What is the purpose of the attention mechanism in the given context of processing an input sentence with a bidirectional recurrent neural network?",
            "reference-answers": [
                "The attention mechanism focuses on another part of the input sentence as the output is produced, allowing the model to selectively attend to different parts of the sentence."
            ]
        },
        {
            "question": "What is the output of the model after processing the input sentence with a bidirectional recurrent neural network?",
            "reference-answers": [
                "The output of the model after processing the input sentence with a bidirectional recurrent neural network is the output, which is produced after attending to the states that correspond to different words in the sentence."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen74-slide77/text.txt": [
        {
            "question": "What is the role of the attention mechanism in the image captioning task described in the text?",
            "reference-answers": [
                "The attention mechanism runs over the 2D parts of the image, not over the one-dimensional sequences of input tokens, as it attends to the various parts of the image as it's producing the output."
            ]
        },
        {
            "question": "What is the primary difference between the image captioning task and other tasks involving input images?",
            "reference-answers": [
                "The primary difference between the image captioning task and other tasks involving input images is that the image captioning task uses an attention mechanism over the 2D parts of the image, rather than running it over one-dimensional sequences of input tokens."
            ]
        },
        {
            "question": "What type of mechanism is used in the image captioning task to attend to the various parts of the image as it's producing the output?",
            "reference-answers": [
                "Attention mechanism."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen75-slide76/text.txt": [
        {
            "question": "What is the next step after setting up setups together in the multi-encoder setup?",
            "reference-answers": [
                "...the source words or the multi-encoder setup."
            ]
        },
        {
            "question": "What is the next step in the multi-encoder setup after setting up setups together?",
            "reference-answers": [
                "...the multi-encoder setup."
            ]
        },
        {
            "question": "What is the next step after setting up the setups together?",
            "reference-answers": [
                "...the multi-encoder setup."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen76-slide77/text.txt": [
        {
            "question": "What is the type of combination described in the setup for using image information with an additional encoder, as mentioned in the context of multiple text inputs?",
            "reference-answers": [
                "The same type of combination that we had with multiple text inputs."
            ]
        },
        {
            "question": "What is the type of combination described in the text as being used to produce output words from a source image?",
            "reference-answers": [
                "A decoder that produces the output words."
            ]
        },
        {
            "question": "What type of combination is used to produce output words from the source image, which is similar to the combination used with multiple text inputs in a previous lecture?",
            "reference-answers": [
                "A decoder that produces the output words."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen77-slide78/text.txt": [
        {
            "question": "What is the name of the particular setup that Inrich Ljubovitsky and Helsel combined to combine attention over the source text and attention over the image in multiple ways?",
            "reference-answers": [
                "Hierarchical attention."
            ]
        },
        {
            "question": "What is the name of the attention setup used by Inrich Ljubovitsky and Helsel that combined attention over the source text and attention over the image in multiple ways?",
            "reference-answers": [
                "The hierarchical attention."
            ]
        },
        {
            "question": "What is the name of the attention mechanism used by Inrich Ljubovitsky and Helsel in their setup?",
            "reference-answers": [
                "Hierarchical attention."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen78-slide79/text.txt": [
        {
            "question": "What is the objective of the encoder in a visually supported translation run?",
            "reference-answers": [
                "The encoder is trained to produce the target text and produce the target image representation, essentially thinking what the image could be."
            ]
        },
        {
            "question": "What is one of the successful attention approaches used in visually supported translation runs, according to the survey by Sulubacak?",
            "reference-answers": [
                "Hierarchical attention."
            ]
        },
        {
            "question": "What type of attention mechanism is considered one of the best approaches in visually supported translation runs, according to the survey by Sulubacak?",
            "reference-answers": [
                "Hierarchical attention."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen79-slide80/text.txt": [
        {
            "question": "What is the result of using a hierarchical attention approach in a multimodal system when the image is non-matching with the input text?",
            "reference-answers": [
                "The hierarchical attention approach got a worse performance when the image was non-matching with the input text."
            ]
        },
        {
            "question": "What type of model was sensitive to the image information in Desmond Elliott's experiment?",
            "reference-answers": [
                "The hierarchical attention approach was sensitive to the image information in Desmond Elliott's experiment."
            ]
        },
        {
            "question": "What type of models were sensitive to the images provided in Desmond Elliott's experiment?",
            "reference-answers": [
                "The hierarchical attention approach was sensitive to the images provided in Desmond Elliott's experiment."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen80-slide81/text.txt": [
        {
            "question": "What is mentioned in the text as well as the last part of the message?",
            "reference-answers": [
                "That's mentioned there as well. So this last part of the message."
            ]
        },
        {
            "question": "What is mentioned in the last part of the provided text?",
            "reference-answers": [
                "That's mentioned there as well. So this last... exam."
            ]
        },
        {
            "question": "What is the subject of the previous mention that is also mentioned in the last part of the text?",
            "reference-answers": [
                "That's mentioned there as well. So this last... exam."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen81-slide80/text.txt": [
        {
            "question": "What is the main argument presented by the paper from Ozan Raglan regarding the methods used?",
            "reference-answers": [
                "The main argument presented by the paper from Ozan Raglan is that the problem lies not with the methods, but with the data set, which does not require visual information to function."
            ]
        },
        {
            "question": "What is the main claim made by the paper from Ozan Raglan regarding the issue being studied?",
            "reference-answers": [
                "The main claim made by the paper from Ozan Raglan is that the issue being studied is not a problem with the methods, but rather a problem with the data set."
            ]
        },
        {
            "question": "What is the main argument presented in the paper from Ozan Raglan?",
            "reference-answers": [
                "The main argument presented in the paper from Ozan Raglan is that the problem lies not with the methods, but with the data set, which does not require visual information to function."
            ]
        }
    ],
    "nmt-class/lecture11-multimodal-mt/screen82-slide81/text.txt": [
        {
            "question": "What was the outcome of the NMT system when given the degraded input from Desmond's Elliot experiment?",
            "reference-answers": [
                "produced a buoy."
            ]
        },
        {
            "question": "What was the outcome when the NMT system was trained on text-only information, compared to the multimodal system that was trained on both text and visual information?",
            "reference-answers": [
                "The NMT system produced a \"buoy\", guessed that the person was a boy, and the color was blue instead of white."
            ]
        },
        {
            "question": "What type of difference was observed between systems trained on text only information and systems trained on text and visual information in Desmond's Elliot experiment?",
            "reference-answers": [
                "A difference was observed in the translation accuracy, specifically in the NMT setup, where the system guessed a boy and a blue color, whereas the multimodal system correctly produced a girl and the correct white color."
            ]
        }
    ],
    "popular/audio-09/text.en.txt": [
        {
            "question": "What is the approximate amount of EU funding that has been channelled into the Teppler Monastery in western Bohemia?",
            "reference-answers": [
                "Almost 500 million Czech crowns, which is equivalent to around 20 million euros."
            ]
        },
        {
            "question": "What is the name of the monastery in western Bohemia that has received significant funding from the EU to restore it and is now home to a handful of monks and an academy?",
            "reference-answers": [
                "The Teppler Monastery."
            ]
        },
        {
            "question": "What is the approximate number of euros that have been channelled into the Teppler Monastery from EU funds?",
            "reference-answers": [
                "Around 20 million euros."
            ]
        }
    ],
    "popular/audio-10/text.en.txt": [
        {
            "question": "What is the difference in GDP per capita between the Czech Republic and Slovakia in 2015, according to the speaker?",
            "reference-answers": [
                "The difference in GDP per capita between the Czech Republic and Slovakia decreased from 21% to 7% in 2015, a reduction of 14% in seven years."
            ]
        },
        {
            "question": "What is the main argument presented by Erik Nielsen regarding the introduction of the euro in the Czech Republic?",
            "reference-answers": [
                "Erik Nielsen presents the main argument that the introduction of the euro in the Czech Republic has led to positive economic development, citing the example of Slovakia, where economic growth was higher than in the Czech Republic despite being part of the eurozone, and that the differences between the two countries have decreased."
            ]
        },
        {
            "question": "What is the GDP per capita of the Czech Republic compared to Slovakia in 2015, according to the provided text?",
            "reference-answers": [
                "The difference in GDP per capita between the Czech Republic and Slovakia has decreased from 21% to 7% in 2015, a reduction of 14% in seven years."
            ]
        }
    ],
    "popular/audio-12/text.en.txt": [
        {
            "question": "What is the title of the dissertation that Marjina Dlabayowa wrote at university, according to her statement?",
            "reference-answers": [
                "Home to Europe."
            ]
        },
        {
            "question": "What are two big chapters that weigh Marjina Dlabayowa down and should not be repeated in the next 15 years, according to her perspective as a Member of the European Parliament?",
            "reference-answers": [
                "The freedom of establishment and the protection of markets from other countries are two big chapters that weigh Marjina Dlabayowa down and should not be repeated in the next 15 years, according to her perspective as a Member of the European Parliament."
            ]
        },
        {
            "question": "What were the two big chapters that weigh heavily on the EU Member of Parliament Marjina Dlabayowa, and why do they weigh on her?",
            "reference-answers": [
                "The two big chapters that weigh heavily on the EU Member of Parliament Marjina Dlabayowa are the freedom of establishment and communication. The freedom of establishment weighs on her because she believes that countries that are leaving the EU are forgetting the principles of the EU, such as freedom and openness, and are instead limiting it. The communication chapter weighs on her because she believes that there are barriers in the internal market that are too high and that the EU should avoid multiplying these barriers, and also because she thinks that the EU should focus on effective use of funds."
            ]
        }
    ],
    "popular/audio-19/text.en.txt": [
        {
            "question": "How many people in Germany are affected by poor burials at the end of their lives every year?",
            "reference-answers": [
                "Around 10,000 people."
            ]
        },
        {
            "question": "How many people are affected by poor burials in Germany at the end of their lives every year?",
            "reference-answers": [
                "Around 10,000 people."
            ]
        },
        {
            "question": "How many people in Germany are affected by poor burials every year, according to Harald Storz, pastor of a Göttingen city centre church and Tobias brother?",
            "reference-answers": [
                "Around 10,000 people are affected by poor burials in Germany every year."
            ]
        }
    ],
    "popular/audio-24/text.en.txt": [
        {
            "question": "When did the Max Planck Society set up a working group to research its own past, according to Rüdiger vom Bruch?",
            "reference-answers": [
                "In 1997, the Max Planck Society was one of the first institutions to set up a working group to research its own past."
            ]
        },
        {
            "question": "What was the name of the project launched by the Charité in 2013 to commemorate its Jewish employees?",
            "reference-answers": [
                "Gedenkort Charité - Wissenschaft in Verantwortung."
            ]
        },
        {
            "question": "What was the main reason why German universities began to come to terms with their dark past of involvement in Nazi crimes in the late 1990s?",
            "reference-answers": [
                "Public attacks had become so strong that people thought it would be better if they didn't commission a neutral or unbiased investigation by specialised historians themselves."
            ]
        }
    ],
    "popular/video-02/text.en.txt": [
        {
            "question": "What is the main difference between the traditional understanding of addiction and the alternative theory proposed by Bruce Alexander based on his rat park experiment?",
            "reference-answers": [
                "The main difference between the traditional understanding of addiction and the alternative theory proposed by Bruce Alexander based on his rat park experiment is that the traditional understanding focuses solely on the chemicals in the substance causing addiction, whereas the alternative theory suggests that the environment and social factors, including the presence of close relationships and emotional connections, play a significant role in the development and maintenance of addiction."
            ]
        },
        {
            "question": "What is the main difference in the way rats behave in a cage with two bottles of water, one laced with heroin or cocaine, and one with tap water, according to Professor Bruce Alexander's experiment?",
            "reference-answers": [
                "In Professor Bruce Alexander's experiment, the rats are put into cages one by one, and they have nothing but the drugs, whereas in the original experiment, many rats developed an addiction to the drug water and drank it excessively until they killed themselves."
            ]
        },
        {
            "question": "What is the main argument of the author regarding the nature of heroin addiction?",
            "reference-answers": [
                "The author argues that the traditional understanding of addiction as a solely chemical issue is incorrect, and that social and environmental factors, such as isolation and lack of close relationships, play a significant role in the development of addiction."
            ]
        }
    ],
    "popular/video-04/text.en.txt": [
        {
            "question": "What is the difference in functionality between a surgical mask, a medical face mask (SMS), and an FFP mask, and how do these differences affect the protection they offer against airborne particles?",
            "reference-answers": [
                "The main difference in functionality between a surgical mask, a medical face mask (SMS), and an FFP mask is the number of layers of meltblown fleece used in each type of mask. FFP masks have the most layers, typically 5 or 7, which makes them the most protective against airborne particles. Surgical masks, on the other hand, have fewer layers, typically 1 or 2, and are mainly designed to catch droplets or splashes. Medical face masks (SMS) have a combination of meltblown fleece and spunbond, with the spunbond providing additional protection. The number of layers in each mask"
            ]
        },
        {
            "question": "What is the difference in the way air is blown out when wearing a surgical mask compared to a homemade mask, as observed using the Schlieren mirror?",
            "reference-answers": [
                "When wearing a surgical mask, the airflow is blown out to the right and left, and when coughing, this can be seen even more clearly. In contrast, when wearing a homemade mask, the airflow is also blown out to the right and left, but it moves even less forwards."
            ]
        },
        {
            "question": "What is the difference between an FFP-1 mask, an FFP-2 mask, and an FFP-3 mask in terms of the number of particles that can pass through them?",
            "reference-answers": [
                "An FFP-1 mask allows more than 20 particles in 100 to pass through, an FFP-2 mask allows 6 particles in 100 to pass through, and an FFP-3 mask only allows 1 particle in 100 to pass through."
            ]
        }
    ],
    "popular/video-06/text.en.txt": [
        {
            "question": "What is the significance of Sarajevo being designated as the European Capital of Culture 2014, according to the speaker?",
            "reference-answers": [
                "Sarajevo being designated as the European Capital of Culture 2014 would send an important signal in favour of the multi-ethnic character of the city and the state of Bosnia-Herzegovina, and could prompt the country's political class to rethink its position."
            ]
        },
        {
            "question": "What is the significance of designating Sarajevo as the European Capital of Culture in 2014, according to the speaker?",
            "reference-answers": [
                "Designating Sarajevo as the European Capital of Culture in 2014 would send an important signal in favour of the multi-ethnic character of the city and the state of Bosnia-Herzegovina, and could prompt the country's political class to rethink its position."
            ]
        },
        {
            "question": "What is the significance of Sarajevo being designated as the European Capital of Culture 2014?",
            "reference-answers": [
                "Sarajevo being designated as the European Capital of Culture 2014 would send an important signal in favour of the multi-ethnic character of the city and the state of Bosnia-Herzegovina, and could prompt the country's political class to rethink its position, as well as demonstrate its immense intercultural potential."
            ]
        }
    ],
    "popular/video-07/text.en.txt": [
        {
            "question": "What is the European Commission's proposed solution to the issue of couples divorcing in different EU countries, as stated by the speaker?",
            "reference-answers": [
                "The European Commission proposes to increase the choice of options if both parties in the couple agree on the law under which they want to divorce, with a reference point to their lives, place of residence, place of marriage, or other reference points, and also wants to prevent forum shopping and ensure that both partners are well informed about the consequences of the choice of law."
            ]
        },
        {
            "question": "What is the main issue that the European Commission has tackled, according to the speaker, and what is the speaker's stance on harmonizing the law on this issue?",
            "reference-answers": [
                "The main issue that the European Commission has tackled is the problem of couples being unable to find a competent judge or law after a divorce, and the speaker's stance is that they are not harmonizing the law on this issue, but rather ensuring transparency and providing citizens with an answer to their problems."
            ]
        },
        {
            "question": "What is the European Commission's proposed solution to the issue of divorce laws in the European Union, as presented by the European Commission?",
            "reference-answers": [
                "The European Commission proposes to increase the choice of options if both parties in the couple agree on the law under which they want to divorce, with a reference point to their lives, place of residence, place of marriage, or other reference points, and also wants to ensure that both partners are well informed about the consequences, both social and legal, of the choice of law."
            ]
        }
    ],
    "popular/video-08/text.en.txt": [
        {
            "question": "What is the proposed solution to address the risks associated with deep-sea drilling in European waters, according to the speaker?",
            "reference-answers": [
                "We agreed with you in our resolution that it would be appropriate to declare a moratorium at least on new applications for deep-sea drilling until we have a complete overview of what is needed and how the deficits and gaps can be closed."
            ]
        },
        {
            "question": "What is the proposed solution for addressing the risks associated with deep-sea drilling in European waters, according to the EU Commissioner?",
            "reference-answers": [
                "We agreed with you in our resolution that it would be appropriate to declare a moratorium at least on new applications for deep-sea drilling until we have a complete overview of what is needed and how the deficits and gaps can be closed."
            ]
        },
        {
            "question": "What is the proposed solution to the environmental disaster in the European Union, according to the Commissioner mentioned in the text?",
            "reference-answers": [
                "We propose a moratorium on new applications for deep-sea drilling until we have a complete overview of what is needed and how the deficits and gaps can be closed."
            ]
        }
    ],
    "popular/video-13/text.en.txt": [
        {
            "question": "What is the origin of the concept of micro-apartments?",
            "reference-answers": [
                "The concept of micro-apartments originally comes from Asia."
            ]
        },
        {
            "question": "What is the origin of the concept of micro-apartments?",
            "reference-answers": [
                "The concept of micro-apartments originally comes from Asia."
            ]
        },
        {
            "question": "What is the typical price range for a micro-apartment in Europe?",
            "reference-answers": [
                "100 to 200 euros."
            ]
        }
    ],
    "popular/video-14/text.en.txt": [
        {
            "question": "What is the name of the research laboratory where Google is working on its self-driving car project?",
            "reference-answers": [
                "Google X."
            ]
        },
        {
            "question": "What is the name of the research laboratory where Google is working on the self-driving car project?",
            "reference-answers": [
                "Google X."
            ]
        },
        {
            "question": "What is the name of the research laboratory at Google where the self-driving car project is being developed?",
            "reference-answers": [
                "Google X."
            ]
        }
    ],
    "popular/video-15/text.en.txt": [
        {
            "question": "What is the name of the Abrogans manuscript, and in what year is it believed to have been written?",
            "reference-answers": [
                "The Abrogans manuscript is called the Abrogans, and it is believed to have been written around the year 770."
            ]
        },
        {
            "question": "What is the name of the book that the fragments found in Admont are an extremely early version of?",
            "reference-answers": [
                "The Abrogans."
            ]
        },
        {
            "question": "What is the name of the Abrogans manuscript, and approximately how many years old is it?",
            "reference-answers": [
                "The Abrogans manuscript is called the Abrogans, and it is more than 1200 years old."
            ]
        }
    ],
    "popular/video-23/text.en.txt": [
        {
            "question": "What types of toys did German children play with in 1946, and how were they often made?",
            "reference-answers": [
                "German children played with homemade toys made from various materials such as sticks, scraps of wood, fabric, cigar boxes, and other available objects. These toys were often created by fathers, uncles, or skilled individuals using tools like fretsaws or carved by hand. Children also collected and played with objects they found in their environment, such as wood, stones, and other rubble from the war-torn area."
            ]
        },
        {
            "question": "What games did children play in Cologne during the war, and how did their circumstances influence the types of games they played?",
            "reference-answers": [
                "In Cologne during the war, children played games such as collecting wood, coal claw, and haul stones, as they had to worry about basic necessities like warmth and food. They also played with homemade toys made from scraps, like a sheep, duck, and farm animals. The rubble and ruins of the city were also a playground, where children would dig for treasures like grenades, crates, and other scrap metal. The games they played were shaped by their circumstances, with the children having an advantage in stealing coal, and the scarcity of toys leading to creativity and resourcefulness in making their own games and toys."
            ]
        },
        {
            "question": "What types of toys were children in post-war Germany most likely to have, given the scarcity of traditional toys and the need to create their own entertainment?",
            "reference-answers": [
                "Homemade toys made from scraps, such as sticks, wood, scraps of fabric, cigar boxes, sticky tape, and other materials found in the rubble, were the most common type of toys."
            ]
        }
    ],
    "ukr-biology/book02/topic01-Обмін речовин та перетворення енергії в організмі людини/text.en.txt": [
        {
            "question": "What is the main difference between assimilation and dissimilation in the human body, and what are the primary goals of these two processes?",
            "reference-answers": [
                "Assimilation and dissimilation are two processes in the human body that differ in their primary goals. Assimilation is a process that results in the formation of organic compounds necessary for the vital activity of cells, and it involves the body spending energy. The primary goal of assimilation is to obtain energy and build the body.\n\nDissimilation, on the other hand, is a process that results in the breakdown of organic compounds into simpler substances, and it involves the accumulation of energy. The primary goal of dissimilation is to conserve energy."
            ]
        },
        {
            "question": "What are the two main processes that occur in the human body: assimilation and dissimilation, and what are their main differences?",
            "reference-answers": [
                "The two main processes that occur in the human body are assimilation and dissimilation. The main differences between them are that assimilation results in the breakdown of organic compounds into simpler substances, and dissimilation results in the breakdown of organic compounds into simpler substances, but the human body accumulates energy during this process."
            ]
        },
        {
            "question": "What is the main difference between assimilation and dissimilation in the human body?",
            "reference-answers": [
                "The main difference between assimilation and dissimilation in the human body is that assimilation results in the formation of organic compounds necessary for the vital activity of cells, spending energy, whereas dissimilation results in the breakdown of organic compounds into simpler substances, accumulating energy."
            ]
        }
    ],
    "ukr-biology/book02/topic02-Травлення/text.en.txt": [
        {
            "question": "What is the main function of the digestive system in the human body, and where does the absorption of digestive products occur?",
            "reference-answers": [
                "The main function of the digestive system in the human body is to digest food and provide the body with necessary substances. The absorption of digestive products occurs in the small intestine, where the process of splitting substances is completed and the absorption of the splitting products takes place."
            ]
        },
        {
            "question": "What is the name of the disease that was first described as a consequence of eating blood sausages in the 18th century?",
            "reference-answers": [
                "Botulism."
            ]
        },
        {
            "question": "What is the main function of the digestive system, and how does it differ from the nervous and humoral systems of the human body in regulating its work?",
            "reference-answers": [
                "The main function of the digestive system is to ensure the process of digestion and provide the body with necessary substances. This function differs from the nervous and humoral systems of the human body in that it involves reactions involving enzymes and the absorption of digestive products, whereas the nervous and humoral systems regulate the digestive system by sending nerve impulses and biologically active substances, respectively."
            ]
        }
    ],
    "ukr-biology/book02/topic03-Дихання/text.en.txt": [
        {
            "question": "What is the main function of the vocal cords in the formation of the voice, and how do they contribute to the production of sounds?",
            "reference-answers": [
                "The vocal cords of the larynx play the main role in the formation of the voice, and they contribute to the production of sounds when exhaled air passes through the glottis, causing the tense ligaments to vibrate, and the pitch of the voice increases with an increase in the frequency of the vibrations of the vocal cords."
            ]
        },
        {
            "question": "What is the primary function of the vocal cords in the formation of the voice?",
            "reference-answers": [
                "The vocal cords consist of elastic fibers and are stretched across the larynx parallel to each other, between them is the glottis. The tension of the vocal cords is regulated by the muscles attached to them. The voice is produced when exhaled air passes through the glottis, which causes the tense ligaments to vibrate."
            ]
        },
        {
            "question": "What is the main role played by the vocal cords of the larynx in the formation of the voice?",
            "reference-answers": [
                "The main role in the formation of the voice is played by the vocal cords of the larynx, which vibrate when exhaled air passes through the glottis, producing sound."
            ]
        }
    ],
    "ukr-biology/book02/topic04-Транспорт речовин/text.en.txt": [
        {
            "question": "What is the primary function of the nephron in the process of urine formation?",
            "reference-answers": [
                "The primary function of the nephron in the process of urine formation is filtration of blood plasma, resulting in the formation of primary urine."
            ]
        },
        {
            "question": "What are the main functions of the excretory system, and what processes occur in the kidneys to form primary and secondary urine?",
            "reference-answers": [
                "The main functions of the excretory system are to remove waste products and excess substances from the body, regulate the amount of water in the body, and maintain the body's acid-base balance. In the kidneys, primary urine is formed through the process of filtration, where blood plasma is filtered into the capsule cavity, resulting in primary urine. This urine is then converted into secondary urine through reabsorption and secretion processes in the convoluted tubule."
            ]
        },
        {
            "question": "What is the main role of the skin in the processes of thermoregulation of the body?",
            "reference-answers": [
                "The skin plays the main role in the processes of thermoregulation of the body, as it facilitates heat loss and helps to regulate body temperature through the amount of blood flowing through the skin capillaries, and also through sweat evaporation."
            ]
        }
    ],
    "ukr-biology/book02/topic05-Опора та рух/text.en.txt": [
        {
            "question": "What is the approximate efficiency of the work of an individual muscle cell compared to the efficiency of human muscles as a whole?",
            "reference-answers": [
                "Approximately 50%"
            ]
        },
        {
            "question": "What are the physical qualities of muscles that can be evaluated to compare the efficiency of the work of different muscles?",
            "reference-answers": [
                "Physical properties of muscles, such as muscle strength, speed of contraction, endurance and tone, are the characteristics by which this work can be evaluated."
            ]
        },
        {
            "question": "What are the two main types of muscle work, and how do they differ in terms of the role of static and dynamic contractions in performing physical tasks?",
            "reference-answers": [
                "The two main types of muscle work are static and dynamic. Static work is performed when muscles tense but do not contract, and is characterized by a lack of movement. Dynamic work, on the other hand, involves muscles alternately contracting and stretching, resulting in movement."
            ]
        }
    ],
    "ukr-biology/book02/topic06-Зв’язок організму людини із зовнішнім середовищем. Нервова система/text.en.txt": [
        {
            "question": "What is the main function of the autonomic nervous system in the human body?",
            "reference-answers": [
                "The autonomic nervous system regulates the activity of internal organs, glands, blood vessels, smooth and some striated muscles, and also controls metabolic processes."
            ]
        },
        {
            "question": "What are the main departments of the brain, and what functions do they perform?",
            "reference-answers": [
                "The main departments of the brain are the terminal, midbrain, diencephalon, cerebellum, and medulla oblongata. The functions of these departments are as follows:\n\n- The terminal brain is the highest department of the central nervous system, controlling the activities of other departments of the brain and the spinal cord, and providing complex forms of behavior.\n- The midbrain combines the medulla oblongata and the diencephalon and participates in the regulation of movements and posture, muscle tone, states of wakefulness and sleep, the emergence of emotions.\n- The diencephalon includes the hypothalamus and regulates"
            ]
        },
        {
            "question": "What is the main function of the autonomic nervous system in relation to the regulation of the body's internal organs and tissues?",
            "reference-answers": [
                "The autonomic nervous system regulates the activity of internal organs, glands, blood vessels, smooth and some striated muscles, and also controls metabolic processes."
            ]
        }
    ],
    "ukr-biology/book02/topic07-Зв’язок організму людини із зовнішнім середовищем. Сенсорні системи/text.en.txt": [
        {
            "question": "What is the primary function of the auditory ossicles in the middle ear, and how do they transmit sound vibrations to the inner ear?",
            "reference-answers": [
                "The auditory ossicles in the middle ear transmit sound vibrations to the inner ear by transmitting these vibrations to the oval window of the inner ear."
            ]
        },
        {
            "question": "What are the three main parts of the human auditory sensory system that work together to perceive sound vibrations and maintain balance?",
            "reference-answers": [
                "The outer, middle and inner ear."
            ]
        },
        {
            "question": "What is the function of the vestibular apparatus in the human body, and how does it relate to the perception of sounds and the regulation of body position in space?",
            "reference-answers": [
                "The vestibular apparatus in the human body performs a dual role: perception of sounds (cochlea with the spiral organ) and regulation of the body's position in space, maintaining balance."
            ]
        }
    ],
    "ukr-biology/book02/topic08-Вища нервова діяльність/text.en.txt": [
        {
            "question": "What is the primary function of the right hemisphere of the brain, and how does it differ from the function of the left hemisphere?",
            "reference-answers": [
                "The primary function of the right hemisphere of the brain is the perception of music, emotional attitude to perceived and perceived objects, and providing orientation in space. It differs from the function of the left hemisphere, which predominantly operates with symbolic information (words, symbols, numbers, etc.), reading, and counting."
            ]
        },
        {
            "question": "What is the primary function of the left hemisphere of the human brain, according to the provided text?",
            "reference-answers": [
                "The primary function of the left hemisphere is reading and counting, predominantly operating with symbolic information (words, symbols, numbers, etc.)."
            ]
        },
        {
            "question": "What is the primary function of the right hemisphere of the human brain, according to the provided text?",
            "reference-answers": [
                "The right hemisphere operates with figurative information, provides orientation in space, perception of music, emotional attitude to perceived and perceived objects."
            ]
        }
    ],
    "ukr-biology/book02/topic09-Регуляція функцій організму/text.en.txt": [
        {
            "question": "What is the difference between natural and artificial immunity, and how are they acquired?",
            "reference-answers": [
                "Natural immunity occurs without the active participation of a person, and artificial immunity is the result of the work of doctors. In both cases, active and passive immunity can be distinguished. Natural passive immunity occurs during the transfer of formed antibodies from one person to another, providing short-term protection against infection. Artificial passive immunity is created artificially, by injecting ready-made antibodies from one person to another, also providing short-term protection against infection. Natural active immunity occurs as a result of a previous disease, providing protection against infection for a long time. Artificial active immunity is created artificially by introducing small amounts of antigens into the body in the form of a vaccine,"
            ]
        },
        {
            "question": "What are the three stages of stress and how do they affect the body's ability to resist external influences?",
            "reference-answers": [
                "The three stages of stress are the stage of anxiety, the stage of resistance, and the stage of exhaustion. \n\nIn the stage of anxiety, the body feels threatened and begins to look for ways out of the situation. The body's ability to resist external influences initially decreases, but then increases. \n\nIn the stage of resistance, the body's ability to resist external influences increases due to the mobilization of the body's resources. This stage is the most successful for overcoming a crisis. \n\nIn the stage of exhaustion, the body's ability to resist external influences decreases due to a lack of resources."
            ]
        },
        {
            "question": "What is the main function of the stress response in the human body, and how does it relate to the disruption of homeostasis?",
            "reference-answers": [
                "The main function of the stress response in the human body is the adaptation of the body to changed conditions, its adaptation to a specific situation. This occurs when factors that disrupt homeostasis act on the body, and the stress response is a non-specific neurohumoral response of the body."
            ]
        }
    ],
    "ukr-biology/book02/topic10-Розмноження та розвиток людини/text.en.txt": [
        {
            "question": "What is the primary function of the endocrine system in the human body, as described in the provided text?",
            "reference-answers": [
                "The endocrine system provides control processes using biologically active molecules - hormones."
            ]
        },
        {
            "question": "What is the primary function of the circulatory system in the human body, according to the provided text?",
            "reference-answers": [
                "The circulatory system is a carrier of the body's material resources - nutrients, oxygen, metabolic products, and it performs a regulatory function."
            ]
        },
        {
            "question": "What is the main difference between the postembryonic period of human development and the embryonic period?",
            "reference-answers": [
                "The main difference between the postembryonic period of human development and the embryonic period is that the postembryonic period refers to the period of human life after birth, whereas the embryonic period lasts from the moment of formation of the zygote to the birth of the child."
            ]
        }
    ],
    "ukr-biology/book03/topic01-Хімічний склад клітинита біологічні молекули/text.en.txt": [
        {
            "question": "What is the main function of nucleic acids in living organisms, and how do they differ from each other in terms of composition and structural features?",
            "reference-answers": [
                "The main function of nucleic acids in living organisms is to store and reproduce genetic information. They differ from each other in terms of composition and structural features. DNA nucleotides consist of the monosaccharide deoxyribose and four nitrogenous bases - adenine, thymine, cytosine, and guanine. RNA nucleotides contain ribose instead of deoxyribose, and uracil instead of thymine. An RNA molecule usually consists of one chain of nucleotides, different fragments of which form hydrogen bonds with each other."
            ]
        },
        {
            "question": "What is the main function of nucleic acids, and how do they store and reproduce hereditary information?",
            "reference-answers": [
                "The main function of nucleic acids is to store and reproduce hereditary information. They store and reproduce it by forming a chain in which the nucleotides are arranged sequentially one after another. The structure of DNA contributes to the preservation and reproduction of information, and it consists of two chains of nucleotides connected by hydrogen bonds, while RNA consists of one chain of nucleotides with hydrogen bonds between guanine and cytosine, and between adenine and thymine or adenine and uracil."
            ]
        },
        {
            "question": "What is the main function of nucleic acids in living organisms, and how do they store and reproduce hereditary information?",
            "reference-answers": [
                "The main function of nucleic acids is to store and reproduce hereditary information. They store and reproduce hereditary information by forming a strong covalent bond between the orthophosphate acid residue of one nucleotide and the monosaccharide of another, resulting in a chain of nucleotides that can reach several million in number. This chain, known as a nucleic acid molecule, consists of nucleotides that contain nitrogenous bases, monosaccharides, and orthophosphate acid residues. The structure of DNA contributes to the preservation and reproduction of information, and the principle of complementarity (complementation) ensures that"
            ]
        }
    ],
    "ukr-biology/book03/topic02-Структура клітини/text.en.txt": [
        {
            "question": "What is the difference in the structure of prokaryotic and eukaryotic cells, specifically regarding the presence or absence of membrane organelles?",
            "reference-answers": [
                "Prokaryotic cells do not have membrane organelles, whereas eukaryotic cells have both single-membrane and double-membrane organelles."
            ]
        },
        {
            "question": "What is the primary function of the cytoskeleton in eukaryotic cells, and how does it differ from the cytoskeleton in prokaryotic cells?",
            "reference-answers": [
                "The cytoskeleton in eukaryotic cells has a more complex structure than in prokaryotic cells. The primary function of the cytoskeleton in eukaryotic cells is not explicitly stated, but it is mentioned that the complex internal structure of the cell, the presence of the cytoskeleton, nucleus, and membrane organelles allows eukaryotic cells to reach much larger sizes and form stable cell complexes, enabling true multicellularity and the appearance of large organisms - animals, plants and fungi."
            ]
        },
        {
            "question": "What is the main difference between prokaryotic and eukaryotic cells in terms of the presence or absence of certain organelles in their structure?",
            "reference-answers": [
                "The main difference between prokaryotic and eukaryotic cells is the presence or absence of certain organelles in their structure. Prokaryotic cells do not have membrane organelles, whereas eukaryotic cells have both single-membrane and double-membrane organelles."
            ]
        }
    ],
    "ukr-biology/book03/topic03-Принципи функціонування клітини/text.en.txt": [
        {
            "question": "What is the main difference between autotrophs and heterotrophs in terms of the source of energy and carbon atoms for their metabolic processes?",
            "reference-answers": [
                "Autotrophs obtain carbon from inorganic substances (carbon dioxide) due to the energy of sunlight, while heterotrophs obtain carbon from organic substances of other living organisms due to the oxidation of part of these substances."
            ]
        },
        {
            "question": "What is the role of chemosynthesis in the cycle of elements such as Nitrogen, Sulfur, and Ferrum, and how does it contribute to the existence of living organisms on Earth?",
            "reference-answers": [
                "Chemosynthesis plays a very important role in the cycle of elements such as Nitrogen, Sulfur, and Ferrum. It produces organic substances where photosynthesis is impossible. Thus, deep at the bottom of the oceans there are real \"oases of life\" around the \"black piles\". Sulfur bacteria use these compounds for their growth. And other living organisms feed on them."
            ]
        },
        {
            "question": "What is the main difference between autotrophic and heterotrophic organisms in terms of the sources from which they obtain energy and carbon atoms for their metabolic processes?",
            "reference-answers": [
                "Autotrophs obtain energy and carbon atoms from inorganic substances, such as carbon dioxide, due to the energy of sunlight, whereas heterotrophs obtain energy and carbon atoms from organic substances of other living organisms due to the oxidation of part of these substances."
            ]
        }
    ],
    "ukr-biology/book03/topic04-Збереження та реалізаціяспадкової інформації/text.en.txt": [
        {
            "question": "What is the difference between mitotic and meiotic division in terms of the number of chromosomes received by the daughter cells?",
            "reference-answers": [
                "In mitotic division, the daughter cells receive the same number of chromosomes as the mother cell. In meiotic division, the daughter cells receive half the number of chromosomes and half the genetic material that the mother cell had."
            ]
        },
        {
            "question": "What is the primary difference between mitotic division and meiotic division in eukaryotic cells?",
            "reference-answers": [
                "The primary difference between mitotic division and meiotic division in eukaryotic cells is that meiosis results in the formation of sex cells (gametes) containing half the number of chromosomes, whereas mitosis results in the formation of daughter cells with the same number of chromosomes as the parent cell."
            ]
        },
        {
            "question": "What is the main difference between mitotic division and meiotic division, and how do these differences affect the number of chromosomes in the resulting cells?",
            "reference-answers": [
                "The main difference between mitotic division and meiotic division is the number of chromosomes in the resulting cells. In mitotic division, two daughter cells are formed from one mother cell, each receiving the same number of chromosomes as the mother cell. In meiotic division, two cell divisions occur, resulting in four daughter cells, each receiving half the number of chromosomes as the mother cell."
            ]
        }
    ],
    "ukr-biology/book03/topic05-Закономірності успадкування ознак/text.en.txt": [
        {
            "question": "What is the difference between somatic mutations and generative mutations in terms of their transmission to descendants?",
            "reference-answers": [
                "If somatic mutations occur in somatic cells, they can be transmitted to descendants only under the condition of vegetative reproduction. If they occur in gametes (sperm or egg cells), then they can be transmitted to descendants during normal sexual reproduction."
            ]
        },
        {
            "question": "What are the main differences between somatic mutations and generative mutations in the context of hereditary diseases?",
            "reference-answers": [
                "Somatic mutations can be transmitted to descendants only under the condition of vegetative reproduction, whereas generative mutations can be transmitted to descendants during normal sexual reproduction."
            ]
        },
        {
            "question": "What types of mutations can occur at the genome level, and what are some examples of genomic mutations?",
            "reference-answers": [
                "Genomic mutations include polyploidy and heteroploidy (aneuploidy ¬. Polyploidy is an increase in the number of chromosomes by adding entire chromosome sets as a result of a violation of meiosis. Heteroploidy is a change in the number of chromosomes that is not a multiple of the haploid set. The phenomenon when any of the chromosomes in the genotype has not two, but three homologous chromosomes is called trisomy. The loss of one of the homologous chromosomes also occurs - monosomy."
            ]
        }
    ],
    "ukr-biology/book03/topic06-Еволюція органічного світу/text.en.txt": [
        {
            "question": "What is the approximate time period when the ancestors of modern humans diverged from the ancestors of chimpanzees?",
            "reference-answers": [
                "8-5 million years ago."
            ]
        },
        {
            "question": "What is the approximate time period when the genus Homo was formed, and what was its first representative?",
            "reference-answers": [
                "The genus Homo was formed approximately 2.4 million years ago in Africa, and its first representative was Homo habilis."
            ]
        },
        {
            "question": "What is the approximate time period when the genus Homo was formed, and what was the first tool made by its early representatives?",
            "reference-answers": [
                "The approximate time period when the genus Homo was formed is 2.4 million years ago, and its early representatives made the first stone tools, with Homo habilis being the first to make stone tools."
            ]
        }
    ],
    "ukr-biology/book03/topic07-Біорізноманіття/text.en.txt": [
        {
            "question": "What is the main difference in the systematic categories of the Plant kingdom and the Animal kingdom, and what are the higher taxonomic categories for each?",
            "reference-answers": [
                "The main difference in the systematic categories of the Plant kingdom and the Animal kingdom is the inclusion of the \"Division\" category in the Plant kingdom, which is not present in the Animal kingdom. The higher taxonomic categories for the Plant kingdom are:\n\nSpecies → Genus → Family → Order → Class → Division → Kingdom of Plants\n\nThe higher taxonomic categories for the Animal kingdom are:\n\nSpecies → Genus → Family → Order → Class → Phylum → Kingdom of Animals"
            ]
        },
        {
            "question": "What is the main systematic category that Carl Linnaeus introduced into science, and what are its characteristics?",
            "reference-answers": [
                "The main systematic category that Carl Linnaeus introduced into science is the species. The species name consists of two Latin words, the first of which is the name of the genus, and the second is the specific epithet."
            ]
        },
        {
            "question": "What is the main systematic category that Carl Linnaeus introduced into science, which is the foundation of the biological systematics?",
            "reference-answers": [
                "The main systematic category that Carl Linnaeus introduced into science is the species, which consists of two Latin words: the name of the genus and the specific epithet."
            ]
        }
    ],
    "ukr-biology/book03/topic08-Надорганізмові біологічні системи/text.en.txt": [
        {
            "question": "What is the term used to describe the conditions in which a species of organisms is best adapted to live, and how does it relate to the stability of ecosystems?",
            "reference-answers": [
                "The term used to describe the conditions in which a species of organisms is best adapted to live is called the \"biological optimum for a certain species of organisms.\" This condition is characterized by the presence of factors that support the survival and reproduction of the species, and it is often the result of the species being adapted to its environment. The biological optimum for a species is closely related to the stability of ecosystems, as it allows the species to thrive and contribute to the overall health and balance of the ecosystem."
            ]
        },
        {
            "question": "What are the four components of the biosphere according to the given text?",
            "reference-answers": [
                "Living, biogenic, inert, and bioinert matter."
            ]
        },
        {
            "question": "What is the definition of biological optimum according to the text, and how does it relate to the stability of ecosystems?",
            "reference-answers": [
                "The biological optimum is the set of environmental conditions to which a certain species of organisms is best adapted. It is the state of conditions in which a species can survive and reproduce most successfully. The biological optimum is related to the stability of ecosystems because organisms try to avoid the influence of negative factors and live in conditions to which they are best adapted. This means that if a species lives in its biological optimum, it is more likely to be stable and resilient in the face of environmental changes."
            ]
        }
    ],
    "ukr-biology/book03/topic09-Біологія як основа біотехнологіїта медицини/text.en.txt": [
        {
            "question": "What is the main purpose of gene therapy, and how does it differ from classical selection in creating genetically modified organisms?",
            "reference-answers": [
                "The main purpose of gene therapy is the treatment of hereditary diseases. It involves replacing a defective gene in cells with a normal one. This process differs from classical selection in creating genetically modified organisms, as gene therapy specifically targets and corrects genetic defects, whereas classical selection involves selecting for desirable traits in a population, often resulting in significant genetic changes."
            ]
        },
        {
            "question": "What are the main directions of using cell engineering technologies in modern biotechnology?",
            "reference-answers": [
                "Industrial production of valuable biologically active substances of plant origin, Pharmacy, household chemicals, food industry, Use of tissue and cell cultures for rapid clonal micropropagation and plant health improvement, Obtaining hybridomas (by merging different cells, for example, a cancer cell and a lymphocyte into one cell), Cloning of animals and plants."
            ]
        },
        {
            "question": "What is the main purpose of gene therapy, according to the provided text?",
            "reference-answers": [
                "The main purpose of gene therapy is the treatment of hereditary diseases, specifically to replace a defective gene in cells with a normal one."
            ]
        }
    ],
    "ukr-biology/book04/topic01-Біорізноманіття/text.en.txt": [
        {
            "question": "What is the primary method of nutrition used by osmotrophs, such as fungi and fungus-like organisms, to obtain the substances they need from the environment?",
            "reference-answers": [
                "obtaining the substances they need from the environment, absorbing them with the surface of their body."
            ]
        },
        {
            "question": "What is the primary method of nutrition for osmotrophs, such as fungi and fungus-like organisms, and how does this method relate to their body structure?",
            "reference-answers": [
                "The primary method of nutrition for osmotrophs, such as fungi and fungus-like organisms, is absorption of substances with the surface of their body. This method is facilitated by the fact that their body has the shape of a mycelium, a giant branched structure consisting of individual filamentous processes called hyphae."
            ]
        },
        {
            "question": "What is the characteristic feature of the mycelium of fungi, which allows them to absorb organic substances from the external environment?",
            "reference-answers": [
                "The characteristic feature of the mycelium of fungi, which allows them to absorb organic substances from the external environment, is that their body has the shape of a mycelium, a giant branched structure, the individual filamentous processes of which are called hyphae."
            ]
        }
    ],
    "ukr-biology/book04/topic02-Обмін речовин і перетворення енергії/text.en.txt": [
        {
            "question": "What is the primary role of the kidneys in the elimination of toxic substances from the body, and how do other systems also participate in this process?",
            "reference-answers": [
                "The kidneys play the greatest role in the elimination of toxic substances and products formed from them, but other systems also take an active part in this process, including the intestines, lungs, and skin."
            ]
        },
        {
            "question": "What is the primary role of the kidneys in the elimination of toxic substances from the body?",
            "reference-answers": [
                "The kidneys play the greatest role in the elimination of toxic substances and products formed from them, and water-soluble toxic compounds from the blood enter the capsule and tubules of the nephrons through passive filtration or active transport."
            ]
        },
        {
            "question": "What systems of the human body carry out nervous and humoral regulation, and how do these systems influence each other?",
            "reference-answers": [
                "The autonomic nervous system, divided into sympathetic and parasympathetic, carries out nervous regulation, while the endocrine system, consisting of endocrine glands, carries out humoral regulation. The nervous and humoral systems influence each other, with the nervous system affecting the release of hormones and the action of hormones regulating the work of individual parts of the nervous system."
            ]
        }
    ],
    "ukr-biology/book04/topic03-Спадковість і мінливість/text.en.txt": [
        {
            "question": "What is the difference in the life expectancy and health problems between individuals with Down syndrome and those with Patau and Edwards syndromes?",
            "reference-answers": [
                "Individuals with Down syndrome live longer, but they have health problems. People with Patau and Edwards syndromes have significant developmental abnormalities of various body systems and live very short lives."
            ]
        },
        {
            "question": "What are some examples of hereditary diseases mentioned in the text that occur in humans, and what are the causes of their occurrence?",
            "reference-answers": [
                "Examples of hereditary diseases mentioned in the text include:\n- Down syndrome\n- Patau syndrome\n- Edwards syndrome\n- Klinefelter syndrome\n- Shereshevsky-Turner syndrome\n- Phenylketonuria\n- Hemophilia\n- Sickle cell anemia\n- Cystic fibrosis\n- Hypertension\n- Myocardial infarction\n- Stroke\n- Rheumatism\n- Diabetes\n- Gastric and duodenal ulcers\n- Alzheimer's disease"
            ]
        },
        {
            "question": "What are the main causes of the development of hereditary diseases in humans, according to the provided text?",
            "reference-answers": [
                "The main causes of the development of hereditary diseases in humans include the formation of a relatively vulnerable genotype, due to which, under certain conditions, the probability of developing the disease sharply increases, and the interaction of hereditary factors and environmental factors."
            ]
        }
    ],
    "ukr-biology/book04/topic04-Репродукція та розвиток організмів/text.en.txt": [
        {
            "question": "What is the significance of the plow in the development of agriculture in Europe and how did this influence reproductive behavior in human societies?",
            "reference-answers": [
                "The plow played a significant role in the development of agriculture in Europe, particularly in the process of agricultural labor. Working with the plow required high physical exertion, which led to the main cultivation of the land being carried out by men. This contributed to the spread and consolidation of monogamous marriages (one man and one woman) in the cultural tradition, ensuring the most effective transfer of both genetic and material inheritance to their descendants."
            ]
        },
        {
            "question": "What is the significance of the development of agriculture in Europe, and how did it influence the reproductive behavior of humans in that region?",
            "reference-answers": [
                "The basis of agriculture in Europe was the plow, and then the plow, which required high physical exertion, contributing to the spread and consolidation of monogamous marriages (one man and one woman) in the cultural tradition, ensuring the most effective transfer of both genetic and material inheritance to their descendants."
            ]
        },
        {
            "question": "What is the main cause of mortality in children before the spread of modern medical technologies?",
            "reference-answers": [
                "The main cause of mortality in children before the spread of modern medical technologies was disease, and during periods of crop failure, hunger."
            ]
        }
    ],
    "ukr-biology/book05/topic01-Адаптації/text.en.txt": [
        {
            "question": "What is the adaptive significance of photoperiodism for living organisms?",
            "reference-answers": [
                "Photoperiodism is a set of changes in physiological reactions to changes in light, which is determined by the ratio of the duration of day and night. This phenomenon is characteristic of both animals and plants, and it plays an important role in regulating processes in living organisms. In plants, the daily rhythm of light initiates the processes of photosynthesis, flower formation, and fruiting. In animals, the daily rhythm of light influences processes such as hunting, rest, social interactions, mating behavior, migrations, and molting."
            ]
        },
        {
            "question": "What is the definition of health according to the provided text?",
            "reference-answers": [
                "Health is a complex concept, consisting of the absence of diseases and physical defects of the body, as well as complete mental and social well-being, and it is formed during a person's existence and depends on their lifestyle, habits, behavior, and social conditions."
            ]
        },
        {
            "question": "What is the definition of health according to the provided text?",
            "reference-answers": [
                "Health is a complex concept, consisting of the absence of diseases and physical defects of the body, as well as complete mental and social well-being, and it is formed during a person's existence and depends on their lifestyle, habits, behavior, and social conditions."
            ]
        }
    ],
    "ukr-biology/book05/topic02-Біологічні основи здорового способу життя/text.en.txt": [
        {
            "question": "What is the main difference between sapronous and zoonotic infections, and how do they enter the human body?",
            "reference-answers": [
                "Sapronous infections are transmitted through unwashed hands and enter the body orally or through damage to the body's integuments, whereas zoonotic infections are transmitted through a vector (ticks, mosquitoes, fleas, etc.) and enter the body through skin damage, respiratory system, or bites of sick animals."
            ]
        },
        {
            "question": "What are some common signs of stroke that can be recognized by individuals?",
            "reference-answers": [
                "Sudden weakness, paralysis of the muscles of the face or limbs, mostly on one side; speech impairment; rapid vision deterioration; sudden dizziness, loss of coordination or balance; a sharp headache without any cause; numbness of the limbs (on one side)."
            ]
        },
        {
            "question": "What are the main tasks of ecology according to the provided text?",
            "reference-answers": [
                "Studying the impact of the habitat on the structural features and vital activity of organisms;"
            ]
        }
    ],
    "ukr-biology/book05/topic03-Екологія/text.en.txt": [
        {
            "question": "What is the main difference between the biomes of terrestrial and aquatic ecosystems, according to the classification mentioned in the text?",
            "reference-answers": [
                "As a rule, aquatic and terrestrial biomes are considered separately."
            ]
        },
        {
            "question": "What is the definition of the biosphere according to V. I. Vernadsky, and what components does it consist of?",
            "reference-answers": [
                "The biosphere, according to V. I. Vernadsky, is a special part of the Earth inhabited by living organisms. It consists of four main components: living matter, biogenic matter, inert matter, and bioinert matter."
            ]
        },
        {
            "question": "What is the main difference between biogenic and bioinert matter according to the definition of the biosphere?",
            "reference-answers": [
                "Biogenic matter includes all matter created or processed by living organisms, whereas bioinert matter is created with the simultaneous participation of living organisms and factors of inanimate nature."
            ]
        }
    ],
    "ukr-biology/book05/topic04-Сталий розвиток та раціональне природокористування/text.en.txt": [
        {
            "question": "What is the difference between ecological thinking and rational use of nature, and how do they relate to each other in the context of sustainable development?",
            "reference-answers": [
                "Ecological thinking and rational use of nature are related concepts that are interconnected in the context of sustainable development. Ecological thinking is the consideration of phenomena and events and decision-making taking into account the interactions of man and nature with the natural environment based on diverse and deep knowledge about the environment and a responsible attitude to nature and human health. Rational use of nature refers to the ability to understand and manage natural resources in a way that minimizes harm to the environment and ensures the long-term sustainability of human activities.\n\nIn other words, ecological thinking is a way of thinking that considers the complex relationships between human activities and the natural environment, while rational use of"
            ]
        },
        {
            "question": "What is the role of experts in the field of ecology in making decisions on the processing of household waste, construction of treatment facilities, and educational work in the field of ecology?",
            "reference-answers": [
                "At this stage, the role of experts in the field of ecology increases significantly, because not always existing problems have a simple and obvious solution."
            ]
        },
        {
            "question": "What is the main difference between ecosystems that are comfortable for humanity to live in and those that can be destroyed by humans?",
            "reference-answers": [
                "Ecosystems that are comfortable for humanity to live in can be destroyed quite easily by humans themselves, whereas ecosystems that are not comfortable for humanity to live in have a fairly high chance of survival under the worst conditions."
            ]
        }
    ],
    "ukr-biology/book05/topic05-Застосування результатів біологічних досліджень у медицині, селекції та біотехнології/text.en.txt": [
        {
            "question": "What is the main task that remains to be solved in order to massively implement 3D printing technologies for human organs?",
            "reference-answers": [
                "The main task that remains to be solved in order to massively implement 3D printing technologies for human organs is the utilization of excess greenhouse gases, primarily carbon dioxide and methane."
            ]
        },
        {
            "question": "What are some of the main sources of biological hazards, including disease agents, disease vectors, and toxin producers, that can pose a threat to human health and the environment?",
            "reference-answers": [
                "Predatory animals (tigers, sharks, bears), large herbivores (cows, horses, elephants), animals with mechanical means of protection (porcupines, hedgehogs), etc. (cause physical damage); viruses (HIV, rabies virus), bacteria (Koch's bacillus, pale treponema, cholera vibrio), eukaryotes (malarial plasmodium, echinococcus, bovine tapeworm) (disease agents); mosquitoes, ticks, mosquitoes, mollusks, dogs, cats, bats, etc. (disease vectors); poisonous arthropods ("
            ]
        },
        {
            "question": "What is the main task that remains to be solved to address the problem of rising sea levels and the forced displacement of hundreds of millions of people caused by climate change?",
            "reference-answers": [
                "The main task remains the utilization of excess greenhouse gases, primarily carbon dioxide and methane, to solve this problem."
            ]
        }
    ],
    "world-history/chapter01-Understanding-the-Past/text.txt": [
        {
            "question": "How would a Marxist historian approach the story of colonial Latin America between the Spanish conquest that began in 1493 and the independence movements of the 1820s?",
            "reference-answers": [
                "A Marxist historian would examine unfair labor practices and moments of class conflict like rebellion or riot."
            ]
        },
        {
            "question": "What are some of the limitations that historians face when trying to represent women, the poor, and minority communities on an equal footing with those who have traditionally held power in the field of social history?",
            "reference-answers": [
                "Historians face limitations in representing women, the poor, and minority communities due to a lack of records, and societal factors such as colonialism, which can alter the historical record and limit the availability of sources, and the dominance of colonial powers that have historically been the focus of the discipline."
            ]
        },
        {
            "question": "What were the main limitations in representing women, the poor, and minority communities on an equal footing with those who have traditionally held power in the field of social history, according to the text?",
            "reference-answers": [
                "Lacking records, it remains difficult to represent women, the poor, and minority communities on an equal footing with those who have traditionally held power in the field of social history."
            ]
        }
    ],
    "world-history/chapter02-Early-Humans/text.txt": [
        {
            "question": "When did the Indigenous peoples of Australia begin to practice a mostly hunter-gatherer lifestyle, and what influenced their decision to continue this lifestyle?",
            "reference-answers": [
                "The Indigenous peoples of Australia continued to practice a mostly hunter-gatherer lifestyle until Europeans arrived about 250 years ago, and they apparently consciously determined that hunting and gathering were more suitable and practical given their own needs and the environment in which they lived."
            ]
        },
        {
            "question": "When did the Indigenous people of Australia begin to actively cultivate sorghum, and what time period is this likely to have occurred?",
            "reference-answers": [
                "Around six thousand years ago."
            ]
        },
        {
            "question": "What were some of the key changes brought about by the rise of agriculture, and how did these changes impact human society?",
            "reference-answers": [
                "The rise of agriculture brought about several key changes to human society, including the shift from humans being the deciding factor in determining which plants would grow to humans selecting plants for their edible properties, leading to gradual but important transformations in the plants themselves. Additionally, agriculture led to the domestication of numerous types of animals, often selected for characteristics beneficial to humans, such as docility, strength, ability to feed on readily available foods, and rapid growth and reproduction. These changes resulted in significant impacts on human society, including a loss of leisure time, with farmers spending thirty or more hours engaged in farming compared to twenty hours per week for hunter-gather"
            ]
        }
    ],
    "world-history/chapter03-Early-Civilizations-and-Urban-Societies/text.txt": [
        {
            "question": "What is the likely cause of the decline of the Indus Valley Civilization, according to the theory that suggests it was related to regional climate change?",
            "reference-answers": [
                "Changes in the pattern of seasonal wind and rainfall, known as the monsoon in South Asia, may have caused these environmental effects, which would have resulted in a decline in population due to a lack of a secure source of water for drinking and irrigation."
            ]
        },
        {
            "question": "What is the name of the Greek corruption of the Egyptian name for the Semitic-speaking chieftains that later came to be known as the Hyksos?",
            "reference-answers": [
                "Hyksos."
            ]
        },
        {
            "question": "What were the main factors that contributed to the decline of the Indus Valley Civilization around 1500 BCE?",
            "reference-answers": [
                "The decline of the Indus Valley Civilization around 1500 BCE was likely due to a combination of factors, including regional climate change, environmental degradation, and possibly epidemic disease, rather than a violent conquest by nomadic Indo-European speakers, as previously believed."
            ]
        }
    ],
    "world-history/chapter04-The-Near-East/text.txt": [
        {
            "question": "What is the approximate date of the birth of Abraham, according to the biblical chronology, and in which city was he born?",
            "reference-answers": [
                "Abraham was born around 2150 BCE in the Mesopotamian city of Ur."
            ]
        },
        {
            "question": "What is the approximate birth year of Abraham, according to the biblical chronology?",
            "reference-answers": [
                "2150 BCE"
            ]
        },
        {
            "question": "What is the approximate time period during which the story of Abraham and his family was developed, according to historians?",
            "reference-answers": [
                "The story of Abraham and his family was developed between the tenth and sixth centuries BCE."
            ]
        }
    ],
    "world-history/chapter05-Asia-in-Ancient-Times/text.txt": [
        {
            "question": "What was the ultimate goal of a person's earthly life according to the Vedic religion of the Aryans?",
            "reference-answers": [
                "The ultimate goal of a person's earthly life was to achieve union with Brahman, the ultimate and universal reality."
            ]
        },
        {
            "question": "What was the ultimate goal of a person's earthly life according to the Vedic religion of the Aryans?",
            "reference-answers": [
                "The ultimate goal of a person's earthly life was to achieve union with Brahman, the ultimate and universal reality."
            ]
        },
        {
            "question": "What was the ultimate goal of a person's earthly life according to the Vedic religion of the Aryans?",
            "reference-answers": [
                "The ultimate goal of a person's earthly life was to achieve union with Brahman, the ultimate and universal reality."
            ]
        }
    ],
    "world-history/chapter06-Mediterranean-Peoples/text.txt": [
        {
            "question": "Who was the first emperor of the Roman Empire after the death of Augustus, and what was notable about his ascension to power?",
            "reference-answers": [
                "Vespasian was the first emperor of the Roman Empire after the death of Augustus, and what was notable about his ascension to power was that he survived the civil war and adopted the name Caesar and the title Augustus, even though he was not related to the family of Augustus or their descendants."
            ]
        },
        {
            "question": "What event occurred in 44 BCE that led to the assassination of Julius Caesar?",
            "reference-answers": [
                "Two of Caesar's former optimates, Brutus and Cassius, led a conspiracy that resulted in his assassination."
            ]
        },
        {
            "question": "What was the outcome of Octavian's decision to officially step down as dictator and \"restore\" the Roman Republic in 27 BCE?",
            "reference-answers": [
                "Octavian officially stepped down as dictator and \"restored\" the Roman Republic in 27 BCE, but in reality, he had inaugurated the Empire, with himself as emperor possessing almost godlike authority."
            ]
        }
    ],
    "world-history/chapter07-Experiencing-the-Roman-Empire/text.txt": [
        {
            "question": "What was the significance of the Edict of Milan, issued by Emperor Constantine in 313 CE, in terms of religious toleration in the Roman Empire?",
            "reference-answers": [
                "The Edict of Milan, issued by Emperor Constantine in 313 CE, outlined a policy of religious toleration in which Christianity was no longer illegal and most traditional Roman religious practices could continue."
            ]
        },
        {
            "question": "What was the outcome of the Edict of Milan issued by Emperor Constantine in 313 CE regarding the policy of religious toleration in the Roman Empire?",
            "reference-answers": [
                "Christianity was no longer illegal, and most traditional Roman religious practices could continue."
            ]
        },
        {
            "question": "What was the outcome of the Edict of Milan issued by Emperor Constantine in 313 CE regarding the policy of religious toleration in the Roman Empire?",
            "reference-answers": [
                "Christianity was no longer illegal, and most traditional Roman religious practices could continue."
            ]
        }
    ],
    "world-history/chapter08-The-Americas-in-Ancient-Times/text.txt": [
        {
            "question": "What was the approximate population of Pueblo Bonito at its peak around 1000, and how many rooms were there in total in the settlement?",
            "reference-answers": [
                "The approximate population of Pueblo Bonito at its peak around 1000 was about one hundred people, though its six hundred pueblo rooms could have housed as many as one thousand."
            ]
        },
        {
            "question": "What was the approximate population of the settlement of Pueblo Bonito at its peak, and how many people could its 600 pueblo rooms have housed?",
            "reference-answers": [
                "At its peak, the settlement of Pueblo Bonito may have had a modest population of about one hundred people, though its six hundred pueblo rooms could have housed as many as one thousand."
            ]
        },
        {
            "question": "What was the approximate population of the settlement of Pueblo Bonito at its peak?",
            "reference-answers": [
                "about one hundred people."
            ]
        }
    ],
    "world-history/chapter09-Africa-in-Ancient-Times/text.txt": [
        {
            "question": "What was the primary advantage of the dromedary camel in facilitating transSaharan trade, and how did its adoption change desert transport in the region?",
            "reference-answers": [
                "The primary advantage of the dromedary camel in facilitating transSaharan trade was its ability to store fat and water, enabling it to travel up to ten days without stopping for fresh water, more than twice the time and distance of almost every other pack animal."
            ]
        },
        {
            "question": "What was the primary commodity exchanged during the early stage of trans-Saharan trade, and what was its significance in the agricultural communities south of the Sahara?",
            "reference-answers": [
                "Salt, which was carried to the south and acted as a sort of currency, was the primary commodity exchanged during the early stage of trans-Saharan trade, and its significance in the agricultural communities south of the Sahara was that humans required salt to maintain healthy bodily functions and must regularly consume salt to replace its loss through sweat and urination."
            ]
        },
        {
            "question": "What was the primary reason for the Roman use of the dromedary camel in North Africa?",
            "reference-answers": [
                "The Roman use of the dromedary camel in North Africa was primarily to secure the southernmost frontiers of their new provinces."
            ]
        }
    ],
    "world-history/chapter10-Empires-of-Faith/text.txt": [
        {
            "question": "What role did the Kushan Empire play in the trade route linking the Mediterranean and East Asia, and how did its diversity of population contribute to its understanding of this empire's role in Late Antiquity?",
            "reference-answers": [
                "The Kushan Empire served as an important cog in the trade route linking the Mediterranean and East Asia, acting as the link between the trading partners China and the Roman Empire. Its connections to Rome are clear from the Roman coins found in the Kushan region, as well as from written evidence that several Kushan embassies were sent to Roman emperors. Romans in turn received various luxury goods from Asia via Kushan, including jewelry, furs, and silk. The Kushan Empire's diversity of population, with a mix of people practicing Buddhism and Zoroastrianism among other faiths, contributed to its understanding of this empire"
            ]
        },
        {
            "question": "What role did the Kushan Empire play in facilitating the spread of Buddhism in the region, and how did its connections to China contribute to this process?",
            "reference-answers": [
                "The Kushan Empire played a crucial role in facilitating the spread of Buddhism in the region through its connections to China. Buddhist monks were able to bring their religion to China via the pass connecting Kushan and China, and the Kushan monk Lokaksema was one of the most prominent examples of this religious transmission. Lokaksema traveled to China in the 180s, translating Mahayana Buddhist texts with his students and making Buddhist scriptures available in Chinese, which helped to spread Buddhism to a wider audience."
            ]
        },
        {
            "question": "What role did the Kushan Empire play as a link between the trading partners China and the Roman Empire on the Silk Roads in Late Antiquity?",
            "reference-answers": [
                "The Kushan Empire served as an important cog in the trade route linking the Mediterranean and East Asia, acting as the link between the trading partners China and the Roman Empire on the Silk Roads in Late Antiquity."
            ]
        }
    ],
    "world-history/chapter11-The-Rise-of-Islam-and-the-Caliphates/text.txt": [
        {
            "question": "How did the Abbasid Translation Movement contribute to the growth of learning and openness to new ideas in early Abbasid society?",
            "reference-answers": [
                "The Abbasid Translation Movement, or the Greco-Arabic Translation Movement, contributed to the growth of learning and openness to new ideas in early Abbasid society by preserving and translating ancient texts into Arabic, especially from Greek and Persian, and by fostering a culture of learning among the upper echelons of society and especially in Baghdad. This movement allowed for the creation of significantly less expensive books through the introduction of Chinese papermaking techniques, and the patronage of scholarly work by the caliph himself proved to be the catalyst for an explosion of medieval learning."
            ]
        },
        {
            "question": "What was the significance of the Abbasid Translation Movement in the early Abbasid period, and how did it contribute to the growth of learning and knowledge in the Islamic world?",
            "reference-answers": [
                "The Abbasid Translation Movement, also known as the Greco-Arabic Translation Movement, was a significant event in the early Abbasid period, marking a major milestone in the growth of learning and knowledge in the Islamic world. This movement involved the translation of ancient Greek and Persian texts into Arabic, which greatly expanded the knowledge base of the Islamic world. The movement was supported by the Abbasid elite, who provided financial support to scholars, and it led to an explosion of medieval learning. The translations preserved many important works by Greek thinkers such as Aristotle, Dioscorides, Galen, Hippocrates, and Ptolemy, which were"
            ]
        },
        {
            "question": "What was the significance of the Abbasid Translation Movement, and how did it contribute to the growth of learning and scholarship in the Islamic world during the Abbasid period?",
            "reference-answers": [
                "The Abbasid Translation Movement, also known as the Greco-Arabic Translation Movement, was a significant event in the Islamic world during the Abbasid period. It was a major catalyst for the growth of learning and scholarship, as the Abbasids strongly supported learning, especially in their capital, Baghdad. The movement involved the translation of ancient texts from Greek, Persian, and other languages into Arabic, which allowed for the preservation and dissemination of knowledge from the ancient world. This movement led to an explosion of medieval learning, as scholars were able to access and study works that had previously been inaccessible. The Abbasids' patronage of scholarly work and"
            ]
        }
    ],
    "world-history/chapter12-India,-the-Indian-Ocean-Basin,-and-East-Asia/text.txt": [
        {
            "question": "What was the significance of the Taika Reforms in Japanese history, and what reforms did they include?",
            "reference-answers": [
                "The Taika Reforms, initiated by King Temmu and Jito in 672, were a set of reforms that sought to adopt the centralization instituted by the Tang, who came to power in China in 618 CE. The reforms included building a capital at Fujiwara-kyo, establishing a system of taxation, conscription, and labor service known as the Taihoo Code (701), and an administrative and penal code system based on that of Tang China, established in 718."
            ]
        },
        {
            "question": "What event in 794 marked the end of the Nara period in Japanese history?",
            "reference-answers": [
                "Emperor Kammu moved his capital about twenty miles north to Heian-kyo, the site of today’s Kyoto, ending the Nara period."
            ]
        },
        {
            "question": "What was the significance of the introduction of Buddhism in Japan during the Kofun period, and how did it coincide with the rule of the Yamato clan?",
            "reference-answers": [
                "The arrival of Buddhism in Japan during the Kofun period coincided with the rule of the Yamato clan, a group said to have descended from the goddess Amaterasu."
            ]
        }
    ],
    "world-history/chapter13-The-Post-Roman-West-and-the-Crusading-Movement/text.txt": [
        {
            "question": "What was the primary objective of the First Crusade, and was it ultimately accomplished?",
            "reference-answers": [
                "The primary objective of the First Crusade was to retake the Holy Land from Muslim rule, and it was ultimately accomplished, as the crusaders took control of Jerusalem in the summer of 1099."
            ]
        },
        {
            "question": "What was the primary objective of the First Crusade, and how did it differ from the goals of the subsequent Crusades?",
            "reference-answers": [
                "The primary objective of the First Crusade was the conquest of Jerusalem, and it was the only Crusade to accomplish its objective. The subsequent Crusades, however, had different objectives, with the goal of fighting against the enemies of the church, including non-Christians in the Baltic regions, heretics in France, and the pope's personal enemies in Italy."
            ]
        },
        {
            "question": "What was the main objective of the First Crusade, and was it accomplished?",
            "reference-answers": [
                "The main objective of the First Crusade was to retake the Holy Land from Muslim rule, and it was accomplished, as the crusaders successfully took control of Jerusalem in the summer of 1099."
            ]
        }
    ],
    "world-history/chapter14-Pax-Mongolica-The-Steppe-Empire-of-the-Mongols/text.txt": [
        {
            "question": "What was the outcome of the Fifth Crusade, and how did it affect the relationship between Christians and Muslims in the Holy Land?",
            "reference-answers": [
                "The Fifth Crusade failed, with the crusaders agreeing to withdraw from their conquests and return to Europe, ending the crusade in yet another failure. The treaty concluded between Frederick II and Sultan al-Kamil in 1219 allowed Frederick to be the titular king of Jerusalem, but with limited power, and a ten-year truce between Muslims and Christians was put in place."
            ]
        },
        {
            "question": "What was the outcome of the Fifth Crusade, as led by Frederick II, in 1228, and how did it differ from the previous crusades?",
            "reference-answers": [
                "Frederick II agreed to lead a new crusade, but due to personal misfortune and lack of enthusiasm among Europe's vassals, he was unable to get underway. The delays were so severe that the exasperated Pope Gregory IX excommunicated him, cutting him off from the church and its sacred rites. Frederick landed in Acre, the main port still in Christian hands, and concluded the Treaty of Jaffa with Sultan al-Kamil in 1219, which allowed Frederick to be the titular king of Jerusalem with limited power."
            ]
        },
        {
            "question": "What was the outcome of the Fifth Crusade, and how did it differ from the Fourth Crusade in terms of the crusaders' objectives and the treatment of the Muslim population?",
            "reference-answers": [
                "The outcome of the Fifth Crusade was that the crusaders agreed to withdraw from their conquests and return to Europe, ending the crusade in yet another failure. The Fifth Crusade differed from the Fourth Crusade in that the Fifth Crusade did not involve the sacking of Constantinople, and it did not result in the re-imposition of Catholicism on Eastern Christianity. Instead, the crusaders were able to negotiate a treaty with the Ayyubid ruler al-Kamil, which allowed Frederick II to be the titular king of Jerusalem with limited power, and established a ten-year truce between Muslims and Christians in the Holy Land"
            ]
        }
    ],
    "world-history/chapter15-States-and-Societies-in-Sub-Saharan-Africa/text.txt": [
        {
            "question": "Who was the leader of the Songhai rebels who became the first king of the Songhai Empire, and what was his capital?",
            "reference-answers": [
                "Sunni Ali, and his capital was Gao."
            ]
        },
        {
            "question": "Who was the leader of the Songhai rebels, Sunni Ali, and what was his notable achievement?",
            "reference-answers": [
                "Sunni Ali became the first king of the Songhai Empire after leading the rebels against the Malian rulers, and he achieved notable success by marshaling his massive cavalry and fleet of war canoes, extending his empire deep into the desert in the north and as far as Djenné in the southwest, capturing Mali's great religious and scholarly center in Timbuktu, the trading town of Djenné, and almost the whole of the Middle Niger floodplain and the Bandiagara uplands."
            ]
        },
        {
            "question": "What was the name of the leader of the Songhai rebels who became the first king of the Songhai Empire after the Malian rulers withdrew in the 1430s?",
            "reference-answers": [
                "Sunni Ali."
            ]
        }
    ],
    "world-history/chapter16-Climate-Change-and-Plague-in-the-Fourteenth-Century/text.txt": [
        {
            "question": "How did the flagellants' actions and rhetoric contribute to the spread of the plague, and what ultimately led to their condemnation by Pope Clement VI?",
            "reference-answers": [
                "The flagellants' actions and rhetoric contributed to the spread of the plague through their contaminated blood, as they traveled from town to town, reciting penitential verses and lashing themselves with leather whips until they drew blood. This ultimately led to their condemnation by Pope Clement VI."
            ]
        },
        {
            "question": "What were some of the long-term economic and demographic consequences of the plague in medieval Europe?",
            "reference-answers": [
                "The plague left each region it affected with long-term economic and demographic consequences, including widespread depopulation and cyclic outbreaks of the disease in the fourteenth and fifteenth centuries."
            ]
        },
        {
            "question": "What were the long-term economic and demographic consequences of the plague in medieval Europe, and how did they impact the social structures and hierarchies of the time?",
            "reference-answers": [
                "The plague left each region it affected with long-term economic and demographic consequences, including widespread depopulation and cyclic outbreaks of the disease in the fourteenth and fifteenth centuries. Old systems of belief came into question, and ancient social hierarchies shifted to accommodate the significant population losses that followed the plague."
            ]
        }
    ],
    "world-history/chapter17-The-Ottomans,-the-Mamluks,-and-the-Ming/text.txt": [
        {
            "question": "What was the primary reason for the Ottoman sultans to gather Christian children from European lands as part of the devshirme system?",
            "reference-answers": [
                "The primary reason for the Ottoman sultans to gather Christian children from European lands as part of the devshirme system was to counter the power of the Turkish nobles who controlled the army and the state's administration."
            ]
        },
        {
            "question": "What was the name of the dynasty that Zhu Yuanzhang proclaimed himself emperor with in 1368, dubbing his new dynasty the Ming (“bright”) after defeating the last Yuan emperor?",
            "reference-answers": [
                "The Ming (\"bright\")"
            ]
        },
        {
            "question": "What was the primary reason why Ottoman sultans began gathering Christian children from European lands as part of the devshirme system?",
            "reference-answers": [
                "The Ottoman sultans began gathering Christian children from European lands as part of the devshirme system in order to counter the power of the Turkish nobles who controlled the army and the state's administration."
            ]
        }
    ]
}