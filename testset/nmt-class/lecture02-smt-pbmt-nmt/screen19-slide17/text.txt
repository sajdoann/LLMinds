 The framework is called LoglingerModal and that allows you to do all these things. The idea is that you will model the whole probability that you are after, the probability of the target sentence given the source, as a weighted combination of totally independent feature functions. And these feature functions can consider the translations from many different aspects. And what you do is that you have some proposals. So we have the input sentence, you have some proposals, some proposed possible output. And you will run all these feature functions and you will combine, you will collect their scores and you will combine them with a weighted sum. And that will give you a score for the sentence. You can now score based on whatever you like, condition probability that way, the other way, language model of the source, whatever you like. The only thing you have to make it a probability is that if you consider all the possible input sentences, all the possible output sentences, you are giving points to these pairs of sources and targets and you have to have a proper probability of that afterwards. So the easiest way is to see how many points you are distributing in sum and then divide every score of a particular sentence pair by this total sum of the points that you have distributed. That sums the normalization constant. That sounds very difficult to compute. Like you have to consider all the sentences in both languages and see how many points they got from the feature functions. But the great thing... ...