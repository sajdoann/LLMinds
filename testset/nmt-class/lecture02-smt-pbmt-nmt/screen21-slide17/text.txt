 Make it a proper probability. Okay, so here in this log-linear model I can talk about one example feature function and the example feature function for simplicity is the feature function which represents the language model. So here the idea is that the language model is a feature function which receives the source and it receives the candidate target translation and it disregards the source. It is language model. It looks only at the target and it simply uses the probability of n grams whatever the n gram is to to estimate the probability to estimate the probability of the target candidate and to make it work nicely you just put a log in front of this calculation. So it is very easy to embed the original language model that we had the probability based on n grams into this log-linear framework You just create one feature function which ignores the source side and uses the target side an important aspect of this log-linear model are the weights. So these weights specify the relative importance and that goes back to the idea that that sometimes the language model is more important than the translation model because it like this this thing which is better which sentences are are nicer and sometimes it is less so so these weights allow you to balance the mix of the components and we will have a lecture on on this later on on this later on how to find the weights automatically you