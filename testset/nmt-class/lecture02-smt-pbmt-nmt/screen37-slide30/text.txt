 We could fix this if we realized that this nemam is also somehow linked in the meaning to this no. So if there was this link between nemam and no, then we would not extract this orange phrase alone. We would extract the pair of orange and green phrases together. So we would have a large unit that does not induce an error., but in that case, if our training corpus was only these two sentences, we would not know how to translate nemamkočku at all, because we would be hoping to see žádného here. And that's not in the input. So if you have longer units, you are risking data sparseness. You're losing coverage. With longer units, you are improving precision, but losing recall. With smaller units, you are improving recall, but losing precision. So this is exactly the issue. I had a site research trying to introduce alignments here hoping to find a good balance but unfortunately I failed. There was no reasonable setting how to introduce the alignments, the additional alignments, so that the precision would increase and the recall would not decrease too much. It like fighted against me. It was impossible to.