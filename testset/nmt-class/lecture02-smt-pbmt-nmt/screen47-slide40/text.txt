 So here is an illustration how deep networks can handle visual tasks. The task here is again classification. We need to find out what is in the picture. We have a collection of pictures, cars, cats, dogs, whatever. And we have three hidden layers. We already know that the first hidden layer is doing linear combinations of coordinates. And the coordinates here are X, Y, and the color. So this, if you look at what the neurons do in the first layer, you will see that they draw separation boundaries and color separation boundaries. Then these features can be combined into some more complex features that use these lines to approximate simple shapes. So we know how to approximate a circle with three lines and so on. So the network has some capacity because we specify how many neurons we have. So this, and how many neurons we have in the lower layer and how many neurons here. And the network will itself, for itself, find whether it is better to approximate a circle with three lines or four lines, because it still has the fourth line free. So this is exactly what is happening in this deep learning approach. The sequence of layers is trained automatically so that it observes the relevant distinguishing features for the final classification.