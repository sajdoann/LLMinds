 So now the problem with neural networks formation translation is how do we produce text with this? We do not have a collection of thousands of picture types. We need to produce words, a sequence of words in the target language. So the idea is that you map each word to a vector of zeros and ones. And the very simple approach is that indeed the vectors will be as long as the dictionaries of the and you put zeros everywhere except for the position which corresponds to the given word. So if you have a sentence, the cat is on the mat. This sentence can be represented as a matrix. The matrix is very tall and very narrow. It's tall as their English words and it contains one, only single one in each of the columns. And that highlights which word is where. the cat is on the mat and so on.