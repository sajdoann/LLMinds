 In the same year, another team applied that same approach to the full sentences. So they disregarded the log-link-near approach, the phrase-based approach. They simply fed the input sentence into an encoder and then decoded it from there. So the encoder consumes the source words one at a time. This is the one-hot representation of the word. So first, the one-hot representation is converted to the dense embedding. of the word. And then these embedded words are consumed to the sentence state or encoder state representation. So that is a vector which somehow represents everything that we have consumed so far. And in every step, there is a matrix that specifies how do we mix these states so far with the current word. And you simply digest the whole input sentence and you arrive at a final representation. Thank you. Honest Herrlin, that's my response. All right. I'll be showing you. It is just an Okay. I'll be showing you.