 ... if you have a vector representation of a sentence, you can again train the network to produce ... to decode the individual words from that. So you have that sentence level representation and you ask it what is the word that I should produce now. It will give you a distribution over all the target words or the target subword units and you will pick the highest scoring one and then you have the calculation, the step in the recurrent decoder and the step is a calculation which takes its previous state, the word it has just produced, and it proposes the next word. So the decoder is the language model which is exactly the language model that we were talking about. It is the language model that produces target sentence one word at a time, given the source sentence embedded in this vector, or encoded in this vector, and in later stages the source sentence is still there, and you also have the access to all the words that were produced so far. So this decoder is exactly the clever language model, the technical device which you can feed with the representation of the full source, and then step by step it will produce the target words one at a time, and you always give it the information which words of the candidates you have chosen and it will give you the next one. So this the decoder is exactly that formula.