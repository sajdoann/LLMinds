 to find them out. So here is a comparison of the two approaches. The goal of classical statistical machine translation, as I said previously, was to find minimum translation units, which can be seen as graph partitions. These minimum translation units can operate on the words or on some linguistic representation of the sentence. And these minimum translation units need to be free across many sentence pairs and they should be easy to operate with. And ideally you would find them in an unsupervised fashion from the data. And you would translate by decomposing the sentence into these minimum translation units and putting the translations back together. The goal of neural machine translation is to avoid any translation units, but instead you construct a neural network architecture which digests input words, and produces the sequence of output words. And the closer you are to your intended input and output, the better. The network will learn all the transformations by itself. But the catch is that the network must not be too complex, because with the complexity you are adding too many free parameters and the training will never converge. There are numerical problems that you are running into and you will have a lack of data to train that many parameters. So there is a balance between the size of the training data that you have, the number of parameters that you allow the network to have, and also the computation time that you have to process that data. Because you don't want these models to be finished in a year of training. for the Però d œr to recruit more than the line task. So this webinar should be broadcast by we want theriends man to your這裡. And a lot of managersing etc.