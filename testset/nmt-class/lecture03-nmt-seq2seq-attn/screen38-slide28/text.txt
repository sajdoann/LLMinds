 So here it is in picture. So the encoder, decoder architecture is nothing more complex than two recurrent neural networks attached to each other. First you have the RNN encoder which digests the input one symbol at a time accumulating the knowledge in the state and then this state is used as the initial state of the second recurrent neural network and that's the decoder and the decoder is fed at the beginning with the beginning of sentence symbol and with this state it like decides what is the most likely first word in the output and then again gets this gets its prediction or out selection of the distribution as the input and it produces the next word. So this part the second part is the conditional language model it's conditioned on the source sentence and it produces the most likely target language sentence. So there are two embeddings here that can be used. One is to convert the source language words into the continuous representation that the encoder digest and there is also the target site or output embeddings that are used to convert the target language words to the representation that the decoder can digest. Often these two embeddings the embeddings are shared because even if you translate between languages with a different script there are sometimes words that should be copied so it makes sense to have a single vocabulary for both of the languages. And the benefit of all these shared embeddings is also that you have only one embedding matrix in your training and the same matrix is updated both during the backpropagation through the decoder