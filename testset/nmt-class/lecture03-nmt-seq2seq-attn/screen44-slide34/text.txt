 So how do we train that system? The idea is that you have a big parallel corpus and next week we'll talk about how to get parallel corpora and how to align them sentence by sentence. So we have a set of sentence pairs. So we have a set of pairs source sentence units, target sentence units and we can start with the random initialization. So we can process the input through the whole network to get the output candidate and now we need to score whether the output candidate matches well or how well it matches with the expected output candidate. So for an output word yi we have the probability distribution that's for each time step. We know the distribution over the full vocabulary. and hopefully the word that is expected has also indeed the highest probability in this distribution. Maybe not and if not then we need to change the computation so that it will get the highest probability.