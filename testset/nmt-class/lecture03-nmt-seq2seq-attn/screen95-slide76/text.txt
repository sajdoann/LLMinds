 The use of language model, and this is something that we have discussed already in the past, is different. The language model is the main driving force in neural MT. The language model decides which words should be now produced, whereas in classical pre-neural approaches to machine translation, the language model was used to consider the better candidates and separate them from, discriminate them from the and the alignment in classical statistical machine translation was a prerequisite, a step before the system was trained. Here the alignment or the attention are learned with translation at the same time. So they come as a side effect, we get them for free.