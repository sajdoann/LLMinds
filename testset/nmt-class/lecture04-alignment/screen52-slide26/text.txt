 So here is again the summary. The expectation maximization algorithm consists of two steps. In expectation step you apply the modal to the data. So the modal is the dictionary of word translations. The data are the alignments and so using well actually the yeah the modal in the IBM modal 1 is the formula that we had which defined the probability of the source sentence target sentence given the alignment so that's the full modal. So parts of the modal are hidden so the alignments between words and using the modal we assign the probabilities to what is there? So in short in the expectation step you apply the modal to the data so you have the dictionary and you draw the alignments refine the alignments and the maximization step is the other part. You have the alignments you observe the data and you change the