 And the phrase based model is specific in that it builds upon this important phrase based assumption. The assumption is that sentences can be translated by translating short sequences of words independently of each other. So with phrase based MTE you break down the input sentence the source sentence F1-J into K phrases. This number of phrases is something that the the model decides on the go. So the same sentence can be translated with short phrases or longer phrases depending on the match of the sentence with the training data. Then each of these phrases is translated independently of the others. That's the key assumption of phrase based MTE. And then you concatenate the translated phrases and you concatenate them in some order. And there is one more mapping the possible reordering which can be also included in the the score for the hypothesis. So for some languages it will be more natural to keep the order of the phrases the same way as they were ordered in the input sentence. For some languages it is important to make some particular movements. It's important to realize that even if the phrases are translated monotonically the word order can change within individual phrases. So the phrases are multi word expressions and multi word expressions can do any reordering within those phrases as desired. So I've silently introduced one more hidden variable the segmentation. So the argmax that we are running ideally would be an argmax over summation over all possible segmentations of the given input sentence. So you have the source words you are considering the target words and there are many ways in which you can arrive at the same output. So you have the source words but through different segmentations. And these different segmentations will give you different scores in the model because now the feature functions in phrase based MTE have three parameters. They have the input sentence, the output sentence and also the segmentation. And so this segmentation is a hidden parameter in the maximization. is a hidden parameter in the same output sentence. So this is just a scoring segmentation. So to put it really correctly. We are not searching for the best output sentence given the source sentence. But we are searching for the best derivation of that output sentence. So we're searching for the best segmentation of the input and translation of this segmented input.