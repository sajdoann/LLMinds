 Here is an illustration of the effect of weights on the hypothesis that are considered. So remember there is about 13 or so weights or maybe 9 weights in the baseline phrase based model. The two most important ones are phrase translation probability and language model score. And what I'm illustrating here is the language model score and the phrase penalty. So the phrase penalty controls whether the system prefers many segments when segmenting the input sentence or few segments. So if the phrase penalty or actually the phrase bonus here if the phrase penalty is high then for whatever the input sentence was the candidate translation was this very piecewise one. So each of these phrases was translated independently of the context. If the phrase penalty or phrase bonus is said to be very low then it is trying to translate the sentence with as long pieces as possible. Verdict ještě není konečný a soud. So there is only one, two, three instead of like six or seven phrases. So that is the phrase penalty. and the language model score must not be exaggerated because then the system would start fabulating then it would prefer nice sentences regardless what the source sentence was saying. So it has to be said reasonably but it must not be negative. So if you if you are a Czech speaker and if you start looking at the at the negative language model scores. so they are the candidate translations when the weight for the language model score is negative then you will see that based on the fixed this is fixed input based on the fixed input words. Suddenly the.. But rather the beer brewers twins and and package rapping companies all these words the beer brewers and twins. And twins are licensed according to the phrase table. So there is a lot of garbage in the phrase table as well. but this garbage can suddenly with bad weight setting can arise so and it can be selected in the in the beam search if the weight combination is very strange. So you need to find the good balance of weights so that the quality of the output sentence the fluency of the output sentence is not but not exaggerated so it doesn't fabulate and also the segmentation of the input sentence is reasonable and I've already I was already talking about this so if you if your test data matches very well your training data then the phrase bonus can be pretty low the phrase penalty in other words can be pretty high so it's good to use long phrases if there is the good match if there is the bad match between and the training data then it would probably be better to use shorter phrases and translate individual words. So the held out set on which the minimum error rate training is done should really match your test domain it should be extracted from your test data and not from your training data so to say but if you don't have if you don't know your test data upfront if you're in a competition or if you're serving It leads to words dropped. Negative language mode leads to obscure wordings and various strange words appearing there. Higher phrase penalty chop sentences into more segments.