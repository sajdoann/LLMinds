 So, again, let's summarize it. So, factored phrase-based empty modal is an extension of the phrase-based modal. Phrase extraction, the standard procedure, is used for the mapping steps. There is also the extraction for generation steps that simply observes the monolingual corpus and sees how often a particular word form was with a particle attack. And then there is the decoding. And we'll go over the decoding and extraction in a second. This fits very nicely to the log-linear structure of the phrase-based modal that we have discussed in the previous lecture. Each of these steps simply brings in new features. So, you will score your final translation not only how good was it in terms of engrams of the language modal, of engrams of word forms, but also how good it was in terms of engrams of morphological tags, engrams of lemmas if you wish, and also in terms of the phrase translations, how well was it translated considering the lemma sequences of the source and target languages, how well was it translated considering the morphological tags in the source and target languages. These weights, so there will be more components and weights of these components can be again trained by the minimum error rate training, except that it will have a harder time because there will be more features to consider. So, how