 So here is the solution. The solution is called alternative decoding paths. And you essentially combine the two models to operate at once. So you let the system do the normal word for word like form for form translation. And you also pass the lemma and part of speech being translated independently and the fun for being generated from lemma and the morphology. These two components will bring in separate features. that each will get some weight in the minimum error rate training. And on some held out data set the minimum error rate training will identify how often on average should it trust the direct path and how often on average should it resort to this separation of the lemma and the part of speech. And that is exactly what needs to be done. The system is now flexible. It can the backoff to the separation to the independence assumptions if needed. But it has also the original full power of copying what it has known, what it has seen in the data well.