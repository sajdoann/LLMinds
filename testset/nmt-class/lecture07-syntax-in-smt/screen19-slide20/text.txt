 So now let's discuss how this device of synchronous substitution grammars or synchronous context-free grammars is used in machine translation. Here is a summary and the main point of this summary is to illustrate how the language model plays with the procedure. So the idea is that you will be translating while parsing. you are given a source sentence in Chinese. You have these rules which have the left hand side for productions but in the right hand side they have the source side and target side. And you use the source side of the productions to do the parsing. So you are validating the correctness of the input sentence. And while doing so you are putting together the target language parts based on the target language side of each of the rules. And that builds the output sentence in the target language. So in contrast to the left to right processing in phrase based MT where the input was digested in any order. And the output was produced left to right. And you had these multiple hypotheses here. The input is digested bottom up. And the output is produced in the exact parallel bottom up fashion. So this is a very different style of processing. And this style of processing also works with the search space. So in the CKW algorithm you also have the search space of possible parses. And these parses now are not only parses of the source but they are also constructions of the target. I'm going to use the same model. So you are searching over all the possible constructions of the target that are licensed by the gradual digestion of the parts of the input. And we need to integrate the left to right language model with that in some way. So here is the full sentence. I know it's too little to read but I'll zoom in a second on that. So we have the Chinese words and we have the gradual application of rules here. And we are putting together the target pars of the sentence. And at the end when we have digested the whole input sentence. There we already have the full construction of the target site. So let's zoom into.