 So we need to extract more rules. We need to make sure that the hierarchical or syntactic system is not any weaker in covering the input sentences than the phrase-based system. So in other words, you would like the syntactic system to also digest grammatically incorrect sentences. If our grammar was perfect, but the user still produced something which is which is not grammatically correct, then our grammar would not license it and we would not translate it. And that is something we don't want from our machine translation system. We do not want our machine translation system to require only valid inputs. We want to be robust and to handle also partly wrong inputs. So what you need to do is you need to make your grammatical constructions smaller or decomposed into smaller bits. so that they can be used more often and extract also all the smaller phrases that the phrase-based MG system would do. So here, instead of having this whole IP phrase as one element with four parts where the VP was dangling and we could not extract it, we binarize it and head out. This is exactly the heads that I was talking about on the first the first slide when talking about constituency and dependency trees. So every production that has more elements than two will be converted to a sequence of binary productions and that will give you more points where your alignments can match with these subparts. Some of these binarization steps are not well motivated from the linguistic point of view. So in the constituency syntactic tree. But they allow you to extract phrases which would otherwise be non-reachable for the system.