 First question is how do we actually encode syntactic information at each of the tokens and this is a very old idea so this is this is idea which days back to Mark Steenman's combinatory category grammars and CCGs and the the motivation was to reuse the high quality taggers knew about the whole sentence kind of. Then based on these super tags, once you find them, you could directly construct the tree. So the super tags are labels, but these labels are not really atomic. They are treated as atomic in these neural networks, but they were designed to have structure and that structure reflected how that word fits into the rest of the sentence. BODENGES. And so this is the way to put syntactic information into individual tokens. You label the tokens with something that is happening in the surrounding sentence. And by the way, this is what the morphology rich languages do by themselves. So in Czech we have many endings of words and this is a natural way. These endings are natural way to indicate the relations between words. So in Czech we have So that's the super tagging only makes this explicit and uses like formal labels, but the natural language already exhibits this property. So either you when putting the information together you rely on the sequence that the order of the bits of information or you change the individual words in some slight way you like label the words. So this is this is the word for a cat. is what city is the Taj Mahal in or where is the Taj Mahal and when you are producing this sentence the fact whether you should produce the inn or should not produce the inn that depends on something which is very far away and the idea with supertext is that you can bring this information a little closer the idea is that the verb the is will be the central element and this supertext for the for the is for the word is will differ the the CCG tag will encode that this is the is which requires the preposition versus this is the is which does not require the preposition so the CCG tags kind of encode valency frames if you have some linguistic background the valencies or subcategorization frames specify what word has to be complemented with and the CCG tag will put this in a compact label yeah so if we know this CCG tag if someone tells us that this is this word is requires the inn then we will know that we need the inn and the network can the set of these tags is obviously much smaller than the set of all the words so the network can make use of this more dense information so it can learn oh whenever there was a verb which required this inn we need to use the inn so it highlights the the syntactic information so here