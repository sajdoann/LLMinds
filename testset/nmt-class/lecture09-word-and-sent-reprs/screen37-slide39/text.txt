 So this is the new empty model and the encoder decoder architecture in the simplest possible approach. The encoder digests the whole input sentence and stores it in a fixed length vector and this fixed length vector is then used in the decoder to produce the target sentence. So we can think of or we know that there is a cut through this network that guess what the encoder and right before the decoder and . This cut has the whole representation of the sentence.