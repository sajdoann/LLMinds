 If we do it across all the test sets and all the many setups and we plot the correlation between the BLEU score and the semantic measure, we will see a negative correlation. So, one first thing to mention is that if we ignore the BLEU score, then we see a positive correlation. So, there are many metrics, some of them and some of them are the similarity base, some of them are the classification tasks. This is the Heiter paraphrases, this is the sentence paraphrases based on the Chinese source sentences. This is the COCO data set paraphrases based on the images. And if the particular point is white, then it means that the score of the system in the in the image classification is in good correlation with some of the semantic tasks like the sentiment prediction for movie reviews. And if the dot here is black, as it is always when correlating BLEU with something, then the correlation is negative. The better the system configuration performs in BLEU score, the worse it performs in the particular task. The lower triangle is for English to Czech models and the upper triangle is for the English to German models. And so this is this. Blah versus other metrics is negative correlation and pairwise average across all the points except for the BLEU, row and column is positive. So, all the semantic evaluations are in line with each other. So, the semantic representations are like self-consistent or semantic evaluations. So, if a sentence representation is good for movie sentiment, it will be also good for paraphrases in some way. And vice versa. But if a sentence representation is good for the translation quality, then it is bad in the semantic terms. One task stands out here. That's this line. And there's the track task. And there it's a classification task. And you are predicting what is the type of the question. Whether the question is asking asking for number, person or location and maybe other classes. And this type of classification can be actually resolved very easily just by looking at the first word of the sentence. Like is it where, is it what or is it who. And based on this superficial information you can do the classification. So it kind of illustrates that the sequence to sequence model is operating at the shallow level. representation stores the, not the meaning of the sentence but the words that are there. And it's natural that for a good translation you need to know which words were in the source sentence. And it's less important to know whether someone had a positive evaluation of a movie. So to translate you do not really need to process the message of the sentence. And that's what the, what the system exploits. The system tries, is trained to produce good translations not to understand the sentence. So here's.