 So today, we're going to talk about using more than two languages in the setup. And we'll first motivate for that. And then we'll talk about transfer learning, which is a setup where you want to use these more languages only in the preparation phase. And in the end, when the system is running, you are actually interested in only one language pair. The language pair that you somehow focus on. And all the other languages are just auxiliary data that you want to use. So that's transfer setup. And then, we will move to a setup which is truly multilingual, where you want the system to perform on multiple languages at the same time very well. So you need to preserve the translation quality of all the languages involved. And the last bit of the lecture will be devoted to systems which are, so to say, massively multilingual. And there, you have many languages, dozens of languages in one system present. And that obviously brings new challenges. Some of these slides are based on the slides by my PhD student who has recently successfully defended, Tom Kotzmi. And other slides are also based on colleagues from Edinburgh or Zurich, Rico Senrich and Adam Lope. with the Becker with the Becker with the Becker with the Becker with the Becker. See which is the final letter of the stars.