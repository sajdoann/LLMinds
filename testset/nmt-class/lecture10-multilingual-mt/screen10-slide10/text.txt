 There is one concept or one warning that I have to say at this point. Neural network excel at overfitting. So they are very quick learners. As soon as you change the content of your training batches, the models will adapt and they will happily forget what has been learned in the past. They learn in a different way than humans. We as humans accumulate the knowledge. But neural networks, the way they are trained these days, they will really to the most recent batches. So here is an illustration of the phenomenon. The phenomenon is called catastrophic forgetting. Again, we have the baseline of some machine translation system which is learning on the big English Czech corpus. And we thought that that was our experiment with helping the model to learn better in a way similar to humans. Maybe let's show the models in the training data, let's first show some easy sentences. And if the model learns well on the easy sentences, then it would understand better the more complex sentences. So hopefully with this curriculum style of learning, with clever organization of the training data, we would get to a better performance. So in these experiments, we have seen how horrible the catastrophic forgetting can be.