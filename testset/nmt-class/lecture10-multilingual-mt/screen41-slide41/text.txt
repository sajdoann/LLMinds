 to including additional sources. So the first setup was by Zoffa and Knight. And it directly learned to produce English from French and German sources. And the way it was done was that these recurrent neural networks were deep, by the way. So it was a deep recurrent neural network. The French one processed the sentence into a single vector that represented the whole meaning of the sentence in French. The same was done by the German decoder. And then these two decoders, the outputs of these two decoders, were put together, either by summation or averaging or whatever. And these joint representation, French-German representation of the sentence, were used as the source for the decoder. And the decoder was conditioned on both the source languages and it produced hopefully better outputs. Yeah. So the problem, the main drawback of the setup, is that you really need a multiparl corpus. Or it is better if you have it, because you have to feed the decoder with the combined information. So you need to process the source language one and source language two, and then put these vectors together.