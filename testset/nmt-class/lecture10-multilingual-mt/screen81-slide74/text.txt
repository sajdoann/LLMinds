 So this is the performance of this smaller model. Again, this is the baseline size of the transformer setup, where the multilingual system is underperforming the bilingual baselines, because the high-resource languages do not fit into the capacity of the model. But with the adapters, the loss is reduced and the performance on the low-resource languages is retained. This is when translating into English.