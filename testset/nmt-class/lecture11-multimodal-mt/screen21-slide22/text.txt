 If you are deploying it really, and that's what we are doing in a European project called ELITER, you also need to put these components together to working system. And this integration can be pretty hard and can introduce further errors, which I'm going to mention as well. So if you have independent systems, you will be acquiring the sound, you'll be shipping it to the ASR system, then the ASR system the lowercase words, you would ship it to the sentence segmenter that would do the sentence segmentation, then you would again ship it to maybe some other institute on the earth in Europe. It will translate individual these sentences into the target language and there would be no room for any uncertainty, so no ambiguity of the input can be and it will be reasonably well handled there. We would have to be sending NBEST lists, for example, and then you ship it to some place where it gets presented. And then it is presented. And what we are trying to do is not only to put this pipeline together so that we can transcribe and translate.