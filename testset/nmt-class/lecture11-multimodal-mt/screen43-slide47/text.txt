 About the segmentation, if we have a sequence of words, how do we insert punctuations? So the early models used simply language model scoring. So you were considering a window of a few words and you were checking whether the probability of this sequence of words is higher or lower, if the words are there without any punctuation symbol or if you insert a comma or if you insert a full stop or if you insert a question mark. And you were quickly comparing these probabilities and you were choosing the most probable one. Another approach would be to use sequence labeling algorithms. So you have a stream of words, a sequence of words and for every word you are adding a tag as in part of speech tagging and this tag does not indicate the part of speech but instead this tag indicates what punctuation should be used after this word. So maybe nothing, maybe a full stop, maybe a a comma, maybe a question mark and a capitalization for the next word and other things. And there are many techniques, many underlying approaches possible. You can use it in Markov models, condition random fields or some recurrent neural networks such as LSTMs to do this sequence labeling task. And you can also consider this task a machine translation task. So in a spoken language translation system you can easily have 1-2 machine translation systems running. One for the translation itself and this one as a prerequisite, as a first step, a monolingual translation. Translating from sequence of English words without punctuation to a sequence of English words with punctuation. And you can again use all the approaches that we have discussed, the phrase based empty or some neural empty. In these setups that I've discussed so far, I have not mentioned what of whether we are using the sound information at all or not. If you go for the machine translation, then probably there is, you wouldn't find an easy neural empty system that would have like, that would expect the sound there. So that could be more complicated, especially in phrase based empty, there wouldn't be any chance to include the sound. In sequence labeling, again, depends on the architecture. Sometimes it may be easier to feed in the original sound and sometimes it would be difficult. And in the language model based approach, there is no way to include the sound. But the sound is very informative. If I make a pause, it can indicate the end of the sentence. Actually, usually that it does not correlate with the end of the sentence. But if I change the intonation, that definitely makes an indication of the end of the sentence and also other aspects of the prosody play a role.