 So here is an overview picture of the more important approaches to the training. That's again from the survey that I mentioned at the beginning of my lecture. And the standard training would be to train the speech encoder and the text decoder on the speech-to-text speech corpus or SLT corpus. But this suffers from the insufficient training data. So what you can do the speech encoder trained to produce the golden transcript. So for this you would use maybe a larger speech corpus. And then you would pre-train the translation system where the input is the text in the source language and the decoder is producing the target language. And again you would pre-train this. and then you would reuse the speech encoder and the decoder from the translation phase and fine-tune it on the small SLT dataset. So this is the pre-training that utilizes the additional data. You could also use the teacher-student or knowledge distillation approach. There you train the parallel, the machine translation system that goes from text to target text. And you create additional and the teacher-student. You create additional data with the teacher approach or you force the student to produce the same probability distributions at its end as the teacher has. So this is another way of transferring knowledge. And then something which is similar to what we discussed last week is the multitask learning approach. There you have the speech encoder to digest the speech. And you are I'm using in the underlying principle Fluent connection problem and playing the loop. There you have the mode ofkm of the logic and you are powering before it one is the actually something which is about turning water to the pairs of the drops of the output. And one of the codes that goes directly to the target individual language. And one code of the codes that goes directly to the source language. And one decoder that goes to the source language. And in this multitask learning, you are training it on a triples of the input, the sound, the source transcript and the target individual setting. And then at run time this system will be capable of producing both the transcript of the source and the translation in the target language. So you can again pre-train some of these components, but it is a setting in which the system is forced when it's being trained to explicitly consider the target, the source language transcript, and that helps with the alignment because it influences how the training goes by knowing what are the word level units in the source speech.